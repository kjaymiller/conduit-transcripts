---
description: '<p>This episode on YouTube: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=fIPC_xzqJ0o">https://www.youtube.com/watch?v=fIPC_xzqJ0o</a></p><p></p><p>00:00
  Intro</p><p>00:30 Greets for Doug</p><p>01:46 Apache Solr and stuff</p><p>03:08
  Hello LTR project</p><p>04:42 Secret sauce of Doug''s continuous blogging</p><p>08:50
  SearchArray</p><p>13:22 Running complex ML experiments</p><p>17:29 Efficient search
  orgs</p><p>22:58 Writing a book on search and AI</p><p></p><p>Show notes:</p><p>-
  Doug''s talk on Learning To Rank at Reddit delivered at the Berlin Buzzwords 2024
  conference: <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=gUtF1gyHsSM">https://www.youtube.com/watch?v=gUtF1gyHsSM</a></p><p>-
  Hello LTR: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/o19s/hello-ltr">https://github.com/o19s/hello-ltr</a></p><p>-
  Lexical search for pandas with SearchArray: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://github.com/softwaredoug/searcharray">https://github.com/softwaredoug/searcharray</a></p><p>-
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://softwaredoug.com/">https://softwaredoug.com/</a></p><p>-
  What AI Engineers Should Know about Search: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search">https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search</a></p><p>-
  AI Powered Search: <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.manning.com/books/ai-powered-search">https://www.manning.com/books/ai-powered-search</a></p><p>-
  Quepid: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/o19s/quepid">https://github.com/o19s/quepid</a></p><p>-
  Branching out in your ML / search experiments: <a target="_blank" rel="noopener
  noreferrer nofollow" href="https://dvc.org/doc/use-cases">https://dvc.org/doc/use-cases</a></p><p>-
  Doug on Twitter: <a target="_blank" rel="noopener noreferrer nofollow" href="https://x.com/softwaredoug">https://x.com/softwaredoug</a></p><p>-
  Doug on LinkedIn: <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.linkedin.com/in/softwaredoug/">https://www.linkedin.com/in/softwaredoug/</a></p>'
image_url: https://media.rss.com/vector-podcast/ep_cover_20240718_110721_6a250f534a47b913cfe9ab7513e63b01.png
pub_date: Thu, 18 Jul 2024 11:10:42 GMT
title: Berlin Buzzwords 2024 - Doug Turnbull - Learning in Public
url: https://rss.com/podcasts/vector-podcast/1572886
whisper_segments: '[{"id": 0, "seek": 0, "start": 0.0, "end": 13.52, "text": " A",
  "tokens": [50364, 316, 51040], "temperature": 1.0, "avg_logprob": -4.316565619574653,
  "compression_ratio": 0.5294117647058824, "no_speech_prob": 0.48129671812057495},
  {"id": 1, "seek": 0, "start": 13.52, "end": 20.14, "text": " timeick", "tokens":
  [51040, 565, 618, 51371], "temperature": 1.0, "avg_logprob": -4.316565619574653,
  "compression_ratio": 0.5294117647058824, "no_speech_prob": 0.48129671812057495},
  {"id": 2, "seek": 2014, "start": 20.14, "end": 30.14, "text": " Cool.", "tokens":
  [50364, 8561, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3635210477388822,
  "compression_ratio": 1.4, "no_speech_prob": 0.37665465474128723}, {"id": 3, "seek":
  2014, "start": 30.14, "end": 34.14, "text": " Yeah.", "tokens": [50864, 865, 13,
  51064], "temperature": 0.0, "avg_logprob": -0.3635210477388822, "compression_ratio":
  1.4, "no_speech_prob": 0.37665465474128723}, {"id": 4, "seek": 2014, "start": 34.14,
  "end": 42.14, "text": " Hello, how are you? Hi, Doug. It''s great meeting you at
  Berlin Boswords. Yeah, I can see you. Yeah, great to see you.", "tokens": [51064,
  2425, 11, 577, 366, 291, 30, 2421, 11, 12742, 13, 467, 311, 869, 3440, 291, 412,
  13848, 22264, 86, 5703, 13, 865, 11, 286, 393, 536, 291, 13, 865, 11, 869, 281,
  536, 291, 13, 51464], "temperature": 0.0, "avg_logprob": -0.3635210477388822, "compression_ratio":
  1.4, "no_speech_prob": 0.37665465474128723}, {"id": 5, "seek": 2014, "start": 42.14,
  "end": 46.14, "text": " It''s your second time on the podcast and yeah, excited
  to be back.", "tokens": [51464, 467, 311, 428, 1150, 565, 322, 264, 7367, 293, 1338,
  11, 2919, 281, 312, 646, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3635210477388822,
  "compression_ratio": 1.4, "no_speech_prob": 0.37665465474128723}, {"id": 6, "seek":
  4614, "start": 46.14, "end": 51.14, "text": " Yeah, awesome. I think it''s like
  two years or only one. Yeah, I think so.", "tokens": [50364, 865, 11, 3476, 13,
  286, 519, 309, 311, 411, 732, 924, 420, 787, 472, 13, 865, 11, 286, 519, 370, 13,
  50614], "temperature": 0.0, "avg_logprob": -0.2507284849117964, "compression_ratio":
  1.502824858757062, "no_speech_prob": 0.08665119856595993}, {"id": 7, "seek": 4614,
  "start": 51.14, "end": 61.14, "text": " But how have you been? I wasn''t going.
  I''ve been great. Just been doing traditional learning to rank over at Reddit.",
  "tokens": [50614, 583, 577, 362, 291, 668, 30, 286, 2067, 380, 516, 13, 286, 600,
  668, 869, 13, 1449, 668, 884, 5164, 2539, 281, 6181, 670, 412, 32210, 13, 51114],
  "temperature": 0.0, "avg_logprob": -0.2507284849117964, "compression_ratio": 1.502824858757062,
  "no_speech_prob": 0.08665119856595993}, {"id": 8, "seek": 4614, "start": 61.14,
  "end": 68.14, "text": " And it''s been a lot of fun. A lot of it''s just meat and
  potato stuff. Yeah.", "tokens": [51114, 400, 309, 311, 668, 257, 688, 295, 1019,
  13, 316, 688, 295, 309, 311, 445, 4615, 293, 7445, 1507, 13, 865, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.2507284849117964, "compression_ratio": 1.502824858757062,
  "no_speech_prob": 0.08665119856595993}, {"id": 9, "seek": 6814, "start": 68.14,
  "end": 73.14, "text": " The stuff that I think is really important like your training
  data with search.", "tokens": [50364, 440, 1507, 300, 286, 519, 307, 534, 1021,
  411, 428, 3097, 1412, 365, 3164, 13, 50614], "temperature": 0.0, "avg_logprob":
  -0.16343793869018555, "compression_ratio": 1.7768595041322315, "no_speech_prob":
  0.10796502977609634}, {"id": 10, "seek": 6814, "start": 73.14, "end": 78.14, "text":
  " And you''re getting your features right and that sort of thing.", "tokens": [50614,
  400, 291, 434, 1242, 428, 4122, 558, 293, 300, 1333, 295, 551, 13, 50864], "temperature":
  0.0, "avg_logprob": -0.16343793869018555, "compression_ratio": 1.7768595041322315,
  "no_speech_prob": 0.10796502977609634}, {"id": 11, "seek": 6814, "start": 78.14,
  "end": 84.14, "text": " Not actually too much vector search lately. So kind of.",
  "tokens": [50864, 1726, 767, 886, 709, 8062, 3164, 12881, 13, 407, 733, 295, 13,
  51164], "temperature": 0.0, "avg_logprob": -0.16343793869018555, "compression_ratio":
  1.7768595041322315, "no_speech_prob": 0.10796502977609634}, {"id": 12, "seek": 6814,
  "start": 84.14, "end": 95.14, "text": " Having a path in the ranking model space
  and I still think that''s really important for if you''re building a rag app or
  if you''re building a lot of these things, a lot of people are sort of discovering
  this through the vector route.", "tokens": [51164, 389, 6152, 257, 3100, 294, 264,
  17833, 2316, 1901, 293, 286, 920, 519, 300, 311, 534, 1021, 337, 498, 291, 434,
  2390, 257, 17539, 724, 420, 498, 291, 434, 2390, 257, 688, 295, 613, 721, 11, 257,
  688, 295, 561, 366, 1333, 295, 24773, 341, 807, 264, 8062, 7955, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.16343793869018555, "compression_ratio": 1.7768595041322315,
  "no_speech_prob": 0.10796502977609634}, {"id": 13, "seek": 9514, "start": 95.14,
  "end": 100.14, "text": " They''re like realizing there''s a small other side of
  information retrieval. Yeah, that''s important.", "tokens": [50364, 814, 434, 411,
  16734, 456, 311, 257, 1359, 661, 1252, 295, 1589, 19817, 3337, 13, 865, 11, 300,
  311, 1021, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20446961205284875,
  "compression_ratio": 1.613899613899614, "no_speech_prob": 0.4473632574081421}, {"id":
  14, "seek": 9514, "start": 100.14, "end": 106.14, "text": " And that''s that''s
  really exciting to me because I think a lot of new ideas that suffer coming in the
  space. Yeah, yeah.", "tokens": [50614, 400, 300, 311, 300, 311, 534, 4670, 281,
  385, 570, 286, 519, 257, 688, 295, 777, 3487, 300, 9753, 1348, 294, 264, 1901, 13,
  865, 11, 1338, 13, 50914], "temperature": 0.0, "avg_logprob": -0.20446961205284875,
  "compression_ratio": 1.613899613899614, "no_speech_prob": 0.4473632574081421}, {"id":
  15, "seek": 9514, "start": 106.14, "end": 110.14, "text": " Yeah, amazing talk as
  well. I''m sure we''ll link it.", "tokens": [50914, 865, 11, 2243, 751, 382, 731,
  13, 286, 478, 988, 321, 603, 2113, 309, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.20446961205284875, "compression_ratio": 1.613899613899614, "no_speech_prob":
  0.4473632574081421}, {"id": 16, "seek": 9514, "start": 110.14, "end": 118.14, "text":
  " What was it''s published? The one you just gave. And you also reminded me of time
  as I told you, you know, of the time when I was working on solar.", "tokens": [51114,
  708, 390, 309, 311, 6572, 30, 440, 472, 291, 445, 2729, 13, 400, 291, 611, 15920,
  385, 295, 565, 382, 286, 1907, 291, 11, 291, 458, 11, 295, 264, 565, 562, 286, 390,
  1364, 322, 7936, 13, 51514], "temperature": 0.0, "avg_logprob": -0.20446961205284875,
  "compression_ratio": 1.613899613899614, "no_speech_prob": 0.4473632574081421}, {"id":
  17, "seek": 11814, "start": 118.14, "end": 126.14, "text": " Starting at version
  one. It was each to ask you which version you''re running, but then I was like,
  what will it matter to me?", "tokens": [50364, 16217, 412, 3037, 472, 13, 467, 390,
  1184, 281, 1029, 291, 597, 3037, 291, 434, 2614, 11, 457, 550, 286, 390, 411, 11,
  437, 486, 309, 1871, 281, 385, 30, 50764], "temperature": 0.0, "avg_logprob": -0.2614104644111965,
  "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.13754825294017792},
  {"id": 18, "seek": 11814, "start": 126.14, "end": 135.14, "text": " Well, it''s
  we were running solar seven until recently and one of the things you didn''t talk
  about in the talk was having performance problems with solar seven.", "tokens":
  [50764, 1042, 11, 309, 311, 321, 645, 2614, 7936, 3407, 1826, 3938, 293, 472, 295,
  264, 721, 291, 994, 380, 751, 466, 294, 264, 751, 390, 1419, 3389, 2740, 365, 7936,
  3407, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2614104644111965, "compression_ratio":
  1.6623931623931625, "no_speech_prob": 0.13754825294017792}, {"id": 19, "seek": 11814,
  "start": 135.14, "end": 142.14, "text": " Yeah. And moving to solar nine fixed it.
  So it helped with a lot of stability and performance problems.", "tokens": [51214,
  865, 13, 400, 2684, 281, 7936, 4949, 6806, 309, 13, 407, 309, 4254, 365, 257, 688,
  295, 11826, 293, 3389, 2740, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2614104644111965,
  "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.13754825294017792},
  {"id": 20, "seek": 14214, "start": 142.14, "end": 151.14, "text": " And that''s
  just one of those things that a lot of these projects machine like not just like
  learning to rank is like a lot of machine learning projects.", "tokens": [50364,
  400, 300, 311, 445, 472, 295, 729, 721, 300, 257, 688, 295, 613, 4455, 3479, 411,
  406, 445, 411, 2539, 281, 6181, 307, 411, 257, 688, 295, 3479, 2539, 4455, 13, 50814],
  "temperature": 0.0, "avg_logprob": -0.20529462640935725, "compression_ratio": 1.8372093023255813,
  "no_speech_prob": 0.01549532637000084}, {"id": 21, "seek": 14214, "start": 151.14,
  "end": 160.14, "text": " You what I find is especially learning to rank you''re
  often like building out and scaling up infrastructure for a certain problem at the
  same time you''re doing machine learning.", "tokens": [50814, 509, 437, 286, 915,
  307, 2318, 2539, 281, 6181, 291, 434, 2049, 411, 2390, 484, 293, 21589, 493, 6896,
  337, 257, 1629, 1154, 412, 264, 912, 565, 291, 434, 884, 3479, 2539, 13, 51264],
  "temperature": 0.0, "avg_logprob": -0.20529462640935725, "compression_ratio": 1.8372093023255813,
  "no_speech_prob": 0.01549532637000084}, {"id": 22, "seek": 14214, "start": 160.14,
  "end": 161.14, "text": " Yeah.", "tokens": [51264, 865, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.20529462640935725, "compression_ratio": 1.8372093023255813,
  "no_speech_prob": 0.01549532637000084}, {"id": 23, "seek": 14214, "start": 161.14,
  "end": 170.14, "text": " So it''s it''s you''re finding these problems. Yeah, and
  you will spend weeks. Yeah, or month like why is this slow? It''s unexpectedly slow.",
  "tokens": [51314, 407, 309, 311, 309, 311, 291, 434, 5006, 613, 2740, 13, 865, 11,
  293, 291, 486, 3496, 3259, 13, 865, 11, 420, 1618, 411, 983, 307, 341, 2964, 30,
  467, 311, 40452, 2964, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20529462640935725,
  "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.01549532637000084},
  {"id": 24, "seek": 17014, "start": 170.14, "end": 176.14, "text": " What''s behind
  it is and then you realize, oh, solar nine doesn''t have this problem and will resolve
  it. Yeah.", "tokens": [50364, 708, 311, 2261, 309, 307, 293, 550, 291, 4325, 11,
  1954, 11, 7936, 4949, 1177, 380, 362, 341, 1154, 293, 486, 14151, 309, 13, 865,
  13, 50664], "temperature": 0.0, "avg_logprob": -0.28207980178472564, "compression_ratio":
  1.6654545454545455, "no_speech_prob": 0.08824250847101212}, {"id": 25, "seek": 17014,
  "start": 176.14, "end": 181.14, "text": " And we were already upgrading. So like,
  okay, we can put this. We don''t have to stress out about this performance problem.",
  "tokens": [50664, 400, 321, 645, 1217, 36249, 13, 407, 411, 11, 1392, 11, 321, 393,
  829, 341, 13, 492, 500, 380, 362, 281, 4244, 484, 466, 341, 3389, 1154, 13, 50914],
  "temperature": 0.0, "avg_logprob": -0.28207980178472564, "compression_ratio": 1.6654545454545455,
  "no_speech_prob": 0.08824250847101212}, {"id": 26, "seek": 17014, "start": 181.14,
  "end": 184.14, "text": " That''s why it takes a year to year.", "tokens": [50914,
  663, 311, 983, 309, 2516, 257, 1064, 281, 1064, 13, 51064], "temperature": 0.0,
  "avg_logprob": -0.28207980178472564, "compression_ratio": 1.6654545454545455, "no_speech_prob":
  0.08824250847101212}, {"id": 27, "seek": 17014, "start": 184.14, "end": 187.14,
  "text": " For these projects. Yeah, yeah, start to show.", "tokens": [51064, 1171,
  613, 4455, 13, 865, 11, 1338, 11, 722, 281, 855, 13, 51214], "temperature": 0.0,
  "avg_logprob": -0.28207980178472564, "compression_ratio": 1.6654545454545455, "no_speech_prob":
  0.08824250847101212}, {"id": 28, "seek": 17014, "start": 187.14, "end": 188.14,
  "text": " Yeah.", "tokens": [51214, 865, 13, 51264], "temperature": 0.0, "avg_logprob":
  -0.28207980178472564, "compression_ratio": 1.6654545454545455, "no_speech_prob":
  0.08824250847101212}, {"id": 29, "seek": 17014, "start": 188.14, "end": 195.14,
  "text": " I also would like to say thank you for your project that I think you started
  back at OEC Open Source Connections.", "tokens": [51264, 286, 611, 576, 411, 281,
  584, 1309, 291, 337, 428, 1716, 300, 286, 519, 291, 1409, 646, 412, 422, 8140, 7238,
  29629, 11653, 626, 13, 51614], "temperature": 0.0, "avg_logprob": -0.28207980178472564,
  "compression_ratio": 1.6654545454545455, "no_speech_prob": 0.08824250847101212},
  {"id": 30, "seek": 17014, "start": 195.14, "end": 197.14, "text": " Yeah. Hello
  LTR. Yeah.", "tokens": [51614, 865, 13, 2425, 441, 25936, 13, 865, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.28207980178472564, "compression_ratio": 1.6654545454545455,
  "no_speech_prob": 0.08824250847101212}, {"id": 31, "seek": 19714, "start": 197.14,
  "end": 207.14, "text": " I think it''s still out there and it''s out. That''s a
  great project. Yeah, it really allowed me to quickly, you know, jump on the on the
  train and start moving because I was actually alone on the team.", "tokens": [50364,
  286, 519, 309, 311, 920, 484, 456, 293, 309, 311, 484, 13, 663, 311, 257, 869, 1716,
  13, 865, 11, 309, 534, 4350, 385, 281, 2661, 11, 291, 458, 11, 3012, 322, 264, 322,
  264, 3847, 293, 722, 2684, 570, 286, 390, 767, 3312, 322, 264, 1469, 13, 50864],
  "temperature": 0.0, "avg_logprob": -0.20264286465115017, "compression_ratio": 1.5850622406639003,
  "no_speech_prob": 0.22208599746227264}, {"id": 32, "seek": 19714, "start": 207.14,
  "end": 216.14, "text": " I did do search before, but it wasn''t related to a mile
  at all, right? It was like feature engineering button at different side of things
  and.", "tokens": [50864, 286, 630, 360, 3164, 949, 11, 457, 309, 2067, 380, 4077,
  281, 257, 12620, 412, 439, 11, 558, 30, 467, 390, 411, 4111, 7043, 2960, 412, 819,
  1252, 295, 721, 293, 13, 51314], "temperature": 0.0, "avg_logprob": -0.20264286465115017,
  "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.22208599746227264},
  {"id": 33, "seek": 19714, "start": 216.14, "end": 218.14, "text": " Yeah, so thanks
  for that. Really? Yeah.", "tokens": [51314, 865, 11, 370, 3231, 337, 300, 13, 4083,
  30, 865, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20264286465115017, "compression_ratio":
  1.5850622406639003, "no_speech_prob": 0.22208599746227264}, {"id": 34, "seek": 21814,
  "start": 218.14, "end": 226.14, "text": " I think I think it''s really important
  and one thing I think it''s the career advice that''s helped me is to learn in public.",
  "tokens": [50364, 286, 519, 286, 519, 309, 311, 534, 1021, 293, 472, 551, 286, 519,
  309, 311, 264, 3988, 5192, 300, 311, 4254, 385, 307, 281, 1466, 294, 1908, 13, 50764],
  "temperature": 0.0, "avg_logprob": -0.11759167823238649, "compression_ratio": 1.4795321637426901,
  "no_speech_prob": 0.507870078086853}, {"id": 35, "seek": 21814, "start": 226.14,
  "end": 232.14, "text": " So a lot of hello LTR came up when I was learning how to
  do LTR.", "tokens": [50764, 407, 257, 688, 295, 7751, 441, 25936, 1361, 493, 562,
  286, 390, 2539, 577, 281, 360, 441, 25936, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.11759167823238649, "compression_ratio": 1.4795321637426901, "no_speech_prob":
  0.507870078086853}, {"id": 36, "seek": 21814, "start": 232.14, "end": 237.14, "text":
  " And I had to get some examples and like try different things out.", "tokens":
  [51064, 400, 286, 632, 281, 483, 512, 5110, 293, 411, 853, 819, 721, 484, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.11759167823238649, "compression_ratio": 1.4795321637426901,
  "no_speech_prob": 0.507870078086853}, {"id": 37, "seek": 23714, "start": 237.14,
  "end": 249.14, "text": " And then as I made mistakes, those mistakes became lessons
  for the LTR training that came out of hello LTR, also called hello LTR that open
  source connection it does.", "tokens": [50364, 400, 550, 382, 286, 1027, 8038, 11,
  729, 8038, 3062, 8820, 337, 264, 441, 25936, 3097, 300, 1361, 484, 295, 7751, 441,
  25936, 11, 611, 1219, 7751, 441, 25936, 300, 1269, 4009, 4984, 309, 775, 13, 50964],
  "temperature": 0.0, "avg_logprob": -0.1723451858911759, "compression_ratio": 1.6308411214953271,
  "no_speech_prob": 0.21308627724647522}, {"id": 38, "seek": 23714, "start": 249.14,
  "end": 255.14, "text": " So it''s I really encourage people like the best way the
  best teachers are often people actively learning.", "tokens": [50964, 407, 309,
  311, 286, 534, 5373, 561, 411, 264, 1151, 636, 264, 1151, 6023, 366, 2049, 561,
  13022, 2539, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1723451858911759,
  "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.21308627724647522},
  {"id": 39, "seek": 23714, "start": 255.14, "end": 259.14, "text": " Yeah, because
  you will encounter the mistakes that the experts forgot about.", "tokens": [51264,
  865, 11, 570, 291, 486, 8593, 264, 8038, 300, 264, 8572, 5298, 466, 13, 51464],
  "temperature": 0.0, "avg_logprob": -0.1723451858911759, "compression_ratio": 1.6308411214953271,
  "no_speech_prob": 0.21308627724647522}, {"id": 40, "seek": 25914, "start": 259.14,
  "end": 264.14, "text": " I couldn''t tell you about how to learn how a loop worked
  from Python because I''ve done too long.", "tokens": [50364, 286, 2809, 380, 980,
  291, 466, 577, 281, 1466, 577, 257, 6367, 2732, 490, 15329, 570, 286, 600, 1096,
  886, 938, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2932789049650493, "compression_ratio":
  1.6557377049180328, "no_speech_prob": 0.276696115732193}, {"id": 41, "seek": 25914,
  "start": 264.14, "end": 274.14, "text": " But the person who would teach, have the
  empathy to teach that really well to someone learning that''s scratch would be probably
  my son if he was learning Python for so.", "tokens": [50614, 583, 264, 954, 567,
  576, 2924, 11, 362, 264, 18701, 281, 2924, 300, 534, 731, 281, 1580, 2539, 300,
  311, 8459, 576, 312, 1391, 452, 1872, 498, 415, 390, 2539, 15329, 337, 370, 13,
  51114], "temperature": 0.0, "avg_logprob": -0.2932789049650493, "compression_ratio":
  1.6557377049180328, "no_speech_prob": 0.276696115732193}, {"id": 42, "seek": 25914,
  "start": 274.14, "end": 283.14, "text": " So I really encourage like be out there
  speaking, blogging, yeah, because you''ll have insight to how to teach a product
  that expert won''t.", "tokens": [51114, 407, 286, 534, 5373, 411, 312, 484, 456,
  4124, 11, 6968, 3249, 11, 1338, 11, 570, 291, 603, 362, 11269, 281, 577, 281, 2924,
  257, 1674, 300, 5844, 1582, 380, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.2932789049650493, "compression_ratio": 1.6557377049180328, "no_speech_prob":
  0.276696115732193}, {"id": 43, "seek": 28314, "start": 283.14, "end": 291.14, "text":
  " Yeah, that''s that''s another side of your professional life that amazes me is
  that how do you find time to block so it''s like.", "tokens": [50364, 865, 11, 300,
  311, 300, 311, 1071, 1252, 295, 428, 4843, 993, 300, 669, 921, 279, 385, 307, 300,
  577, 360, 291, 915, 565, 281, 3461, 370, 309, 311, 411, 13, 50764], "temperature":
  0.0, "avg_logprob": -0.19301744154941888, "compression_ratio": 1.5660377358490567,
  "no_speech_prob": 0.16326384246349335}, {"id": 44, "seek": 28314, "start": 291.14,
  "end": 301.14, "text": " And that those are really deep things sometimes you go
  into detail with its code or you offer some thought model like do you sleep at all.",
  "tokens": [50764, 400, 300, 729, 366, 534, 2452, 721, 2171, 291, 352, 666, 2607,
  365, 1080, 3089, 420, 291, 2626, 512, 1194, 2316, 411, 360, 291, 2817, 412, 439,
  13, 51264], "temperature": 0.0, "avg_logprob": -0.19301744154941888, "compression_ratio":
  1.5660377358490567, "no_speech_prob": 0.16326384246349335}, {"id": 45, "seek": 28314,
  "start": 301.14, "end": 306.14, "text": " I think I just have a high tolerance for
  making mistakes in public.", "tokens": [51264, 286, 519, 286, 445, 362, 257, 1090,
  23368, 337, 1455, 8038, 294, 1908, 13, 51514], "temperature": 0.0, "avg_logprob":
  -0.19301744154941888, "compression_ratio": 1.5660377358490567, "no_speech_prob":
  0.16326384246349335}, {"id": 46, "seek": 30614, "start": 306.14, "end": 311.14,
  "text": " And also I think a lot of it has to do with having a history degree.",
  "tokens": [50364, 400, 611, 286, 519, 257, 688, 295, 309, 575, 281, 360, 365, 1419,
  257, 2503, 4314, 13, 50614], "temperature": 0.0, "avg_logprob": -0.24321552387719014,
  "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.12327217310667038},
  {"id": 47, "seek": 30614, "start": 311.14, "end": 316.14, "text": " Oh really, I
  didn''t know that. Yeah, history and computer science. So when you get when you
  do history.", "tokens": [50614, 876, 534, 11, 286, 994, 380, 458, 300, 13, 865,
  11, 2503, 293, 3820, 3497, 13, 407, 562, 291, 483, 562, 291, 360, 2503, 13, 50864],
  "temperature": 0.0, "avg_logprob": -0.24321552387719014, "compression_ratio": 1.8227272727272728,
  "no_speech_prob": 0.12327217310667038}, {"id": 48, "seek": 30614, "start": 316.14,
  "end": 325.14, "text": " It''s a lot of writing writing writing, writing, reporting
  writing and then a lot of it''s also when you get to this your senior level history.",
  "tokens": [50864, 467, 311, 257, 688, 295, 3579, 3579, 3579, 11, 3579, 11, 10031,
  3579, 293, 550, 257, 688, 295, 309, 311, 611, 562, 291, 483, 281, 341, 428, 7965,
  1496, 2503, 13, 51314], "temperature": 0.0, "avg_logprob": -0.24321552387719014,
  "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.12327217310667038},
  {"id": 49, "seek": 30614, "start": 325.14, "end": 331.14, "text": " It''s like not
  just writing an essay, but can you write your argument in a single page.", "tokens":
  [51314, 467, 311, 411, 406, 445, 3579, 364, 16238, 11, 457, 393, 291, 2464, 428,
  6770, 294, 257, 2167, 3028, 13, 51614], "temperature": 0.0, "avg_logprob": -0.24321552387719014,
  "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.12327217310667038},
  {"id": 50, "seek": 33114, "start": 331.14, "end": 341.14, "text": " And so that''s
  which is funny because you think when you''re a student, you think I''m going to
  make the margins big and I''m going to make the text big so I can take up more space.",
  "tokens": [50364, 400, 370, 300, 311, 597, 307, 4074, 570, 291, 519, 562, 291, 434,
  257, 3107, 11, 291, 519, 286, 478, 516, 281, 652, 264, 30317, 955, 293, 286, 478,
  516, 281, 652, 264, 2487, 955, 370, 286, 393, 747, 493, 544, 1901, 13, 50864], "temperature":
  0.0, "avg_logprob": -0.20271820068359375, "compression_ratio": 1.7439613526570048,
  "no_speech_prob": 0.10355423390865326}, {"id": 51, "seek": 33114, "start": 341.14,
  "end": 346.14, "text": " Yeah, when you start writing a lot, you tend to write you
  tend to get really verbose.", "tokens": [50864, 865, 11, 562, 291, 722, 3579, 257,
  688, 11, 291, 3928, 281, 2464, 291, 3928, 281, 483, 534, 9595, 541, 13, 51114],
  "temperature": 0.0, "avg_logprob": -0.20271820068359375, "compression_ratio": 1.7439613526570048,
  "no_speech_prob": 0.10355423390865326}, {"id": 52, "seek": 33114, "start": 346.14,
  "end": 349.14, "text": " Yeah, then you have to learn to make your arguments like
  exactly.", "tokens": [51114, 865, 11, 550, 291, 362, 281, 1466, 281, 652, 428, 12869,
  411, 2293, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20271820068359375,
  "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.10355423390865326},
  {"id": 53, "seek": 33114, "start": 349.14, "end": 351.14, "text": " Yes, and shorter.",
  "tokens": [51264, 1079, 11, 293, 11639, 13, 51364], "temperature": 0.0, "avg_logprob":
  -0.20271820068359375, "compression_ratio": 1.7439613526570048, "no_speech_prob":
  0.10355423390865326}, {"id": 54, "seek": 33114, "start": 351.14, "end": 352.14,
  "text": " And yeah, so.", "tokens": [51364, 400, 1338, 11, 370, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.20271820068359375, "compression_ratio": 1.7439613526570048,
  "no_speech_prob": 0.10355423390865326}, {"id": 55, "seek": 35214, "start": 352.14,
  "end": 361.14, "text": " Yeah, it also now when I''m doing the product management
  role, I have I do not have a history degree like you, but I have to write some things
  in a concise way.", "tokens": [50364, 865, 11, 309, 611, 586, 562, 286, 478, 884,
  264, 1674, 4592, 3090, 11, 286, 362, 286, 360, 406, 362, 257, 2503, 4314, 411, 291,
  11, 457, 286, 362, 281, 2464, 512, 721, 294, 257, 44882, 636, 13, 50814], "temperature":
  0.0, "avg_logprob": -0.20056160916103405, "compression_ratio": 1.5825688073394495,
  "no_speech_prob": 0.40724697709083557}, {"id": 56, "seek": 35214, "start": 361.14,
  "end": 366.14, "text": " Sometimes they say you have to remove half of the page
  because you''re not feeding the page limit.", "tokens": [50814, 4803, 436, 584,
  291, 362, 281, 4159, 1922, 295, 264, 3028, 570, 291, 434, 406, 12919, 264, 3028,
  4948, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20056160916103405, "compression_ratio":
  1.5825688073394495, "no_speech_prob": 0.40724697709083557}, {"id": 57, "seek": 35214,
  "start": 366.14, "end": 368.14, "text": " I make that mistake all the time.", "tokens":
  [51064, 286, 652, 300, 6146, 439, 264, 565, 13, 51164], "temperature": 0.0, "avg_logprob":
  -0.20056160916103405, "compression_ratio": 1.5825688073394495, "no_speech_prob":
  0.40724697709083557}, {"id": 58, "seek": 35214, "start": 368.14, "end": 371.14,
  "text": " Yeah, how many one pageers are exactly like 10 pages.", "tokens": [51164,
  865, 11, 577, 867, 472, 3028, 433, 366, 2293, 411, 1266, 7183, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.20056160916103405, "compression_ratio": 1.5825688073394495,
  "no_speech_prob": 0.40724697709083557}, {"id": 59, "seek": 37114, "start": 371.14,
  "end": 378.14, "text": " And another thing is like never talk about hypothetical
  future because you don''t even know yourself what it will happen or not, right.",
  "tokens": [50364, 400, 1071, 551, 307, 411, 1128, 751, 466, 33053, 2027, 570, 291,
  500, 380, 754, 458, 1803, 437, 309, 486, 1051, 420, 406, 11, 558, 13, 50714], "temperature":
  0.0, "avg_logprob": -0.26978559153420584, "compression_ratio": 1.7657992565055762,
  "no_speech_prob": 0.7693508267402649}, {"id": 60, "seek": 37114, "start": 378.14,
  "end": 384.14, "text": " Yeah, only talk either talk about things that you''re absolutely
  certain have happened or you certain that they have planned already, right.", "tokens":
  [50714, 865, 11, 787, 751, 2139, 751, 466, 721, 300, 291, 434, 3122, 1629, 362,
  2011, 420, 291, 1629, 300, 436, 362, 8589, 1217, 11, 558, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.26978559153420584, "compression_ratio": 1.7657992565055762,
  "no_speech_prob": 0.7693508267402649}, {"id": 61, "seek": 37114, "start": 384.14,
  "end": 386.14, "text": " Yeah, that''s how we do the product management.", "tokens":
  [51014, 865, 11, 300, 311, 577, 321, 360, 264, 1674, 4592, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.26978559153420584, "compression_ratio": 1.7657992565055762,
  "no_speech_prob": 0.7693508267402649}, {"id": 62, "seek": 37114, "start": 386.14,
  "end": 394.14, "text": " Yeah, it teaches that that''s the side of things, but I
  guess what I do is out and I then go to blogging and and and and use you as a great
  example there.", "tokens": [51114, 865, 11, 309, 16876, 300, 300, 311, 264, 1252,
  295, 721, 11, 457, 286, 2041, 437, 286, 360, 307, 484, 293, 286, 550, 352, 281,
  6968, 3249, 293, 293, 293, 293, 764, 291, 382, 257, 869, 1365, 456, 13, 51514],
  "temperature": 0.0, "avg_logprob": -0.26978559153420584, "compression_ratio": 1.7657992565055762,
  "no_speech_prob": 0.7693508267402649}, {"id": 63, "seek": 39414, "start": 394.14,
  "end": 398.14, "text": " You go and unleash yourself and blogging and you write
  what you want, right.", "tokens": [50364, 509, 352, 293, 49814, 1803, 293, 6968,
  3249, 293, 291, 2464, 437, 291, 528, 11, 558, 13, 50564], "temperature": 0.0, "avg_logprob":
  -0.2016909339211204, "compression_ratio": 1.6939890710382515, "no_speech_prob":
  0.7486097812652588}, {"id": 64, "seek": 39414, "start": 398.14, "end": 413.14, "text":
  " But you still need to what you want said that you became more successful blogger
  at the moment you actually started modeling that specific person you''re writing
  to not an abstract audience and not yourself because you''re not writing.", "tokens":
  [50564, 583, 291, 920, 643, 281, 437, 291, 528, 848, 300, 291, 3062, 544, 4406,
  6968, 1321, 412, 264, 1623, 291, 767, 1409, 15983, 300, 2685, 954, 291, 434, 3579,
  281, 406, 364, 12649, 4034, 293, 406, 1803, 570, 291, 434, 406, 3579, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.2016909339211204, "compression_ratio": 1.6939890710382515,
  "no_speech_prob": 0.7486097812652588}, {"id": 65, "seek": 41314, "start": 413.14,
  "end": 416.14, "text": " And so is this how you still perceive it.", "tokens": [50364,
  400, 370, 307, 341, 577, 291, 920, 20281, 309, 13, 50514], "temperature": 0.0, "avg_logprob":
  -0.16255636889525135, "compression_ratio": 1.5609756097560976, "no_speech_prob":
  0.7266706228256226}, {"id": 66, "seek": 41314, "start": 416.14, "end": 426.14, "text":
  " Well, I definitely write to myself six months from now, but I also write the audience
  I imagine is like a close group of friends.", "tokens": [50514, 1042, 11, 286, 2138,
  2464, 281, 2059, 2309, 2493, 490, 586, 11, 457, 286, 611, 2464, 264, 4034, 286,
  3811, 307, 411, 257, 1998, 1594, 295, 1855, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.16255636889525135, "compression_ratio": 1.5609756097560976, "no_speech_prob":
  0.7266706228256226}, {"id": 67, "seek": 41314, "start": 426.14, "end": 429.14, "text":
  " So I almost think about blogging as sometimes and this is easy.", "tokens": [51014,
  407, 286, 1920, 519, 466, 6968, 3249, 382, 2171, 293, 341, 307, 1858, 13, 51164],
  "temperature": 0.0, "avg_logprob": -0.16255636889525135, "compression_ratio": 1.5609756097560976,
  "no_speech_prob": 0.7266706228256226}, {"id": 68, "seek": 41314, "start": 429.14,
  "end": 434.14, "text": " It''s easy for people often to imagine sitting down and
  writing a long email or Slack message.", "tokens": [51164, 467, 311, 1858, 337,
  561, 2049, 281, 3811, 3798, 760, 293, 3579, 257, 938, 3796, 420, 37211, 3636, 13,
  51414], "temperature": 0.0, "avg_logprob": -0.16255636889525135, "compression_ratio":
  1.5609756097560976, "no_speech_prob": 0.7266706228256226}, {"id": 69, "seek": 41314,
  "start": 434.14, "end": 437.14, "text": " And what if you just turn that into a
  blog post.", "tokens": [51414, 400, 437, 498, 291, 445, 1261, 300, 666, 257, 6968,
  2183, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16255636889525135, "compression_ratio":
  1.5609756097560976, "no_speech_prob": 0.7266706228256226}, {"id": 70, "seek": 41314,
  "start": 437.14, "end": 438.14, "text": " Yeah.", "tokens": [51564, 865, 13, 51614],
  "temperature": 0.0, "avg_logprob": -0.16255636889525135, "compression_ratio": 1.5609756097560976,
  "no_speech_prob": 0.7266706228256226}, {"id": 71, "seek": 43814, "start": 438.14,
  "end": 446.14, "text": " And to me, that''s that''s an inspiration for this so many
  times you get excited about something and want to send a message to your friends.",
  "tokens": [50364, 400, 281, 385, 11, 300, 311, 300, 311, 364, 10249, 337, 341, 370,
  867, 1413, 291, 483, 2919, 466, 746, 293, 528, 281, 2845, 257, 3636, 281, 428, 1855,
  13, 50764], "temperature": 0.0, "avg_logprob": -0.21016060678582443, "compression_ratio":
  1.678294573643411, "no_speech_prob": 0.01751577854156494}, {"id": 72, "seek": 43814,
  "start": 446.14, "end": 448.14, "text": " Yeah, and share it.", "tokens": [50764,
  865, 11, 293, 2073, 309, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21016060678582443,
  "compression_ratio": 1.678294573643411, "no_speech_prob": 0.01751577854156494},
  {"id": 73, "seek": 43814, "start": 448.14, "end": 453.14, "text": " Well, turn that
  enthusiasm and that message into a blog post and then that those are the best blog
  posts.", "tokens": [50864, 1042, 11, 1261, 300, 23417, 293, 300, 3636, 666, 257,
  6968, 2183, 293, 550, 300, 729, 366, 264, 1151, 6968, 12300, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.21016060678582443, "compression_ratio": 1.678294573643411,
  "no_speech_prob": 0.01751577854156494}, {"id": 74, "seek": 43814, "start": 453.14,
  "end": 457.14, "text": " And I also think it''s really important to remember it''s
  blogging.", "tokens": [51114, 400, 286, 611, 519, 309, 311, 534, 1021, 281, 1604,
  309, 311, 6968, 3249, 13, 51314], "temperature": 0.0, "avg_logprob": -0.21016060678582443,
  "compression_ratio": 1.678294573643411, "no_speech_prob": 0.01751577854156494},
  {"id": 75, "seek": 43814, "start": 457.14, "end": 461.14, "text": " It''s like it''s
  a step above writing us a from a post.", "tokens": [51314, 467, 311, 411, 309, 311,
  257, 1823, 3673, 3579, 505, 257, 490, 257, 2183, 13, 51514], "temperature": 0.0,
  "avg_logprob": -0.21016060678582443, "compression_ratio": 1.678294573643411, "no_speech_prob":
  0.01751577854156494}, {"id": 76, "seek": 43814, "start": 461.14, "end": 464.14,
  "text": " It''s very informal. Don''t take it too seriously.", "tokens": [51514,
  467, 311, 588, 24342, 13, 1468, 380, 747, 309, 886, 6638, 13, 51664], "temperature":
  0.0, "avg_logprob": -0.21016060678582443, "compression_ratio": 1.678294573643411,
  "no_speech_prob": 0.01751577854156494}, {"id": 77, "seek": 46414, "start": 464.14,
  "end": 466.14, "text": " You will make mistakes exactly.", "tokens": [50364, 509,
  486, 652, 8038, 2293, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20486576757698416,
  "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.46770596504211426},
  {"id": 78, "seek": 46414, "start": 466.14, "end": 470.14, "text": " You will it''s
  and it''s a do it for fun.", "tokens": [50464, 509, 486, 309, 311, 293, 309, 311,
  257, 360, 309, 337, 1019, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20486576757698416,
  "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.46770596504211426},
  {"id": 79, "seek": 46414, "start": 470.14, "end": 471.14, "text": " Yeah.", "tokens":
  [50664, 865, 13, 50714], "temperature": 0.0, "avg_logprob": -0.20486576757698416,
  "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.46770596504211426},
  {"id": 80, "seek": 46414, "start": 471.14, "end": 474.14, "text": " But yeah, I
  do it a lot because I want.", "tokens": [50714, 583, 1338, 11, 286, 360, 309, 257,
  688, 570, 286, 528, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20486576757698416,
  "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.46770596504211426},
  {"id": 81, "seek": 46414, "start": 474.14, "end": 479.14, "text": " I think I I
  there''s a meme of like someone starting out on something.", "tokens": [50864, 286,
  519, 286, 286, 456, 311, 257, 21701, 295, 411, 1580, 2891, 484, 322, 746, 13, 51114],
  "temperature": 0.0, "avg_logprob": -0.20486576757698416, "compression_ratio": 1.8798076923076923,
  "no_speech_prob": 0.46770596504211426}, {"id": 82, "seek": 46414, "start": 479.14,
  "end": 484.14, "text": " Yeah, someone being very senior and then or someone being
  like mid career and then someone.", "tokens": [51114, 865, 11, 1580, 885, 588, 7965,
  293, 550, 420, 1580, 885, 411, 2062, 3988, 293, 550, 1580, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.20486576757698416, "compression_ratio": 1.8798076923076923,
  "no_speech_prob": 0.46770596504211426}, {"id": 83, "seek": 46414, "start": 484.14,
  "end": 486.14, "text": " Super senior in their career.", "tokens": [51364, 4548,
  7965, 294, 641, 3988, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20486576757698416,
  "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.46770596504211426},
  {"id": 84, "seek": 46414, "start": 486.14, "end": 490.14, "text": " And often the
  like starting out this meme starting out super senior are the same.", "tokens":
  [51464, 400, 2049, 264, 411, 2891, 484, 341, 21701, 2891, 484, 1687, 7965, 366,
  264, 912, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20486576757698416, "compression_ratio":
  1.8798076923076923, "no_speech_prob": 0.46770596504211426}, {"id": 85, "seek": 49014,
  "start": 490.14, "end": 498.14, "text": " And it''s like my version of that is doing
  when you start out you code and do stuff to impress your friends like in high school
  or whatever.", "tokens": [50364, 400, 309, 311, 411, 452, 3037, 295, 300, 307, 884,
  562, 291, 722, 484, 291, 3089, 293, 360, 1507, 281, 6729, 428, 1855, 411, 294, 1090,
  1395, 420, 2035, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11580961476201597,
  "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.10690049082040787},
  {"id": 86, "seek": 49014, "start": 498.14, "end": 502.14, "text": " And then you
  get like all worried about like having some big impact and like.", "tokens": [50764,
  400, 550, 291, 483, 411, 439, 5804, 466, 411, 1419, 512, 955, 2712, 293, 411, 13,
  50964], "temperature": 0.0, "avg_logprob": -0.11580961476201597, "compression_ratio":
  1.8532818532818534, "no_speech_prob": 0.10690049082040787}, {"id": 87, "seek": 49014,
  "start": 502.14, "end": 504.14, "text": " Impressing the whole world.", "tokens":
  [50964, 8270, 18605, 264, 1379, 1002, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.11580961476201597, "compression_ratio": 1.8532818532818534, "no_speech_prob":
  0.10690049082040787}, {"id": 88, "seek": 49014, "start": 504.14, "end": 509.14,
  "text": " And then when you get super senior again, you''re just like I just want
  to like do full stuff to impress my friends.", "tokens": [51064, 400, 550, 562,
  291, 483, 1687, 7965, 797, 11, 291, 434, 445, 411, 286, 445, 528, 281, 411, 360,
  1577, 1507, 281, 6729, 452, 1855, 13, 51314], "temperature": 0.0, "avg_logprob":
  -0.11580961476201597, "compression_ratio": 1.8532818532818534, "no_speech_prob":
  0.10690049082040787}, {"id": 89, "seek": 49014, "start": 509.14, "end": 510.14,
  "text": " Yeah.", "tokens": [51314, 865, 13, 51364], "temperature": 0.0, "avg_logprob":
  -0.11580961476201597, "compression_ratio": 1.8532818532818534, "no_speech_prob":
  0.10690049082040787}, {"id": 90, "seek": 49014, "start": 510.14, "end": 515.14,
  "text": " And which actually turns out also to be stuff that the whole world cares
  about because usually your friends are.", "tokens": [51364, 400, 597, 767, 4523,
  484, 611, 281, 312, 1507, 300, 264, 1379, 1002, 12310, 466, 570, 2673, 428, 1855,
  366, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11580961476201597, "compression_ratio":
  1.8532818532818534, "no_speech_prob": 0.10690049082040787}, {"id": 91, "seek": 51514,
  "start": 515.14, "end": 521.14, "text": " Like doing cool stuff themselves like
  you know vector searcher or doing cool AI stuff.", "tokens": [50364, 1743, 884,
  1627, 1507, 2969, 411, 291, 458, 8062, 3164, 260, 420, 884, 1627, 7318, 1507, 13,
  50664], "temperature": 0.0, "avg_logprob": -0.20795553922653198, "compression_ratio":
  1.7829457364341086, "no_speech_prob": 0.14798229932785034}, {"id": 92, "seek": 51514,
  "start": 521.14, "end": 522.14, "text": " Yeah.", "tokens": [50664, 865, 13, 50714],
  "temperature": 0.0, "avg_logprob": -0.20795553922653198, "compression_ratio": 1.7829457364341086,
  "no_speech_prob": 0.14798229932785034}, {"id": 93, "seek": 51514, "start": 522.14,
  "end": 525.14, "text": " So it turns out that the rest of the world finds that it''s
  interesting to.", "tokens": [50714, 407, 309, 4523, 484, 300, 264, 1472, 295, 264,
  1002, 10704, 300, 309, 311, 1880, 281, 13, 50864], "temperature": 0.0, "avg_logprob":
  -0.20795553922653198, "compression_ratio": 1.7829457364341086, "no_speech_prob":
  0.14798229932785034}, {"id": 94, "seek": 51514, "start": 525.14, "end": 528.14,
  "text": " But I think that''s a really important thing to have an authentic voice.",
  "tokens": [50864, 583, 286, 519, 300, 311, 257, 534, 1021, 551, 281, 362, 364, 12466,
  3177, 13, 51014], "temperature": 0.0, "avg_logprob": -0.20795553922653198, "compression_ratio":
  1.7829457364341086, "no_speech_prob": 0.14798229932785034}, {"id": 95, "seek": 51514,
  "start": 528.14, "end": 529.14, "text": " Yeah.", "tokens": [51014, 865, 13, 51064],
  "temperature": 0.0, "avg_logprob": -0.20795553922653198, "compression_ratio": 1.7829457364341086,
  "no_speech_prob": 0.14798229932785034}, {"id": 96, "seek": 51514, "start": 529.14,
  "end": 532.14, "text": " So it''s also part of the building up your profile.", "tokens":
  [51064, 407, 309, 311, 611, 644, 295, 264, 2390, 493, 428, 7964, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.20795553922653198, "compression_ratio": 1.7829457364341086,
  "no_speech_prob": 0.14798229932785034}, {"id": 97, "seek": 51514, "start": 532.14,
  "end": 533.14, "text": " Yeah.", "tokens": [51214, 865, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.20795553922653198, "compression_ratio": 1.7829457364341086,
  "no_speech_prob": 0.14798229932785034}, {"id": 98, "seek": 51514, "start": 533.14,
  "end": 534.14, "text": " Yeah.", "tokens": [51264, 865, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.20795553922653198, "compression_ratio": 1.7829457364341086,
  "no_speech_prob": 0.14798229932785034}, {"id": 99, "seek": 51514, "start": 534.14,
  "end": 540.14, "text": " So I think like Steve Jobs, I think I think said like computer
  is a bicycle for the mind, right?", "tokens": [51314, 407, 286, 519, 411, 7466,
  29169, 11, 286, 519, 286, 519, 848, 411, 3820, 307, 257, 20888, 337, 264, 1575,
  11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.20795553922653198, "compression_ratio":
  1.7829457364341086, "no_speech_prob": 0.14798229932785034}, {"id": 100, "seek":
  51514, "start": 540.14, "end": 542.14, "text": " And so blogging is also in a way
  bicycle for the mind.", "tokens": [51614, 400, 370, 6968, 3249, 307, 611, 294, 257,
  636, 20888, 337, 264, 1575, 13, 51714], "temperature": 0.0, "avg_logprob": -0.20795553922653198,
  "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.14798229932785034},
  {"id": 101, "seek": 54214, "start": 542.14, "end": 544.14, "text": " You have to
  rework yourself.", "tokens": [50364, 509, 362, 281, 48376, 1803, 13, 50464], "temperature":
  0.0, "avg_logprob": -0.211898926765688, "compression_ratio": 1.5520361990950227,
  "no_speech_prob": 0.08107094466686249}, {"id": 102, "seek": 54214, "start": 544.14,
  "end": 545.14, "text": " Right.", "tokens": [50464, 1779, 13, 50514], "temperature":
  0.0, "avg_logprob": -0.211898926765688, "compression_ratio": 1.5520361990950227,
  "no_speech_prob": 0.08107094466686249}, {"id": 103, "seek": 54214, "start": 545.14,
  "end": 550.14, "text": " It''s it''s also the programming that you do on the site
  like searcher rate.", "tokens": [50514, 467, 311, 309, 311, 611, 264, 9410, 300,
  291, 360, 322, 264, 3621, 411, 3164, 260, 3314, 13, 50764], "temperature": 0.0,
  "avg_logprob": -0.211898926765688, "compression_ratio": 1.5520361990950227, "no_speech_prob":
  0.08107094466686249}, {"id": 104, "seek": 54214, "start": 550.14, "end": 553.14,
  "text": " So tell me more about what was the motivation.", "tokens": [50764, 407,
  980, 385, 544, 466, 437, 390, 264, 12335, 13, 50914], "temperature": 0.0, "avg_logprob":
  -0.211898926765688, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.08107094466686249},
  {"id": 105, "seek": 54214, "start": 553.14, "end": 555.14, "text": " Why did you
  start working?", "tokens": [50914, 1545, 630, 291, 722, 1364, 30, 51014], "temperature":
  0.0, "avg_logprob": -0.211898926765688, "compression_ratio": 1.5520361990950227,
  "no_speech_prob": 0.08107094466686249}, {"id": 106, "seek": 54214, "start": 555.14,
  "end": 559.14, "text": " So I think I like to go against the grain a little bit.",
  "tokens": [51014, 407, 286, 519, 286, 411, 281, 352, 1970, 264, 12837, 257, 707,
  857, 13, 51214], "temperature": 0.0, "avg_logprob": -0.211898926765688, "compression_ratio":
  1.5520361990950227, "no_speech_prob": 0.08107094466686249}, {"id": 107, "seek":
  54214, "start": 559.14, "end": 567.14, "text": " So I actually had worked on different
  versions of vector search for a long time before this for craze.", "tokens": [51214,
  407, 286, 767, 632, 2732, 322, 819, 9606, 295, 8062, 3164, 337, 257, 938, 565, 949,
  341, 337, 2094, 1381, 13, 51614], "temperature": 0.0, "avg_logprob": -0.211898926765688,
  "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.08107094466686249},
  {"id": 108, "seek": 56714, "start": 567.14, "end": 575.14, "text": " And different
  hacks and things to make vector search work in a in the current in the solar or
  last search world.", "tokens": [50364, 400, 819, 33617, 293, 721, 281, 652, 8062,
  3164, 589, 294, 257, 294, 264, 2190, 294, 264, 7936, 420, 1036, 3164, 1002, 13,
  50764], "temperature": 0.0, "avg_logprob": -0.21895347322736466, "compression_ratio":
  1.5842105263157895, "no_speech_prob": 0.017902947962284088}, {"id": 109, "seek":
  56714, "start": 575.14, "end": 578.14, "text": " So everyone''s in vector search.",
  "tokens": [50764, 407, 1518, 311, 294, 8062, 3164, 13, 50914], "temperature": 0.0,
  "avg_logprob": -0.21895347322736466, "compression_ratio": 1.5842105263157895, "no_speech_prob":
  0.017902947962284088}, {"id": 110, "seek": 56714, "start": 578.14, "end": 585.14,
  "text": " And I decided that in part because I wanted to get do a little bit more
  native programming.", "tokens": [50914, 400, 286, 3047, 300, 294, 644, 570, 286,
  1415, 281, 483, 360, 257, 707, 857, 544, 8470, 9410, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.21895347322736466, "compression_ratio": 1.5842105263157895,
  "no_speech_prob": 0.017902947962284088}, {"id": 111, "seek": 56714, "start": 585.14,
  "end": 586.14, "text": " Get facts.", "tokens": [51264, 3240, 9130, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.21895347322736466, "compression_ratio": 1.5842105263157895,
  "no_speech_prob": 0.017902947962284088}, {"id": 112, "seek": 56714, "start": 586.14,
  "end": 587.14, "text": " I used to do that.", "tokens": [51314, 286, 1143, 281,
  360, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21895347322736466, "compression_ratio":
  1.5842105263157895, "no_speech_prob": 0.017902947962284088}, {"id": 113, "seek":
  56714, "start": 587.14, "end": 588.14, "text": " I used to be a C programmer.",
  "tokens": [51364, 286, 1143, 281, 312, 257, 383, 32116, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.21895347322736466, "compression_ratio": 1.5842105263157895,
  "no_speech_prob": 0.017902947962284088}, {"id": 114, "seek": 56714, "start": 588.14,
  "end": 590.14, "text": " Yeah.", "tokens": [51414, 865, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.21895347322736466, "compression_ratio": 1.5842105263157895,
  "no_speech_prob": 0.017902947962284088}, {"id": 115, "seek": 59014, "start": 590.14,
  "end": 593.14, "text": " And I found that.", "tokens": [50364, 400, 286, 1352, 300,
  13, 50514], "temperature": 0.0, "avg_logprob": -0.20218599888316371, "compression_ratio":
  1.7098039215686274, "no_speech_prob": 0.002256857231259346}, {"id": 116, "seek":
  59014, "start": 593.14, "end": 598.14, "text": " Vector search is very welcoming
  to machine learning engineer data science community.", "tokens": [50514, 691, 20814,
  3164, 307, 588, 17378, 281, 3479, 2539, 11403, 1412, 3497, 1768, 13, 50764], "temperature":
  0.0, "avg_logprob": -0.20218599888316371, "compression_ratio": 1.7098039215686274,
  "no_speech_prob": 0.002256857231259346}, {"id": 117, "seek": 59014, "start": 598.14,
  "end": 601.14, "text": " But the traditional lexical search engines like solar and
  elastic search.", "tokens": [50764, 583, 264, 5164, 476, 87, 804, 3164, 12982, 411,
  7936, 293, 17115, 3164, 13, 50914], "temperature": 0.0, "avg_logprob": -0.20218599888316371,
  "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.002256857231259346},
  {"id": 118, "seek": 59014, "start": 601.14, "end": 602.14, "text": " They''re very
  weird.", "tokens": [50914, 814, 434, 588, 3657, 13, 50964], "temperature": 0.0,
  "avg_logprob": -0.20218599888316371, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.002256857231259346}, {"id": 119, "seek": 59014, "start": 602.14, "end": 603.14,
  "text": " Yeah.", "tokens": [50964, 865, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.20218599888316371, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.002256857231259346}, {"id": 120, "seek": 59014, "start": 603.14, "end": 605.14,
  "text": " They''re very like you have to know this weird query DSL.", "tokens":
  [51014, 814, 434, 588, 411, 291, 362, 281, 458, 341, 3657, 14581, 15816, 43, 13,
  51114], "temperature": 0.0, "avg_logprob": -0.20218599888316371, "compression_ratio":
  1.7098039215686274, "no_speech_prob": 0.002256857231259346}, {"id": 121, "seek":
  59014, "start": 605.14, "end": 607.14, "text": " You have to understand these things.",
  "tokens": [51114, 509, 362, 281, 1223, 613, 721, 13, 51214], "temperature": 0.0,
  "avg_logprob": -0.20218599888316371, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.002256857231259346}, {"id": 122, "seek": 59014, "start": 607.14, "end": 608.14,
  "text": " Organization.", "tokens": [51214, 23979, 13, 51264], "temperature": 0.0,
  "avg_logprob": -0.20218599888316371, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.002256857231259346}, {"id": 123, "seek": 59014, "start": 608.14, "end": 610.14,
  "text": " So I wanted to take that.", "tokens": [51264, 407, 286, 1415, 281, 747,
  300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20218599888316371, "compression_ratio":
  1.7098039215686274, "no_speech_prob": 0.002256857231259346}, {"id": 124, "seek":
  59014, "start": 610.14, "end": 617.14, "text": " And take that lexical world and
  bring it into a data science or data high data sort of environment.", "tokens":
  [51364, 400, 747, 300, 476, 87, 804, 1002, 293, 1565, 309, 666, 257, 1412, 3497,
  420, 1412, 1090, 1412, 1333, 295, 2823, 13, 51714], "temperature": 0.0, "avg_logprob":
  -0.20218599888316371, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.002256857231259346}, {"id": 125, "seek": 61714, "start": 617.14, "end": 623.14,
  "text": " And then I found that it''s very comfortable to machine learning people
  and data science.", "tokens": [50364, 400, 550, 286, 1352, 300, 309, 311, 588, 4619,
  281, 3479, 2539, 561, 293, 1412, 3497, 13, 50664], "temperature": 0.0, "avg_logprob":
  -0.31037235260009766, "compression_ratio": 1.596638655462185, "no_speech_prob":
  0.013651189394295216}, {"id": 126, "seek": 61714, "start": 623.14, "end": 624.14,
  "text": " Yeah.", "tokens": [50664, 865, 13, 50714], "temperature": 0.0, "avg_logprob":
  -0.31037235260009766, "compression_ratio": 1.596638655462185, "no_speech_prob":
  0.013651189394295216}, {"id": 127, "seek": 61714, "start": 624.14, "end": 626.14,
  "text": " So I built search array.", "tokens": [50714, 407, 286, 3094, 3164, 10225,
  13, 50814], "temperature": 0.0, "avg_logprob": -0.31037235260009766, "compression_ratio":
  1.596638655462185, "no_speech_prob": 0.013651189394295216}, {"id": 128, "seek":
  61714, "start": 626.14, "end": 627.14, "text": " And what search array.", "tokens":
  [50814, 400, 437, 3164, 10225, 13, 50864], "temperature": 0.0, "avg_logprob": -0.31037235260009766,
  "compression_ratio": 1.596638655462185, "no_speech_prob": 0.013651189394295216},
  {"id": 129, "seek": 61714, "start": 627.14, "end": 632.14, "text": " The reason
  I built that what that does is it''s basically a lexical extension to pandas.",
  "tokens": [50864, 440, 1778, 286, 3094, 300, 437, 300, 775, 307, 309, 311, 1936,
  257, 476, 87, 804, 10320, 281, 4565, 296, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.31037235260009766, "compression_ratio": 1.596638655462185, "no_speech_prob":
  0.013651189394295216}, {"id": 130, "seek": 61714, "start": 632.14, "end": 634.14,
  "text": " So if I have text.", "tokens": [51114, 407, 498, 286, 362, 2487, 13, 51214],
  "temperature": 0.0, "avg_logprob": -0.31037235260009766, "compression_ratio": 1.596638655462185,
  "no_speech_prob": 0.013651189394295216}, {"id": 131, "seek": 61714, "start": 634.14,
  "end": 638.14, "text": " I can make a pandas column that''s just like tokenized
  text.", "tokens": [51214, 286, 393, 652, 257, 4565, 296, 7738, 300, 311, 445, 411,
  14862, 1602, 2487, 13, 51414], "temperature": 0.0, "avg_logprob": -0.31037235260009766,
  "compression_ratio": 1.596638655462185, "no_speech_prob": 0.013651189394295216},
  {"id": 132, "seek": 61714, "start": 638.14, "end": 643.14, "text": " And then I
  can ask it to score against a keyword and get a BM25 score.", "tokens": [51414,
  400, 550, 286, 393, 1029, 309, 281, 6175, 1970, 257, 20428, 293, 483, 257, 15901,
  6074, 6175, 13, 51664], "temperature": 0.0, "avg_logprob": -0.31037235260009766,
  "compression_ratio": 1.596638655462185, "no_speech_prob": 0.013651189394295216},
  {"id": 133, "seek": 64314, "start": 643.14, "end": 646.14, "text": " And this was
  so in a co lab notebook or something.", "tokens": [50364, 400, 341, 390, 370, 294,
  257, 598, 2715, 21060, 420, 746, 13, 50514], "temperature": 0.0, "avg_logprob":
  -0.2264869213104248, "compression_ratio": 1.6329588014981273, "no_speech_prob":
  0.07405898720026016}, {"id": 134, "seek": 64314, "start": 646.14, "end": 650.14,
  "text": " I can quickly further set ideas while having to stand up solar elastic
  search.", "tokens": [50514, 286, 393, 2661, 3052, 992, 3487, 1339, 1419, 281, 1463,
  493, 7936, 17115, 3164, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2264869213104248,
  "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.07405898720026016},
  {"id": 135, "seek": 64314, "start": 650.14, "end": 651.14, "text": " Yeah.", "tokens":
  [50714, 865, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2264869213104248,
  "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.07405898720026016},
  {"id": 136, "seek": 64314, "start": 651.14, "end": 653.14, "text": " Or think about
  Docker container and all this stuff.", "tokens": [50764, 1610, 519, 466, 33772,
  10129, 293, 439, 341, 1507, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2264869213104248,
  "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.07405898720026016},
  {"id": 137, "seek": 64314, "start": 653.14, "end": 657.14, "text": " And I said
  I could see like, OK, I want to tokenize things a certain way.", "tokens": [50864,
  400, 286, 848, 286, 727, 536, 411, 11, 2264, 11, 286, 528, 281, 14862, 1125, 721,
  257, 1629, 636, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2264869213104248,
  "compression_ratio": 1.6329588014981273, "no_speech_prob": 0.07405898720026016},
  {"id": 138, "seek": 64314, "start": 657.14, "end": 661.14, "text": " I want to score
  change the BM25 scoring to be a certain way.", "tokens": [51064, 286, 528, 281,
  6175, 1319, 264, 15901, 6074, 22358, 281, 312, 257, 1629, 636, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.2264869213104248, "compression_ratio": 1.6329588014981273,
  "no_speech_prob": 0.07405898720026016}, {"id": 139, "seek": 64314, "start": 661.14,
  "end": 662.14, "text": " Yeah.", "tokens": [51264, 865, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.2264869213104248, "compression_ratio": 1.6329588014981273,
  "no_speech_prob": 0.07405898720026016}, {"id": 140, "seek": 64314, "start": 662.14,
  "end": 670.14, "text": " And which is you think about like 90% of what you do in
  lexical search engine is tweaking the tokenization.", "tokens": [51314, 400, 597,
  307, 291, 519, 466, 411, 4289, 4, 295, 437, 291, 360, 294, 476, 87, 804, 3164, 2848,
  307, 6986, 2456, 264, 14862, 2144, 13, 51714], "temperature": 0.0, "avg_logprob":
  -0.2264869213104248, "compression_ratio": 1.6329588014981273, "no_speech_prob":
  0.07405898720026016}, {"id": 141, "seek": 67014, "start": 670.14, "end": 671.14,
  "text": " Yeah.", "tokens": [50364, 865, 13, 50414], "temperature": 0.0, "avg_logprob":
  -0.17158998342660758, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.01854291930794716}, {"id": 142, "seek": 67014, "start": 671.14, "end": 674.14,
  "text": " Finging the scoring, trying to index something new and search against
  that.", "tokens": [50414, 479, 8716, 264, 22358, 11, 1382, 281, 8186, 746, 777,
  293, 3164, 1970, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17158998342660758,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01854291930794716},
  {"id": 143, "seek": 67014, "start": 674.14, "end": 676.14, "text": " Like, oh, I
  have any recognition field now.", "tokens": [50564, 1743, 11, 1954, 11, 286, 362,
  604, 11150, 2519, 586, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17158998342660758,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01854291930794716},
  {"id": 144, "seek": 67014, "start": 676.14, "end": 677.14, "text": " No.", "tokens":
  [50664, 883, 13, 50714], "temperature": 0.0, "avg_logprob": -0.17158998342660758,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01854291930794716},
  {"id": 145, "seek": 67014, "start": 677.14, "end": 680.14, "text": " Oh, it''s and
  the other thing is what.", "tokens": [50714, 876, 11, 309, 311, 293, 264, 661, 551,
  307, 437, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17158998342660758, "compression_ratio":
  1.6666666666666667, "no_speech_prob": 0.01854291930794716}, {"id": 146, "seek":
  67014, "start": 680.14, "end": 684.14, "text": " The other thing you do a lot in
  lexical search engines is I want to boost by recency.", "tokens": [50864, 440, 661,
  551, 291, 360, 257, 688, 294, 476, 87, 804, 3164, 12982, 307, 286, 528, 281, 9194,
  538, 850, 3020, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17158998342660758,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01854291930794716},
  {"id": 147, "seek": 67014, "start": 684.14, "end": 685.14, "text": " And I want
  to.", "tokens": [51064, 400, 286, 528, 281, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.17158998342660758, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.01854291930794716}, {"id": 148, "seek": 67014, "start": 685.14, "end": 686.14,
  "text": " Do these other things.", "tokens": [51114, 1144, 613, 661, 721, 13, 51164],
  "temperature": 0.0, "avg_logprob": -0.17158998342660758, "compression_ratio": 1.6666666666666667,
  "no_speech_prob": 0.01854291930794716}, {"id": 149, "seek": 67014, "start": 686.14,
  "end": 691.14, "text": " And a lot of these things can just be done with a really
  fast like I take this column.", "tokens": [51164, 400, 257, 688, 295, 613, 721,
  393, 445, 312, 1096, 365, 257, 534, 2370, 411, 286, 747, 341, 7738, 13, 51414],
  "temperature": 0.0, "avg_logprob": -0.17158998342660758, "compression_ratio": 1.6666666666666667,
  "no_speech_prob": 0.01854291930794716}, {"id": 150, "seek": 67014, "start": 691.14,
  "end": 693.14, "text": " New miracle date column.", "tokens": [51414, 1873, 14660,
  4002, 7738, 13, 51514], "temperature": 0.0, "avg_logprob": -0.17158998342660758,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01854291930794716},
  {"id": 151, "seek": 67014, "start": 693.14, "end": 695.14, "text": " In pandas.",
  "tokens": [51514, 682, 4565, 296, 13, 51614], "temperature": 0.0, "avg_logprob":
  -0.17158998342660758, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.01854291930794716}, {"id": 152, "seek": 67014, "start": 695.14, "end": 696.14,
  "text": " Yeah.", "tokens": [51614, 865, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.17158998342660758, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.01854291930794716}, {"id": 153, "seek": 69614, "start": 696.14, "end": 699.14,
  "text": " And I want to add a score, a num tier ray that''s a BM25 score.", "tokens":
  [50364, 400, 286, 528, 281, 909, 257, 6175, 11, 257, 1031, 12362, 18592, 300, 311,
  257, 15901, 6074, 6175, 13, 50514], "temperature": 0.0, "avg_logprob": -0.3289938173093996,
  "compression_ratio": 1.6412698412698412, "no_speech_prob": 0.1377331167459488},
  {"id": 154, "seek": 69614, "start": 699.14, "end": 701.14, "text": " I multiply
  them together.", "tokens": [50514, 286, 12972, 552, 1214, 13, 50614], "temperature":
  0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 155, "seek": 69614, "start": 701.14,
  "end": 702.14, "text": " Yeah.", "tokens": [50614, 865, 13, 50664], "temperature":
  0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 156, "seek": 69614, "start": 702.14,
  "end": 704.14, "text": " I have a score that''s a recency weighted.", "tokens":
  [50664, 286, 362, 257, 6175, 300, 311, 257, 850, 3020, 32807, 13, 50764], "temperature":
  0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 157, "seek": 69614, "start": 704.14,
  "end": 705.14, "text": " Yeah.", "tokens": [50764, 865, 13, 50814], "temperature":
  0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 158, "seek": 69614, "start": 705.14,
  "end": 708.14, "text": " What does that look like in terms of my offline metrics?",
  "tokens": [50814, 708, 775, 300, 574, 411, 294, 2115, 295, 452, 21857, 16367, 30,
  50964], "temperature": 0.0, "avg_logprob": -0.3289938173093996, "compression_ratio":
  1.6412698412698412, "no_speech_prob": 0.1377331167459488}, {"id": 159, "seek": 69614,
  "start": 708.14, "end": 709.14, "text": " Yeah.", "tokens": [50964, 865, 13, 51014],
  "temperature": 0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 160, "seek": 69614, "start": 709.14,
  "end": 710.14, "text": " Interesting.", "tokens": [51014, 14711, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 161, "seek": 69614, "start": 710.14,
  "end": 713.14, "text": " Without having to go off to like, you have to go out elastic
  search and like that.", "tokens": [51064, 9129, 1419, 281, 352, 766, 281, 411, 11,
  291, 362, 281, 352, 484, 17115, 3164, 293, 411, 300, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.3289938173093996, "compression_ratio": 1.6412698412698412,
  "no_speech_prob": 0.1377331167459488}, {"id": 162, "seek": 69614, "start": 713.14,
  "end": 714.14, "text": " Assuteric stuff.", "tokens": [51214, 6281, 20314, 299,
  1507, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3289938173093996, "compression_ratio":
  1.6412698412698412, "no_speech_prob": 0.1377331167459488}, {"id": 163, "seek": 69614,
  "start": 714.14, "end": 718.14, "text": " So basically it allows you to try out
  some ideas really quickly, right?", "tokens": [51264, 407, 1936, 309, 4045, 291,
  281, 853, 484, 512, 3487, 534, 2661, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob":
  -0.3289938173093996, "compression_ratio": 1.6412698412698412, "no_speech_prob":
  0.1377331167459488}, {"id": 164, "seek": 69614, "start": 718.14, "end": 725.14,
  "text": " But then there will be some kind of offset compared with the reality because
  tokenizing is in solar probably work differently.", "tokens": [51464, 583, 550,
  456, 486, 312, 512, 733, 295, 18687, 5347, 365, 264, 4103, 570, 14862, 3319, 307,
  294, 7936, 1391, 589, 7614, 13, 51814], "temperature": 0.0, "avg_logprob": -0.3289938173093996,
  "compression_ratio": 1.6412698412698412, "no_speech_prob": 0.1377331167459488},
  {"id": 165, "seek": 72514, "start": 725.14, "end": 726.14, "text": " Yeah.", "tokens":
  [50364, 865, 13, 50414], "temperature": 0.0, "avg_logprob": -0.35322280757683366,
  "compression_ratio": 1.643939393939394, "no_speech_prob": 0.013285395689308643},
  {"id": 166, "seek": 72514, "start": 726.14, "end": 728.14, "text": " But that would
  be different probably will be close enough right?", "tokens": [50414, 583, 300,
  576, 312, 819, 1391, 486, 312, 1998, 1547, 558, 30, 50514], "temperature": 0.0,
  "avg_logprob": -0.35322280757683366, "compression_ratio": 1.643939393939394, "no_speech_prob":
  0.013285395689308643}, {"id": 167, "seek": 72514, "start": 728.14, "end": 737.14,
  "text": " So it''s also if you nailed the signal that like you explained today in
  your presentation, you know, what about a number of comments or what about you know
  the recent sea and so on.", "tokens": [50514, 407, 309, 311, 611, 498, 291, 30790,
  264, 6358, 300, 411, 291, 8825, 965, 294, 428, 5860, 11, 291, 458, 11, 437, 466,
  257, 1230, 295, 3053, 420, 437, 466, 291, 458, 264, 5162, 4158, 293, 370, 322, 13,
  50964], "temperature": 0.0, "avg_logprob": -0.35322280757683366, "compression_ratio":
  1.643939393939394, "no_speech_prob": 0.013285395689308643}, {"id": 168, "seek":
  72514, "start": 737.14, "end": 739.14, "text": " Yeah, all of these be on the board.",
  "tokens": [50964, 865, 11, 439, 295, 613, 312, 322, 264, 3150, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.35322280757683366, "compression_ratio": 1.643939393939394,
  "no_speech_prob": 0.013285395689308643}, {"id": 169, "seek": 72514, "start": 739.14,
  "end": 741.14, "text": " And I''ll like try that really quickly.", "tokens": [51064,
  400, 286, 603, 411, 853, 300, 534, 2661, 13, 51164], "temperature": 0.0, "avg_logprob":
  -0.35322280757683366, "compression_ratio": 1.643939393939394, "no_speech_prob":
  0.013285395689308643}, {"id": 170, "seek": 72514, "start": 741.14, "end": 742.14,
  "text": " Yeah.", "tokens": [51164, 865, 13, 51214], "temperature": 0.0, "avg_logprob":
  -0.35322280757683366, "compression_ratio": 1.643939393939394, "no_speech_prob":
  0.013285395689308643}, {"id": 171, "seek": 72514, "start": 742.14, "end": 743.14,
  "text": " Yeah.", "tokens": [51214, 865, 13, 51264], "temperature": 0.0, "avg_logprob":
  -0.35322280757683366, "compression_ratio": 1.643939393939394, "no_speech_prob":
  0.013285395689308643}, {"id": 172, "seek": 72514, "start": 743.14, "end": 748.14,
  "text": " And a lot of times it''s, it''s a big effort to index some new data into
  the search engine.", "tokens": [51264, 400, 257, 688, 295, 1413, 309, 311, 11, 309,
  311, 257, 955, 4630, 281, 8186, 512, 777, 1412, 666, 264, 3164, 2848, 13, 51514],
  "temperature": 0.0, "avg_logprob": -0.35322280757683366, "compression_ratio": 1.643939393939394,
  "no_speech_prob": 0.013285395689308643}, {"id": 173, "seek": 72514, "start": 748.14,
  "end": 749.14, "text": " Yeah.", "tokens": [51514, 865, 13, 51564], "temperature":
  0.0, "avg_logprob": -0.35322280757683366, "compression_ratio": 1.643939393939394,
  "no_speech_prob": 0.013285395689308643}, {"id": 174, "seek": 74914, "start": 749.14,
  "end": 754.14, "text": " And you have to go is the upstream system fast enough to
  handle those load and then stay up to date.", "tokens": [50364, 400, 291, 362, 281,
  352, 307, 264, 33915, 1185, 2370, 1547, 281, 4813, 729, 3677, 293, 550, 1754, 493,
  281, 4002, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1895805278294523, "compression_ratio":
  1.6571428571428573, "no_speech_prob": 0.002668525092303753}, {"id": 175, "seek":
  74914, "start": 754.14, "end": 756.14, "text": " And really to justify a project.",
  "tokens": [50614, 400, 534, 281, 20833, 257, 1716, 13, 50714], "temperature": 0.0,
  "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573, "no_speech_prob":
  0.002668525092303753}, {"id": 176, "seek": 74914, "start": 756.14, "end": 757.14,
  "text": " Yeah.", "tokens": [50714, 865, 13, 50764], "temperature": 0.0, "avg_logprob":
  -0.1895805278294523, "compression_ratio": 1.6571428571428573, "no_speech_prob":
  0.002668525092303753}, {"id": 177, "seek": 74914, "start": 757.14, "end": 761.14,
  "text": " You might start with a prototype and say, OK, I just pull for a small.",
  "tokens": [50764, 509, 1062, 722, 365, 257, 19475, 293, 584, 11, 2264, 11, 286,
  445, 2235, 337, 257, 1359, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1895805278294523,
  "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002668525092303753},
  {"id": 178, "seek": 74914, "start": 761.14, "end": 762.14, "text": " Small chest
  set of data.", "tokens": [50964, 15287, 7443, 992, 295, 1412, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573,
  "no_speech_prob": 0.002668525092303753}, {"id": 179, "seek": 74914, "start": 762.14,
  "end": 763.14, "text": " Yeah.", "tokens": [51014, 865, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573,
  "no_speech_prob": 0.002668525092303753}, {"id": 180, "seek": 74914, "start": 763.14,
  "end": 764.14, "text": " I pulled in some data.", "tokens": [51064, 286, 7373, 294,
  512, 1412, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1895805278294523, "compression_ratio":
  1.6571428571428573, "no_speech_prob": 0.002668525092303753}, {"id": 181, "seek":
  74914, "start": 764.14, "end": 765.14, "text": " It seems like there''s some signal
  here.", "tokens": [51114, 467, 2544, 411, 456, 311, 512, 6358, 510, 13, 51164],
  "temperature": 0.0, "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573,
  "no_speech_prob": 0.002668525092303753}, {"id": 182, "seek": 74914, "start": 765.14,
  "end": 766.14, "text": " Yeah.", "tokens": [51164, 865, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573,
  "no_speech_prob": 0.002668525092303753}, {"id": 183, "seek": 74914, "start": 766.14,
  "end": 767.14, "text": " Let''s plan a project around it.", "tokens": [51214, 961,
  311, 1393, 257, 1716, 926, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1895805278294523,
  "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002668525092303753},
  {"id": 184, "seek": 74914, "start": 767.14, "end": 768.14, "text": " Yeah.", "tokens":
  [51264, 865, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1895805278294523,
  "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002668525092303753},
  {"id": 185, "seek": 74914, "start": 768.14, "end": 771.14, "text": " And so this
  is to me.", "tokens": [51314, 400, 370, 341, 307, 281, 385, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573,
  "no_speech_prob": 0.002668525092303753}, {"id": 186, "seek": 74914, "start": 771.14,
  "end": 774.14, "text": " And actually I''ll, my sees the conference after blue and
  buzzwords.", "tokens": [51464, 400, 767, 286, 603, 11, 452, 8194, 264, 7586, 934,
  3344, 293, 13036, 13832, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1895805278294523,
  "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.002668525092303753},
  {"id": 187, "seek": 74914, "start": 774.14, "end": 776.14, "text": " I''ll talk
  about planning.", "tokens": [51614, 286, 603, 751, 466, 5038, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.1895805278294523, "compression_ratio": 1.6571428571428573,
  "no_speech_prob": 0.002668525092303753}, {"id": 188, "seek": 77614, "start": 776.14,
  "end": 788.14, "text": " But to me, a lot of this like how do we build better prototypes
  to build plans and have ideas and have conversations between engineers data scientists
  and product managers is really one of the inspirations for search array.", "tokens":
  [50364, 583, 281, 385, 11, 257, 688, 295, 341, 411, 577, 360, 321, 1322, 1101, 42197,
  281, 1322, 5482, 293, 362, 3487, 293, 362, 7315, 1296, 11955, 1412, 7708, 293, 1674,
  14084, 307, 534, 472, 295, 264, 17432, 763, 337, 3164, 10225, 13, 50964], "temperature":
  0.0, "avg_logprob": -0.2560033117021833, "compression_ratio": 1.6830188679245284,
  "no_speech_prob": 0.002589531010016799}, {"id": 189, "seek": 77614, "start": 788.14,
  "end": 794.14, "text": " Because to do this before I''d be like, OK, I have to stand
  up some examples, certain custom.", "tokens": [50964, 1436, 281, 360, 341, 949,
  286, 1116, 312, 411, 11, 2264, 11, 286, 362, 281, 1463, 493, 512, 5110, 11, 1629,
  2375, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2560033117021833, "compression_ratio":
  1.6830188679245284, "no_speech_prob": 0.002589531010016799}, {"id": 190, "seek":
  77614, "start": 794.14, "end": 796.14, "text": " Yeah, yeah, yeah, yeah, spend time
  on that.", "tokens": [51264, 865, 11, 1338, 11, 1338, 11, 1338, 11, 3496, 565, 322,
  300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2560033117021833, "compression_ratio":
  1.6830188679245284, "no_speech_prob": 0.002589531010016799}, {"id": 191, "seek":
  77614, "start": 796.14, "end": 799.14, "text": " Yeah, how am I going to absolutely
  locate a cluster and whatnot.", "tokens": [51364, 865, 11, 577, 669, 286, 516, 281,
  3122, 22370, 257, 13630, 293, 25882, 13, 51514], "temperature": 0.0, "avg_logprob":
  -0.2560033117021833, "compression_ratio": 1.6830188679245284, "no_speech_prob":
  0.002589531010016799}, {"id": 192, "seek": 77614, "start": 799.14, "end": 800.14,
  "text": " Yeah, exactly.", "tokens": [51514, 865, 11, 2293, 13, 51564], "temperature":
  0.0, "avg_logprob": -0.2560033117021833, "compression_ratio": 1.6830188679245284,
  "no_speech_prob": 0.002589531010016799}, {"id": 193, "seek": 77614, "start": 800.14,
  "end": 801.14, "text": " Yeah.", "tokens": [51564, 865, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.2560033117021833, "compression_ratio": 1.6830188679245284,
  "no_speech_prob": 0.002589531010016799}, {"id": 194, "seek": 80114, "start": 801.14,
  "end": 805.14, "text": " And I think I actually this reminded me when I was working
  on the learning to rank.", "tokens": [50364, 400, 286, 519, 286, 767, 341, 15920,
  385, 562, 286, 390, 1364, 322, 264, 2539, 281, 6181, 13, 50564], "temperature":
  0.0, "avg_logprob": -0.2879345005956189, "compression_ratio": 1.533596837944664,
  "no_speech_prob": 0.21029916405677795}, {"id": 195, "seek": 80114, "start": 805.14,
  "end": 809.14, "text": " And this was the last project I did in my 10 year tenure
  at Alpha Cent.", "tokens": [50564, 400, 341, 390, 264, 1036, 1716, 286, 630, 294,
  452, 1266, 1064, 32256, 412, 20588, 3408, 13, 50764], "temperature": 0.0, "avg_logprob":
  -0.2879345005956189, "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 196, "seek": 80114, "start": 809.14, "end": 813.14, "text": " I said, Hey,
  can I have this really expensive laptop?", "tokens": [50764, 286, 848, 11, 1911,
  11, 393, 286, 362, 341, 534, 5124, 10732, 30, 50964], "temperature": 0.0, "avg_logprob":
  -0.2879345005956189, "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 197, "seek": 80114, "start": 813.14, "end": 817.14, "text": " So it would
  be like 30 gig around one terabyte drive.", "tokens": [50964, 407, 309, 576, 312,
  411, 2217, 8741, 926, 472, 1796, 34529, 3332, 13, 51164], "temperature": 0.0, "avg_logprob":
  -0.2879345005956189, "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 198, "seek": 80114, "start": 817.14, "end": 820.14, "text": " I thought I
  need so much space for some reason.", "tokens": [51164, 286, 1194, 286, 643, 370,
  709, 1901, 337, 512, 1778, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2879345005956189,
  "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 199, "seek": 80114, "start": 820.14, "end": 822.14, "text": " And it was
  SSD.", "tokens": [51314, 400, 309, 390, 30262, 13, 51414], "temperature": 0.0, "avg_logprob":
  -0.2879345005956189, "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 200, "seek": 80114, "start": 822.14, "end": 824.14, "text": " And and I got
  it approved.", "tokens": [51414, 400, 293, 286, 658, 309, 10826, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.2879345005956189, "compression_ratio": 1.533596837944664,
  "no_speech_prob": 0.21029916405677795}, {"id": 201, "seek": 80114, "start": 824.14,
  "end": 825.14, "text": " It was like, oh, my God.", "tokens": [51514, 467, 390,
  411, 11, 1954, 11, 452, 1265, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2879345005956189,
  "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 202, "seek": 80114, "start": 825.14, "end": 826.14, "text": " So many.",
  "tokens": [51564, 407, 867, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2879345005956189,
  "compression_ratio": 1.533596837944664, "no_speech_prob": 0.21029916405677795},
  {"id": 203, "seek": 82614, "start": 826.14, "end": 833.14, "text": " So and I spent
  like a year working on it and was kind of like bloated version of search array because
  I could do everything on the laptop.", "tokens": [50364, 407, 293, 286, 4418, 411,
  257, 1064, 1364, 322, 309, 293, 390, 733, 295, 411, 1749, 770, 3037, 295, 3164,
  10225, 570, 286, 727, 360, 1203, 322, 264, 10732, 13, 50714], "temperature": 0.0,
  "avg_logprob": -0.25445001315226595, "compression_ratio": 1.6863468634686347, "no_speech_prob":
  0.09308959543704987}, {"id": 204, "seek": 82614, "start": 833.14, "end": 834.14,
  "text": " This connected right.", "tokens": [50714, 639, 4582, 558, 13, 50764],
  "temperature": 0.0, "avg_logprob": -0.25445001315226595, "compression_ratio": 1.6863468634686347,
  "no_speech_prob": 0.09308959543704987}, {"id": 205, "seek": 82614, "start": 834.14,
  "end": 840.14, "text": " The only problem I remember was tracking my experiment
  tree because I would like.", "tokens": [50764, 440, 787, 1154, 286, 1604, 390, 11603,
  452, 5120, 4230, 570, 286, 576, 411, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.25445001315226595, "compression_ratio": 1.6863468634686347, "no_speech_prob":
  0.09308959543704987}, {"id": 206, "seek": 82614, "start": 840.14, "end": 843.14,
  "text": " Let''s the right word for Kate or like kind of branch out.", "tokens":
  [51064, 961, 311, 264, 558, 1349, 337, 16251, 420, 411, 733, 295, 9819, 484, 13,
  51214], "temperature": 0.0, "avg_logprob": -0.25445001315226595, "compression_ratio":
  1.6863468634686347, "no_speech_prob": 0.09308959543704987}, {"id": 207, "seek":
  82614, "start": 843.14, "end": 844.14, "text": " That''s right.", "tokens": [51214,
  663, 311, 558, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25445001315226595,
  "compression_ratio": 1.6863468634686347, "no_speech_prob": 0.09308959543704987},
  {"id": 208, "seek": 82614, "start": 844.14, "end": 853.14, "text": " And then like,
  OK, should I go back now because retreat because looks looks like I went down the
  rabbit hole and it doesn''t give at any value.", "tokens": [51264, 400, 550, 411,
  11, 2264, 11, 820, 286, 352, 646, 586, 570, 15505, 570, 1542, 1542, 411, 286, 1437,
  760, 264, 19509, 5458, 293, 309, 1177, 380, 976, 412, 604, 2158, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.25445001315226595, "compression_ratio": 1.6863468634686347,
  "no_speech_prob": 0.09308959543704987}, {"id": 209, "seek": 85314, "start": 853.14,
  "end": 859.14, "text": " So you go back to that state when it was that bigger, you
  know, and this is you or whatever, right?", "tokens": [50364, 407, 291, 352, 646,
  281, 300, 1785, 562, 309, 390, 300, 3801, 11, 291, 458, 11, 293, 341, 307, 291,
  420, 2035, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.37838138442441643,
  "compression_ratio": 1.5776699029126213, "no_speech_prob": 0.07478807866573334},
  {"id": 210, "seek": 85314, "start": 859.14, "end": 871.14, "text": " So instead
  of from there, that sounds a lot of like what some of the functionality in cute
  that the sort of like search relevance turning tool to you, you, you, PID.", "tokens":
  [50664, 407, 2602, 295, 490, 456, 11, 300, 3263, 257, 688, 295, 411, 437, 512, 295,
  264, 14980, 294, 4052, 300, 264, 1333, 295, 411, 3164, 32684, 6246, 2290, 281, 291,
  11, 291, 11, 291, 11, 430, 2777, 13, 51264], "temperature": 0.0, "avg_logprob":
  -0.37838138442441643, "compression_ratio": 1.5776699029126213, "no_speech_prob":
  0.07478807866573334}, {"id": 211, "seek": 85314, "start": 871.14, "end": 875.14,
  "text": " Because I remember when I was building that many years ago.", "tokens":
  [51264, 1436, 286, 1604, 562, 286, 390, 2390, 300, 867, 924, 2057, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.37838138442441643, "compression_ratio": 1.5776699029126213,
  "no_speech_prob": 0.07478807866573334}, {"id": 212, "seek": 87514, "start": 875.14,
  "end": 883.14, "text": " It was very much like every time you submit like you tweak
  the query and it saves that as a try.", "tokens": [50364, 467, 390, 588, 709, 411,
  633, 565, 291, 10315, 411, 291, 29879, 264, 14581, 293, 309, 19155, 300, 382, 257,
  853, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20984344482421874, "compression_ratio":
  1.6575342465753424, "no_speech_prob": 0.5611611604690552}, {"id": 213, "seek": 87514,
  "start": 883.14, "end": 889.14, "text": " Yeah, another time you can''t fork off
  stuff, but you can go back and be like, oh, this thing didn''t work out. I''m going
  to go back.", "tokens": [50764, 865, 11, 1071, 565, 291, 393, 380, 17716, 766, 1507,
  11, 457, 291, 393, 352, 646, 293, 312, 411, 11, 1954, 11, 341, 551, 994, 380, 589,
  484, 13, 286, 478, 516, 281, 352, 646, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.20984344482421874, "compression_ratio": 1.6575342465753424, "no_speech_prob":
  0.5611611604690552}, {"id": 214, "seek": 87514, "start": 889.14, "end": 896.14,
  "text": " And yeah, it''s it is funny how yeah, I have the same feeling. And even
  in a notebook environment.", "tokens": [51064, 400, 1338, 11, 309, 311, 309, 307,
  4074, 577, 1338, 11, 286, 362, 264, 912, 2633, 13, 400, 754, 294, 257, 21060, 2823,
  13, 51414], "temperature": 0.0, "avg_logprob": -0.20984344482421874, "compression_ratio":
  1.6575342465753424, "no_speech_prob": 0.5611611604690552}, {"id": 215, "seek": 87514,
  "start": 896.14, "end": 898.14, "text": " I don''t have that because notebooks.",
  "tokens": [51414, 286, 500, 380, 362, 300, 570, 43782, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.20984344482421874, "compression_ratio": 1.6575342465753424,
  "no_speech_prob": 0.5611611604690552}, {"id": 216, "seek": 89814, "start": 898.14,
  "end": 906.14, "text": " And you tweak a little bit, you forget what happened. You
  like, why did I thought my end ECG was good and I got bad. What did I do wrong?",
  "tokens": [50364, 400, 291, 29879, 257, 707, 857, 11, 291, 2870, 437, 2011, 13,
  509, 411, 11, 983, 630, 286, 1194, 452, 917, 19081, 38, 390, 665, 293, 286, 658,
  1578, 13, 708, 630, 286, 360, 2085, 30, 50764], "temperature": 0.0, "avg_logprob":
  -0.2177843451499939, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.3629343509674072},
  {"id": 217, "seek": 89814, "start": 906.14, "end": 912.14, "text": " You wish that
  you were like somehow the notebook was like versioning itself as you were going.",
  "tokens": [50764, 509, 3172, 300, 291, 645, 411, 6063, 264, 21060, 390, 411, 3037,
  278, 2564, 382, 291, 645, 516, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2177843451499939,
  "compression_ratio": 1.631578947368421, "no_speech_prob": 0.3629343509674072}, {"id":
  218, "seek": 89814, "start": 912.14, "end": 914.14, "text": " Yeah, exactly.", "tokens":
  [51064, 865, 11, 2293, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2177843451499939,
  "compression_ratio": 1.631578947368421, "no_speech_prob": 0.3629343509674072}, {"id":
  219, "seek": 89814, "start": 914.14, "end": 920.14, "text": " And but and like somehow
  the whole environment was version, but yeah, that doesn''t exist. I wish that kind
  of thing existed.", "tokens": [51164, 400, 457, 293, 411, 6063, 264, 1379, 2823,
  390, 3037, 11, 457, 1338, 11, 300, 1177, 380, 2514, 13, 286, 3172, 300, 733, 295,
  551, 13135, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2177843451499939,
  "compression_ratio": 1.631578947368421, "no_speech_prob": 0.3629343509674072}, {"id":
  220, "seek": 92014, "start": 920.14, "end": 928.14, "text": " Yeah, there was there
  was a tool we were using, but then it was acquired by some company. It was called
  spell dot run.", "tokens": [50364, 865, 11, 456, 390, 456, 390, 257, 2290, 321,
  645, 1228, 11, 457, 550, 309, 390, 17554, 538, 512, 2237, 13, 467, 390, 1219, 9827,
  5893, 1190, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14957671165466307,
  "compression_ratio": 1.5938697318007662, "no_speech_prob": 0.03698601573705673},
  {"id": 221, "seek": 92014, "start": 928.14, "end": 934.14, "text": " So basically
  was like a integrated Python notebook environment that runs a cluster.", "tokens":
  [50764, 407, 1936, 390, 411, 257, 10919, 15329, 21060, 2823, 300, 6676, 257, 13630,
  13, 51064], "temperature": 0.0, "avg_logprob": -0.14957671165466307, "compression_ratio":
  1.5938697318007662, "no_speech_prob": 0.03698601573705673}, {"id": 222, "seek":
  92014, "start": 934.14, "end": 938.14, "text": " And they were heading in the direction.
  I was giving a lot of feedback to them.", "tokens": [51064, 400, 436, 645, 9864,
  294, 264, 3513, 13, 286, 390, 2902, 257, 688, 295, 5824, 281, 552, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.14957671165466307, "compression_ratio": 1.5938697318007662,
  "no_speech_prob": 0.03698601573705673}, {"id": 223, "seek": 92014, "start": 938.14,
  "end": 946.14, "text": " Hey, can you actually build an infrastructure, which will
  allow me to also, you know, maintain my branched out, you know, experiment.", "tokens":
  [51264, 1911, 11, 393, 291, 767, 1322, 364, 6896, 11, 597, 486, 2089, 385, 281,
  611, 11, 291, 458, 11, 6909, 452, 9819, 292, 484, 11, 291, 458, 11, 5120, 13, 51664],
  "temperature": 0.0, "avg_logprob": -0.14957671165466307, "compression_ratio": 1.5938697318007662,
  "no_speech_prob": 0.03698601573705673}, {"id": 224, "seek": 94614, "start": 946.14,
  "end": 954.14, "text": " And I think they got acquired probably short before they
  could do this and probably they continue doing this. I don''t know.", "tokens":
  [50364, 400, 286, 519, 436, 658, 17554, 1391, 2099, 949, 436, 727, 360, 341, 293,
  1391, 436, 2354, 884, 341, 13, 286, 500, 380, 458, 13, 50764], "temperature": 0.0,
  "avg_logprob": -0.2650107984189634, "compression_ratio": 1.7176470588235293, "no_speech_prob":
  0.17509548366069794}, {"id": 225, "seek": 94614, "start": 954.14, "end": 962.14,
  "text": " But there is another project called DVC, I think, which allows you to
  basically maintain your experiments as deep hashes, right.", "tokens": [50764, 583,
  456, 307, 1071, 1716, 1219, 17021, 34, 11, 286, 519, 11, 597, 4045, 291, 281, 1936,
  6909, 428, 12050, 382, 2452, 575, 8076, 11, 558, 13, 51164], "temperature": 0.0,
  "avg_logprob": -0.2650107984189634, "compression_ratio": 1.7176470588235293, "no_speech_prob":
  0.17509548366069794}, {"id": 226, "seek": 94614, "start": 962.14, "end": 967.14,
  "text": " So you basically, you can, you can, you can get cash your code along with
  your data.", "tokens": [51164, 407, 291, 1936, 11, 291, 393, 11, 291, 393, 11, 291,
  393, 483, 6388, 428, 3089, 2051, 365, 428, 1412, 13, 51414], "temperature": 0.0,
  "avg_logprob": -0.2650107984189634, "compression_ratio": 1.7176470588235293, "no_speech_prob":
  0.17509548366069794}, {"id": 227, "seek": 94614, "start": 967.14, "end": 973.14,
  "text": " And then you upload your data. Let''s say to some cloud, I don''t know,
  drive some drive abstract one.", "tokens": [51414, 400, 550, 291, 6580, 428, 1412,
  13, 961, 311, 584, 281, 512, 4588, 11, 286, 500, 380, 458, 11, 3332, 512, 3332,
  12649, 472, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2650107984189634,
  "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.17509548366069794},
  {"id": 228, "seek": 97314, "start": 973.14, "end": 980.14, "text": " And then you
  have your code associated with that. So you can basically restore you or someone
  else that can restore the experiment.", "tokens": [50364, 400, 550, 291, 362, 428,
  3089, 6615, 365, 300, 13, 407, 291, 393, 1936, 15227, 291, 420, 1580, 1646, 300,
  393, 15227, 264, 5120, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2212868118286133,
  "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.024939825758337975},
  {"id": 229, "seek": 97314, "start": 980.14, "end": 984.14, "text": " I think if
  that if that was frictionless, right.", "tokens": [50714, 286, 519, 498, 300, 498,
  300, 390, 17710, 1832, 11, 558, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2212868118286133,
  "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.024939825758337975},
  {"id": 230, "seek": 97314, "start": 984.14, "end": 993.14, "text": " Or even the
  matter of it existing, right, because I had to literally like write something down
  on a piece of paper to remember what I need to do.", "tokens": [50914, 1610, 754,
  264, 1871, 295, 309, 6741, 11, 558, 11, 570, 286, 632, 281, 3736, 411, 2464, 746,
  760, 322, 257, 2522, 295, 3035, 281, 1604, 437, 286, 643, 281, 360, 13, 51364],
  "temperature": 0.0, "avg_logprob": -0.2212868118286133, "compression_ratio": 1.6311475409836065,
  "no_speech_prob": 0.024939825758337975}, {"id": 231, "seek": 97314, "start": 993.14,
  "end": 998.14, "text": " You know, sometimes I would go crazy at shopify. So we
  had a, we had a,", "tokens": [51364, 509, 458, 11, 2171, 286, 576, 352, 3219, 412,
  3945, 2505, 13, 407, 321, 632, 257, 11, 321, 632, 257, 11, 51614], "temperature":
  0.0, "avg_logprob": -0.2212868118286133, "compression_ratio": 1.6311475409836065,
  "no_speech_prob": 0.024939825758337975}, {"id": 232, "seek": 99814, "start": 998.14,
  "end": 1005.14, "text": " our testing, search testing infrastructure, the notebooks.
  So everything was in a monorepo.", "tokens": [50364, 527, 4997, 11, 3164, 4997,
  6896, 11, 264, 43782, 13, 407, 1203, 390, 294, 257, 1108, 418, 2259, 13, 50714],
  "temperature": 0.0, "avg_logprob": -0.33198479683168475, "compression_ratio": 1.6460176991150441,
  "no_speech_prob": 0.010275633074343204}, {"id": 233, "seek": 99814, "start": 1005.14,
  "end": 1012.14, "text": " So you could stand up elastic search. And you could have,
  we had a, this is a rails environment.", "tokens": [50714, 407, 291, 727, 1463,
  493, 17115, 3164, 13, 400, 291, 727, 362, 11, 321, 632, 257, 11, 341, 307, 257,
  27649, 2823, 13, 51064], "temperature": 0.0, "avg_logprob": -0.33198479683168475,
  "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.010275633074343204},
  {"id": 234, "seek": 99814, "start": 1012.14, "end": 1023.14, "text": " There''s
  a, all the relevance logic was in a Ruby library that we, a rails monolith would
  load and so call in the network call, a lasso search and do whatever, pre and post
  processing.", "tokens": [51064, 821, 311, 257, 11, 439, 264, 32684, 9952, 390, 294,
  257, 19907, 6405, 300, 321, 11, 257, 27649, 1108, 29131, 576, 3677, 293, 370, 818,
  294, 264, 3209, 818, 11, 257, 2439, 539, 3164, 293, 360, 2035, 11, 659, 293, 2183,
  9007, 13, 51614], "temperature": 0.0, "avg_logprob": -0.33198479683168475, "compression_ratio":
  1.6460176991150441, "no_speech_prob": 0.010275633074343204}, {"id": 235, "seek":
  102314, "start": 1023.14, "end": 1037.1399999999999, "text": " But when we stood
  up the test environment, we would say, we wanted to load this. We wanted to load
  the right configs, but we would basically put the company commit tasks of the repo
  that we,", "tokens": [50364, 583, 562, 321, 9371, 493, 264, 1500, 2823, 11, 321,
  576, 584, 11, 321, 1415, 281, 3677, 341, 13, 492, 1415, 281, 3677, 264, 558, 6662,
  82, 11, 457, 321, 576, 1936, 829, 264, 2237, 5599, 9608, 295, 264, 49040, 300, 321,
  11, 51064], "temperature": 0.0, "avg_logprob": -0.25421034495035805, "compression_ratio":
  1.7380952380952381, "no_speech_prob": 0.2891211211681366}, {"id": 236, "seek": 102314,
  "start": 1037.1399999999999, "end": 1045.1399999999999, "text": " that it was supposed
  to be and it would load the config and it would be amazing. But yeah, it''s, it''s
  getting reproducible environments.", "tokens": [51064, 300, 309, 390, 3442, 281,
  312, 293, 309, 576, 3677, 264, 6662, 293, 309, 576, 312, 2243, 13, 583, 1338, 11,
  309, 311, 11, 309, 311, 1242, 11408, 32128, 12388, 13, 51464], "temperature": 0.0,
  "avg_logprob": -0.25421034495035805, "compression_ratio": 1.7380952380952381, "no_speech_prob":
  0.2891211211681366}, {"id": 237, "seek": 102314, "start": 1045.1399999999999, "end":
  1048.1399999999999, "text": " Yeah, and experiments is a challenge.", "tokens":
  [51464, 865, 11, 293, 12050, 307, 257, 3430, 13, 51614], "temperature": 0.0, "avg_logprob":
  -0.25421034495035805, "compression_ratio": 1.7380952380952381, "no_speech_prob":
  0.2891211211681366}, {"id": 238, "seek": 104814, "start": 1048.14, "end": 1058.14,
  "text": " This is where, I mean, at some point, basically like your experiment rate
  will be, you know, trumped by how quickly you can deploy this or how quickly you
  can like,", "tokens": [50364, 639, 307, 689, 11, 286, 914, 11, 412, 512, 935, 11,
  1936, 411, 428, 5120, 3314, 486, 312, 11, 291, 458, 11, 21779, 292, 538, 577, 2661,
  291, 393, 7274, 341, 420, 577, 2661, 291, 393, 411, 11, 50864], "temperature": 0.0,
  "avg_logprob": -0.32446371031201576, "compression_ratio": 1.830827067669173, "no_speech_prob":
  0.10876153409481049}, {"id": 239, "seek": 104814, "start": 1058.14, "end": 1065.14,
  "text": " shuffle things, right? So yeah, I think so. This is where infrastructure
  comes as a big topic and in your talk.", "tokens": [50864, 39426, 721, 11, 558,
  30, 407, 1338, 11, 286, 519, 370, 13, 639, 307, 689, 6896, 1487, 382, 257, 955,
  4829, 293, 294, 428, 751, 13, 51214], "temperature": 0.0, "avg_logprob": -0.32446371031201576,
  "compression_ratio": 1.830827067669173, "no_speech_prob": 0.10876153409481049},
  {"id": 240, "seek": 104814, "start": 1065.14, "end": 1077.14, "text": " Yeah, I
  think you spent a good, yeah. Yeah. I think it''s like partnership, right? So we
  had a, there has to be like a big steam in my career too as partnerships like partnerships
  with PM partnerships with data.", "tokens": [51214, 865, 11, 286, 519, 291, 4418,
  257, 665, 11, 1338, 13, 865, 13, 286, 519, 309, 311, 411, 9982, 11, 558, 30, 407,
  321, 632, 257, 11, 456, 575, 281, 312, 411, 257, 955, 11952, 294, 452, 3988, 886,
  382, 18245, 411, 18245, 365, 12499, 18245, 365, 1412, 13, 51814], "temperature":
  0.0, "avg_logprob": -0.32446371031201576, "compression_ratio": 1.830827067669173,
  "no_speech_prob": 0.10876153409481049}, {"id": 241, "seek": 107714, "start": 1077.14,
  "end": 1089.14, "text": " Yeah, partnerships with infrastructure. You really have
  to have one cohesive team and one of the anti patterns is when they''re so separate
  that it creates.", "tokens": [50364, 865, 11, 18245, 365, 6896, 13, 509, 534, 362,
  281, 362, 472, 43025, 1469, 293, 472, 295, 264, 6061, 8294, 307, 562, 436, 434,
  370, 4994, 300, 309, 7829, 13, 50964], "temperature": 0.0, "avg_logprob": -0.16034182380227482,
  "compression_ratio": 1.649789029535865, "no_speech_prob": 0.0009954140987247229},
  {"id": 242, "seek": 107714, "start": 1089.14, "end": 1090.14, "text": " I agree.",
  "tokens": [50964, 286, 3986, 13, 51014], "temperature": 0.0, "avg_logprob": -0.16034182380227482,
  "compression_ratio": 1.649789029535865, "no_speech_prob": 0.0009954140987247229},
  {"id": 243, "seek": 107714, "start": 1090.14, "end": 1092.14, "text": " You have
  to throw a requirement over the fence. Yeah.", "tokens": [51014, 509, 362, 281,
  3507, 257, 11695, 670, 264, 15422, 13, 865, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.16034182380227482, "compression_ratio": 1.649789029535865, "no_speech_prob":
  0.0009954140987247229}, {"id": 244, "seek": 107714, "start": 1092.14, "end": 1096.14,
  "text": " And then a month later, maybe you get something back, but it''s not quite
  what you want.", "tokens": [51114, 400, 550, 257, 1618, 1780, 11, 1310, 291, 483,
  746, 646, 11, 457, 309, 311, 406, 1596, 437, 291, 528, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.16034182380227482, "compression_ratio": 1.649789029535865,
  "no_speech_prob": 0.0009954140987247229}, {"id": 245, "seek": 107714, "start": 1096.14,
  "end": 1100.14, "text": " You really have to act like one team. Yeah.", "tokens":
  [51314, 509, 534, 362, 281, 605, 411, 472, 1469, 13, 865, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.16034182380227482, "compression_ratio": 1.649789029535865,
  "no_speech_prob": 0.0009954140987247229}, {"id": 246, "seek": 107714, "start": 1100.14,
  "end": 1102.14, "text": " And search is so multi functional.", "tokens": [51514,
  400, 3164, 307, 370, 4825, 11745, 13, 51614], "temperature": 0.0, "avg_logprob":
  -0.16034182380227482, "compression_ratio": 1.649789029535865, "no_speech_prob":
  0.0009954140987247229}, {"id": 247, "seek": 107714, "start": 1102.14, "end": 1103.14,
  "text": " Yeah.", "tokens": [51614, 865, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.16034182380227482, "compression_ratio": 1.649789029535865, "no_speech_prob":
  0.0009954140987247229}, {"id": 248, "seek": 110314, "start": 1103.14, "end": 1111.14,
  "text": " And I''ve seen it at Shopify, the challenge was like infrastructure was
  a different or.", "tokens": [50364, 400, 286, 600, 1612, 309, 412, 43991, 11, 264,
  3430, 390, 411, 6896, 390, 257, 819, 420, 13, 50764], "temperature": 0.0, "avg_logprob":
  -0.23146100791103869, "compression_ratio": 1.5825242718446602, "no_speech_prob":
  0.003333881963044405}, {"id": 249, "seek": 110314, "start": 1111.14, "end": 1119.14,
  "text": " And so we would throw things back and forth over the fence and be not
  quite right. We want to and we have to figure out the right way to partner.", "tokens":
  [50764, 400, 370, 321, 576, 3507, 721, 646, 293, 5220, 670, 264, 15422, 293, 312,
  406, 1596, 558, 13, 492, 528, 281, 293, 321, 362, 281, 2573, 484, 264, 558, 636,
  281, 4975, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23146100791103869,
  "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.003333881963044405},
  {"id": 250, "seek": 110314, "start": 1119.14, "end": 1126.14, "text": " At Reddit,
  it''s a bit more, we have a bit more of a challenge that data is a different group.",
  "tokens": [51164, 1711, 32210, 11, 309, 311, 257, 857, 544, 11, 321, 362, 257, 857,
  544, 295, 257, 3430, 300, 1412, 307, 257, 819, 1594, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.23146100791103869, "compression_ratio": 1.5825242718446602,
  "no_speech_prob": 0.003333881963044405}, {"id": 251, "seek": 112614, "start": 1126.14,
  "end": 1135.14, "text": " So we''re sort of throwing things over the fence, getting
  things back. Yeah. And so we have to like actively work to make sure those partnerships
  are like are healthy. Yeah.", "tokens": [50364, 407, 321, 434, 1333, 295, 10238,
  721, 670, 264, 15422, 11, 1242, 721, 646, 13, 865, 13, 400, 370, 321, 362, 281,
  411, 13022, 589, 281, 652, 988, 729, 18245, 366, 411, 366, 4627, 13, 865, 13, 50814],
  "temperature": 0.0, "avg_logprob": -0.1591036779838696, "compression_ratio": 1.7429577464788732,
  "no_speech_prob": 0.00650776457041502}, {"id": 252, "seek": 112614, "start": 1135.14,
  "end": 1144.14, "text": " But it''s a big challenge. And I think like organizationally,
  there are reasons that companies separate things out that are beyond search.", "tokens":
  [50814, 583, 309, 311, 257, 955, 3430, 13, 400, 286, 519, 411, 4475, 379, 11, 456,
  366, 4112, 300, 3431, 4994, 721, 484, 300, 366, 4399, 3164, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.1591036779838696, "compression_ratio": 1.7429577464788732,
  "no_speech_prob": 0.00650776457041502}, {"id": 253, "seek": 112614, "start": 1144.14,
  "end": 1153.14, "text": " So it''s, it''s not like there''s a easy solution, but
  it''s, it''s definitely when you get to search with these data products, like not
  just search for recommendations and feed and things.", "tokens": [51264, 407, 309,
  311, 11, 309, 311, 406, 411, 456, 311, 257, 1858, 3827, 11, 457, 309, 311, 11, 309,
  311, 2138, 562, 291, 483, 281, 3164, 365, 613, 1412, 3383, 11, 411, 406, 445, 3164,
  337, 10434, 293, 3154, 293, 721, 13, 51714], "temperature": 0.0, "avg_logprob":
  -0.1591036779838696, "compression_ratio": 1.7429577464788732, "no_speech_prob":
  0.00650776457041502}, {"id": 254, "seek": 115314, "start": 1153.14, "end": 1166.14,
  "text": " These become having cross functional partnerships and not only cross functional
  partnerships, but individuals who can work beyond their domain and get them for
  like their multiple hats.", "tokens": [50364, 1981, 1813, 1419, 3278, 11745, 18245,
  293, 406, 787, 3278, 11745, 18245, 11, 457, 5346, 567, 393, 589, 4399, 641, 9274,
  293, 483, 552, 337, 411, 641, 3866, 20549, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.29346837997436526, "compression_ratio": 1.6018518518518519, "no_speech_prob":
  0.049247436225414276}, {"id": 255, "seek": 115314, "start": 1166.14, "end": 1167.14,
  "text": " Yeah.", "tokens": [51014, 865, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.29346837997436526, "compression_ratio": 1.6018518518518519, "no_speech_prob":
  0.049247436225414276}, {"id": 256, "seek": 115314, "start": 1167.14, "end": 1169.14,
  "text": " Is really important.", "tokens": [51064, 1119, 534, 1021, 13, 51164],
  "temperature": 0.0, "avg_logprob": -0.29346837997436526, "compression_ratio": 1.6018518518518519,
  "no_speech_prob": 0.049247436225414276}, {"id": 257, "seek": 115314, "start": 1169.14,
  "end": 1179.14, "text": " Yeah, I think you''re absolutely spot on the, you know,
  and in back in the previous company, declined of silo AI and now I don''t know.",
  "tokens": [51164, 865, 11, 286, 519, 291, 434, 3122, 4008, 322, 264, 11, 291, 458,
  11, 293, 294, 646, 294, 264, 3894, 2237, 11, 29213, 295, 3425, 78, 7318, 293, 586,
  286, 500, 380, 458, 13, 51664], "temperature": 0.0, "avg_logprob": -0.29346837997436526,
  "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.049247436225414276},
  {"id": 258, "seek": 117914, "start": 1179.14, "end": 1195.14, "text": " I feel sort
  of like the same, but one thing I found after like breaking some arrows in the beginning,
  I found that if you can try to find the mutual benefits, that they will be driven
  as well as you.", "tokens": [50364, 286, 841, 1333, 295, 411, 264, 912, 11, 457,
  472, 551, 286, 1352, 934, 411, 7697, 512, 19669, 294, 264, 2863, 11, 286, 1352,
  300, 498, 291, 393, 853, 281, 915, 264, 16917, 5311, 11, 300, 436, 486, 312, 9555,
  382, 731, 382, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2047961378750736,
  "compression_ratio": 1.5228426395939085, "no_speech_prob": 0.3792873024940491},
  {"id": 259, "seek": 117914, "start": 1195.14, "end": 1199.14, "text": " Yeah, you
  don''t know what''s the outcome going to be because experiments are always like
  that. Right.", "tokens": [51164, 865, 11, 291, 500, 380, 458, 437, 311, 264, 9700,
  516, 281, 312, 570, 12050, 366, 1009, 411, 300, 13, 1779, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.2047961378750736, "compression_ratio": 1.5228426395939085,
  "no_speech_prob": 0.3792873024940491}, {"id": 260, "seek": 119914, "start": 1199.14,
  "end": 1212.14, "text": " Yeah, but the fact that we are having an experiment cross
  department, this is amazing. Then you go to all these meetings with executives and
  you say you, you praise them and they probably some way of praise you, like your
  team.", "tokens": [50364, 865, 11, 457, 264, 1186, 300, 321, 366, 1419, 364, 5120,
  3278, 5882, 11, 341, 307, 2243, 13, 1396, 291, 352, 281, 439, 613, 8410, 365, 28485,
  293, 291, 584, 291, 11, 291, 13286, 552, 293, 436, 1391, 512, 636, 295, 13286, 291,
  11, 411, 428, 1469, 13, 51014], "temperature": 0.0, "avg_logprob": -0.20556675946270977,
  "compression_ratio": 1.7011494252873562, "no_speech_prob": 0.618987500667572}, {"id":
  261, "seek": 119914, "start": 1212.14, "end": 1215.14, "text": " And, and that''s
  how you get the right.", "tokens": [51014, 400, 11, 293, 300, 311, 577, 291, 483,
  264, 558, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20556675946270977, "compression_ratio":
  1.7011494252873562, "no_speech_prob": 0.618987500667572}, {"id": 262, "seek": 119914,
  "start": 1215.14, "end": 1219.14, "text": " But, but things happen things happen.
  You just need to be persistent. I guess.", "tokens": [51164, 583, 11, 457, 721,
  1051, 721, 1051, 13, 509, 445, 643, 281, 312, 24315, 13, 286, 2041, 13, 51364],
  "temperature": 0.0, "avg_logprob": -0.20556675946270977, "compression_ratio": 1.7011494252873562,
  "no_speech_prob": 0.618987500667572}, {"id": 263, "seek": 119914, "start": 1219.14,
  "end": 1224.14, "text": " Yeah, things happen all the time. And like, you know,
  organizational changes are like the weather.", "tokens": [51364, 865, 11, 721, 1051,
  439, 264, 565, 13, 400, 411, 11, 291, 458, 11, 24730, 2962, 366, 411, 264, 5503,
  13, 51614], "temperature": 0.0, "avg_logprob": -0.20556675946270977, "compression_ratio":
  1.7011494252873562, "no_speech_prob": 0.618987500667572}, {"id": 264, "seek": 122414,
  "start": 1224.14, "end": 1226.14, "text": " You never know.", "tokens": [50364,
  509, 1128, 458, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3169645083847866,
  "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.048401039093732834},
  {"id": 265, "seek": 122414, "start": 1226.14, "end": 1231.14, "text": " There''s
  going to be a reward for someone comes in with a new perspective or whatever.",
  "tokens": [50464, 821, 311, 516, 281, 312, 257, 7782, 337, 1580, 1487, 294, 365,
  257, 777, 4585, 420, 2035, 13, 50714], "temperature": 0.0, "avg_logprob": -0.3169645083847866,
  "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.048401039093732834},
  {"id": 266, "seek": 122414, "start": 1231.14, "end": 1237.14, "text": " And that''s
  another career lesson is not to get too caught up like emotionally.", "tokens":
  [50714, 400, 300, 311, 1071, 3988, 6898, 307, 406, 281, 483, 886, 5415, 493, 411,
  17991, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3169645083847866, "compression_ratio":
  1.6051502145922747, "no_speech_prob": 0.048401039093732834}, {"id": 267, "seek":
  122414, "start": 1237.14, "end": 1239.14, "text": " Oh, yeah, something happens.",
  "tokens": [51014, 876, 11, 1338, 11, 746, 2314, 13, 51114], "temperature": 0.0,
  "avg_logprob": -0.3169645083847866, "compression_ratio": 1.6051502145922747, "no_speech_prob":
  0.048401039093732834}, {"id": 268, "seek": 122414, "start": 1239.14, "end": 1248.14,
  "text": " Yeah, it''s not a lot of times it''s just that so many things are on your
  control that are just like out in the politics or whatever organization changes
  of the home.", "tokens": [51114, 865, 11, 309, 311, 406, 257, 688, 295, 1413, 309,
  311, 445, 300, 370, 867, 721, 366, 322, 428, 1969, 300, 366, 445, 411, 484, 294,
  264, 7341, 420, 2035, 4475, 2962, 295, 264, 1280, 13, 51564], "temperature": 0.0,
  "avg_logprob": -0.3169645083847866, "compression_ratio": 1.6051502145922747, "no_speech_prob":
  0.048401039093732834}, {"id": 269, "seek": 124814, "start": 1248.14, "end": 1256.14,
  "text": " Yeah, I think it''s sort of mental model called circles of interest in
  the inner one. It''s like your direct control.", "tokens": [50364, 865, 11, 286,
  519, 309, 311, 1333, 295, 4973, 2316, 1219, 13040, 295, 1179, 294, 264, 7284, 472,
  13, 467, 311, 411, 428, 2047, 1969, 13, 50764], "temperature": 0.4, "avg_logprob":
  -0.36006989350190033, "compression_ratio": 1.5692307692307692, "no_speech_prob":
  0.6002137064933777}, {"id": 270, "seek": 124814, "start": 1256.14, "end": 1259.14,
  "text": " It''s probably you your time and whatever.", "tokens": [50764, 467, 311,
  1391, 291, 428, 565, 293, 2035, 13, 50914], "temperature": 0.4, "avg_logprob": -0.36006989350190033,
  "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.6002137064933777},
  {"id": 271, "seek": 124814, "start": 1259.14, "end": 1267.14, "text": " Where you
  work specific tasks. Yeah, another one is like inference. So you cannot control.
  But you can influence people or things or whatever it is.", "tokens": [50914, 2305,
  291, 589, 2685, 9608, 13, 865, 11, 1071, 472, 307, 411, 38253, 13, 407, 291, 2644,
  1969, 13, 583, 291, 393, 6503, 561, 420, 721, 420, 2035, 309, 307, 13, 51314], "temperature":
  0.4, "avg_logprob": -0.36006989350190033, "compression_ratio": 1.5692307692307692,
  "no_speech_prob": 0.6002137064933777}, {"id": 272, "seek": 126714, "start": 1267.14,
  "end": 1274.14, "text": " And the last one is that even if it bothers you, but you
  cannot do anything. So it''s in all control area.", "tokens": [50364, 400, 264,
  1036, 472, 307, 300, 754, 498, 309, 33980, 291, 11, 457, 291, 2644, 360, 1340, 13,
  407, 309, 311, 294, 439, 1969, 1859, 13, 50714], "temperature": 0.0, "avg_logprob":
  -0.24816614931279962, "compression_ratio": 1.5594059405940595, "no_speech_prob":
  0.5769426226615906}, {"id": 273, "seek": 126714, "start": 1274.14, "end": 1281.14,
  "text": " Yeah. So you have to accept it or move on or do something. But don''t
  get stuck on that. So it''s have.", "tokens": [50714, 865, 13, 407, 291, 362, 281,
  3241, 309, 420, 1286, 322, 420, 360, 746, 13, 583, 500, 380, 483, 5541, 322, 300,
  13, 407, 309, 311, 362, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24816614931279962,
  "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.5769426226615906},
  {"id": 274, "seek": 126714, "start": 1281.14, "end": 1284.14, "text": " And things
  of course keep moving between the.", "tokens": [51064, 400, 721, 295, 1164, 1066,
  2684, 1296, 264, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24816614931279962,
  "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.5769426226615906},
  {"id": 275, "seek": 126714, "start": 1284.14, "end": 1288.14, "text": " It''s just
  like dynamic system, but still good to be aware of.", "tokens": [51214, 467, 311,
  445, 411, 8546, 1185, 11, 457, 920, 665, 281, 312, 3650, 295, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.24816614931279962, "compression_ratio": 1.5594059405940595,
  "no_speech_prob": 0.5769426226615906}, {"id": 276, "seek": 128814, "start": 1288.14,
  "end": 1298.14, "text": " And you know, with your way of blogging and book writing
  and yeah, projects you actually have that way of kind of okay, this is stuck. I''m
  going to, you know,", "tokens": [50364, 400, 291, 458, 11, 365, 428, 636, 295, 6968,
  3249, 293, 1446, 3579, 293, 1338, 11, 4455, 291, 767, 362, 300, 636, 295, 733, 295,
  1392, 11, 341, 307, 5541, 13, 286, 478, 516, 281, 11, 291, 458, 11, 50864], "temperature":
  0.0, "avg_logprob": -0.37427713812851326, "compression_ratio": 1.5918367346938775,
  "no_speech_prob": 0.7087719440460205}, {"id": 277, "seek": 128814, "start": 1298.14,
  "end": 1302.14, "text": " relieve stress by blogging, even though writing is.",
  "tokens": [50864, 30450, 4244, 538, 6968, 3249, 11, 754, 1673, 3579, 307, 13, 51064],
  "temperature": 0.0, "avg_logprob": -0.37427713812851326, "compression_ratio": 1.5918367346938775,
  "no_speech_prob": 0.7087719440460205}, {"id": 278, "seek": 128814, "start": 1302.14,
  "end": 1309.14, "text": " Oh, you''re right. I do think like the other career advice
  is like you get hyper focused on one thing.", "tokens": [51064, 876, 11, 291, 434,
  558, 13, 286, 360, 519, 411, 264, 661, 3988, 5192, 307, 411, 291, 483, 9848, 5178,
  322, 472, 551, 13, 51414], "temperature": 0.0, "avg_logprob": -0.37427713812851326,
  "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.7087719440460205},
  {"id": 279, "seek": 130914, "start": 1309.14, "end": 1319.14, "text": " You lose
  the forest for the trees. Yes. And take a step back. Maybe there''s a project that
  you really like that got canceled or something. Yes.", "tokens": [50364, 509, 3624,
  264, 6719, 337, 264, 5852, 13, 1079, 13, 400, 747, 257, 1823, 646, 13, 2704, 456,
  311, 257, 1716, 300, 291, 534, 411, 300, 658, 24839, 420, 746, 13, 1079, 13, 50864],
  "temperature": 0.0, "avg_logprob": -0.13649994243275035, "compression_ratio": 1.7666666666666666,
  "no_speech_prob": 0.4097462296485901}, {"id": 280, "seek": 130914, "start": 1319.14,
  "end": 1322.14, "text": " We''ll take a step back and.", "tokens": [50864, 492,
  603, 747, 257, 1823, 646, 293, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13649994243275035,
  "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.4097462296485901},
  {"id": 281, "seek": 130914, "start": 1322.14, "end": 1324.14, "text": " First of
  all, a year, you don''t remember.", "tokens": [51014, 2386, 295, 439, 11, 257, 1064,
  11, 291, 500, 380, 1604, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13649994243275035,
  "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.4097462296485901},
  {"id": 282, "seek": 130914, "start": 1324.14, "end": 1335.14, "text": " But there
  are so many interesting things to work on. And I think people forget that that there
  is. There''s so many interesting things to work on. And I, you know, I had a brief
  break between Shopify and Reddit.", "tokens": [51114, 583, 456, 366, 370, 867, 1880,
  721, 281, 589, 322, 13, 400, 286, 519, 561, 2870, 300, 300, 456, 307, 13, 821, 311,
  370, 867, 1880, 721, 281, 589, 322, 13, 400, 286, 11, 291, 458, 11, 286, 632, 257,
  5353, 1821, 1296, 43991, 293, 32210, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.13649994243275035, "compression_ratio": 1.7666666666666666, "no_speech_prob":
  0.4097462296485901}, {"id": 283, "seek": 133514, "start": 1335.14, "end": 1341.14,
  "text": " And I, I realized what life would be like when I was retired, because
  I would get up and.", "tokens": [50364, 400, 286, 11, 286, 5334, 437, 993, 576,
  312, 411, 562, 286, 390, 16776, 11, 570, 286, 576, 483, 493, 293, 13, 50664], "temperature":
  0.0, "avg_logprob": -0.1767823455530569, "compression_ratio": 1.718487394957983,
  "no_speech_prob": 0.08263206481933594}, {"id": 284, "seek": 133514, "start": 1341.14,
  "end": 1348.14, "text": " It''s not like I just laid around and nothing. I was just
  like, Oh, what could I play with? What could I do? Oh, there''s a problem. There''s
  that interest and problem.", "tokens": [50664, 467, 311, 406, 411, 286, 445, 9897,
  926, 293, 1825, 13, 286, 390, 445, 411, 11, 876, 11, 437, 727, 286, 862, 365, 30,
  708, 727, 286, 360, 30, 876, 11, 456, 311, 257, 1154, 13, 821, 311, 300, 1179, 293,
  1154, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1767823455530569, "compression_ratio":
  1.718487394957983, "no_speech_prob": 0.08263206481933594}, {"id": 285, "seek": 133514,
  "start": 1348.14, "end": 1358.14, "text": " And that really opens your eyes to that.
  There''s always there''s sort of like more fish in the sea. So to speak of like
  problems to work on or cool stuff.", "tokens": [51014, 400, 300, 534, 9870, 428,
  2575, 281, 300, 13, 821, 311, 1009, 456, 311, 1333, 295, 411, 544, 3506, 294, 264,
  4158, 13, 407, 281, 1710, 295, 411, 2740, 281, 589, 322, 420, 1627, 1507, 13, 51514],
  "temperature": 0.0, "avg_logprob": -0.1767823455530569, "compression_ratio": 1.718487394957983,
  "no_speech_prob": 0.08263206481933594}, {"id": 286, "seek": 135814, "start": 1358.14,
  "end": 1369.14, "text": " So yeah, there was even a study that when people retire
  because they got money or like a lottery or some other wise, they go enjoy life,
  but they also age much quicker.", "tokens": [50364, 407, 1338, 11, 456, 390, 754,
  257, 2979, 300, 562, 561, 10731, 570, 436, 658, 1460, 420, 411, 257, 27391, 420,
  512, 661, 10829, 11, 436, 352, 2103, 993, 11, 457, 436, 611, 3205, 709, 16255, 13,
  50914], "temperature": 0.0, "avg_logprob": -0.21416019698948535, "compression_ratio":
  1.68359375, "no_speech_prob": 0.5870619416236877}, {"id": 287, "seek": 135814, "start":
  1369.14, "end": 1374.14, "text": " And sometimes they unfortunately die quicker
  because they have nothing to sort of strive for.", "tokens": [50914, 400, 2171,
  436, 7015, 978, 16255, 570, 436, 362, 1825, 281, 1333, 295, 23829, 337, 13, 51164],
  "temperature": 0.0, "avg_logprob": -0.21416019698948535, "compression_ratio": 1.68359375,
  "no_speech_prob": 0.5870619416236877}, {"id": 288, "seek": 135814, "start": 1374.14,
  "end": 1375.14, "text": " Yeah.", "tokens": [51164, 865, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.21416019698948535, "compression_ratio": 1.68359375, "no_speech_prob":
  0.5870619416236877}, {"id": 289, "seek": 135814, "start": 1375.14, "end": 1386.14,
  "text": " So that''s that''s really really cool advice. And if this was not enough,
  all this cute bit search array, blogging, of course, work and other things podcasting
  now.", "tokens": [51214, 407, 300, 311, 300, 311, 534, 534, 1627, 5192, 13, 400,
  498, 341, 390, 406, 1547, 11, 439, 341, 4052, 857, 3164, 10225, 11, 6968, 3249,
  11, 295, 1164, 11, 589, 293, 661, 721, 7367, 278, 586, 13, 51764], "temperature":
  0.0, "avg_logprob": -0.21416019698948535, "compression_ratio": 1.68359375, "no_speech_prob":
  0.5870619416236877}, {"id": 290, "seek": 138614, "start": 1386.14, "end": 1396.14,
  "text": " You also write a book tell me a bit more about that before we close. Oh,
  yeah, yeah, it''s it''s it''s you just joked on the stage that the idea came to
  2018.", "tokens": [50364, 509, 611, 2464, 257, 1446, 980, 385, 257, 857, 544, 466,
  300, 949, 321, 1998, 13, 876, 11, 1338, 11, 1338, 11, 309, 311, 309, 311, 309, 311,
  291, 445, 361, 9511, 322, 264, 3233, 300, 264, 1558, 1361, 281, 6096, 13, 50864],
  "temperature": 0.0, "avg_logprob": -0.28647143805204933, "compression_ratio": 1.4871794871794872,
  "no_speech_prob": 0.14315122365951538}, {"id": 291, "seek": 138614, "start": 1396.14,
  "end": 1401.14, "text": " Yeah, so tray tray and a share of the book. So trace the
  primary author and.", "tokens": [50864, 865, 11, 370, 16027, 16027, 293, 257, 2073,
  295, 264, 1446, 13, 407, 13508, 264, 6194, 3793, 293, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.28647143805204933, "compression_ratio": 1.4871794871794872,
  "no_speech_prob": 0.14315122365951538}, {"id": 292, "seek": 140114, "start": 1401.14,
  "end": 1415.14, "text": " tray came to me and I think 2018 said, Hey, I want to
  let you know I''m writing a search book. I think I''ll be done and I want to really,
  you know, for work and my wife and everything and family. I want to be done in six
  months and I''m stressed everyone out.", "tokens": [50364, 16027, 1361, 281, 385,
  293, 286, 519, 6096, 848, 11, 1911, 11, 286, 528, 281, 718, 291, 458, 286, 478,
  3579, 257, 3164, 1446, 13, 286, 519, 286, 603, 312, 1096, 293, 286, 528, 281, 534,
  11, 291, 458, 11, 337, 589, 293, 452, 3836, 293, 1203, 293, 1605, 13, 286, 528,
  281, 312, 1096, 294, 2309, 2493, 293, 286, 478, 14471, 1518, 484, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.1892619640269178, "compression_ratio": 1.6650246305418719,
  "no_speech_prob": 0.4966784715652466}, {"id": 293, "seek": 140114, "start": 1415.14,
  "end": 1420.14, "text": " And here we are. It''s, you know, there was a pandemic.
  There was a lot of stuff.", "tokens": [51064, 400, 510, 321, 366, 13, 467, 311,
  11, 291, 458, 11, 456, 390, 257, 5388, 13, 821, 390, 257, 688, 295, 1507, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.1892619640269178, "compression_ratio": 1.6650246305418719,
  "no_speech_prob": 0.4966784715652466}, {"id": 294, "seek": 142014, "start": 1420.14,
  "end": 1432.14, "text": " But it''s 2024 and it''s funny because the nature what
  you might refer to as AI in 2018, of course, is now is LLM''s and these things.",
  "tokens": [50364, 583, 309, 311, 45237, 293, 309, 311, 4074, 570, 264, 3687, 437,
  291, 1062, 2864, 281, 382, 7318, 294, 6096, 11, 295, 1164, 11, 307, 586, 307, 441,
  43, 44, 311, 293, 613, 721, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2590762107603012,
  "compression_ratio": 1.3757575757575757, "no_speech_prob": 0.4854569137096405},
  {"id": 295, "seek": 142014, "start": 1432.14, "end": 1441.14, "text": " But it''s
  really exciting. I think like a lot of the things in the book are timeless techniques.",
  "tokens": [50964, 583, 309, 311, 534, 4670, 13, 286, 519, 411, 257, 688, 295, 264,
  721, 294, 264, 1446, 366, 41200, 7512, 13, 51414], "temperature": 0.0, "avg_logprob":
  -0.2590762107603012, "compression_ratio": 1.3757575757575757, "no_speech_prob":
  0.4854569137096405}, {"id": 296, "seek": 144114, "start": 1441.14, "end": 1449.14,
  "text": " We initially focused the book on solar, but we''re taking we took a step
  back when we said let''s make this applicable to many search engines. Yeah.", "tokens":
  [50364, 492, 9105, 5178, 264, 1446, 322, 7936, 11, 457, 321, 434, 1940, 321, 1890,
  257, 1823, 646, 562, 321, 848, 718, 311, 652, 341, 21142, 281, 867, 3164, 12982,
  13, 865, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25826309124628705, "compression_ratio":
  1.6311475409836065, "no_speech_prob": 0.35062384605407715}, {"id": 297, "seek":
  144114, "start": 1449.14, "end": 1459.14, "text": " And there are examples being
  worked on for many platforms. It''s the ecosystem is so huge now. There''s all kinds
  of vector databases that are even adding lexical sir.", "tokens": [50764, 400, 456,
  366, 5110, 885, 2732, 322, 337, 867, 9473, 13, 467, 311, 264, 11311, 307, 370, 2603,
  586, 13, 821, 311, 439, 3685, 295, 8062, 22380, 300, 366, 754, 5127, 476, 87, 804,
  4735, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25826309124628705, "compression_ratio":
  1.6311475409836065, "no_speech_prob": 0.35062384605407715}, {"id": 298, "seek":
  144114, "start": 1459.14, "end": 1463.14, "text": " And then there''s of course
  solar elastic search. There''s open search. There''s a best.", "tokens": [51264,
  400, 550, 456, 311, 295, 1164, 7936, 17115, 3164, 13, 821, 311, 1269, 3164, 13,
  821, 311, 257, 1151, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25826309124628705,
  "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.35062384605407715},
  {"id": 299, "seek": 146314, "start": 1463.14, "end": 1473.14, "text": " Yeah. In
  this more and more traditional space. And so like I worked primarily on the learning
  terrain content.", "tokens": [50364, 865, 13, 682, 341, 544, 293, 544, 5164, 1901,
  13, 400, 370, 411, 286, 2732, 10029, 322, 264, 2539, 17674, 2701, 13, 50864], "temperature":
  0.0, "avg_logprob": -0.1641262875327581, "compression_ratio": 1.6729857819905214,
  "no_speech_prob": 0.2525365948677063}, {"id": 300, "seek": 146314, "start": 1473.14,
  "end": 1489.14, "text": " And so a lot of the things about how you get training
  data or train a model or how you evaluate these things, how you expose users to
  search results that are maybe a bit novel, like you do a little exploration to build
  out your training data.", "tokens": [50864, 400, 370, 257, 688, 295, 264, 721, 466,
  577, 291, 483, 3097, 1412, 420, 3847, 257, 2316, 420, 577, 291, 13059, 613, 721,
  11, 577, 291, 19219, 5022, 281, 3164, 3542, 300, 366, 1310, 257, 857, 7613, 11,
  411, 291, 360, 257, 707, 16197, 281, 1322, 484, 428, 3097, 1412, 13, 51664], "temperature":
  0.0, "avg_logprob": -0.1641262875327581, "compression_ratio": 1.6729857819905214,
  "no_speech_prob": 0.2525365948677063}, {"id": 301, "seek": 148914, "start": 1489.14,
  "end": 1498.14, "text": " And so these things are regardless of where search goes
  or where rag goes for whatever.", "tokens": [50364, 400, 370, 613, 721, 366, 10060,
  295, 689, 3164, 1709, 420, 689, 17539, 1709, 337, 2035, 13, 50814], "temperature":
  0.0, "avg_logprob": -0.18054664668752185, "compression_ratio": 1.5792349726775956,
  "no_speech_prob": 0.1436457633972168}, {"id": 302, "seek": 148914, "start": 1498.14,
  "end": 1514.14, "text": " It''s there are still very relevant. And it feels like
  in a way, a lot of how users are interacting with with the world and with products
  is through some kind of search or some kind of retrieval system.", "tokens": [50814,
  467, 311, 456, 366, 920, 588, 7340, 13, 400, 309, 3417, 411, 294, 257, 636, 11,
  257, 688, 295, 577, 5022, 366, 18017, 365, 365, 264, 1002, 293, 365, 3383, 307,
  807, 512, 733, 295, 3164, 420, 512, 733, 295, 19817, 3337, 1185, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.18054664668752185, "compression_ratio": 1.5792349726775956,
  "no_speech_prob": 0.1436457633972168}, {"id": 303, "seek": 151414, "start": 1514.14,
  "end": 1522.14, "text": " Even if it''s a recommendation system or a feature some
  that''s becoming feeling more like search where it''s like real time and I''m getting
  the stuff updated in real time.", "tokens": [50364, 2754, 498, 309, 311, 257, 11879,
  1185, 420, 257, 4111, 512, 300, 311, 5617, 2633, 544, 411, 3164, 689, 309, 311,
  411, 957, 565, 293, 286, 478, 1242, 264, 1507, 10588, 294, 957, 565, 13, 50764],
  "temperature": 0.0, "avg_logprob": -0.29161275443384205, "compression_ratio": 1.475609756097561,
  "no_speech_prob": 0.17734618484973907}, {"id": 304, "seek": 151414, "start": 1522.14,
  "end": 1527.14, "text": " And of course, rag is searched. So I think search is still
  there, right?", "tokens": [50764, 400, 295, 1164, 11, 17539, 307, 22961, 13, 407,
  286, 519, 3164, 307, 920, 456, 11, 558, 30, 51014], "temperature": 0.0, "avg_logprob":
  -0.29161275443384205, "compression_ratio": 1.475609756097561, "no_speech_prob":
  0.17734618484973907}, {"id": 305, "seek": 152714, "start": 1527.14, "end": 1538.14,
  "text": " And I think it''s going over the world and on which I realize some crowd
  is now gathering to have lunch and we will have lunch soon as well.", "tokens":
  [50364, 400, 286, 519, 309, 311, 516, 670, 264, 1002, 293, 322, 597, 286, 4325,
  512, 6919, 307, 586, 13519, 281, 362, 6349, 293, 321, 486, 362, 6349, 2321, 382,
  731, 13, 50914], "temperature": 0.0, "avg_logprob": -0.4734039306640625, "compression_ratio":
  1.555, "no_speech_prob": 0.8607131838798523}, {"id": 306, "seek": 152714, "start":
  1538.14, "end": 1551.14, "text": " It''s always a pleasure to talk to you and finally
  in person I think we''ve never met but I think if you''ve been to a new senior revolution
  in 2003, seeing around an island.", "tokens": [50914, 467, 311, 1009, 257, 6834,
  281, 751, 281, 291, 293, 2721, 294, 954, 286, 519, 321, 600, 1128, 1131, 457, 286,
  519, 498, 291, 600, 668, 281, 257, 777, 7965, 8894, 294, 16416, 11, 2577, 926, 364,
  6077, 13, 51564], "temperature": 0.0, "avg_logprob": -0.4734039306640625, "compression_ratio":
  1.555, "no_speech_prob": 0.8607131838798523}, {"id": 307, "seek": 155114, "start":
  1551.14, "end": 1559.14, "text": " I''ve been there as well. Is that the one in
  San Diego or no, no, in Dublin, in Dublin, yeah, I''ve been there. Yes, I wasn''t.
  Yeah, yeah.", "tokens": [50364, 286, 600, 668, 456, 382, 731, 13, 1119, 300, 264,
  472, 294, 5271, 16377, 420, 572, 11, 572, 11, 294, 42323, 11, 294, 42323, 11, 1338,
  11, 286, 600, 668, 456, 13, 1079, 11, 286, 2067, 380, 13, 865, 11, 1338, 13, 50764],
  "temperature": 0.0, "avg_logprob": -0.4421159602977611, "compression_ratio": 1.5963302752293578,
  "no_speech_prob": 0.7104085087776184}, {"id": 308, "seek": 155114, "start": 1559.14,
  "end": 1566.14, "text": " Then I need in there to, you know, to go high. But you
  know, that''s when I introduced Kupit actually.", "tokens": [50764, 1396, 286, 643,
  294, 456, 281, 11, 291, 458, 11, 281, 352, 1090, 13, 583, 291, 458, 11, 300, 311,
  562, 286, 7268, 591, 1010, 270, 767, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.4421159602977611, "compression_ratio": 1.5963302752293578, "no_speech_prob":
  0.7104085087776184}, {"id": 309, "seek": 155114, "start": 1566.14, "end": 1568.14,
  "text": " Yeah, I know.", "tokens": [51114, 865, 11, 286, 458, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.4421159602977611, "compression_ratio": 1.5963302752293578,
  "no_speech_prob": 0.7104085087776184}, {"id": 310, "seek": 155114, "start": 1568.14,
  "end": 1574.14, "text": " It''s amazing. The workter. Yeah. That''s a still relevant
  project. It''s running 2013 JavaScript.", "tokens": [51214, 467, 311, 2243, 13,
  440, 589, 391, 13, 865, 13, 663, 311, 257, 920, 7340, 1716, 13, 467, 311, 2614,
  9012, 15778, 13, 51514], "temperature": 0.0, "avg_logprob": -0.4421159602977611,
  "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.7104085087776184},
  {"id": 311, "seek": 157414, "start": 1574.14, "end": 1579.14, "text": " Yeah, and
  I''ve been consistently deploying it in every company I agree.", "tokens": [50364,
  865, 11, 293, 286, 600, 668, 14961, 34198, 309, 294, 633, 2237, 286, 3986, 13, 50614],
  "temperature": 0.0, "avg_logprob": -0.27200904846191404, "compression_ratio": 1.5020242914979758,
  "no_speech_prob": 0.6817588210105896}, {"id": 312, "seek": 157414, "start": 1579.14,
  "end": 1586.14, "text": " So in Tom Tom, we just released a new algorithm to production.
  Thanks to Kupit in two weeks.", "tokens": [50614, 407, 294, 5041, 5041, 11, 321,
  445, 4736, 257, 777, 9284, 281, 4265, 13, 2561, 281, 591, 1010, 270, 294, 732, 3259,
  13, 50964], "temperature": 0.0, "avg_logprob": -0.27200904846191404, "compression_ratio":
  1.5020242914979758, "no_speech_prob": 0.6817588210105896}, {"id": 313, "seek": 157414,
  "start": 1586.14, "end": 1592.14, "text": " It was, it was on the bookshelf for
  quite some time because the team couldn''t figure out how to test equality.", "tokens":
  [50964, 467, 390, 11, 309, 390, 322, 264, 1446, 46626, 337, 1596, 512, 565, 570,
  264, 1469, 2809, 380, 2573, 484, 577, 281, 1500, 14949, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.27200904846191404, "compression_ratio": 1.5020242914979758,
  "no_speech_prob": 0.6817588210105896}, {"id": 314, "seek": 157414, "start": 1592.14,
  "end": 1598.14, "text": " And I said, okay, let''s just do labeling, right? And
  let''s use Q. Yeah, just simple labels and.", "tokens": [51264, 400, 286, 848, 11,
  1392, 11, 718, 311, 445, 360, 40244, 11, 558, 30, 400, 718, 311, 764, 1249, 13,
  865, 11, 445, 2199, 16949, 293, 13, 51564], "temperature": 0.0, "avg_logprob": -0.27200904846191404,
  "compression_ratio": 1.5020242914979758, "no_speech_prob": 0.6817588210105896},
  {"id": 315, "seek": 159814, "start": 1598.14, "end": 1607.14, "text": " And we saw
  like more than 10% increase in precision with new algorithm. And they said, as a
  product manager, I approved the release. Let''s go.", "tokens": [50364, 400, 321,
  1866, 411, 544, 813, 1266, 4, 3488, 294, 18356, 365, 777, 9284, 13, 400, 436, 848,
  11, 382, 257, 1674, 6598, 11, 286, 10826, 264, 4374, 13, 961, 311, 352, 13, 50814],
  "temperature": 0.0, "avg_logprob": -0.2732205240350021, "compression_ratio": 1.5493562231759657,
  "no_speech_prob": 0.276660293340683}, {"id": 316, "seek": 159814, "start": 1607.14,
  "end": 1610.14, "text": " That''s also that''s great. Thanks for creating the tool.",
  "tokens": [50814, 663, 311, 611, 300, 311, 869, 13, 2561, 337, 4084, 264, 2290,
  13, 50964], "temperature": 0.0, "avg_logprob": -0.2732205240350021, "compression_ratio":
  1.5493562231759657, "no_speech_prob": 0.276660293340683}, {"id": 317, "seek": 159814,
  "start": 1610.14, "end": 1619.14, "text": " Great. Sure. Happy to have a lot of
  making tools. Yeah. Thanks for a time, Doug. Enjoy the conference. Thank you. Stay
  in Berlin. Yes. Thank you. Awesome. Thanks.", "tokens": [50964, 3769, 13, 4894,
  13, 8277, 281, 362, 257, 688, 295, 1455, 3873, 13, 865, 13, 2561, 337, 257, 565,
  11, 12742, 13, 15411, 264, 7586, 13, 1044, 291, 13, 8691, 294, 13848, 13, 1079,
  13, 1044, 291, 13, 10391, 13, 2561, 13, 51414], "temperature": 0.0, "avg_logprob":
  -0.2732205240350021, "compression_ratio": 1.5493562231759657, "no_speech_prob":
  0.276660293340683}, {"id": 318, "seek": 162814, "start": 1628.14, "end": 1631.14,
  "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50514], "temperature": 0.0,
  "avg_logprob": -0.7868684927622477, "compression_ratio": 0.5555555555555556, "no_speech_prob":
  0.9280984997749329}]'
---

A timeick Cool. Yeah. Hello, how are you? Hi, Doug. It's great meeting you at Berlin Boswords. Yeah, I can see you. Yeah, great to see you. It's your second time on the podcast and yeah, excited to be back. Yeah, awesome. I think it's like two years or only one. Yeah, I think so.
But how have you been? I wasn't going. I've been great. Just been doing traditional learning to rank over at Reddit. And it's been a lot of fun. A lot of it's just meat and potato stuff. Yeah. The stuff that I think is really important like your training data with search.
And you're getting your features right and that sort of thing. Not actually too much vector search lately. So kind of.
Having a path in the ranking model space and I still think that's really important for if you're building a rag app or if you're building a lot of these things, a lot of people are sort of discovering this through the vector route.
They're like realizing there's a small other side of information retrieval. Yeah, that's important. And that's that's really exciting to me because I think a lot of new ideas that suffer coming in the space. Yeah, yeah. Yeah, amazing talk as well. I'm sure we'll link it.
What was it's published? The one you just gave. And you also reminded me of time as I told you, you know, of the time when I was working on solar. Starting at version one.
It was each to ask you which version you're running, but then I was like, what will it matter to me? Well, it's we were running solar seven until recently and one of the things you didn't talk about in the talk was having performance problems with solar seven. Yeah.
And moving to solar nine fixed it. So it helped with a lot of stability and performance problems. And that's just one of those things that a lot of these projects machine like not just like learning to rank is like a lot of machine learning projects.
You what I find is especially learning to rank you're often like building out and scaling up infrastructure for a certain problem at the same time you're doing machine learning. Yeah. So it's it's you're finding these problems. Yeah, and you will spend weeks.
Yeah, or month like why is this slow? It's unexpectedly slow. What's behind it is and then you realize, oh, solar nine doesn't have this problem and will resolve it. Yeah. And we were already upgrading. So like, okay, we can put this. We don't have to stress out about this performance problem.
That's why it takes a year to year. For these projects. Yeah, yeah, start to show. Yeah. I also would like to say thank you for your project that I think you started back at OEC Open Source Connections. Yeah. Hello LTR. Yeah. I think it's still out there and it's out. That's a great project.
Yeah, it really allowed me to quickly, you know, jump on the on the train and start moving because I was actually alone on the team. I did do search before, but it wasn't related to a mile at all, right? It was like feature engineering button at different side of things and.
Yeah, so thanks for that. Really? Yeah. I think I think it's really important and one thing I think it's the career advice that's helped me is to learn in public. So a lot of hello LTR came up when I was learning how to do LTR. And I had to get some examples and like try different things out.
And then as I made mistakes, those mistakes became lessons for the LTR training that came out of hello LTR, also called hello LTR that open source connection it does. So it's I really encourage people like the best way the best teachers are often people actively learning.
Yeah, because you will encounter the mistakes that the experts forgot about. I couldn't tell you about how to learn how a loop worked from Python because I've done too long.
But the person who would teach, have the empathy to teach that really well to someone learning that's scratch would be probably my son if he was learning Python for so.
So I really encourage like be out there speaking, blogging, yeah, because you'll have insight to how to teach a product that expert won't. Yeah, that's that's another side of your professional life that amazes me is that how do you find time to block so it's like.
And that those are really deep things sometimes you go into detail with its code or you offer some thought model like do you sleep at all. I think I just have a high tolerance for making mistakes in public. And also I think a lot of it has to do with having a history degree.
Oh really, I didn't know that. Yeah, history and computer science. So when you get when you do history. It's a lot of writing writing writing, writing, reporting writing and then a lot of it's also when you get to this your senior level history.
It's like not just writing an essay, but can you write your argument in a single page. And so that's which is funny because you think when you're a student, you think I'm going to make the margins big and I'm going to make the text big so I can take up more space.
Yeah, when you start writing a lot, you tend to write you tend to get really verbose. Yeah, then you have to learn to make your arguments like exactly. Yes, and shorter. And yeah, so.
Yeah, it also now when I'm doing the product management role, I have I do not have a history degree like you, but I have to write some things in a concise way. Sometimes they say you have to remove half of the page because you're not feeding the page limit. I make that mistake all the time.
Yeah, how many one pageers are exactly like 10 pages. And another thing is like never talk about hypothetical future because you don't even know yourself what it will happen or not, right.
Yeah, only talk either talk about things that you're absolutely certain have happened or you certain that they have planned already, right. Yeah, that's how we do the product management.
Yeah, it teaches that that's the side of things, but I guess what I do is out and I then go to blogging and and and and use you as a great example there. You go and unleash yourself and blogging and you write what you want, right.
But you still need to what you want said that you became more successful blogger at the moment you actually started modeling that specific person you're writing to not an abstract audience and not yourself because you're not writing. And so is this how you still perceive it.
Well, I definitely write to myself six months from now, but I also write the audience I imagine is like a close group of friends. So I almost think about blogging as sometimes and this is easy. It's easy for people often to imagine sitting down and writing a long email or Slack message.
And what if you just turn that into a blog post. Yeah. And to me, that's that's an inspiration for this so many times you get excited about something and want to send a message to your friends. Yeah, and share it.
Well, turn that enthusiasm and that message into a blog post and then that those are the best blog posts. And I also think it's really important to remember it's blogging. It's like it's a step above writing us a from a post. It's very informal. Don't take it too seriously.
You will make mistakes exactly. You will it's and it's a do it for fun. Yeah. But yeah, I do it a lot because I want. I think I I there's a meme of like someone starting out on something. Yeah, someone being very senior and then or someone being like mid career and then someone.
Super senior in their career. And often the like starting out this meme starting out super senior are the same. And it's like my version of that is doing when you start out you code and do stuff to impress your friends like in high school or whatever.
And then you get like all worried about like having some big impact and like. Impressing the whole world. And then when you get super senior again, you're just like I just want to like do full stuff to impress my friends. Yeah.
And which actually turns out also to be stuff that the whole world cares about because usually your friends are. Like doing cool stuff themselves like you know vector searcher or doing cool AI stuff. Yeah. So it turns out that the rest of the world finds that it's interesting to.
But I think that's a really important thing to have an authentic voice. Yeah. So it's also part of the building up your profile. Yeah. Yeah. So I think like Steve Jobs, I think I think said like computer is a bicycle for the mind, right? And so blogging is also in a way bicycle for the mind.
You have to rework yourself. Right. It's it's also the programming that you do on the site like searcher rate. So tell me more about what was the motivation. Why did you start working? So I think I like to go against the grain a little bit.
So I actually had worked on different versions of vector search for a long time before this for craze. And different hacks and things to make vector search work in a in the current in the solar or last search world. So everyone's in vector search.
And I decided that in part because I wanted to get do a little bit more native programming. Get facts. I used to do that. I used to be a C programmer. Yeah. And I found that. Vector search is very welcoming to machine learning engineer data science community.
But the traditional lexical search engines like solar and elastic search. They're very weird. Yeah. They're very like you have to know this weird query DSL. You have to understand these things. Organization. So I wanted to take that.
And take that lexical world and bring it into a data science or data high data sort of environment. And then I found that it's very comfortable to machine learning people and data science. Yeah. So I built search array. And what search array.
The reason I built that what that does is it's basically a lexical extension to pandas. So if I have text. I can make a pandas column that's just like tokenized text. And then I can ask it to score against a keyword and get a BM25 score. And this was so in a co lab notebook or something.
I can quickly further set ideas while having to stand up solar elastic search. Yeah. Or think about Docker container and all this stuff. And I said I could see like, OK, I want to tokenize things a certain way. I want to score change the BM25 scoring to be a certain way. Yeah.
And which is you think about like 90% of what you do in lexical search engine is tweaking the tokenization. Yeah. Finging the scoring, trying to index something new and search against that. Like, oh, I have any recognition field now. No. Oh, it's and the other thing is what.
The other thing you do a lot in lexical search engines is I want to boost by recency. And I want to. Do these other things. And a lot of these things can just be done with a really fast like I take this column. New miracle date column. In pandas. Yeah.
And I want to add a score, a num tier ray that's a BM25 score. I multiply them together. Yeah. I have a score that's a recency weighted. Yeah. What does that look like in terms of my offline metrics? Yeah. Interesting.
Without having to go off to like, you have to go out elastic search and like that. Assuteric stuff. So basically it allows you to try out some ideas really quickly, right? But then there will be some kind of offset compared with the reality because tokenizing is in solar probably work differently.
Yeah. But that would be different probably will be close enough right? So it's also if you nailed the signal that like you explained today in your presentation, you know, what about a number of comments or what about you know the recent sea and so on. Yeah, all of these be on the board.
And I'll like try that really quickly. Yeah. Yeah. And a lot of times it's, it's a big effort to index some new data into the search engine. Yeah. And you have to go is the upstream system fast enough to handle those load and then stay up to date. And really to justify a project. Yeah.
You might start with a prototype and say, OK, I just pull for a small. Small chest set of data. Yeah. I pulled in some data. It seems like there's some signal here. Yeah. Let's plan a project around it. Yeah. And so this is to me. And actually I'll, my sees the conference after blue and buzzwords.
I'll talk about planning. But to me, a lot of this like how do we build better prototypes to build plans and have ideas and have conversations between engineers data scientists and product managers is really one of the inspirations for search array.
Because to do this before I'd be like, OK, I have to stand up some examples, certain custom. Yeah, yeah, yeah, yeah, spend time on that. Yeah, how am I going to absolutely locate a cluster and whatnot. Yeah, exactly. Yeah.
And I think I actually this reminded me when I was working on the learning to rank. And this was the last project I did in my 10 year tenure at Alpha Cent. I said, Hey, can I have this really expensive laptop? So it would be like 30 gig around one terabyte drive.
I thought I need so much space for some reason. And it was SSD. And and I got it approved. It was like, oh, my God. So many. So and I spent like a year working on it and was kind of like bloated version of search array because I could do everything on the laptop. This connected right.
The only problem I remember was tracking my experiment tree because I would like. Let's the right word for Kate or like kind of branch out. That's right. And then like, OK, should I go back now because retreat because looks looks like I went down the rabbit hole and it doesn't give at any value.
So you go back to that state when it was that bigger, you know, and this is you or whatever, right? So instead of from there, that sounds a lot of like what some of the functionality in cute that the sort of like search relevance turning tool to you, you, you, PID.
Because I remember when I was building that many years ago. It was very much like every time you submit like you tweak the query and it saves that as a try. Yeah, another time you can't fork off stuff, but you can go back and be like, oh, this thing didn't work out. I'm going to go back.
And yeah, it's it is funny how yeah, I have the same feeling. And even in a notebook environment. I don't have that because notebooks. And you tweak a little bit, you forget what happened. You like, why did I thought my end ECG was good and I got bad.
What did I do wrong? You wish that you were like somehow the notebook was like versioning itself as you were going. Yeah, exactly. And but and like somehow the whole environment was version, but yeah, that doesn't exist. I wish that kind of thing existed.
Yeah, there was there was a tool we were using, but then it was acquired by some company. It was called spell dot run. So basically was like a integrated Python notebook environment that runs a cluster. And they were heading in the direction. I was giving a lot of feedback to them.
Hey, can you actually build an infrastructure, which will allow me to also, you know, maintain my branched out, you know, experiment. And I think they got acquired probably short before they could do this and probably they continue doing this. I don't know.
But there is another project called DVC, I think, which allows you to basically maintain your experiments as deep hashes, right. So you basically, you can, you can, you can get cash your code along with your data. And then you upload your data.
Let's say to some cloud, I don't know, drive some drive abstract one. And then you have your code associated with that. So you can basically restore you or someone else that can restore the experiment. I think if that if that was frictionless, right.
Or even the matter of it existing, right, because I had to literally like write something down on a piece of paper to remember what I need to do. You know, sometimes I would go crazy at shopify. So we had a, we had a, our testing, search testing infrastructure, the notebooks.
So everything was in a monorepo. So you could stand up elastic search. And you could have, we had a, this is a rails environment.
There's a, all the relevance logic was in a Ruby library that we, a rails monolith would load and so call in the network call, a lasso search and do whatever, pre and post processing. But when we stood up the test environment, we would say, we wanted to load this.
We wanted to load the right configs, but we would basically put the company commit tasks of the repo that we, that it was supposed to be and it would load the config and it would be amazing. But yeah, it's, it's getting reproducible environments. Yeah, and experiments is a challenge.
This is where, I mean, at some point, basically like your experiment rate will be, you know, trumped by how quickly you can deploy this or how quickly you can like, shuffle things, right? So yeah, I think so. This is where infrastructure comes as a big topic and in your talk.
Yeah, I think you spent a good, yeah. Yeah. I think it's like partnership, right? So we had a, there has to be like a big steam in my career too as partnerships like partnerships with PM partnerships with data. Yeah, partnerships with infrastructure.
You really have to have one cohesive team and one of the anti patterns is when they're so separate that it creates. I agree. You have to throw a requirement over the fence. Yeah. And then a month later, maybe you get something back, but it's not quite what you want.
You really have to act like one team. Yeah. And search is so multi functional. Yeah. And I've seen it at Shopify, the challenge was like infrastructure was a different or. And so we would throw things back and forth over the fence and be not quite right.
We want to and we have to figure out the right way to partner. At Reddit, it's a bit more, we have a bit more of a challenge that data is a different group. So we're sort of throwing things over the fence, getting things back. Yeah.
And so we have to like actively work to make sure those partnerships are like are healthy. Yeah. But it's a big challenge. And I think like organizationally, there are reasons that companies separate things out that are beyond search.
So it's, it's not like there's a easy solution, but it's, it's definitely when you get to search with these data products, like not just search for recommendations and feed and things.
These become having cross functional partnerships and not only cross functional partnerships, but individuals who can work beyond their domain and get them for like their multiple hats. Yeah. Is really important.
Yeah, I think you're absolutely spot on the, you know, and in back in the previous company, declined of silo AI and now I don't know.
I feel sort of like the same, but one thing I found after like breaking some arrows in the beginning, I found that if you can try to find the mutual benefits, that they will be driven as well as you. Yeah, you don't know what's the outcome going to be because experiments are always like that.
Right. Yeah, but the fact that we are having an experiment cross department, this is amazing. Then you go to all these meetings with executives and you say you, you praise them and they probably some way of praise you, like your team. And, and that's how you get the right.
But, but things happen things happen. You just need to be persistent. I guess. Yeah, things happen all the time. And like, you know, organizational changes are like the weather. You never know. There's going to be a reward for someone comes in with a new perspective or whatever.
And that's another career lesson is not to get too caught up like emotionally. Oh, yeah, something happens. Yeah, it's not a lot of times it's just that so many things are on your control that are just like out in the politics or whatever organization changes of the home.
Yeah, I think it's sort of mental model called circles of interest in the inner one. It's like your direct control. It's probably you your time and whatever. Where you work specific tasks. Yeah, another one is like inference. So you cannot control.
But you can influence people or things or whatever it is. And the last one is that even if it bothers you, but you cannot do anything. So it's in all control area. Yeah. So you have to accept it or move on or do something. But don't get stuck on that. So it's have.
And things of course keep moving between the. It's just like dynamic system, but still good to be aware of. And you know, with your way of blogging and book writing and yeah, projects you actually have that way of kind of okay, this is stuck.
I'm going to, you know, relieve stress by blogging, even though writing is. Oh, you're right. I do think like the other career advice is like you get hyper focused on one thing. You lose the forest for the trees. Yes. And take a step back.
Maybe there's a project that you really like that got canceled or something. Yes. We'll take a step back and. First of all, a year, you don't remember. But there are so many interesting things to work on. And I think people forget that that there is. There's so many interesting things to work on.
And I, you know, I had a brief break between Shopify and Reddit. And I, I realized what life would be like when I was retired, because I would get up and. It's not like I just laid around and nothing. I was just like, Oh, what could I play with? What could I do? Oh, there's a problem.
There's that interest and problem. And that really opens your eyes to that. There's always there's sort of like more fish in the sea. So to speak of like problems to work on or cool stuff.
So yeah, there was even a study that when people retire because they got money or like a lottery or some other wise, they go enjoy life, but they also age much quicker. And sometimes they unfortunately die quicker because they have nothing to sort of strive for. Yeah.
So that's that's really really cool advice. And if this was not enough, all this cute bit search array, blogging, of course, work and other things podcasting now. You also write a book tell me a bit more about that before we close.
Oh, yeah, yeah, it's it's it's you just joked on the stage that the idea came to 2018. Yeah, so tray tray and a share of the book. So trace the primary author and. tray came to me and I think 2018 said, Hey, I want to let you know I'm writing a search book.
I think I'll be done and I want to really, you know, for work and my wife and everything and family. I want to be done in six months and I'm stressed everyone out. And here we are. It's, you know, there was a pandemic. There was a lot of stuff.
But it's 2024 and it's funny because the nature what you might refer to as AI in 2018, of course, is now is LLM's and these things. But it's really exciting. I think like a lot of the things in the book are timeless techniques.
We initially focused the book on solar, but we're taking we took a step back when we said let's make this applicable to many search engines. Yeah. And there are examples being worked on for many platforms. It's the ecosystem is so huge now.
There's all kinds of vector databases that are even adding lexical sir. And then there's of course solar elastic search. There's open search. There's a best. Yeah. In this more and more traditional space. And so like I worked primarily on the learning terrain content.
And so a lot of the things about how you get training data or train a model or how you evaluate these things, how you expose users to search results that are maybe a bit novel, like you do a little exploration to build out your training data.
And so these things are regardless of where search goes or where rag goes for whatever. It's there are still very relevant. And it feels like in a way, a lot of how users are interacting with with the world and with products is through some kind of search or some kind of retrieval system.
Even if it's a recommendation system or a feature some that's becoming feeling more like search where it's like real time and I'm getting the stuff updated in real time. And of course, rag is searched.
So I think search is still there, right? And I think it's going over the world and on which I realize some crowd is now gathering to have lunch and we will have lunch soon as well.
It's always a pleasure to talk to you and finally in person I think we've never met but I think if you've been to a new senior revolution in 2003, seeing around an island. I've been there as well. Is that the one in San Diego or no, no, in Dublin, in Dublin, yeah, I've been there. Yes, I wasn't.
Yeah, yeah. Then I need in there to, you know, to go high. But you know, that's when I introduced Kupit actually. Yeah, I know. It's amazing. The workter. Yeah. That's a still relevant project. It's running 2013 JavaScript. Yeah, and I've been consistently deploying it in every company I agree.
So in Tom Tom, we just released a new algorithm to production. Thanks to Kupit in two weeks. It was, it was on the bookshelf for quite some time because the team couldn't figure out how to test equality. And I said, okay, let's just do labeling, right? And let's use Q. Yeah, just simple labels and.
And we saw like more than 10% increase in precision with new algorithm. And they said, as a product manager, I approved the release. Let's go. That's also that's great. Thanks for creating the tool. Great. Sure. Happy to have a lot of making tools. Yeah. Thanks for a time, Doug.
Enjoy the conference. Thank you. Stay in Berlin. Yes. Thank you. Awesome. Thanks. Thank you.