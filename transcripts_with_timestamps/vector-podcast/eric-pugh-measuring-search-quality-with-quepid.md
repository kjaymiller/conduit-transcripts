---
description: '<p>This episode on YouTube: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM">https://www.youtube.com/watch?v=1L7UjjPz5wM</a></p><p></p><p><a
  target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=0s">00:00</a>
  Intro</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=21s">00:21</a>
  Guest Introduction: Eric Pugh</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=180s">03:00</a>
  Eric''s story in search and the evolution of search technology</p><p><a target="_blank"
  rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=447s">7:27</a>
  Quepid: Improving Search Relevancy</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=608s">10:08</a>
  When to use Quepid</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=893s">14:53</a>
  Flash back to Apache Solr 1.4 and the book (of which Eric is one author)</p><p><a
  target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=1069s">17:49</a>
  Quepid Demo and Future Enhancements</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=1437s">23:57</a>
  Real-Time Query Doc Pairs with WebSockets</p><p><a target="_blank" rel="noopener
  noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=1456s">24:16</a>
  Integrating Quepid with Search Engines</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=1557s">25:57</a>
  Introducing LLM-Based Judgments</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=1685s">28:05</a>
  Scaling Up Judgments with AI</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=1728s">28:48</a> Data Science
  Notebooks in Quepid</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=2003s">33:23</a> Custom
  Scoring in Quepid</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=2363s">39:23</a>
  API and Developer Tools</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=1L7UjjPz5wM&amp;t=2537s">42:17</a> The Future
  of Search and Personal Reflections</p><p></p><p>Show notes:</p><p>- Hosted Quepid:
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://app.quepid.com/">https://app.quepid.com/</a></p><p>-
  Ragas: Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/explodinggradients">https://github.com/explodinggradients</a><a
  target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbnBCSEIwRlFsd0RDQUdnbDFiRFF0d1dEUDRLZ3xBQ3Jtc0tuaGNDd2FpZzdITFdiRjNmbjJwanh1cnpuQ2VaWDZmZjZicXZjVTREZEVsdXhHd0x6WUZwREd1QXJRN2dtWXgtc1g4NDhSOU11ZXdpajVxb1hxZmpkSXdtNnhhbktYSTkwMmJjWmxPZFBjcTREa3NERQ&amp;q=https%3A%2F%2Fgithub.com%2Fexplodinggradients%2Fragas&amp;v=1L7UjjPz5wM">...</a></p><p>-
  Why Quepid: <a target="_blank" rel="noopener noreferrer nofollow" href="https://quepid.com/why-quepid/">https://quepid.com/why-quepid/</a></p><p>-
  Quepid on Github: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/o19s/quepid">https://github.com/o19s/quepid</a></p><p></p>'
image_url: https://media.rss.com/vector-podcast/ep_cover_20240626_010626_075b8a8d662d3fbf1946ef06b8218efa.png
pub_date: Wed, 26 Jun 2024 13:42:56 GMT
title: Eric Pugh - Measuring Search Quality with Quepid
url: https://rss.com/podcasts/vector-podcast/1539938
whisper_segments: '[{"id": 0, "seek": 0, "start": 0.0, "end": 23.88, "text": " Hello
  there, vector podcast season 3.", "tokens": [50364, 2425, 456, 11, 8062, 7367, 3196,
  805, 13, 51558], "temperature": 0.0, "avg_logprob": -0.39413962156876275, "compression_ratio":
  1.0533333333333332, "no_speech_prob": 0.15871569514274597}, {"id": 1, "seek": 0,
  "start": 23.88, "end": 26.28, "text": " In this season I made one simple promise.",
  "tokens": [51558, 682, 341, 3196, 286, 1027, 472, 2199, 6228, 13, 51678], "temperature":
  0.0, "avg_logprob": -0.39413962156876275, "compression_ratio": 1.0533333333333332,
  "no_speech_prob": 0.15871569514274597}, {"id": 2, "seek": 2628, "start": 26.28,
  "end": 29.16, "text": " I will try to stick to 30 minute episodes.", "tokens": [50364,
  286, 486, 853, 281, 2897, 281, 2217, 3456, 9313, 13, 50508], "temperature": 0.0,
  "avg_logprob": -0.25778030255518924, "compression_ratio": 1.491869918699187, "no_speech_prob":
  0.6543307900428772}, {"id": 3, "seek": 2628, "start": 29.16, "end": 31.0, "text":
  " Let''s see how well I will do it.", "tokens": [50508, 961, 311, 536, 577, 731,
  286, 486, 360, 309, 13, 50600], "temperature": 0.0, "avg_logprob": -0.25778030255518924,
  "compression_ratio": 1.491869918699187, "no_speech_prob": 0.6543307900428772}, {"id":
  4, "seek": 2628, "start": 31.0, "end": 37.6, "text": " It''s not always easy, especially
  when you have guests like Eric Pugh that I''m really having a pleasure to talk to
  today.", "tokens": [50600, 467, 311, 406, 1009, 1858, 11, 2318, 562, 291, 362, 9804,
  411, 9336, 430, 1984, 300, 286, 478, 534, 1419, 257, 6834, 281, 751, 281, 965, 13,
  50930], "temperature": 0.0, "avg_logprob": -0.25778030255518924, "compression_ratio":
  1.491869918699187, "no_speech_prob": 0.6543307900428772}, {"id": 5, "seek": 2628,
  "start": 38.6, "end": 44.400000000000006, "text": " I can say that we''ve been working
  together on Cupid, on ideation, on things.", "tokens": [50980, 286, 393, 584, 300,
  321, 600, 668, 1364, 1214, 322, 383, 6127, 11, 322, 1153, 399, 11, 322, 721, 13,
  51270], "temperature": 0.0, "avg_logprob": -0.25778030255518924, "compression_ratio":
  1.491869918699187, "no_speech_prob": 0.6543307900428772}, {"id": 6, "seek": 2628,
  "start": 45.400000000000006, "end": 47.64, "text": " And I''ve learned a ton from
  you.", "tokens": [51320, 400, 286, 600, 3264, 257, 2952, 490, 291, 13, 51432], "temperature":
  0.0, "avg_logprob": -0.25778030255518924, "compression_ratio": 1.491869918699187,
  "no_speech_prob": 0.6543307900428772}, {"id": 7, "seek": 2628, "start": 48.36, "end":
  50.400000000000006, "text": " Yeah, yeah, I''m super excited.", "tokens": [51468,
  865, 11, 1338, 11, 286, 478, 1687, 2919, 13, 51570], "temperature": 0.0, "avg_logprob":
  -0.25778030255518924, "compression_ratio": 1.491869918699187, "no_speech_prob":
  0.6543307900428772}, {"id": 8, "seek": 2628, "start": 50.400000000000006, "end":
  52.400000000000006, "text": " So when did I come visit you?", "tokens": [51570,
  407, 562, 630, 286, 808, 3441, 291, 30, 51670], "temperature": 0.0, "avg_logprob":
  -0.25778030255518924, "compression_ratio": 1.491869918699187, "no_speech_prob":
  0.6543307900428772}, {"id": 9, "seek": 5240, "start": 53.36, "end": 58.08, "text":
  " I think it was two years ago or some two years ago.", "tokens": [50412, 286, 519,
  309, 390, 732, 924, 2057, 420, 512, 732, 924, 2057, 13, 50648], "temperature": 0.0,
  "avg_logprob": -0.3425343283291521, "compression_ratio": 1.914438502673797, "no_speech_prob":
  0.1269148290157318}, {"id": 10, "seek": 5240, "start": 58.08, "end": 58.879999999999995,
  "text": " I think so.", "tokens": [50648, 286, 519, 370, 13, 50688], "temperature":
  0.0, "avg_logprob": -0.3425343283291521, "compression_ratio": 1.914438502673797,
  "no_speech_prob": 0.1269148290157318}, {"id": 11, "seek": 5240, "start": 58.879999999999995,
  "end": 60.56, "text": " It was pandemic, I guess.", "tokens": [50688, 467, 390,
  5388, 11, 286, 2041, 13, 50772], "temperature": 0.0, "avg_logprob": -0.3425343283291521,
  "compression_ratio": 1.914438502673797, "no_speech_prob": 0.1269148290157318}, {"id":
  12, "seek": 5240, "start": 60.56, "end": 62.72, "text": " Yeah, it was the very
  end of the pandemic.", "tokens": [50772, 865, 11, 309, 390, 264, 588, 917, 295,
  264, 5388, 13, 50880], "temperature": 0.0, "avg_logprob": -0.3425343283291521, "compression_ratio":
  1.914438502673797, "no_speech_prob": 0.1269148290157318}, {"id": 13, "seek": 5240,
  "start": 62.72, "end": 63.2, "text": " Right.", "tokens": [50880, 1779, 13, 50904],
  "temperature": 0.0, "avg_logprob": -0.3425343283291521, "compression_ratio": 1.914438502673797,
  "no_speech_prob": 0.1269148290157318}, {"id": 14, "seek": 5240, "start": 63.2, "end":
  66.32, "text": " I remember getting my, yeah, so it was still pandemic.", "tokens":
  [50904, 286, 1604, 1242, 452, 11, 1338, 11, 370, 309, 390, 920, 5388, 13, 51060],
  "temperature": 0.0, "avg_logprob": -0.3425343283291521, "compression_ratio": 1.914438502673797,
  "no_speech_prob": 0.1269148290157318}, {"id": 15, "seek": 5240, "start": 66.32,
  "end": 67.2, "text": " It was still pandemic.", "tokens": [51060, 467, 390, 920,
  5388, 13, 51104], "temperature": 0.0, "avg_logprob": -0.3425343283291521, "compression_ratio":
  1.914438502673797, "no_speech_prob": 0.1269148290157318}, {"id": 16, "seek": 5240,
  "start": 67.2, "end": 68.64, "text": " Yeah, it''s still pandemic, right?", "tokens":
  [51104, 865, 11, 309, 311, 920, 5388, 11, 558, 30, 51176], "temperature": 0.0, "avg_logprob":
  -0.3425343283291521, "compression_ratio": 1.914438502673797, "no_speech_prob": 0.1269148290157318},
  {"id": 17, "seek": 5240, "start": 68.64, "end": 75.75999999999999, "text": " Because
  I had to get Cupid to say, yeah, so I was, yeah, I was like, I want to meet to meet
  you in person.", "tokens": [51176, 1436, 286, 632, 281, 483, 383, 6127, 281, 584,
  11, 1338, 11, 370, 286, 390, 11, 1338, 11, 286, 390, 411, 11, 286, 528, 281, 1677,
  281, 1677, 291, 294, 954, 13, 51532], "temperature": 0.0, "avg_logprob": -0.3425343283291521,
  "compression_ratio": 1.914438502673797, "no_speech_prob": 0.1269148290157318}, {"id":
  18, "seek": 7576, "start": 75.84, "end": 80.64, "text": " And I called you and said,
  I''m going to come to Helsinki and visit you.", "tokens": [50368, 400, 286, 1219,
  291, 293, 848, 11, 286, 478, 516, 281, 808, 281, 45429, 41917, 293, 3441, 291, 13,
  50608], "temperature": 0.0, "avg_logprob": -0.28815899156544306, "compression_ratio":
  1.5970149253731343, "no_speech_prob": 0.07496391236782074}, {"id": 19, "seek": 7576,
  "start": 80.64, "end": 83.28, "text": " And I think you were like, why?", "tokens":
  [50608, 400, 286, 519, 291, 645, 411, 11, 983, 30, 50740], "temperature": 0.0, "avg_logprob":
  -0.28815899156544306, "compression_ratio": 1.5970149253731343, "no_speech_prob":
  0.07496391236782074}, {"id": 20, "seek": 7576, "start": 83.28, "end": 86.0, "text":
  " I mean, we don''t work together or say we worked on Cupid though.", "tokens":
  [50740, 286, 914, 11, 321, 500, 380, 589, 1214, 420, 584, 321, 2732, 322, 383, 6127,
  1673, 13, 50876], "temperature": 0.0, "avg_logprob": -0.28815899156544306, "compression_ratio":
  1.5970149253731343, "no_speech_prob": 0.07496391236782074}, {"id": 21, "seek": 7576,
  "start": 86.0, "end": 88.4, "text": " Quite a few evenings together, right?", "tokens":
  [50876, 20464, 257, 1326, 42835, 1214, 11, 558, 30, 50996], "temperature": 0.0,
  "avg_logprob": -0.28815899156544306, "compression_ratio": 1.5970149253731343, "no_speech_prob":
  0.07496391236782074}, {"id": 22, "seek": 7576, "start": 88.4, "end": 91.60000000000001,
  "text": " I think it was like nine o''clock your time, Helsinki time.", "tokens":
  [50996, 286, 519, 309, 390, 411, 4949, 277, 6, 9023, 428, 565, 11, 45429, 41917,
  565, 13, 51156], "temperature": 0.0, "avg_logprob": -0.28815899156544306, "compression_ratio":
  1.5970149253731343, "no_speech_prob": 0.07496391236782074}, {"id": 23, "seek": 7576,
  "start": 91.60000000000001, "end": 92.32000000000001, "text": " Yes.", "tokens":
  [51156, 1079, 13, 51192], "temperature": 0.0, "avg_logprob": -0.28815899156544306,
  "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.07496391236782074},
  {"id": 24, "seek": 7576, "start": 92.32000000000001, "end": 92.80000000000001, "text":
  " Yes.", "tokens": [51192, 1079, 13, 51216], "temperature": 0.0, "avg_logprob":
  -0.28815899156544306, "compression_ratio": 1.5970149253731343, "no_speech_prob":
  0.07496391236782074}, {"id": 25, "seek": 7576, "start": 92.80000000000001, "end":
  93.12, "text": " Who was it?", "tokens": [51216, 2102, 390, 309, 30, 51232], "temperature":
  0.0, "avg_logprob": -0.28815899156544306, "compression_ratio": 1.5970149253731343,
  "no_speech_prob": 0.07496391236782074}, {"id": 26, "seek": 7576, "start": 93.12,
  "end": 94.24000000000001, "text": " And it was Friday.", "tokens": [51232, 400,
  309, 390, 6984, 13, 51288], "temperature": 0.0, "avg_logprob": -0.28815899156544306,
  "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.07496391236782074},
  {"id": 27, "seek": 7576, "start": 94.24000000000001, "end": 96.4, "text": " I remember
  vividly Friday.", "tokens": [51288, 286, 1604, 23603, 356, 6984, 13, 51396], "temperature":
  0.0, "avg_logprob": -0.28815899156544306, "compression_ratio": 1.5970149253731343,
  "no_speech_prob": 0.07496391236782074}, {"id": 28, "seek": 7576, "start": 97.52000000000001,
  "end": 98.32000000000001, "text": " What else to do?", "tokens": [51452, 708, 1646,
  281, 360, 30, 51492], "temperature": 0.0, "avg_logprob": -0.28815899156544306, "compression_ratio":
  1.5970149253731343, "no_speech_prob": 0.07496391236782074}, {"id": 29, "seek": 7576,
  "start": 98.32000000000001, "end": 101.44, "text": " So I went camping with my family.",
  "tokens": [51492, 407, 286, 1437, 19470, 365, 452, 1605, 13, 51648], "temperature":
  0.0, "avg_logprob": -0.28815899156544306, "compression_ratio": 1.5970149253731343,
  "no_speech_prob": 0.07496391236782074}, {"id": 30, "seek": 7576, "start": 101.44,
  "end": 102.4, "text": " Can I screen share?", "tokens": [51648, 1664, 286, 2568,
  2073, 30, 51696], "temperature": 0.0, "avg_logprob": -0.28815899156544306, "compression_ratio":
  1.5970149253731343, "no_speech_prob": 0.07496391236782074}, {"id": 31, "seek": 7576,
  "start": 102.4, "end": 102.72, "text": " Did you meet?", "tokens": [51696, 2589,
  291, 1677, 30, 51712], "temperature": 0.0, "avg_logprob": -0.28815899156544306,
  "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.07496391236782074},
  {"id": 32, "seek": 7576, "start": 102.72, "end": 103.44, "text": " Yes, yes.", "tokens":
  [51712, 1079, 11, 2086, 13, 51748], "temperature": 0.0, "avg_logprob": -0.28815899156544306,
  "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.07496391236782074},
  {"id": 33, "seek": 10344, "start": 103.92, "end": 104.39999999999999, "text": "
  Of course.", "tokens": [50388, 2720, 1164, 13, 50412], "temperature": 0.0, "avg_logprob":
  -0.33767520256762235, "compression_ratio": 1.5812807881773399, "no_speech_prob":
  0.07604223489761353}, {"id": 34, "seek": 10344, "start": 104.39999999999999, "end":
  106.0, "text": " You can give me permissions.", "tokens": [50412, 509, 393, 976,
  385, 32723, 13, 50492], "temperature": 0.0, "avg_logprob": -0.33767520256762235,
  "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07604223489761353},
  {"id": 35, "seek": 10344, "start": 106.0, "end": 108.96, "text": " I went camping
  with my family.", "tokens": [50492, 286, 1437, 19470, 365, 452, 1605, 13, 50640],
  "temperature": 0.0, "avg_logprob": -0.33767520256762235, "compression_ratio": 1.5812807881773399,
  "no_speech_prob": 0.07604223489761353}, {"id": 36, "seek": 10344, "start": 108.96,
  "end": 117.03999999999999, "text": " And if you think back to my visit to you, you
  and your wife gave me a little gift.", "tokens": [50640, 400, 498, 291, 519, 646,
  281, 452, 3441, 281, 291, 11, 291, 293, 428, 3836, 2729, 385, 257, 707, 5306, 13,
  51044], "temperature": 0.0, "avg_logprob": -0.33767520256762235, "compression_ratio":
  1.5812807881773399, "no_speech_prob": 0.07604223489761353}, {"id": 37, "seek": 10344,
  "start": 118.16, "end": 119.75999999999999, "text": " Yeah, give me a free share.",
  "tokens": [51100, 865, 11, 976, 385, 257, 1737, 2073, 13, 51180], "temperature":
  0.0, "avg_logprob": -0.33767520256762235, "compression_ratio": 1.5812807881773399,
  "no_speech_prob": 0.07604223489761353}, {"id": 38, "seek": 10344, "start": 119.75999999999999,
  "end": 121.2, "text": " I can only do you host.", "tokens": [51180, 286, 393, 787,
  360, 291, 3975, 13, 51252], "temperature": 0.0, "avg_logprob": -0.33767520256762235,
  "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07604223489761353},
  {"id": 39, "seek": 10344, "start": 121.2, "end": 123.84, "text": " Let''s do a host
  and you can screen share.", "tokens": [51252, 961, 311, 360, 257, 3975, 293, 291,
  393, 2568, 2073, 13, 51384], "temperature": 0.0, "avg_logprob": -0.33767520256762235,
  "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07604223489761353},
  {"id": 40, "seek": 10344, "start": 123.84, "end": 124.56, "text": " Yeah, I can.",
  "tokens": [51384, 865, 11, 286, 393, 13, 51420], "temperature": 0.0, "avg_logprob":
  -0.33767520256762235, "compression_ratio": 1.5812807881773399, "no_speech_prob":
  0.07604223489761353}, {"id": 41, "seek": 10344, "start": 124.56, "end": 125.44,
  "text": " All right.", "tokens": [51420, 1057, 558, 13, 51464], "temperature": 0.0,
  "avg_logprob": -0.33767520256762235, "compression_ratio": 1.5812807881773399, "no_speech_prob":
  0.07604223489761353}, {"id": 42, "seek": 10344, "start": 125.44, "end": 130.56,
  "text": " And so I just wanted to share off this, this cup.", "tokens": [51464,
  400, 370, 286, 445, 1415, 281, 2073, 766, 341, 11, 341, 4414, 13, 51720], "temperature":
  0.0, "avg_logprob": -0.33767520256762235, "compression_ratio": 1.5812807881773399,
  "no_speech_prob": 0.07604223489761353}, {"id": 43, "seek": 13056, "start": 130.56,
  "end": 133.28, "text": " Oh, there it is.", "tokens": [50364, 876, 11, 456, 309,
  307, 13, 50500], "temperature": 0.0, "avg_logprob": -0.2157975126195837, "compression_ratio":
  1.5390625, "no_speech_prob": 0.02091003768146038}, {"id": 44, "seek": 13056, "start":
  133.28, "end": 135.52, "text": " So we''ve had that little wooden cup.", "tokens":
  [50500, 407, 321, 600, 632, 300, 707, 14744, 4414, 13, 50612], "temperature": 0.0,
  "avg_logprob": -0.2157975126195837, "compression_ratio": 1.5390625, "no_speech_prob":
  0.02091003768146038}, {"id": 45, "seek": 13056, "start": 135.52, "end": 139.52,
  "text": " I think it''s a traditional finish drinking vessel when you''re out in",
  "tokens": [50612, 286, 519, 309, 311, 257, 5164, 2413, 7583, 18098, 562, 291, 434,
  484, 294, 50812], "temperature": 0.0, "avg_logprob": -0.2157975126195837, "compression_ratio":
  1.5390625, "no_speech_prob": 0.02091003768146038}, {"id": 46, "seek": 13056, "start":
  139.52, "end": 139.92000000000002, "text": " nature.", "tokens": [50812, 3687, 13,
  50832], "temperature": 0.0, "avg_logprob": -0.2157975126195837, "compression_ratio":
  1.5390625, "no_speech_prob": 0.02091003768146038}, {"id": 47, "seek": 13056, "start":
  139.92000000000002, "end": 141.68, "text": " And there it is with coffee.", "tokens":
  [50832, 400, 456, 309, 307, 365, 4982, 13, 50920], "temperature": 0.0, "avg_logprob":
  -0.2157975126195837, "compression_ratio": 1.5390625, "no_speech_prob": 0.02091003768146038},
  {"id": 48, "seek": 13056, "start": 141.68, "end": 147.92000000000002, "text": "
  And then I''m also showing off my metal ceramic metal enameled cup", "tokens": [50920,
  400, 550, 286, 478, 611, 4099, 766, 452, 5760, 29996, 5760, 465, 16103, 292, 4414,
  51232], "temperature": 0.0, "avg_logprob": -0.2157975126195837, "compression_ratio":
  1.5390625, "no_speech_prob": 0.02091003768146038}, {"id": 49, "seek": 13056, "start":
  147.92000000000002, "end": 153.2, "text": " that I picked up at OpenSearchCon EU
  a couple weeks ago in Berlin", "tokens": [51232, 300, 286, 6183, 493, 412, 7238,
  10637, 1178, 9838, 10887, 257, 1916, 3259, 2057, 294, 13848, 51496], "temperature":
  0.0, "avg_logprob": -0.2157975126195837, "compression_ratio": 1.5390625, "no_speech_prob":
  0.02091003768146038}, {"id": 50, "seek": 13056, "start": 153.2, "end": 157.2, "text":
  " that Zeta Alpha shared had some great conversations about search,", "tokens":
  [51496, 300, 1176, 7664, 20588, 5507, 632, 512, 869, 7315, 466, 3164, 11, 51696],
  "temperature": 0.0, "avg_logprob": -0.2157975126195837, "compression_ratio": 1.5390625,
  "no_speech_prob": 0.02091003768146038}, {"id": 51, "seek": 13056, "start": 157.2,
  "end": 159.04, "text": " relevancy and measurement with them.", "tokens": [51696,
  25916, 6717, 293, 13160, 365, 552, 13, 51788], "temperature": 0.0, "avg_logprob":
  -0.2157975126195837, "compression_ratio": 1.5390625, "no_speech_prob": 0.02091003768146038},
  {"id": 52, "seek": 15904, "start": 159.04, "end": 164.23999999999998, "text": "
  So we took these two cups on our family camping trip the other week.", "tokens":
  [50364, 407, 321, 1890, 613, 732, 13381, 322, 527, 1605, 19470, 4931, 264, 661,
  1243, 13, 50624], "temperature": 0.0, "avg_logprob": -0.21564528677198622, "compression_ratio":
  1.5977443609022557, "no_speech_prob": 0.02588249370455742}, {"id": 53, "seek": 15904,
  "start": 164.23999999999998, "end": 166.48, "text": " I wanted to show those off
  to you.", "tokens": [50624, 286, 1415, 281, 855, 729, 766, 281, 291, 13, 50736],
  "temperature": 0.0, "avg_logprob": -0.21564528677198622, "compression_ratio": 1.5977443609022557,
  "no_speech_prob": 0.02588249370455742}, {"id": 54, "seek": 15904, "start": 166.48,
  "end": 167.51999999999998, "text": " This is lovely.", "tokens": [50736, 639, 307,
  7496, 13, 50788], "temperature": 0.0, "avg_logprob": -0.21564528677198622, "compression_ratio":
  1.5977443609022557, "no_speech_prob": 0.02588249370455742}, {"id": 55, "seek": 15904,
  "start": 167.51999999999998, "end": 168.23999999999998, "text": " This is lovely.",
  "tokens": [50788, 639, 307, 7496, 13, 50824], "temperature": 0.0, "avg_logprob":
  -0.21564528677198622, "compression_ratio": 1.5977443609022557, "no_speech_prob":
  0.02588249370455742}, {"id": 56, "seek": 15904, "start": 168.23999999999998, "end":
  171.44, "text": " And I''m glad you''re putting this in good news.", "tokens": [50824,
  400, 286, 478, 5404, 291, 434, 3372, 341, 294, 665, 2583, 13, 50984], "temperature":
  0.0, "avg_logprob": -0.21564528677198622, "compression_ratio": 1.5977443609022557,
  "no_speech_prob": 0.02588249370455742}, {"id": 57, "seek": 15904, "start": 172.0,
  "end": 172.48, "text": " Yep.", "tokens": [51012, 7010, 13, 51036], "temperature":
  0.0, "avg_logprob": -0.21564528677198622, "compression_ratio": 1.5977443609022557,
  "no_speech_prob": 0.02588249370455742}, {"id": 58, "seek": 15904, "start": 172.48,
  "end": 173.51999999999998, "text": " It goes with us.", "tokens": [51036, 467, 1709,
  365, 505, 13, 51088], "temperature": 0.0, "avg_logprob": -0.21564528677198622, "compression_ratio":
  1.5977443609022557, "no_speech_prob": 0.02588249370455742}, {"id": 59, "seek": 15904,
  "start": 173.51999999999998, "end": 174.95999999999998, "text": " So fantastic.",
  "tokens": [51088, 407, 5456, 13, 51160], "temperature": 0.0, "avg_logprob": -0.21564528677198622,
  "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02588249370455742},
  {"id": 60, "seek": 15904, "start": 174.95999999999998, "end": 175.76, "text": "
  Yes.", "tokens": [51160, 1079, 13, 51200], "temperature": 0.0, "avg_logprob": -0.21564528677198622,
  "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02588249370455742},
  {"id": 61, "seek": 15904, "start": 175.76, "end": 176.95999999999998, "text": "
  Yes, where we start.", "tokens": [51200, 1079, 11, 689, 321, 722, 13, 51260], "temperature":
  0.0, "avg_logprob": -0.21564528677198622, "compression_ratio": 1.5977443609022557,
  "no_speech_prob": 0.02588249370455742}, {"id": 62, "seek": 15904, "start": 176.95999999999998,
  "end": 178.23999999999998, "text": " First of all, hello.", "tokens": [51260, 2386,
  295, 439, 11, 7751, 13, 51324], "temperature": 0.0, "avg_logprob": -0.21564528677198622,
  "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02588249370455742},
  {"id": 63, "seek": 15904, "start": 178.23999999999998, "end": 179.12, "text": "
  Welcome.", "tokens": [51324, 4027, 13, 51368], "temperature": 0.0, "avg_logprob":
  -0.21564528677198622, "compression_ratio": 1.5977443609022557, "no_speech_prob":
  0.02588249370455742}, {"id": 64, "seek": 15904, "start": 179.12, "end": 180.07999999999998,
  "text": " Welcome.", "tokens": [51368, 4027, 13, 51416], "temperature": 0.0, "avg_logprob":
  -0.21564528677198622, "compression_ratio": 1.5977443609022557, "no_speech_prob":
  0.02588249370455742}, {"id": 65, "seek": 15904, "start": 180.07999999999998, "end":
  180.56, "text": " Yeah.", "tokens": [51416, 865, 13, 51440], "temperature": 0.0,
  "avg_logprob": -0.21564528677198622, "compression_ratio": 1.5977443609022557, "no_speech_prob":
  0.02588249370455742}, {"id": 66, "seek": 15904, "start": 180.56, "end": 181.92,
  "text": " Thank you very much for having me.", "tokens": [51440, 1044, 291, 588,
  709, 337, 1419, 385, 13, 51508], "temperature": 0.0, "avg_logprob": -0.21564528677198622,
  "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02588249370455742},
  {"id": 67, "seek": 15904, "start": 181.92, "end": 183.04, "text": " It''s long overdue.",
  "tokens": [51508, 467, 311, 938, 19853, 622, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.21564528677198622, "compression_ratio": 1.5977443609022557, "no_speech_prob":
  0.02588249370455742}, {"id": 68, "seek": 15904, "start": 183.04, "end": 186.23999999999998,
  "text": " And usually we start with a little bit of a background.", "tokens": [51564,
  400, 2673, 321, 722, 365, 257, 707, 857, 295, 257, 3678, 13, 51724], "temperature":
  0.0, "avg_logprob": -0.21564528677198622, "compression_ratio": 1.5977443609022557,
  "no_speech_prob": 0.02588249370455742}, {"id": 69, "seek": 15904, "start": 186.23999999999998,
  "end": 187.6, "text": " Obviously, people can go.", "tokens": [51724, 7580, 11,
  561, 393, 352, 13, 51792], "temperature": 0.0, "avg_logprob": -0.21564528677198622,
  "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02588249370455742},
  {"id": 70, "seek": 18760, "start": 187.6, "end": 190.16, "text": " I think you even
  have a Wikipedia page about you.", "tokens": [50364, 286, 519, 291, 754, 362, 257,
  28999, 3028, 466, 291, 13, 50492], "temperature": 0.0, "avg_logprob": -0.21349844179655375,
  "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.030675683170557022},
  {"id": 71, "seek": 18760, "start": 190.16, "end": 190.88, "text": " I think so.",
  "tokens": [50492, 286, 519, 370, 13, 50528], "temperature": 0.0, "avg_logprob":
  -0.21349844179655375, "compression_ratio": 1.7509433962264151, "no_speech_prob":
  0.030675683170557022}, {"id": 72, "seek": 18760, "start": 190.88, "end": 191.84,
  "text": " I don''t know.", "tokens": [50528, 286, 500, 380, 458, 13, 50576], "temperature":
  0.0, "avg_logprob": -0.21349844179655375, "compression_ratio": 1.7509433962264151,
  "no_speech_prob": 0.030675683170557022}, {"id": 73, "seek": 18760, "start": 191.84,
  "end": 193.28, "text": " That is a lot of people.", "tokens": [50576, 663, 307,
  257, 688, 295, 561, 13, 50648], "temperature": 0.0, "avg_logprob": -0.21349844179655375,
  "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.030675683170557022},
  {"id": 74, "seek": 18760, "start": 193.28, "end": 193.51999999999998, "text": "
  Right.", "tokens": [50648, 1779, 13, 50660], "temperature": 0.0, "avg_logprob":
  -0.21349844179655375, "compression_ratio": 1.7509433962264151, "no_speech_prob":
  0.030675683170557022}, {"id": 75, "seek": 18760, "start": 193.51999999999998, "end":
  196.88, "text": " That is a lot of people to get to a Wikipedia page.", "tokens":
  [50660, 663, 307, 257, 688, 295, 561, 281, 483, 281, 257, 28999, 3028, 13, 50828],
  "temperature": 0.0, "avg_logprob": -0.21349844179655375, "compression_ratio": 1.7509433962264151,
  "no_speech_prob": 0.030675683170557022}, {"id": 76, "seek": 18760, "start": 196.88,
  "end": 198.79999999999998, "text": " I don''t know that I''m quite there yet.",
  "tokens": [50828, 286, 500, 380, 458, 300, 286, 478, 1596, 456, 1939, 13, 50924],
  "temperature": 0.0, "avg_logprob": -0.21349844179655375, "compression_ratio": 1.7509433962264151,
  "no_speech_prob": 0.030675683170557022}, {"id": 77, "seek": 18760, "start": 198.79999999999998,
  "end": 199.12, "text": " Yes.", "tokens": [50924, 1079, 13, 50940], "temperature":
  0.0, "avg_logprob": -0.21349844179655375, "compression_ratio": 1.7509433962264151,
  "no_speech_prob": 0.030675683170557022}, {"id": 78, "seek": 18760, "start": 199.12,
  "end": 201.12, "text": " So my name''s Eric Pugh.", "tokens": [50940, 407, 452,
  1315, 311, 9336, 430, 1984, 13, 51040], "temperature": 0.0, "avg_logprob": -0.21349844179655375,
  "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.030675683170557022},
  {"id": 79, "seek": 18760, "start": 201.12, "end": 203.6, "text": " Been doing search
  for about, I don''t know.", "tokens": [51040, 32839, 884, 3164, 337, 466, 11, 286,
  500, 380, 458, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21349844179655375,
  "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.030675683170557022},
  {"id": 80, "seek": 18760, "start": 203.6, "end": 206.4, "text": " We''re like getting
  15 years.", "tokens": [51164, 492, 434, 411, 1242, 2119, 924, 13, 51304], "temperature":
  0.0, "avg_logprob": -0.21349844179655375, "compression_ratio": 1.7509433962264151,
  "no_speech_prob": 0.030675683170557022}, {"id": 81, "seek": 18760, "start": 206.4,
  "end": 210.79999999999998, "text": " And I was there for when a search was like
  first,", "tokens": [51304, 400, 286, 390, 456, 337, 562, 257, 3164, 390, 411, 700,
  11, 51524], "temperature": 0.0, "avg_logprob": -0.21349844179655375, "compression_ratio":
  1.7509433962264151, "no_speech_prob": 0.030675683170557022}, {"id": 82, "seek":
  18760, "start": 210.79999999999998, "end": 212.4, "text": " oh, you have your own
  search engine.", "tokens": [51524, 1954, 11, 291, 362, 428, 1065, 3164, 2848, 13,
  51604], "temperature": 0.0, "avg_logprob": -0.21349844179655375, "compression_ratio":
  1.7509433962264151, "no_speech_prob": 0.030675683170557022}, {"id": 83, "seek":
  18760, "start": 212.4, "end": 213.76, "text": " It was very exotic.", "tokens":
  [51604, 467, 390, 588, 27063, 13, 51672], "temperature": 0.0, "avg_logprob": -0.21349844179655375,
  "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.030675683170557022},
  {"id": 84, "seek": 18760, "start": 213.76, "end": 215.84, "text": " And there was
  nothing open source.", "tokens": [51672, 400, 456, 390, 1825, 1269, 4009, 13, 51776],
  "temperature": 0.0, "avg_logprob": -0.21349844179655375, "compression_ratio": 1.7509433962264151,
  "no_speech_prob": 0.030675683170557022}, {"id": 85, "seek": 18760, "start": 215.84,
  "end": 217.04, "text": " It was all commercial.", "tokens": [51776, 467, 390, 439,
  6841, 13, 51836], "temperature": 0.0, "avg_logprob": -0.21349844179655375, "compression_ratio":
  1.7509433962264151, "no_speech_prob": 0.030675683170557022}, {"id": 86, "seek":
  21760, "start": 217.6, "end": 220.88, "text": " And then cut my teeth in search
  going", "tokens": [50364, 400, 550, 1723, 452, 7798, 294, 3164, 516, 50528], "temperature":
  0.0, "avg_logprob": -0.20726046671394174, "compression_ratio": 1.6459143968871595,
  "no_speech_prob": 0.0006410639034584165}, {"id": 87, "seek": 21760, "start": 220.88,
  "end": 223.35999999999999, "text": " through the big data time period.", "tokens":
  [50528, 807, 264, 955, 1412, 565, 2896, 13, 50652], "temperature": 0.0, "avg_logprob":
  -0.20726046671394174, "compression_ratio": 1.6459143968871595, "no_speech_prob":
  0.0006410639034584165}, {"id": 88, "seek": 21760, "start": 223.35999999999999, "end":
  223.84, "text": " Right.", "tokens": [50652, 1779, 13, 50676], "temperature": 0.0,
  "avg_logprob": -0.20726046671394174, "compression_ratio": 1.6459143968871595, "no_speech_prob":
  0.0006410639034584165}, {"id": 89, "seek": 21760, "start": 223.84, "end": 226.4,
  "text": " When, as Grant Ingersoll said once,", "tokens": [50676, 1133, 11, 382,
  17529, 682, 9458, 1833, 848, 1564, 11, 50804], "temperature": 0.0, "avg_logprob":
  -0.20726046671394174, "compression_ratio": 1.6459143968871595, "no_speech_prob":
  0.0006410639034584165}, {"id": 90, "seek": 21760, "start": 226.4, "end": 228.79999999999998,
  "text": " search is the UI to big data.", "tokens": [50804, 3164, 307, 264, 15682,
  281, 955, 1412, 13, 50924], "temperature": 0.0, "avg_logprob": -0.20726046671394174,
  "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.0006410639034584165},
  {"id": 91, "seek": 21760, "start": 228.79999999999998, "end": 230.48, "text": "
  And it was all about data.", "tokens": [50924, 400, 309, 390, 439, 466, 1412, 13,
  51008], "temperature": 0.0, "avg_logprob": -0.20726046671394174, "compression_ratio":
  1.6459143968871595, "no_speech_prob": 0.0006410639034584165}, {"id": 92, "seek":
  21760, "start": 230.48, "end": 233.68, "text": " Can we handle and how do we store
  it and scale up our search", "tokens": [51008, 1664, 321, 4813, 293, 577, 360, 321,
  3531, 309, 293, 4373, 493, 527, 3164, 51168], "temperature": 0.0, "avg_logprob":
  -0.20726046671394174, "compression_ratio": 1.6459143968871595, "no_speech_prob":
  0.0006410639034584165}, {"id": 93, "seek": 21760, "start": 233.68, "end": 234.72,
  "text": " engines?", "tokens": [51168, 12982, 30, 51220], "temperature": 0.0, "avg_logprob":
  -0.20726046671394174, "compression_ratio": 1.6459143968871595, "no_speech_prob":
  0.0006410639034584165}, {"id": 94, "seek": 21760, "start": 234.72, "end": 237.04,
  "text": " And that was great and kind of led", "tokens": [51220, 400, 300, 390,
  869, 293, 733, 295, 4684, 51336], "temperature": 0.0, "avg_logprob": -0.20726046671394174,
  "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.0006410639034584165},
  {"id": 95, "seek": 21760, "start": 237.04, "end": 239.35999999999999, "text": "
  into the machine learning time period.", "tokens": [51336, 666, 264, 3479, 2539,
  565, 2896, 13, 51452], "temperature": 0.0, "avg_logprob": -0.20726046671394174,
  "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.0006410639034584165},
  {"id": 96, "seek": 21760, "start": 239.35999999999999, "end": 244.0, "text": " We''re
  really at that point, it was like, OK, we have lots of data.", "tokens": [51452,
  492, 434, 534, 412, 300, 935, 11, 309, 390, 411, 11, 2264, 11, 321, 362, 3195, 295,
  1412, 13, 51684], "temperature": 0.0, "avg_logprob": -0.20726046671394174, "compression_ratio":
  1.6459143968871595, "no_speech_prob": 0.0006410639034584165}, {"id": 97, "seek":
  21760, "start": 244.0, "end": 245.32, "text": " We can now search it.", "tokens":
  [51684, 492, 393, 586, 3164, 309, 13, 51750], "temperature": 0.0, "avg_logprob":
  -0.20726046671394174, "compression_ratio": 1.6459143968871595, "no_speech_prob":
  0.0006410639034584165}, {"id": 98, "seek": 21760, "start": 245.32, "end": 246.48,
  "text": " What does it mean?", "tokens": [51750, 708, 775, 309, 914, 30, 51808],
  "temperature": 0.0, "avg_logprob": -0.20726046671394174, "compression_ratio": 1.6459143968871595,
  "no_speech_prob": 0.0006410639034584165}, {"id": 99, "seek": 24648, "start": 246.76,
  "end": 248.76, "text": " What are people looking for?", "tokens": [50378, 708, 366,
  561, 1237, 337, 30, 50478], "temperature": 0.0, "avg_logprob": -0.19754366147316108,
  "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0022490399423986673},
  {"id": 100, "seek": 24648, "start": 248.76, "end": 252.76, "text": " It wasn''t
  enough to have fast search with 10 blue links.", "tokens": [50478, 467, 2067, 380,
  1547, 281, 362, 2370, 3164, 365, 1266, 3344, 6123, 13, 50678], "temperature": 0.0,
  "avg_logprob": -0.19754366147316108, "compression_ratio": 1.6629213483146068, "no_speech_prob":
  0.0022490399423986673}, {"id": 101, "seek": 24648, "start": 252.76, "end": 255.35999999999999,
  "text": " It was all of a sudden became really important to be like,", "tokens":
  [50678, 467, 390, 439, 295, 257, 3990, 3062, 534, 1021, 281, 312, 411, 11, 50808],
  "temperature": 0.0, "avg_logprob": -0.19754366147316108, "compression_ratio": 1.6629213483146068,
  "no_speech_prob": 0.0022490399423986673}, {"id": 102, "seek": 24648, "start": 255.35999999999999,
  "end": 258.76, "text": " am I giving my users what they want or not?", "tokens":
  [50808, 669, 286, 2902, 452, 5022, 437, 436, 528, 420, 406, 30, 50978], "temperature":
  0.0, "avg_logprob": -0.19754366147316108, "compression_ratio": 1.6629213483146068,
  "no_speech_prob": 0.0022490399423986673}, {"id": 103, "seek": 24648, "start": 258.76,
  "end": 263.36, "text": " And machine learning and data science really kind of came
  along", "tokens": [50978, 400, 3479, 2539, 293, 1412, 3497, 534, 733, 295, 1361,
  2051, 51208], "temperature": 0.0, "avg_logprob": -0.19754366147316108, "compression_ratio":
  1.6629213483146068, "no_speech_prob": 0.0022490399423986673}, {"id": 104, "seek":
  24648, "start": 263.36, "end": 266.96, "text": " and helped us make those determinations.",
  "tokens": [51208, 293, 4254, 505, 652, 729, 3618, 10325, 13, 51388], "temperature":
  0.0, "avg_logprob": -0.19754366147316108, "compression_ratio": 1.6629213483146068,
  "no_speech_prob": 0.0022490399423986673}, {"id": 105, "seek": 24648, "start": 266.96,
  "end": 270.4, "text": " So really, and that''s when open source connections,", "tokens":
  [51388, 407, 534, 11, 293, 300, 311, 562, 1269, 4009, 9271, 11, 51560], "temperature":
  0.0, "avg_logprob": -0.19754366147316108, "compression_ratio": 1.6629213483146068,
  "no_speech_prob": 0.0022490399423986673}, {"id": 106, "seek": 24648, "start": 270.4,
  "end": 272.76, "text": " the company I was one of the co-founders of,", "tokens":
  [51560, 264, 2237, 286, 390, 472, 295, 264, 598, 12, 17493, 433, 295, 11, 51678],
  "temperature": 0.0, "avg_logprob": -0.19754366147316108, "compression_ratio": 1.6629213483146068,
  "no_speech_prob": 0.0022490399423986673}, {"id": 107, "seek": 24648, "start": 272.76,
  "end": 275.24, "text": " and I''m one of the leaders of really kind of focusing",
  "tokens": [51678, 293, 286, 478, 472, 295, 264, 3523, 295, 534, 733, 295, 8416,
  51802], "temperature": 0.0, "avg_logprob": -0.19754366147316108, "compression_ratio":
  1.6629213483146068, "no_speech_prob": 0.0022490399423986673}, {"id": 108, "seek":
  27524, "start": 275.92, "end": 278.76, "text": " on the value side of search, relevancy.",
  "tokens": [50398, 322, 264, 2158, 1252, 295, 3164, 11, 25916, 6717, 13, 50540],
  "temperature": 0.0, "avg_logprob": -0.20609786918571404, "compression_ratio": 1.624,
  "no_speech_prob": 0.012816332280635834}, {"id": 109, "seek": 27524, "start": 278.76,
  "end": 281.6, "text": " Am I giving people what they''re looking for?", "tokens":
  [50540, 2012, 286, 2902, 561, 437, 436, 434, 1237, 337, 30, 50682], "temperature":
  0.0, "avg_logprob": -0.20609786918571404, "compression_ratio": 1.624, "no_speech_prob":
  0.012816332280635834}, {"id": 110, "seek": 27524, "start": 281.6, "end": 284.48,
  "text": " How do I drive more revenue in e-commerce?", "tokens": [50682, 1012, 360,
  286, 3332, 544, 9324, 294, 308, 12, 26926, 30, 50826], "temperature": 0.0, "avg_logprob":
  -0.20609786918571404, "compression_ratio": 1.624, "no_speech_prob": 0.012816332280635834},
  {"id": 111, "seek": 27524, "start": 284.48, "end": 287.48, "text": " How do I help
  people use my SaaS products?", "tokens": [50826, 1012, 360, 286, 854, 561, 764,
  452, 49733, 3383, 30, 50976], "temperature": 0.0, "avg_logprob": -0.20609786918571404,
  "compression_ratio": 1.624, "no_speech_prob": 0.012816332280635834}, {"id": 112,
  "seek": 27524, "start": 287.48, "end": 290.12, "text": " Are they subscribed and
  renew their subscriptions?", "tokens": [50976, 2014, 436, 16665, 293, 10162, 641,
  44951, 30, 51108], "temperature": 0.0, "avg_logprob": -0.20609786918571404, "compression_ratio":
  1.624, "no_speech_prob": 0.012816332280635834}, {"id": 113, "seek": 27524, "start":
  290.12, "end": 291.8, "text": " All of this, right?", "tokens": [51108, 1057, 295,
  341, 11, 558, 30, 51192], "temperature": 0.0, "avg_logprob": -0.20609786918571404,
  "compression_ratio": 1.624, "no_speech_prob": 0.012816332280635834}, {"id": 114,
  "seek": 27524, "start": 291.8, "end": 294.6, "text": " And yeah, machine learning
  was awesome.", "tokens": [51192, 400, 1338, 11, 3479, 2539, 390, 3476, 13, 51332],
  "temperature": 0.0, "avg_logprob": -0.20609786918571404, "compression_ratio": 1.624,
  "no_speech_prob": 0.012816332280635834}, {"id": 115, "seek": 27524, "start": 294.6,
  "end": 296.04, "text": " Data science was awesome.", "tokens": [51332, 11888, 3497,
  390, 3476, 13, 51404], "temperature": 0.0, "avg_logprob": -0.20609786918571404,
  "compression_ratio": 1.624, "no_speech_prob": 0.012816332280635834}, {"id": 116,
  "seek": 27524, "start": 296.04, "end": 299.0, "text": " Really got into a whole
  measurement thing.", "tokens": [51404, 4083, 658, 666, 257, 1379, 13160, 551, 13,
  51552], "temperature": 0.0, "avg_logprob": -0.20609786918571404, "compression_ratio":
  1.624, "no_speech_prob": 0.012816332280635834}, {"id": 117, "seek": 27524, "start":
  299.0, "end": 303.8, "text": " And that was kind of one of the products that I stored,",
  "tokens": [51552, 400, 300, 390, 733, 295, 472, 295, 264, 3383, 300, 286, 12187,
  11, 51792], "temperature": 0.0, "avg_logprob": -0.20609786918571404, "compression_ratio":
  1.624, "no_speech_prob": 0.012816332280635834}, {"id": 118, "seek": 30380, "start":
  303.8, "end": 308.8, "text": " Cupid, we know each other, came out of that time
  period", "tokens": [50364, 383, 6127, 11, 321, 458, 1184, 661, 11, 1361, 484, 295,
  300, 565, 2896, 50614], "temperature": 0.0, "avg_logprob": -0.17252057269938942,
  "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0014866720885038376},
  {"id": 119, "seek": 30380, "start": 309.08, "end": 312.2, "text": " because we said,
  why are we building custom tooling", "tokens": [50628, 570, 321, 848, 11, 983, 366,
  321, 2390, 2375, 46593, 50784], "temperature": 0.0, "avg_logprob": -0.17252057269938942,
  "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0014866720885038376},
  {"id": 120, "seek": 30380, "start": 312.2, "end": 315.0, "text": " for every project,
  maybe we could share some things.", "tokens": [50784, 337, 633, 1716, 11, 1310,
  321, 727, 2073, 512, 721, 13, 50924], "temperature": 0.0, "avg_logprob": -0.17252057269938942,
  "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0014866720885038376},
  {"id": 121, "seek": 30380, "start": 315.0, "end": 319.16, "text": " So, and then
  yeah, today it''s really been exciting", "tokens": [50924, 407, 11, 293, 550, 1338,
  11, 965, 309, 311, 534, 668, 4670, 51132], "temperature": 0.0, "avg_logprob": -0.17252057269938942,
  "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0014866720885038376},
  {"id": 122, "seek": 30380, "start": 319.16, "end": 323.68, "text": " to see sort
  of generative AI come along and vectors.", "tokens": [51132, 281, 536, 1333, 295,
  1337, 1166, 7318, 808, 2051, 293, 18875, 13, 51358], "temperature": 0.0, "avg_logprob":
  -0.17252057269938942, "compression_ratio": 1.5761316872427984, "no_speech_prob":
  0.0014866720885038376}, {"id": 123, "seek": 30380, "start": 323.68, "end": 327.04,
  "text": " And it''s interesting because I still feel, you know,", "tokens": [51358,
  400, 309, 311, 1880, 570, 286, 920, 841, 11, 291, 458, 11, 51526], "temperature":
  0.0, "avg_logprob": -0.17252057269938942, "compression_ratio": 1.5761316872427984,
  "no_speech_prob": 0.0014866720885038376}, {"id": 124, "seek": 30380, "start": 327.04,
  "end": 331.48, "text": " for a little while I was like, is search still gonna be
  a domain?", "tokens": [51526, 337, 257, 707, 1339, 286, 390, 411, 11, 307, 3164,
  920, 799, 312, 257, 9274, 30, 51748], "temperature": 0.0, "avg_logprob": -0.17252057269938942,
  "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0014866720885038376},
  {"id": 125, "seek": 33148, "start": 331.56, "end": 333.84000000000003, "text": "
  And you know, search is totally changed,", "tokens": [50368, 400, 291, 458, 11,
  3164, 307, 3879, 3105, 11, 50482], "temperature": 0.0, "avg_logprob": -0.18408670230787627,
  "compression_ratio": 1.5420168067226891, "no_speech_prob": 0.00013959500938653946},
  {"id": 126, "seek": 33148, "start": 333.84000000000003, "end": 338.68, "text": "
  but it''s still how people interact with systems, right?", "tokens": [50482, 457,
  309, 311, 920, 577, 561, 4648, 365, 3652, 11, 558, 30, 50724], "temperature": 0.0,
  "avg_logprob": -0.18408670230787627, "compression_ratio": 1.5420168067226891, "no_speech_prob":
  0.00013959500938653946}, {"id": 127, "seek": 33148, "start": 338.68, "end": 343.6,
  "text": " Whether it''s a spot and a retrieval augmented generation", "tokens":
  [50724, 8503, 309, 311, 257, 4008, 293, 257, 19817, 3337, 36155, 5125, 50970], "temperature":
  0.0, "avg_logprob": -0.18408670230787627, "compression_ratio": 1.5420168067226891,
  "no_speech_prob": 0.00013959500938653946}, {"id": 128, "seek": 33148, "start": 343.6,
  "end": 346.12, "text": " or a more traditional keyword search,", "tokens": [50970,
  420, 257, 544, 5164, 20428, 3164, 11, 51096], "temperature": 0.0, "avg_logprob":
  -0.18408670230787627, "compression_ratio": 1.5420168067226891, "no_speech_prob":
  0.00013959500938653946}, {"id": 129, "seek": 33148, "start": 347.08000000000004,
  "end": 350.20000000000005, "text": " using LLMs, using models, using vectors,",
  "tokens": [51144, 1228, 441, 43, 26386, 11, 1228, 5245, 11, 1228, 18875, 11, 51300],
  "temperature": 0.0, "avg_logprob": -0.18408670230787627, "compression_ratio": 1.5420168067226891,
  "no_speech_prob": 0.00013959500938653946}, {"id": 130, "seek": 33148, "start": 350.20000000000005,
  "end": 352.48, "text": " still a search engine in the middle of it,", "tokens":
  [51300, 920, 257, 3164, 2848, 294, 264, 2808, 295, 309, 11, 51414], "temperature":
  0.0, "avg_logprob": -0.18408670230787627, "compression_ratio": 1.5420168067226891,
  "no_speech_prob": 0.00013959500938653946}, {"id": 131, "seek": 33148, "start": 352.48,
  "end": 355.28000000000003, "text": " mediating, moderating that conversation.",
  "tokens": [51414, 17269, 990, 11, 10494, 990, 300, 3761, 13, 51554], "temperature":
  0.0, "avg_logprob": -0.18408670230787627, "compression_ratio": 1.5420168067226891,
  "no_speech_prob": 0.00013959500938653946}, {"id": 132, "seek": 33148, "start": 355.28000000000003,
  "end": 360.0, "text": " So really excited about what Gen AI has let us do.", "tokens":
  [51554, 407, 534, 2919, 466, 437, 3632, 7318, 575, 718, 505, 360, 13, 51790], "temperature":
  0.0, "avg_logprob": -0.18408670230787627, "compression_ratio": 1.5420168067226891,
  "no_speech_prob": 0.00013959500938653946}, {"id": 133, "seek": 36000, "start": 360.0,
  "end": 363.72, "text": " And I think my big takeaway right now is", "tokens": [50364,
  400, 286, 519, 452, 955, 30681, 558, 586, 307, 50550], "temperature": 0.0, "avg_logprob":
  -0.1490144633283519, "compression_ratio": 1.6680497925311204, "no_speech_prob":
  8.178748976206407e-05}, {"id": 134, "seek": 36000, "start": 363.72, "end": 368.2,
  "text": " that historically search was fairly mediocre.", "tokens": [50550, 300,
  16180, 3164, 390, 6457, 45415, 13, 50774], "temperature": 0.0, "avg_logprob": -0.1490144633283519,
  "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.178748976206407e-05},
  {"id": 135, "seek": 36000, "start": 368.2, "end": 370.92, "text": " You could make
  it a little better, you could make it a little worse,", "tokens": [50774, 509, 727,
  652, 309, 257, 707, 1101, 11, 291, 727, 652, 309, 257, 707, 5324, 11, 50910], "temperature":
  0.0, "avg_logprob": -0.1490144633283519, "compression_ratio": 1.6680497925311204,
  "no_speech_prob": 8.178748976206407e-05}, {"id": 136, "seek": 36000, "start": 370.92,
  "end": 374.36, "text": " but it was always like people understood it was fairly
  explainable.", "tokens": [50910, 457, 309, 390, 1009, 411, 561, 7320, 309, 390,
  6457, 2903, 712, 13, 51082], "temperature": 0.0, "avg_logprob": -0.1490144633283519,
  "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.178748976206407e-05},
  {"id": 137, "seek": 36000, "start": 375.44, "end": 379.0, "text": " Why I''m really
  excited about measurement", "tokens": [51136, 1545, 286, 478, 534, 2919, 466, 13160,
  51314], "temperature": 0.0, "avg_logprob": -0.1490144633283519, "compression_ratio":
  1.6680497925311204, "no_speech_prob": 8.178748976206407e-05}, {"id": 138, "seek":
  36000, "start": 379.0, "end": 383.12, "text": " and understanding these days is
  because now with Gen AI,", "tokens": [51314, 293, 3701, 613, 1708, 307, 570, 586,
  365, 3632, 7318, 11, 51520], "temperature": 0.0, "avg_logprob": -0.1490144633283519,
  "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.178748976206407e-05},
  {"id": 139, "seek": 36000, "start": 383.12, "end": 385.08, "text": " we have much
  better tools.", "tokens": [51520, 321, 362, 709, 1101, 3873, 13, 51618], "temperature":
  0.0, "avg_logprob": -0.1490144633283519, "compression_ratio": 1.6680497925311204,
  "no_speech_prob": 8.178748976206407e-05}, {"id": 140, "seek": 36000, "start": 385.08,
  "end": 388.4, "text": " We don''t have to have mediocre search kind of better,",
  "tokens": [51618, 492, 500, 380, 362, 281, 362, 45415, 3164, 733, 295, 1101, 11,
  51784], "temperature": 0.0, "avg_logprob": -0.1490144633283519, "compression_ratio":
  1.6680497925311204, "no_speech_prob": 8.178748976206407e-05}, {"id": 141, "seek":
  38840, "start": 388.4, "end": 389.47999999999996, "text": " kind of worse.", "tokens":
  [50364, 733, 295, 5324, 13, 50418], "temperature": 0.0, "avg_logprob": -0.23618685078417134,
  "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0020165250170975924},
  {"id": 142, "seek": 38840, "start": 389.47999999999996, "end": 393.52, "text": "
  Instead we can have amazing, accurate search results", "tokens": [50418, 7156, 321,
  393, 362, 2243, 11, 8559, 3164, 3542, 50620], "temperature": 0.0, "avg_logprob":
  -0.23618685078417134, "compression_ratio": 1.7261904761904763, "no_speech_prob":
  0.0020165250170975924}, {"id": 143, "seek": 38840, "start": 393.52, "end": 395.79999999999995,
  "text": " that really understand what you''re looking for.", "tokens": [50620, 300,
  534, 1223, 437, 291, 434, 1237, 337, 13, 50734], "temperature": 0.0, "avg_logprob":
  -0.23618685078417134, "compression_ratio": 1.7261904761904763, "no_speech_prob":
  0.0020165250170975924}, {"id": 144, "seek": 38840, "start": 395.79999999999995,
  "end": 399.12, "text": " And you''re like, yes, this is exactly what I wanted.",
  "tokens": [50734, 400, 291, 434, 411, 11, 2086, 11, 341, 307, 2293, 437, 286, 1415,
  13, 50900], "temperature": 0.0, "avg_logprob": -0.23618685078417134, "compression_ratio":
  1.7261904761904763, "no_speech_prob": 0.0020165250170975924}, {"id": 145, "seek":
  38840, "start": 399.12, "end": 402.79999999999995, "text": " But, whoops side of
  it is sometimes those search results", "tokens": [50900, 583, 11, 567, 3370, 1252,
  295, 309, 307, 2171, 729, 3164, 3542, 51084], "temperature": 0.0, "avg_logprob":
  -0.23618685078417134, "compression_ratio": 1.7261904761904763, "no_speech_prob":
  0.0020165250170975924}, {"id": 146, "seek": 38840, "start": 402.79999999999995,
  "end": 405.23999999999995, "text": " are back shit crazy and you know,", "tokens":
  [51084, 366, 646, 4611, 3219, 293, 291, 458, 11, 51206], "temperature": 0.0, "avg_logprob":
  -0.23618685078417134, "compression_ratio": 1.7261904761904763, "no_speech_prob":
  0.0020165250170975924}, {"id": 147, "seek": 38840, "start": 405.23999999999995,
  "end": 410.0, "text": " no idea why it came back with it and you made me lose trust.",
  "tokens": [51206, 572, 1558, 983, 309, 1361, 646, 365, 309, 293, 291, 1027, 385,
  3624, 3361, 13, 51444], "temperature": 0.0, "avg_logprob": -0.23618685078417134,
  "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0020165250170975924},
  {"id": 148, "seek": 38840, "start": 410.0, "end": 414.76, "text": " And so now instead
  of all search results sort of being", "tokens": [51444, 400, 370, 586, 2602, 295,
  439, 3164, 3542, 1333, 295, 885, 51682], "temperature": 0.0, "avg_logprob": -0.23618685078417134,
  "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.0020165250170975924},
  {"id": 149, "seek": 38840, "start": 414.76, "end": 418.2, "text": " in the middle
  sort of, yeah, a little better, little worse,", "tokens": [51682, 294, 264, 2808,
  1333, 295, 11, 1338, 11, 257, 707, 1101, 11, 707, 5324, 11, 51854], "temperature":
  0.0, "avg_logprob": -0.23618685078417134, "compression_ratio": 1.7261904761904763,
  "no_speech_prob": 0.0020165250170975924}, {"id": 150, "seek": 41820, "start": 418.2,
  "end": 419.59999999999997, "text": " we''re now really polarized.", "tokens": [50364,
  321, 434, 586, 534, 48623, 13, 50434], "temperature": 0.0, "avg_logprob": -0.13140755940258989,
  "compression_ratio": 1.8278688524590163, "no_speech_prob": 0.000396077724872157},
  {"id": 151, "seek": 41820, "start": 419.59999999999997, "end": 423.44, "text": "
  Sometimes they''re amazing, sometimes they''re terrible.", "tokens": [50434, 4803,
  436, 434, 2243, 11, 2171, 436, 434, 6237, 13, 50626], "temperature": 0.0, "avg_logprob":
  -0.13140755940258989, "compression_ratio": 1.8278688524590163, "no_speech_prob":
  0.000396077724872157}, {"id": 152, "seek": 41820, "start": 423.44, "end": 426.8,
  "text": " And we need to understand what that curve looks like", "tokens": [50626,
  400, 321, 643, 281, 1223, 437, 300, 7605, 1542, 411, 50794], "temperature": 0.0,
  "avg_logprob": -0.13140755940258989, "compression_ratio": 1.8278688524590163, "no_speech_prob":
  0.000396077724872157}, {"id": 153, "seek": 41820, "start": 426.8, "end": 430.52,
  "text": " and make sure that the amount of terrible", "tokens": [50794, 293, 652,
  988, 300, 264, 2372, 295, 6237, 50980], "temperature": 0.0, "avg_logprob": -0.13140755940258989,
  "compression_ratio": 1.8278688524590163, "no_speech_prob": 0.000396077724872157},
  {"id": 154, "seek": 41820, "start": 430.52, "end": 432.8, "text": " is something
  that we''re willing to deal with, right?", "tokens": [50980, 307, 746, 300, 321,
  434, 4950, 281, 2028, 365, 11, 558, 30, 51094], "temperature": 0.0, "avg_logprob":
  -0.13140755940258989, "compression_ratio": 1.8278688524590163, "no_speech_prob":
  0.000396077724872157}, {"id": 155, "seek": 41820, "start": 432.8, "end": 436.36,
  "text": " Terrible results, one in 10,000, one in 5,000,", "tokens": [51094, 6564,
  4457, 3542, 11, 472, 294, 1266, 11, 1360, 11, 472, 294, 1025, 11, 1360, 11, 51272],
  "temperature": 0.0, "avg_logprob": -0.13140755940258989, "compression_ratio": 1.8278688524590163,
  "no_speech_prob": 0.000396077724872157}, {"id": 156, "seek": 41820, "start": 436.36,
  "end": 439.12, "text": " one in a million, depending on your domain,", "tokens":
  [51272, 472, 294, 257, 2459, 11, 5413, 322, 428, 9274, 11, 51410], "temperature":
  0.0, "avg_logprob": -0.13140755940258989, "compression_ratio": 1.8278688524590163,
  "no_speech_prob": 0.000396077724872157}, {"id": 157, "seek": 41820, "start": 439.12,
  "end": 442.48, "text": " it may need to be one in a billion is a terrible,", "tokens":
  [51410, 309, 815, 643, 281, 312, 472, 294, 257, 5218, 307, 257, 6237, 11, 51578],
  "temperature": 0.0, "avg_logprob": -0.13140755940258989, "compression_ratio": 1.8278688524590163,
  "no_speech_prob": 0.000396077724872157}, {"id": 158, "seek": 41820, "start": 442.48,
  "end": 443.91999999999996, "text": " right, depending on what you''re doing.", "tokens":
  [51578, 558, 11, 5413, 322, 437, 291, 434, 884, 13, 51650], "temperature": 0.0,
  "avg_logprob": -0.13140755940258989, "compression_ratio": 1.8278688524590163, "no_speech_prob":
  0.000396077724872157}, {"id": 159, "seek": 41820, "start": 443.91999999999996, "end":
  447.59999999999997, "text": " So exciting times, really exciting.", "tokens": [51650,
  407, 4670, 1413, 11, 534, 4670, 13, 51834], "temperature": 0.0, "avg_logprob": -0.13140755940258989,
  "compression_ratio": 1.8278688524590163, "no_speech_prob": 0.000396077724872157},
  {"id": 160, "seek": 44760, "start": 447.6, "end": 449.72, "text": " Yeah, it''s
  amazing, it''s amazing story.", "tokens": [50364, 865, 11, 309, 311, 2243, 11, 309,
  311, 2243, 1657, 13, 50470], "temperature": 0.0, "avg_logprob": -0.21488162875175476,
  "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.0029164880979806185},
  {"id": 161, "seek": 44760, "start": 449.72, "end": 452.8, "text": " And of course,
  I''m very pleased to also being able", "tokens": [50470, 400, 295, 1164, 11, 286,
  478, 588, 10587, 281, 611, 885, 1075, 50624], "temperature": 0.0, "avg_logprob":
  -0.21488162875175476, "compression_ratio": 1.5694444444444444, "no_speech_prob":
  0.0029164880979806185}, {"id": 162, "seek": 44760, "start": 452.8, "end": 455.72,
  "text": " to pick up, keep it with you early on,", "tokens": [50624, 281, 1888,
  493, 11, 1066, 309, 365, 291, 2440, 322, 11, 50770], "temperature": 0.0, "avg_logprob":
  -0.21488162875175476, "compression_ratio": 1.5694444444444444, "no_speech_prob":
  0.0029164880979806185}, {"id": 163, "seek": 44760, "start": 455.72, "end": 459.72,
  "text": " where I tried to pioneer it two companies ago", "tokens": [50770, 689,
  286, 3031, 281, 37668, 309, 732, 3431, 2057, 50970], "temperature": 0.0, "avg_logprob":
  -0.21488162875175476, "compression_ratio": 1.5694444444444444, "no_speech_prob":
  0.0029164880979806185}, {"id": 164, "seek": 44760, "start": 459.72, "end": 462.12,
  "text": " and I was leaving actually.", "tokens": [50970, 293, 286, 390, 5012, 767,
  13, 51090], "temperature": 0.0, "avg_logprob": -0.21488162875175476, "compression_ratio":
  1.5694444444444444, "no_speech_prob": 0.0029164880979806185}, {"id": 165, "seek":
  44760, "start": 462.12, "end": 463.40000000000003, "text": " But it was almost ready.",
  "tokens": [51090, 583, 309, 390, 1920, 1919, 13, 51154], "temperature": 0.0, "avg_logprob":
  -0.21488162875175476, "compression_ratio": 1.5694444444444444, "no_speech_prob":
  0.0029164880979806185}, {"id": 166, "seek": 44760, "start": 463.40000000000003,
  "end": 465.72, "text": " And then the next company I actually deployed it.", "tokens":
  [51154, 400, 550, 264, 958, 2237, 286, 767, 17826, 309, 13, 51270], "temperature":
  0.0, "avg_logprob": -0.21488162875175476, "compression_ratio": 1.5694444444444444,
  "no_speech_prob": 0.0029164880979806185}, {"id": 167, "seek": 44760, "start": 465.72,
  "end": 470.36, "text": " And we, I remember we generated 70 G-RAT tickets", "tokens":
  [51270, 400, 321, 11, 286, 1604, 321, 10833, 5285, 460, 12, 49, 2218, 12628, 51502],
  "temperature": 0.0, "avg_logprob": -0.21488162875175476, "compression_ratio": 1.5694444444444444,
  "no_speech_prob": 0.0029164880979806185}, {"id": 168, "seek": 44760, "start": 470.36,
  "end": 472.48, "text": " just by looking at queries in Cupid", "tokens": [51502,
  445, 538, 1237, 412, 24109, 294, 383, 6127, 51608], "temperature": 0.0, "avg_logprob":
  -0.21488162875175476, "compression_ratio": 1.5694444444444444, "no_speech_prob":
  0.0029164880979806185}, {"id": 169, "seek": 44760, "start": 472.48, "end": 474.40000000000003,
  "text": " because you know how it usually goes.", "tokens": [51608, 570, 291, 458,
  577, 309, 2673, 1709, 13, 51704], "temperature": 0.0, "avg_logprob": -0.21488162875175476,
  "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.0029164880979806185},
  {"id": 170, "seek": 44760, "start": 474.40000000000003, "end": 477.44, "text": "
  People develop software, other people check on it,", "tokens": [51704, 3432, 1499,
  4722, 11, 661, 561, 1520, 322, 309, 11, 51856], "temperature": 0.0, "avg_logprob":
  -0.21488162875175476, "compression_ratio": 1.5694444444444444, "no_speech_prob":
  0.0029164880979806185}, {"id": 171, "seek": 47744, "start": 477.44, "end": 480.0,
  "text": " other people are just project managing and things like this", "tokens":
  [50364, 661, 561, 366, 445, 1716, 11642, 293, 721, 411, 341, 50492], "temperature":
  0.0, "avg_logprob": -0.1461128294467926, "compression_ratio": 1.7413793103448276,
  "no_speech_prob": 0.0010672395583242178}, {"id": 172, "seek": 47744, "start": 480.0,
  "end": 483.6, "text": " and no one really takes the lead on looking at the queries.",
  "tokens": [50492, 293, 572, 472, 534, 2516, 264, 1477, 322, 1237, 412, 264, 24109,
  13, 50672], "temperature": 0.0, "avg_logprob": -0.1461128294467926, "compression_ratio":
  1.7413793103448276, "no_speech_prob": 0.0010672395583242178}, {"id": 173, "seek":
  47744, "start": 483.6, "end": 486.76, "text": " And this is actually the most fun
  sometimes to look at queries", "tokens": [50672, 400, 341, 307, 767, 264, 881, 1019,
  2171, 281, 574, 412, 24109, 50830], "temperature": 0.0, "avg_logprob": -0.1461128294467926,
  "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.0010672395583242178},
  {"id": 174, "seek": 47744, "start": 486.76, "end": 489.76, "text": " and sort of
  you know investigate what''s going on.", "tokens": [50830, 293, 1333, 295, 291,
  458, 15013, 437, 311, 516, 322, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1461128294467926,
  "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.0010672395583242178},
  {"id": 175, "seek": 47744, "start": 489.76, "end": 491.28, "text": " Do you even
  like these results?", "tokens": [50980, 1144, 291, 754, 411, 613, 3542, 30, 51056],
  "temperature": 0.0, "avg_logprob": -0.1461128294467926, "compression_ratio": 1.7413793103448276,
  "no_speech_prob": 0.0010672395583242178}, {"id": 176, "seek": 47744, "start": 491.28,
  "end": 493.12, "text": " How do you feel about them?", "tokens": [51056, 1012, 360,
  291, 841, 466, 552, 30, 51148], "temperature": 0.0, "avg_logprob": -0.1461128294467926,
  "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.0010672395583242178},
  {"id": 177, "seek": 47744, "start": 493.12, "end": 495.84, "text": " You know let
  alone setting up a team around it", "tokens": [51148, 509, 458, 718, 3312, 3287,
  493, 257, 1469, 926, 309, 51284], "temperature": 0.0, "avg_logprob": -0.1461128294467926,
  "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.0010672395583242178},
  {"id": 178, "seek": 47744, "start": 495.84, "end": 498.96, "text": " where some
  annotators can actually go and label", "tokens": [51284, 689, 512, 25339, 3391,
  393, 767, 352, 293, 7645, 51440], "temperature": 0.0, "avg_logprob": -0.1461128294467926,
  "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.0010672395583242178},
  {"id": 179, "seek": 47744, "start": 498.96, "end": 500.88, "text": " with some domain
  expertise, you know,", "tokens": [51440, 365, 512, 9274, 11769, 11, 291, 458, 11,
  51536], "temperature": 0.0, "avg_logprob": -0.1461128294467926, "compression_ratio":
  1.7413793103448276, "no_speech_prob": 0.0010672395583242178}, {"id": 180, "seek":
  47744, "start": 500.88, "end": 503.28, "text": " or maybe pretending to be users
  and things like this.", "tokens": [51536, 420, 1310, 22106, 281, 312, 5022, 293,
  721, 411, 341, 13, 51656], "temperature": 0.0, "avg_logprob": -0.1461128294467926,
  "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.0010672395583242178},
  {"id": 181, "seek": 47744, "start": 503.28, "end": 505.4, "text": " So it''s an
  amazing system", "tokens": [51656, 407, 309, 311, 364, 2243, 1185, 51762], "temperature":
  0.0, "avg_logprob": -0.1461128294467926, "compression_ratio": 1.7413793103448276,
  "no_speech_prob": 0.0010672395583242178}, {"id": 182, "seek": 50540, "start": 505.4,
  "end": 507.52, "text": " and we continue to use it today.", "tokens": [50364, 293,
  321, 2354, 281, 764, 309, 965, 13, 50470], "temperature": 0.0, "avg_logprob": -0.2066033573473914,
  "compression_ratio": 1.684, "no_speech_prob": 0.001431247335858643}, {"id": 183,
  "seek": 50540, "start": 507.52, "end": 510.28, "text": " Of course this was the
  first thing I pioneered at TomTom", "tokens": [50470, 2720, 1164, 341, 390, 264,
  700, 551, 286, 19761, 4073, 412, 5041, 23442, 50608], "temperature": 0.0, "avg_logprob":
  -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob": 0.001431247335858643},
  {"id": 184, "seek": 50540, "start": 510.28, "end": 511.4, "text": " and it''s still
  there.", "tokens": [50608, 293, 309, 311, 920, 456, 13, 50664], "temperature": 0.0,
  "avg_logprob": -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob":
  0.001431247335858643}, {"id": 185, "seek": 50540, "start": 512.4, "end": 514.04,
  "text": " It''s fantastic, that is wonderful.", "tokens": [50714, 467, 311, 5456,
  11, 300, 307, 3715, 13, 50796], "temperature": 0.0, "avg_logprob": -0.2066033573473914,
  "compression_ratio": 1.684, "no_speech_prob": 0.001431247335858643}, {"id": 186,
  "seek": 50540, "start": 514.04, "end": 518.16, "text": " I mean, it''s been great
  to see sort of the adoption of the product", "tokens": [50796, 286, 914, 11, 309,
  311, 668, 869, 281, 536, 1333, 295, 264, 19215, 295, 264, 1674, 51002], "temperature":
  0.0, "avg_logprob": -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob":
  0.001431247335858643}, {"id": 187, "seek": 50540, "start": 518.16, "end": 521.3199999999999,
  "text": " and then people have been using it for a long time.", "tokens": [51002,
  293, 550, 561, 362, 668, 1228, 309, 337, 257, 938, 565, 13, 51160], "temperature":
  0.0, "avg_logprob": -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob":
  0.001431247335858643}, {"id": 188, "seek": 50540, "start": 521.3199999999999, "end":
  523.72, "text": " So I''m going to show a query set today", "tokens": [51160, 407,
  286, 478, 516, 281, 855, 257, 14581, 992, 965, 51280], "temperature": 0.0, "avg_logprob":
  -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob": 0.001431247335858643},
  {"id": 189, "seek": 50540, "start": 523.72, "end": 526.36, "text": " that is a thousand
  queries", "tokens": [51280, 300, 307, 257, 4714, 24109, 51412], "temperature": 0.0,
  "avg_logprob": -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob":
  0.001431247335858643}, {"id": 190, "seek": 50540, "start": 526.36, "end": 530.36,
  "text": " and maybe a thousand queries that have been judged", "tokens": [51412,
  293, 1310, 257, 4714, 24109, 300, 362, 668, 27485, 51612], "temperature": 0.0, "avg_logprob":
  -0.2066033573473914, "compression_ratio": 1.684, "no_speech_prob": 0.001431247335858643},
  {"id": 191, "seek": 50540, "start": 530.36, "end": 535.12, "text": " 10 deep right
  by hand for three years.", "tokens": [51612, 1266, 2452, 558, 538, 1011, 337, 1045,
  924, 13, 51850], "temperature": 0.0, "avg_logprob": -0.2066033573473914, "compression_ratio":
  1.684, "no_speech_prob": 0.001431247335858643}, {"id": 192, "seek": 53512, "start":
  535.12, "end": 536.36, "text": " Almost four years.", "tokens": [50364, 12627, 1451,
  924, 13, 50426], "temperature": 0.0, "avg_logprob": -0.16422524452209472, "compression_ratio":
  1.7098039215686274, "no_speech_prob": 0.0014380936045199633}, {"id": 193, "seek":
  53512, "start": 536.36, "end": 540.28, "text": " This one organization that Nerry
  Information Network", "tokens": [50426, 639, 472, 4475, 300, 426, 5318, 15357, 12640,
  50622], "temperature": 0.0, "avg_logprob": -0.16422524452209472, "compression_ratio":
  1.7098039215686274, "no_speech_prob": 0.0014380936045199633}, {"id": 194, "seek":
  53512, "start": 540.28, "end": 542.24, "text": " has been using Cupid for years",
  "tokens": [50622, 575, 668, 1228, 383, 6127, 337, 924, 50720], "temperature": 0.0,
  "avg_logprob": -0.16422524452209472, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.0014380936045199633}, {"id": 195, "seek": 53512, "start": 542.24, "end": 545.96,
  "text": " and now they built up this massive body of ratings", "tokens": [50720,
  293, 586, 436, 3094, 493, 341, 5994, 1772, 295, 24603, 50906], "temperature": 0.0,
  "avg_logprob": -0.16422524452209472, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.0014380936045199633}, {"id": 196, "seek": 53512, "start": 545.96, "end": 549.16,
  "text": " and they have tons of data and trend lines", "tokens": [50906, 293, 436,
  362, 9131, 295, 1412, 293, 6028, 3876, 51066], "temperature": 0.0, "avg_logprob":
  -0.16422524452209472, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.0014380936045199633}, {"id": 197, "seek": 53512, "start": 549.16, "end": 552.24,
  "text": " for what did search look like four years ago?", "tokens": [51066, 337,
  437, 630, 3164, 574, 411, 1451, 924, 2057, 30, 51220], "temperature": 0.0, "avg_logprob":
  -0.16422524452209472, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.0014380936045199633}, {"id": 198, "seek": 53512, "start": 552.24, "end": 554.16,
  "text": " What did it look like last year?", "tokens": [51220, 708, 630, 309, 574,
  411, 1036, 1064, 30, 51316], "temperature": 0.0, "avg_logprob": -0.16422524452209472,
  "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.0014380936045199633},
  {"id": 199, "seek": 53512, "start": 554.16, "end": 556.08, "text": " What does it
  look like today?", "tokens": [51316, 708, 775, 309, 574, 411, 965, 30, 51412], "temperature":
  0.0, "avg_logprob": -0.16422524452209472, "compression_ratio": 1.7098039215686274,
  "no_speech_prob": 0.0014380936045199633}, {"id": 200, "seek": 53512, "start": 556.08,
  "end": 558.52, "text": " It''s really been exciting to see them.", "tokens": [51412,
  467, 311, 534, 668, 4670, 281, 536, 552, 13, 51534], "temperature": 0.0, "avg_logprob":
  -0.16422524452209472, "compression_ratio": 1.7098039215686274, "no_speech_prob":
  0.0014380936045199633}, {"id": 201, "seek": 53512, "start": 558.52, "end": 562.8,
  "text": " They''ve just been using the little hosted Cupid app.cupid.com", "tokens":
  [51534, 814, 600, 445, 668, 1228, 264, 707, 19204, 383, 6127, 724, 13, 66, 6127,
  13, 1112, 51748], "temperature": 0.0, "avg_logprob": -0.16422524452209472, "compression_ratio":
  1.7098039215686274, "no_speech_prob": 0.0014380936045199633}, {"id": 202, "seek":
  53512, "start": 562.8, "end": 564.28, "text": " and but it''s worked for them.",
  "tokens": [51748, 293, 457, 309, 311, 2732, 337, 552, 13, 51822], "temperature":
  0.0, "avg_logprob": -0.16422524452209472, "compression_ratio": 1.7098039215686274,
  "no_speech_prob": 0.0014380936045199633}, {"id": 203, "seek": 56428, "start": 564.3199999999999,
  "end": 567.72, "text": " So a thousand queries definitely takes a long time", "tokens":
  [50366, 407, 257, 4714, 24109, 2138, 2516, 257, 938, 565, 50536], "temperature":
  0.0, "avg_logprob": -0.179394289978549, "compression_ratio": 1.585820895522388,
  "no_speech_prob": 0.00019836827414110303}, {"id": 204, "seek": 56428, "start": 567.72,
  "end": 568.76, "text": " to work your way through.", "tokens": [50536, 281, 589,
  428, 636, 807, 13, 50588], "temperature": 0.0, "avg_logprob": -0.179394289978549,
  "compression_ratio": 1.585820895522388, "no_speech_prob": 0.00019836827414110303},
  {"id": 205, "seek": 56428, "start": 568.76, "end": 571.8399999999999, "text": "
  But these days they''re just kind of keeping an eye", "tokens": [50588, 583, 613,
  1708, 436, 434, 445, 733, 295, 5145, 364, 3313, 50742], "temperature": 0.0, "avg_logprob":
  -0.179394289978549, "compression_ratio": 1.585820895522388, "no_speech_prob": 0.00019836827414110303},
  {"id": 206, "seek": 56428, "start": 571.8399999999999, "end": 573.8, "text": " on
  what''s changing, right?", "tokens": [50742, 322, 437, 311, 4473, 11, 558, 30, 50840],
  "temperature": 0.0, "avg_logprob": -0.179394289978549, "compression_ratio": 1.585820895522388,
  "no_speech_prob": 0.00019836827414110303}, {"id": 207, "seek": 56428, "start": 573.8,
  "end": 577.0, "text": " Barring a major algorithm change.", "tokens": [50840, 363,
  18285, 257, 2563, 9284, 1319, 13, 51000], "temperature": 0.0, "avg_logprob": -0.179394289978549,
  "compression_ratio": 1.585820895522388, "no_speech_prob": 0.00019836827414110303},
  {"id": 208, "seek": 56428, "start": 577.0, "end": 578.8, "text": " It''s just sort
  of staying on top of it", "tokens": [51000, 467, 311, 445, 1333, 295, 7939, 322,
  1192, 295, 309, 51090], "temperature": 0.0, "avg_logprob": -0.179394289978549, "compression_ratio":
  1.585820895522388, "no_speech_prob": 0.00019836827414110303}, {"id": 209, "seek":
  56428, "start": 578.8, "end": 580.72, "text": " and keeping everything right.",
  "tokens": [51090, 293, 5145, 1203, 558, 13, 51186], "temperature": 0.0, "avg_logprob":
  -0.179394289978549, "compression_ratio": 1.585820895522388, "no_speech_prob": 0.00019836827414110303},
  {"id": 210, "seek": 56428, "start": 580.72, "end": 584.12, "text": " But yeah, so
  it''s really exciting to see people using it.", "tokens": [51186, 583, 1338, 11,
  370, 309, 311, 534, 4670, 281, 536, 561, 1228, 309, 13, 51356], "temperature": 0.0,
  "avg_logprob": -0.179394289978549, "compression_ratio": 1.585820895522388, "no_speech_prob":
  0.00019836827414110303}, {"id": 211, "seek": 56428, "start": 584.12, "end": 584.9599999999999,
  "text": " Yeah.", "tokens": [51356, 865, 13, 51398], "temperature": 0.0, "avg_logprob":
  -0.179394289978549, "compression_ratio": 1.585820895522388, "no_speech_prob": 0.00019836827414110303},
  {"id": 212, "seek": 56428, "start": 584.9599999999999, "end": 589.16, "text": "
  Definitely I''m having a little bit of thoughts", "tokens": [51398, 12151, 286,
  478, 1419, 257, 707, 857, 295, 4598, 51608], "temperature": 0.0, "avg_logprob":
  -0.179394289978549, "compression_ratio": 1.585820895522388, "no_speech_prob": 0.00019836827414110303},
  {"id": 213, "seek": 56428, "start": 589.16, "end": 593.68, "text": " about where
  does Cupid live in our generative AI future?", "tokens": [51608, 466, 689, 775,
  383, 6127, 1621, 294, 527, 1337, 1166, 7318, 2027, 30, 51834], "temperature": 0.0,
  "avg_logprob": -0.179394289978549, "compression_ratio": 1.585820895522388, "no_speech_prob":
  0.00019836827414110303}, {"id": 214, "seek": 59368, "start": 593.68, "end": 596.1999999999999,
  "text": " Been playing a lot with tools like Ragus", "tokens": [50364, 32839, 2433,
  257, 688, 365, 3873, 411, 497, 32813, 50490], "temperature": 0.0, "avg_logprob":
  -0.17974929227173783, "compression_ratio": 1.5970695970695972, "no_speech_prob":
  0.03499700874090195}, {"id": 215, "seek": 59368, "start": 596.1999999999999, "end":
  598.5999999999999, "text": " and some of the other ones, right?", "tokens": [50490,
  293, 512, 295, 264, 661, 2306, 11, 558, 30, 50610], "temperature": 0.0, "avg_logprob":
  -0.17974929227173783, "compression_ratio": 1.5970695970695972, "no_speech_prob":
  0.03499700874090195}, {"id": 216, "seek": 59368, "start": 598.5999999999999, "end":
  602.52, "text": " And it''s interesting to see what tooling", "tokens": [50610,
  400, 309, 311, 1880, 281, 536, 437, 46593, 50806], "temperature": 0.0, "avg_logprob":
  -0.17974929227173783, "compression_ratio": 1.5970695970695972, "no_speech_prob":
  0.03499700874090195}, {"id": 217, "seek": 59368, "start": 602.52, "end": 604.3199999999999,
  "text": " and where does Cupid do things?", "tokens": [50806, 293, 689, 775, 383,
  6127, 360, 721, 30, 50896], "temperature": 0.0, "avg_logprob": -0.17974929227173783,
  "compression_ratio": 1.5970695970695972, "no_speech_prob": 0.03499700874090195},
  {"id": 218, "seek": 59368, "start": 604.3199999999999, "end": 606.3199999999999,
  "text": " Well, where does it have challenges?", "tokens": [50896, 1042, 11, 689,
  775, 309, 362, 4759, 30, 50996], "temperature": 0.0, "avg_logprob": -0.17974929227173783,
  "compression_ratio": 1.5970695970695972, "no_speech_prob": 0.03499700874090195},
  {"id": 219, "seek": 59368, "start": 606.3199999999999, "end": 607.64, "text": "
  Where do we want to go with?", "tokens": [50996, 2305, 360, 321, 528, 281, 352,
  365, 30, 51062], "temperature": 0.0, "avg_logprob": -0.17974929227173783, "compression_ratio":
  1.5970695970695972, "no_speech_prob": 0.03499700874090195}, {"id": 220, "seek":
  59368, "start": 607.64, "end": 609.12, "text": " So yeah, for sure.", "tokens":
  [51062, 407, 1338, 11, 337, 988, 13, 51136], "temperature": 0.0, "avg_logprob":
  -0.17974929227173783, "compression_ratio": 1.5970695970695972, "no_speech_prob":
  0.03499700874090195}, {"id": 221, "seek": 59368, "start": 609.12, "end": 610.7199999999999,
  "text": " And for those who don''t know Cupid,", "tokens": [51136, 400, 337, 729,
  567, 500, 380, 458, 383, 6127, 11, 51216], "temperature": 0.0, "avg_logprob": -0.17974929227173783,
  "compression_ratio": 1.5970695970695972, "no_speech_prob": 0.03499700874090195},
  {"id": 222, "seek": 59368, "start": 610.7199999999999, "end": 613.4799999999999,
  "text": " I mean, I can give my short intro,", "tokens": [51216, 286, 914, 11, 286,
  393, 976, 452, 2099, 12897, 11, 51354], "temperature": 0.0, "avg_logprob": -0.17974929227173783,
  "compression_ratio": 1.5970695970695972, "no_speech_prob": 0.03499700874090195},
  {"id": 223, "seek": 59368, "start": 613.4799999999999, "end": 615.4, "text": " but
  obviously feel free to augment.", "tokens": [51354, 457, 2745, 841, 1737, 281, 29919,
  13, 51450], "temperature": 0.0, "avg_logprob": -0.17974929227173783, "compression_ratio":
  1.5970695970695972, "no_speech_prob": 0.03499700874090195}, {"id": 224, "seek":
  59368, "start": 615.4, "end": 618.76, "text": " But like the way I see it is that
  it''s basically", "tokens": [51450, 583, 411, 264, 636, 286, 536, 309, 307, 300,
  309, 311, 1936, 51618], "temperature": 0.0, "avg_logprob": -0.17974929227173783,
  "compression_ratio": 1.5970695970695972, "no_speech_prob": 0.03499700874090195},
  {"id": 225, "seek": 59368, "start": 618.76, "end": 621.9599999999999, "text": "
  instead of hearsay and sort of someone saying,", "tokens": [51618, 2602, 295, 25688,
  320, 293, 1333, 295, 1580, 1566, 11, 51778], "temperature": 0.0, "avg_logprob":
  -0.17974929227173783, "compression_ratio": 1.5970695970695972, "no_speech_prob":
  0.03499700874090195}, {"id": 226, "seek": 62196, "start": 621.96, "end": 623.52,
  "text": " your search doesn''t work.", "tokens": [50364, 428, 3164, 1177, 380, 589,
  13, 50442], "temperature": 0.0, "avg_logprob": -0.20718093810042715, "compression_ratio":
  1.7295081967213115, "no_speech_prob": 0.007505514193326235}, {"id": 227, "seek":
  62196, "start": 623.52, "end": 626.12, "text": " And here is one anecdotal example.",
  "tokens": [50442, 400, 510, 307, 472, 26652, 38180, 1365, 13, 50572], "temperature":
  0.0, "avg_logprob": -0.20718093810042715, "compression_ratio": 1.7295081967213115,
  "no_speech_prob": 0.007505514193326235}, {"id": 228, "seek": 62196, "start": 626.12,
  "end": 628.36, "text": " What you can do is that, oh, vice versa,", "tokens": [50572,
  708, 291, 393, 360, 307, 300, 11, 1954, 11, 11964, 25650, 11, 50684], "temperature":
  0.0, "avg_logprob": -0.20718093810042715, "compression_ratio": 1.7295081967213115,
  "no_speech_prob": 0.007505514193326235}, {"id": 229, "seek": 62196, "start": 628.36,
  "end": 629.76, "text": " you could say I improved search.", "tokens": [50684, 291,
  727, 584, 286, 9689, 3164, 13, 50754], "temperature": 0.0, "avg_logprob": -0.20718093810042715,
  "compression_ratio": 1.7295081967213115, "no_speech_prob": 0.007505514193326235},
  {"id": 230, "seek": 62196, "start": 629.76, "end": 631.5600000000001, "text": "
  And here is one anecdotal example", "tokens": [50754, 400, 510, 307, 472, 26652,
  38180, 1365, 50844], "temperature": 0.0, "avg_logprob": -0.20718093810042715, "compression_ratio":
  1.7295081967213115, "no_speech_prob": 0.007505514193326235}, {"id": 231, "seek":
  62196, "start": 631.5600000000001, "end": 633.6, "text": " where it really shines,
  right?", "tokens": [50844, 689, 309, 534, 28056, 11, 558, 30, 50946], "temperature":
  0.0, "avg_logprob": -0.20718093810042715, "compression_ratio": 1.7295081967213115,
  "no_speech_prob": 0.007505514193326235}, {"id": 232, "seek": 62196, "start": 633.6,
  "end": 635.9200000000001, "text": " Now what should we ship it?", "tokens": [50946,
  823, 437, 820, 321, 5374, 309, 30, 51062], "temperature": 0.0, "avg_logprob": -0.20718093810042715,
  "compression_ratio": 1.7295081967213115, "no_speech_prob": 0.007505514193326235},
  {"id": 233, "seek": 62196, "start": 635.9200000000001, "end": 640.76, "text": "
  So basically I think Cupid really gives you the tooling", "tokens": [51062, 407,
  1936, 286, 519, 383, 6127, 534, 2709, 291, 264, 46593, 51304], "temperature": 0.0,
  "avg_logprob": -0.20718093810042715, "compression_ratio": 1.7295081967213115, "no_speech_prob":
  0.007505514193326235}, {"id": 234, "seek": 62196, "start": 640.84, "end": 644.4000000000001,
  "text": " and you can actually, even if you want,", "tokens": [51308, 293, 291,
  393, 767, 11, 754, 498, 291, 528, 11, 51486], "temperature": 0.0, "avg_logprob":
  -0.20718093810042715, "compression_ratio": 1.7295081967213115, "no_speech_prob":
  0.007505514193326235}, {"id": 235, "seek": 62196, "start": 644.4000000000001, "end":
  647.24, "text": " you can even do it in an unbiased way,", "tokens": [51486, 291,
  393, 754, 360, 309, 294, 364, 517, 5614, 1937, 636, 11, 51628], "temperature": 0.0,
  "avg_logprob": -0.20718093810042715, "compression_ratio": 1.7295081967213115, "no_speech_prob":
  0.007505514193326235}, {"id": 236, "seek": 62196, "start": 647.24, "end": 650.6,
  "text": " as possible where you will do blind labeling in some sense,", "tokens":
  [51628, 382, 1944, 689, 291, 486, 360, 6865, 40244, 294, 512, 2020, 11, 51796],
  "temperature": 0.0, "avg_logprob": -0.20718093810042715, "compression_ratio": 1.7295081967213115,
  "no_speech_prob": 0.007505514193326235}, {"id": 237, "seek": 65060, "start": 650.6,
  "end": 651.6, "text": " right?", "tokens": [50364, 558, 30, 50414], "temperature":
  0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 238, "seek": 65060, "start": 651.6,
  "end": 654.24, "text": " So I''ve done it actually just recently.", "tokens": [50414,
  407, 286, 600, 1096, 309, 767, 445, 3938, 13, 50546], "temperature": 0.0, "avg_logprob":
  -0.222551025390625, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.02434610202908516},
  {"id": 239, "seek": 65060, "start": 654.24, "end": 658.08, "text": " And basically
  you allow your users,", "tokens": [50546, 400, 1936, 291, 2089, 428, 5022, 11, 50738],
  "temperature": 0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 240, "seek": 65060, "start": 658.08,
  "end": 660.12, "text": " well, your domain experts actually,", "tokens": [50738,
  731, 11, 428, 9274, 8572, 767, 11, 50840], "temperature": 0.0, "avg_logprob": -0.222551025390625,
  "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.02434610202908516},
  {"id": 241, "seek": 65060, "start": 660.12, "end": 663.64, "text": " but maybe even
  developers to go label queries.", "tokens": [50840, 457, 1310, 754, 8849, 281, 352,
  7645, 24109, 13, 51016], "temperature": 0.0, "avg_logprob": -0.222551025390625,
  "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.02434610202908516},
  {"id": 242, "seek": 65060, "start": 663.64, "end": 665.52, "text": " And it also
  has this sandbox", "tokens": [51016, 400, 309, 611, 575, 341, 42115, 51110], "temperature":
  0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 243, "seek": 65060, "start": 665.52,
  "end": 668.2, "text": " where you can actually, well, you can plug in your own engine,",
  "tokens": [51110, 689, 291, 393, 767, 11, 731, 11, 291, 393, 5452, 294, 428, 1065,
  2848, 11, 51244], "temperature": 0.0, "avg_logprob": -0.222551025390625, "compression_ratio":
  1.6977611940298507, "no_speech_prob": 0.02434610202908516}, {"id": 244, "seek":
  65060, "start": 668.2, "end": 670.44, "text": " but you can also plug in those standard
  engines", "tokens": [51244, 457, 291, 393, 611, 5452, 294, 729, 3832, 12982, 51356],
  "temperature": 0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 245, "seek": 65060, "start": 670.44,
  "end": 673.64, "text": " like Elastic Search Solar, Open Search and others.", "tokens":
  [51356, 411, 2699, 2750, 17180, 22385, 11, 7238, 17180, 293, 2357, 13, 51516], "temperature":
  0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 246, "seek": 65060, "start": 673.64,
  "end": 676.44, "text": " And I think you even added some vector search engines",
  "tokens": [51516, 400, 286, 519, 291, 754, 3869, 512, 8062, 3164, 12982, 51656],
  "temperature": 0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 247, "seek": 65060, "start": 676.44,
  "end": 677.36, "text": " recently, right?", "tokens": [51656, 3938, 11, 558, 30,
  51702], "temperature": 0.0, "avg_logprob": -0.222551025390625, "compression_ratio":
  1.6977611940298507, "no_speech_prob": 0.02434610202908516}, {"id": 248, "seek":
  65060, "start": 677.36, "end": 679.76, "text": " Yeah, so we have a Vectara,", "tokens":
  [51702, 865, 11, 370, 321, 362, 257, 691, 557, 2419, 11, 51822], "temperature":
  0.0, "avg_logprob": -0.222551025390625, "compression_ratio": 1.6977611940298507,
  "no_speech_prob": 0.02434610202908516}, {"id": 249, "seek": 67976, "start": 679.76,
  "end": 682.0, "text": " which is a pure vector search engine.", "tokens": [50364,
  597, 307, 257, 6075, 8062, 3164, 2848, 13, 50476], "temperature": 0.0, "avg_logprob":
  -0.26311240196228025, "compression_ratio": 1.5541666666666667, "no_speech_prob":
  0.0007325750775635242}, {"id": 250, "seek": 67976, "start": 682.0, "end": 684.0,
  "text": " We''ve got out the only app.", "tokens": [50476, 492, 600, 658, 484, 264,
  787, 724, 13, 50576], "temperature": 0.0, "avg_logprob": -0.26311240196228025, "compression_ratio":
  1.5541666666666667, "no_speech_prob": 0.0007325750775635242}, {"id": 251, "seek":
  67976, "start": 684.0, "end": 686.96, "text": " And then Open Search, Elastic Search
  Solar,", "tokens": [50576, 400, 550, 7238, 17180, 11, 2699, 2750, 17180, 22385,
  11, 50724], "temperature": 0.0, "avg_logprob": -0.26311240196228025, "compression_ratio":
  1.5541666666666667, "no_speech_prob": 0.0007325750775635242}, {"id": 252, "seek":
  67976, "start": 686.96, "end": 688.8, "text": " the Lucine Bay search engines,",
  "tokens": [50724, 264, 9593, 533, 7840, 3164, 12982, 11, 50816], "temperature":
  0.0, "avg_logprob": -0.26311240196228025, "compression_ratio": 1.5541666666666667,
  "no_speech_prob": 0.0007325750775635242}, {"id": 253, "seek": 67976, "start": 688.8,
  "end": 690.96, "text": " and then kind of exciting,", "tokens": [50816, 293, 550,
  733, 295, 4670, 11, 50924], "temperature": 0.0, "avg_logprob": -0.26311240196228025,
  "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.0007325750775635242},
  {"id": 254, "seek": 67976, "start": 690.96, "end": 694.0, "text": " you can also
  now plug in your own search API.", "tokens": [50924, 291, 393, 611, 586, 5452, 294,
  428, 1065, 3164, 9362, 13, 51076], "temperature": 0.0, "avg_logprob": -0.26311240196228025,
  "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.0007325750775635242},
  {"id": 255, "seek": 67976, "start": 694.0, "end": 697.52, "text": " And so you can
  just talk to any API,", "tokens": [51076, 400, 370, 291, 393, 445, 751, 281, 604,
  9362, 11, 51252], "temperature": 0.0, "avg_logprob": -0.26311240196228025, "compression_ratio":
  1.5541666666666667, "no_speech_prob": 0.0007325750775635242}, {"id": 256, "seek":
  67976, "start": 697.52, "end": 701.84, "text": " a restful Git post JSON sort of
  API,", "tokens": [51252, 257, 1472, 906, 16939, 2183, 31828, 1333, 295, 9362, 11,
  51468], "temperature": 0.0, "avg_logprob": -0.26311240196228025, "compression_ratio":
  1.5541666666666667, "no_speech_prob": 0.0007325750775635242}, {"id": 257, "seek":
  67976, "start": 701.84, "end": 703.68, "text": " you can use Cupid as well.", "tokens":
  [51468, 291, 393, 764, 383, 6127, 382, 731, 13, 51560], "temperature": 0.0, "avg_logprob":
  -0.26311240196228025, "compression_ratio": 1.5541666666666667, "no_speech_prob":
  0.0007325750775635242}, {"id": 258, "seek": 67976, "start": 703.68, "end": 705.12,
  "text": " So that''s been really good.", "tokens": [51560, 407, 300, 311, 668, 534,
  665, 13, 51632], "temperature": 0.0, "avg_logprob": -0.26311240196228025, "compression_ratio":
  1.5541666666666667, "no_speech_prob": 0.0007325750775635242}, {"id": 259, "seek":
  67976, "start": 705.12, "end": 706.12, "text": " Fantastic.", "tokens": [51632,
  21320, 13, 51682], "temperature": 0.0, "avg_logprob": -0.26311240196228025, "compression_ratio":
  1.5541666666666667, "no_speech_prob": 0.0007325750775635242}, {"id": 260, "seek":
  67976, "start": 706.12, "end": 708.24, "text": " I love this YCupid.", "tokens":
  [51682, 286, 959, 341, 398, 34, 6127, 13, 51788], "temperature": 0.0, "avg_logprob":
  -0.26311240196228025, "compression_ratio": 1.5541666666666667, "no_speech_prob":
  0.0007325750775635242}, {"id": 261, "seek": 70824, "start": 708.24, "end": 710.72,
  "text": " This is sort of the origin story Doug Turmbolt,", "tokens": [50364, 639,
  307, 1333, 295, 264, 4957, 1657, 12742, 5712, 2504, 4837, 11, 50488], "temperature":
  0.0, "avg_logprob": -0.18321625038429543, "compression_ratio": 1.6354166666666667,
  "no_speech_prob": 0.001267026411369443}, {"id": 262, "seek": 70824, "start": 710.72,
  "end": 712.72, "text": " who many of you may know, right,", "tokens": [50488, 567,
  867, 295, 291, 815, 458, 11, 558, 11, 50588], "temperature": 0.0, "avg_logprob":
  -0.18321625038429543, "compression_ratio": 1.6354166666666667, "no_speech_prob":
  0.001267026411369443}, {"id": 263, "seek": 70824, "start": 712.72, "end": 714.5600000000001,
  "text": " from his book Relevant Search.", "tokens": [50588, 490, 702, 1446, 1300,
  25638, 17180, 13, 50680], "temperature": 0.0, "avg_logprob": -0.18321625038429543,
  "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.001267026411369443},
  {"id": 264, "seek": 70824, "start": 714.5600000000001, "end": 716.76, "text": "
  He created Cupid.", "tokens": [50680, 634, 2942, 383, 6127, 13, 50790], "temperature":
  0.0, "avg_logprob": -0.18321625038429543, "compression_ratio": 1.6354166666666667,
  "no_speech_prob": 0.001267026411369443}, {"id": 265, "seek": 70824, "start": 716.76,
  "end": 719.72, "text": " And we''re looking at like a decade ago at this point.",
  "tokens": [50790, 400, 321, 434, 1237, 412, 411, 257, 10378, 2057, 412, 341, 935,
  13, 50938], "temperature": 0.0, "avg_logprob": -0.18321625038429543, "compression_ratio":
  1.6354166666666667, "no_speech_prob": 0.001267026411369443}, {"id": 266, "seek":
  70824, "start": 719.72, "end": 721.16, "text": " And it was because, you know,",
  "tokens": [50938, 400, 309, 390, 570, 11, 291, 458, 11, 51010], "temperature": 0.0,
  "avg_logprob": -0.18321625038429543, "compression_ratio": 1.6354166666666667, "no_speech_prob":
  0.001267026411369443}, {"id": 267, "seek": 70824, "start": 721.16, "end": 724.12,
  "text": " it was difficult to measure and improve search, right?", "tokens": [51010,
  309, 390, 2252, 281, 3481, 293, 3470, 3164, 11, 558, 30, 51158], "temperature":
  0.0, "avg_logprob": -0.18321625038429543, "compression_ratio": 1.6354166666666667,
  "no_speech_prob": 0.001267026411369443}, {"id": 268, "seek": 70824, "start": 724.12,
  "end": 726.96, "text": " Lots of spreadsheets going back, lots of conversations.",
  "tokens": [51158, 15908, 295, 23651, 1385, 516, 646, 11, 3195, 295, 7315, 13, 51300],
  "temperature": 0.0, "avg_logprob": -0.18321625038429543, "compression_ratio": 1.6354166666666667,
  "no_speech_prob": 0.001267026411369443}, {"id": 269, "seek": 70824, "start": 726.96,
  "end": 728.84, "text": " You fix one thing, break another.", "tokens": [51300, 509,
  3191, 472, 551, 11, 1821, 1071, 13, 51394], "temperature": 0.0, "avg_logprob": -0.18321625038429543,
  "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.001267026411369443},
  {"id": 270, "seek": 70824, "start": 728.84, "end": 732.44, "text": " And Doug and
  Arena were working together on a project.", "tokens": [51394, 400, 12742, 293, 34290,
  645, 1364, 1214, 322, 257, 1716, 13, 51574], "temperature": 0.0, "avg_logprob":
  -0.18321625038429543, "compression_ratio": 1.6354166666666667, "no_speech_prob":
  0.001267026411369443}, {"id": 271, "seek": 70824, "start": 732.44, "end": 734.24,
  "text": " And it was literally,", "tokens": [51574, 400, 309, 390, 3736, 11, 51664],
  "temperature": 0.0, "avg_logprob": -0.18321625038429543, "compression_ratio": 1.6354166666666667,
  "no_speech_prob": 0.001267026411369443}, {"id": 272, "seek": 70824, "start": 734.24,
  "end": 737.12, "text": " this is the origin story for Cupid.", "tokens": [51664,
  341, 307, 264, 4957, 1657, 337, 383, 6127, 13, 51808], "temperature": 0.0, "avg_logprob":
  -0.18321625038429543, "compression_ratio": 1.6354166666666667, "no_speech_prob":
  0.001267026411369443}, {"id": 273, "seek": 73712, "start": 737.12, "end": 742.04,
  "text": " So Cupid''s all about making collaboration better,", "tokens": [50364,
  407, 383, 6127, 311, 439, 466, 1455, 9363, 1101, 11, 50610], "temperature": 0.0,
  "avg_logprob": -0.12884377096300928, "compression_ratio": 1.7702127659574467, "no_speech_prob":
  0.00014859293878544122}, {"id": 274, "seek": 73712, "start": 742.04, "end": 744.76,
  "text": " making your testing more accurate,", "tokens": [50610, 1455, 428, 4997,
  544, 8559, 11, 50746], "temperature": 0.0, "avg_logprob": -0.12884377096300928,
  "compression_ratio": 1.7702127659574467, "no_speech_prob": 0.00014859293878544122},
  {"id": 275, "seek": 73712, "start": 744.76, "end": 747.16, "text": " and making
  things go faster, right?", "tokens": [50746, 293, 1455, 721, 352, 4663, 11, 558,
  30, 50866], "temperature": 0.0, "avg_logprob": -0.12884377096300928, "compression_ratio":
  1.7702127659574467, "no_speech_prob": 0.00014859293878544122}, {"id": 276, "seek":
  73712, "start": 747.16, "end": 751.44, "text": " Because we need to iterate and
  experiment quickly, right?", "tokens": [50866, 1436, 321, 643, 281, 44497, 293,
  5120, 2661, 11, 558, 30, 51080], "temperature": 0.0, "avg_logprob": -0.12884377096300928,
  "compression_ratio": 1.7702127659574467, "no_speech_prob": 0.00014859293878544122},
  {"id": 277, "seek": 73712, "start": 751.44, "end": 753.24, "text": " The one thing
  I know is that the team", "tokens": [51080, 440, 472, 551, 286, 458, 307, 300, 264,
  1469, 51170], "temperature": 0.0, "avg_logprob": -0.12884377096300928, "compression_ratio":
  1.7702127659574467, "no_speech_prob": 0.00014859293878544122}, {"id": 278, "seek":
  73712, "start": 753.24, "end": 755.44, "text": " that can experiment quickly and
  effectively", "tokens": [51170, 300, 393, 5120, 2661, 293, 8659, 51280], "temperature":
  0.0, "avg_logprob": -0.12884377096300928, "compression_ratio": 1.7702127659574467,
  "no_speech_prob": 0.00014859293878544122}, {"id": 279, "seek": 73712, "start": 755.44,
  "end": 757.88, "text": " is the team that''s going to win out, right?", "tokens":
  [51280, 307, 264, 1469, 300, 311, 516, 281, 1942, 484, 11, 558, 30, 51402], "temperature":
  0.0, "avg_logprob": -0.12884377096300928, "compression_ratio": 1.7702127659574467,
  "no_speech_prob": 0.00014859293878544122}, {"id": 280, "seek": 73712, "start": 757.88,
  "end": 760.8, "text": " It''s not about specific technology choices", "tokens":
  [51402, 467, 311, 406, 466, 2685, 2899, 7994, 51548], "temperature": 0.0, "avg_logprob":
  -0.12884377096300928, "compression_ratio": 1.7702127659574467, "no_speech_prob":
  0.00014859293878544122}, {"id": 281, "seek": 73712, "start": 760.8, "end": 762.76,
  "text": " or technical expertise.", "tokens": [51548, 420, 6191, 11769, 13, 51646],
  "temperature": 0.0, "avg_logprob": -0.12884377096300928, "compression_ratio": 1.7702127659574467,
  "no_speech_prob": 0.00014859293878544122}, {"id": 282, "seek": 73712, "start": 762.76,
  "end": 764.48, "text": " It''s experimentation.", "tokens": [51646, 467, 311, 37142,
  13, 51732], "temperature": 0.0, "avg_logprob": -0.12884377096300928, "compression_ratio":
  1.7702127659574467, "no_speech_prob": 0.00014859293878544122}, {"id": 283, "seek":
  73712, "start": 764.48, "end": 765.92, "text": " Can you do it quickly?", "tokens":
  [51732, 1664, 291, 360, 309, 2661, 30, 51804], "temperature": 0.0, "avg_logprob":
  -0.12884377096300928, "compression_ratio": 1.7702127659574467, "no_speech_prob":
  0.00014859293878544122}, {"id": 284, "seek": 76592, "start": 765.92, "end": 770.92,
  "text": " So yeah, so Cupid.com has the advertising free hosted version,", "tokens":
  [50364, 407, 1338, 11, 370, 383, 6127, 13, 1112, 575, 264, 13097, 1737, 19204, 3037,
  11, 50614], "temperature": 0.0, "avg_logprob": -0.21256390652915305, "compression_ratio":
  1.595330739299611, "no_speech_prob": 0.001894827582873404}, {"id": 285, "seek":
  76592, "start": 772.3199999999999, "end": 773.3199999999999, "text": " really excited.",
  "tokens": [50684, 534, 2919, 13, 50734], "temperature": 0.0, "avg_logprob": -0.21256390652915305,
  "compression_ratio": 1.595330739299611, "no_speech_prob": 0.001894827582873404},
  {"id": 286, "seek": 76592, "start": 773.3199999999999, "end": 778.0799999999999,
  "text": " It sort of continues to be useful in today''s world.", "tokens": [50734,
  467, 1333, 295, 6515, 281, 312, 4420, 294, 965, 311, 1002, 13, 50972], "temperature":
  0.0, "avg_logprob": -0.21256390652915305, "compression_ratio": 1.595330739299611,
  "no_speech_prob": 0.001894827582873404}, {"id": 287, "seek": 76592, "start": 778.0799999999999,
  "end": 778.92, "text": " Absolutely.", "tokens": [50972, 7021, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.21256390652915305, "compression_ratio": 1.595330739299611,
  "no_speech_prob": 0.001894827582873404}, {"id": 288, "seek": 76592, "start": 778.92,
  "end": 780.36, "text": " And it''s also open source, right?", "tokens": [51014,
  400, 309, 311, 611, 1269, 4009, 11, 558, 30, 51086], "temperature": 0.0, "avg_logprob":
  -0.21256390652915305, "compression_ratio": 1.595330739299611, "no_speech_prob":
  0.001894827582873404}, {"id": 289, "seek": 76592, "start": 780.36, "end": 784.1999999999999,
  "text": " So you don''t have to be buying anything, whatever.", "tokens": [51086,
  407, 291, 500, 380, 362, 281, 312, 6382, 1340, 11, 2035, 13, 51278], "temperature":
  0.0, "avg_logprob": -0.21256390652915305, "compression_ratio": 1.595330739299611,
  "no_speech_prob": 0.001894827582873404}, {"id": 290, "seek": 76592, "start": 784.1999999999999,
  "end": 785.4, "text": " It used to be a product though.", "tokens": [51278, 467,
  1143, 281, 312, 257, 1674, 1673, 13, 51338], "temperature": 0.0, "avg_logprob":
  -0.21256390652915305, "compression_ratio": 1.595330739299611, "no_speech_prob":
  0.001894827582873404}, {"id": 291, "seek": 76592, "start": 785.4, "end": 786.9599999999999,
  "text": " It used to be generating revenue.", "tokens": [51338, 467, 1143, 281,
  312, 17746, 9324, 13, 51416], "temperature": 0.0, "avg_logprob": -0.21256390652915305,
  "compression_ratio": 1.595330739299611, "no_speech_prob": 0.001894827582873404},
  {"id": 292, "seek": 76592, "start": 786.9599999999999, "end": 788.4399999999999,
  "text": " Yeah, I mean, you told me.", "tokens": [51416, 865, 11, 286, 914, 11,
  291, 1907, 385, 13, 51490], "temperature": 0.0, "avg_logprob": -0.21256390652915305,
  "compression_ratio": 1.595330739299611, "no_speech_prob": 0.001894827582873404},
  {"id": 293, "seek": 76592, "start": 788.4399999999999, "end": 789.4399999999999,
  "text": " We''re consulting soon.", "tokens": [51490, 492, 434, 23682, 2321, 13,
  51540], "temperature": 0.0, "avg_logprob": -0.21256390652915305, "compression_ratio":
  1.595330739299611, "no_speech_prob": 0.001894827582873404}, {"id": 294, "seek":
  76592, "start": 789.4399999999999, "end": 790.92, "text": " So yeah, we used to
  sell it.", "tokens": [51540, 407, 1338, 11, 321, 1143, 281, 3607, 309, 13, 51614],
  "temperature": 0.0, "avg_logprob": -0.21256390652915305, "compression_ratio": 1.595330739299611,
  "no_speech_prob": 0.001894827582873404}, {"id": 295, "seek": 76592, "start": 790.92,
  "end": 794.24, "text": " We used to sell it for $10,000 a year", "tokens": [51614,
  492, 1143, 281, 3607, 309, 337, 1848, 3279, 11, 1360, 257, 1064, 51780], "temperature":
  0.0, "avg_logprob": -0.21256390652915305, "compression_ratio": 1.595330739299611,
  "no_speech_prob": 0.001894827582873404}, {"id": 296, "seek": 79424, "start": 794.24,
  "end": 796.0, "text": " for an enterprise license.", "tokens": [50364, 337, 364,
  14132, 10476, 13, 50452], "temperature": 0.0, "avg_logprob": -0.16556763421921503,
  "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.00370888807810843},
  {"id": 297, "seek": 79424, "start": 796.0, "end": 798.04, "text": " And we had customers
  and it was great.", "tokens": [50452, 400, 321, 632, 4581, 293, 309, 390, 869, 13,
  50554], "temperature": 0.0, "avg_logprob": -0.16556763421921503, "compression_ratio":
  1.5208333333333333, "no_speech_prob": 0.00370888807810843}, {"id": 298, "seek":
  79424, "start": 798.04, "end": 802.4, "text": " But I think then we figured out
  we were making, I don''t know,", "tokens": [50554, 583, 286, 519, 550, 321, 8932,
  484, 321, 645, 1455, 11, 286, 500, 380, 458, 11, 50772], "temperature": 0.0, "avg_logprob":
  -0.16556763421921503, "compression_ratio": 1.5208333333333333, "no_speech_prob":
  0.00370888807810843}, {"id": 299, "seek": 79424, "start": 803.4, "end": 806.4, "text":
  " $80,000 a year, which sounds like a lot,", "tokens": [50822, 1848, 4702, 11, 1360,
  257, 1064, 11, 597, 3263, 411, 257, 688, 11, 50972], "temperature": 0.0, "avg_logprob":
  -0.16556763421921503, "compression_ratio": 1.5208333333333333, "no_speech_prob":
  0.00370888807810843}, {"id": 300, "seek": 79424, "start": 806.4, "end": 810.6, "text":
  " but then investing $150,000 in salary, supporting it.", "tokens": [50972, 457,
  550, 10978, 1848, 20120, 11, 1360, 294, 15360, 11, 7231, 309, 13, 51182], "temperature":
  0.0, "avg_logprob": -0.16556763421921503, "compression_ratio": 1.5208333333333333,
  "no_speech_prob": 0.00370888807810843}, {"id": 301, "seek": 79424, "start": 810.6,
  "end": 813.96, "text": " And it was like, yeah, we''re not a product company.",
  "tokens": [51182, 400, 309, 390, 411, 11, 1338, 11, 321, 434, 406, 257, 1674, 2237,
  13, 51350], "temperature": 0.0, "avg_logprob": -0.16556763421921503, "compression_ratio":
  1.5208333333333333, "no_speech_prob": 0.00370888807810843}, {"id": 302, "seek":
  79424, "start": 813.96, "end": 817.32, "text": " And we are open source connections,",
  "tokens": [51350, 400, 321, 366, 1269, 4009, 9271, 11, 51518], "temperature": 0.0,
  "avg_logprob": -0.16556763421921503, "compression_ratio": 1.5208333333333333, "no_speech_prob":
  0.00370888807810843}, {"id": 303, "seek": 79424, "start": 817.32, "end": 820.24,
  "text": " having a commercial product just didn''t fit naturally.", "tokens": [51518,
  1419, 257, 6841, 1674, 445, 994, 380, 3318, 8195, 13, 51664], "temperature": 0.0,
  "avg_logprob": -0.16556763421921503, "compression_ratio": 1.5208333333333333, "no_speech_prob":
  0.00370888807810843}, {"id": 304, "seek": 82024, "start": 820.24, "end": 825.24,
  "text": " And since we''re all about training our clients", "tokens": [50364, 400,
  1670, 321, 434, 439, 466, 3097, 527, 6982, 50614], "temperature": 0.0, "avg_logprob":
  -0.17847543604233684, "compression_ratio": 1.6259541984732824, "no_speech_prob":
  0.0020903716795146465}, {"id": 305, "seek": 82024, "start": 825.5600000000001, "end":
  828.88, "text": " and empowering search teams, right?", "tokens": [50630, 293, 28261,
  3164, 5491, 11, 558, 30, 50796], "temperature": 0.0, "avg_logprob": -0.17847543604233684,
  "compression_ratio": 1.6259541984732824, "no_speech_prob": 0.0020903716795146465},
  {"id": 306, "seek": 82024, "start": 828.88, "end": 831.52, "text": " Doesn''t necessarily
  feel empowering to be like,", "tokens": [50796, 12955, 380, 4725, 841, 28261, 281,
  312, 411, 11, 50928], "temperature": 0.0, "avg_logprob": -0.17847543604233684, "compression_ratio":
  1.6259541984732824, "no_speech_prob": 0.0020903716795146465}, {"id": 307, "seek":
  82024, "start": 831.52, "end": 833.08, "text": " yes, we''ve empowered you,", "tokens":
  [50928, 2086, 11, 321, 600, 27898, 291, 11, 51006], "temperature": 0.0, "avg_logprob":
  -0.17847543604233684, "compression_ratio": 1.6259541984732824, "no_speech_prob":
  0.0020903716795146465}, {"id": 308, "seek": 82024, "start": 833.08, "end": 834.8,
  "text": " but you have to pay us money every month", "tokens": [51006, 457, 291,
  362, 281, 1689, 505, 1460, 633, 1618, 51092], "temperature": 0.0, "avg_logprob":
  -0.17847543604233684, "compression_ratio": 1.6259541984732824, "no_speech_prob":
  0.0020903716795146465}, {"id": 309, "seek": 82024, "start": 834.8, "end": 837.12,
  "text": " for this one product, right?", "tokens": [51092, 337, 341, 472, 1674,
  11, 558, 30, 51208], "temperature": 0.0, "avg_logprob": -0.17847543604233684, "compression_ratio":
  1.6259541984732824, "no_speech_prob": 0.0020903716795146465}, {"id": 310, "seek":
  82024, "start": 837.12, "end": 840.84, "text": " Just felt more natural to have
  it as an open source project.", "tokens": [51208, 1449, 2762, 544, 3303, 281, 362,
  309, 382, 364, 1269, 4009, 1716, 13, 51394], "temperature": 0.0, "avg_logprob":
  -0.17847543604233684, "compression_ratio": 1.6259541984732824, "no_speech_prob":
  0.0020903716795146465}, {"id": 311, "seek": 82024, "start": 840.84, "end": 841.6800000000001,
  "text": " Yeah, absolutely.", "tokens": [51394, 865, 11, 3122, 13, 51436], "temperature":
  0.0, "avg_logprob": -0.17847543604233684, "compression_ratio": 1.6259541984732824,
  "no_speech_prob": 0.0020903716795146465}, {"id": 312, "seek": 82024, "start": 841.6800000000001,
  "end": 844.4, "text": " And it also fits your, well, how should I say,", "tokens":
  [51436, 400, 309, 611, 9001, 428, 11, 731, 11, 577, 820, 286, 584, 11, 51572], "temperature":
  0.0, "avg_logprob": -0.17847543604233684, "compression_ratio": 1.6259541984732824,
  "no_speech_prob": 0.0020903716795146465}, {"id": 313, "seek": 82024, "start": 844.4,
  "end": 847.44, "text": " your professional line at UI commuter.", "tokens": [51572,
  428, 4843, 1622, 412, 15682, 800, 20314, 13, 51724], "temperature": 0.0, "avg_logprob":
  -0.17847543604233684, "compression_ratio": 1.6259541984732824, "no_speech_prob":
  0.0020903716795146465}, {"id": 314, "seek": 82024, "start": 847.44, "end": 849.4,
  "text": " You''ve seen solar commuter, right?", "tokens": [51724, 509, 600, 1612,
  7936, 800, 20314, 11, 558, 30, 51822], "temperature": 0.0, "avg_logprob": -0.17847543604233684,
  "compression_ratio": 1.6259541984732824, "no_speech_prob": 0.0020903716795146465},
  {"id": 315, "seek": 84940, "start": 849.4, "end": 852.9599999999999, "text": " Yeah,
  so I am a commuter, not active on Lucene,", "tokens": [50364, 865, 11, 370, 286,
  669, 257, 800, 20314, 11, 406, 4967, 322, 9593, 1450, 11, 50542], "temperature":
  0.0, "avg_logprob": -0.16465173326097093, "compression_ratio": 1.6926229508196722,
  "no_speech_prob": 0.00010032494901679456}, {"id": 316, "seek": 84940, "start": 852.9599999999999,
  "end": 855.84, "text": " that''s just a level of technical expertise.", "tokens":
  [50542, 300, 311, 445, 257, 1496, 295, 6191, 11769, 13, 50686], "temperature": 0.0,
  "avg_logprob": -0.16465173326097093, "compression_ratio": 1.6926229508196722, "no_speech_prob":
  0.00010032494901679456}, {"id": 317, "seek": 84940, "start": 855.84, "end": 857.6,
  "text": " But I am a commuter on solar.", "tokens": [50686, 583, 286, 669, 257,
  800, 20314, 322, 7936, 13, 50774], "temperature": 0.0, "avg_logprob": -0.16465173326097093,
  "compression_ratio": 1.6926229508196722, "no_speech_prob": 0.00010032494901679456},
  {"id": 318, "seek": 84940, "start": 857.6, "end": 860.56, "text": " And then interesting
  as like an interesting", "tokens": [50774, 400, 550, 1880, 382, 411, 364, 1880,
  50922], "temperature": 0.0, "avg_logprob": -0.16465173326097093, "compression_ratio":
  1.6926229508196722, "no_speech_prob": 0.00010032494901679456}, {"id": 319, "seek":
  84940, "start": 860.56, "end": 863.4, "text": " personal professional development,",
  "tokens": [50922, 2973, 4843, 3250, 11, 51064], "temperature": 0.0, "avg_logprob":
  -0.16465173326097093, "compression_ratio": 1.6926229508196722, "no_speech_prob":
  0.00010032494901679456}, {"id": 320, "seek": 84940, "start": 863.4, "end": 865.52,
  "text": " I''ve been really gotten much more involved", "tokens": [51064, 286, 600,
  668, 534, 5768, 709, 544, 3288, 51170], "temperature": 0.0, "avg_logprob": -0.16465173326097093,
  "compression_ratio": 1.6926229508196722, "no_speech_prob": 0.00010032494901679456},
  {"id": 321, "seek": 84940, "start": 865.52, "end": 868.9599999999999, "text": "
  with the open search community over the whole year.", "tokens": [51170, 365, 264,
  1269, 3164, 1768, 670, 264, 1379, 1064, 13, 51342], "temperature": 0.0, "avg_logprob":
  -0.16465173326097093, "compression_ratio": 1.6926229508196722, "no_speech_prob":
  0.00010032494901679456}, {"id": 322, "seek": 84940, "start": 868.9599999999999,
  "end": 873.72, "text": " And so I''m now a, they call it a maintainer instead of
  commuter,", "tokens": [51342, 400, 370, 286, 478, 586, 257, 11, 436, 818, 309, 257,
  6909, 260, 2602, 295, 800, 20314, 11, 51580], "temperature": 0.0, "avg_logprob":
  -0.16465173326097093, "compression_ratio": 1.6926229508196722, "no_speech_prob":
  0.00010032494901679456}, {"id": 323, "seek": 84940, "start": 873.72, "end": 877.88,
  "text": " but I am a maintainer for open search documentation,", "tokens": [51580,
  457, 286, 669, 257, 6909, 260, 337, 1269, 3164, 14333, 11, 51788], "temperature":
  0.0, "avg_logprob": -0.16465173326097093, "compression_ratio": 1.6926229508196722,
  "no_speech_prob": 0.00010032494901679456}, {"id": 324, "seek": 87788, "start": 877.88,
  "end": 881.32, "text": " which has really been really a lot fun to work on.", "tokens":
  [50364, 597, 575, 534, 668, 534, 257, 688, 1019, 281, 589, 322, 13, 50536], "temperature":
  0.0, "avg_logprob": -0.19662362110765674, "compression_ratio": 1.532258064516129,
  "no_speech_prob": 0.00040204881224781275}, {"id": 325, "seek": 87788, "start": 881.32,
  "end": 885.16, "text": " And we''re talking about it maybe in another podcast,",
  "tokens": [50536, 400, 321, 434, 1417, 466, 309, 1310, 294, 1071, 7367, 11, 50728],
  "temperature": 0.0, "avg_logprob": -0.19662362110765674, "compression_ratio": 1.532258064516129,
  "no_speech_prob": 0.00040204881224781275}, {"id": 326, "seek": 87788, "start": 885.16,
  "end": 889.16, "text": " but contributing some new features to open search,", "tokens":
  [50728, 457, 19270, 512, 777, 4122, 281, 1269, 3164, 11, 50928], "temperature":
  0.0, "avg_logprob": -0.19662362110765674, "compression_ratio": 1.532258064516129,
  "no_speech_prob": 0.00040204881224781275}, {"id": 327, "seek": 87788, "start": 889.16,
  "end": 890.32, "text": " the open source product.", "tokens": [50928, 264, 1269,
  4009, 1674, 13, 50986], "temperature": 0.0, "avg_logprob": -0.19662362110765674,
  "compression_ratio": 1.532258064516129, "no_speech_prob": 0.00040204881224781275},
  {"id": 328, "seek": 87788, "start": 890.32, "end": 892.52, "text": " So really excited
  about that.", "tokens": [50986, 407, 534, 2919, 466, 300, 13, 51096], "temperature":
  0.0, "avg_logprob": -0.19662362110765674, "compression_ratio": 1.532258064516129,
  "no_speech_prob": 0.00040204881224781275}, {"id": 329, "seek": 87788, "start": 892.52,
  "end": 893.36, "text": " Sam.", "tokens": [51096, 4832, 13, 51138], "temperature":
  0.0, "avg_logprob": -0.19662362110765674, "compression_ratio": 1.532258064516129,
  "no_speech_prob": 0.00040204881224781275}, {"id": 330, "seek": 87788, "start": 893.36,
  "end": 895.16, "text": " Actually, give me one second.", "tokens": [51138, 5135,
  11, 976, 385, 472, 1150, 13, 51228], "temperature": 0.0, "avg_logprob": -0.19662362110765674,
  "compression_ratio": 1.532258064516129, "no_speech_prob": 0.00040204881224781275},
  {"id": 331, "seek": 87788, "start": 895.16, "end": 897.36, "text": " I have one
  thing to confess, one second.", "tokens": [51228, 286, 362, 472, 551, 281, 19367,
  11, 472, 1150, 13, 51338], "temperature": 0.0, "avg_logprob": -0.19662362110765674,
  "compression_ratio": 1.532258064516129, "no_speech_prob": 0.00040204881224781275},
  {"id": 332, "seek": 90788, "start": 908.88, "end": 912.88, "text": " I have to confess
  or share one personal bit", "tokens": [50414, 286, 362, 281, 19367, 420, 2073, 472,
  2973, 857, 50614], "temperature": 0.0, "avg_logprob": -0.27774031687591033, "compression_ratio":
  1.6794871794871795, "no_speech_prob": 0.018705174326896667}, {"id": 333, "seek":
  90788, "start": 912.88, "end": 916.88, "text": " that when I started in search,
  it was,", "tokens": [50614, 300, 562, 286, 1409, 294, 3164, 11, 309, 390, 11, 50814],
  "temperature": 0.0, "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795,
  "no_speech_prob": 0.018705174326896667}, {"id": 334, "seek": 90788, "start": 916.88,
  "end": 918.88, "text": " of course, it was early.", "tokens": [50814, 295, 1164,
  11, 309, 390, 2440, 13, 50914], "temperature": 0.0, "avg_logprob": -0.27774031687591033,
  "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.018705174326896667},
  {"id": 335, "seek": 90788, "start": 918.88, "end": 921.88, "text": " It was like
  2003 about when I wrote my own search engine.", "tokens": [50914, 467, 390, 411,
  16416, 466, 562, 286, 4114, 452, 1065, 3164, 2848, 13, 51064], "temperature": 0.0,
  "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795, "no_speech_prob":
  0.018705174326896667}, {"id": 336, "seek": 90788, "start": 921.88, "end": 924.88,
  "text": " But when I started doing search in the industry, right?", "tokens": [51064,
  583, 562, 286, 1409, 884, 3164, 294, 264, 3518, 11, 558, 30, 51214], "temperature":
  0.0, "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795,
  "no_speech_prob": 0.018705174326896667}, {"id": 337, "seek": 90788, "start": 924.88,
  "end": 926.88, "text": " It was 2010.", "tokens": [51214, 467, 390, 9657, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795,
  "no_speech_prob": 0.018705174326896667}, {"id": 338, "seek": 90788, "start": 926.88,
  "end": 928.88, "text": " And it was a patch of solar.", "tokens": [51314, 400, 309,
  390, 257, 9972, 295, 7936, 13, 51414], "temperature": 0.0, "avg_logprob": -0.27774031687591033,
  "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.018705174326896667},
  {"id": 339, "seek": 90788, "start": 928.88, "end": 930.88, "text": " And when you
  Google a patch of solar,", "tokens": [51414, 400, 562, 291, 3329, 257, 9972, 295,
  7936, 11, 51514], "temperature": 0.0, "avg_logprob": -0.27774031687591033, "compression_ratio":
  1.6794871794871795, "no_speech_prob": 0.018705174326896667}, {"id": 340, "seek":
  90788, "start": 930.88, "end": 933.88, "text": " you would mostly find Java, Java
  dog.", "tokens": [51514, 291, 576, 5240, 915, 10745, 11, 10745, 3000, 13, 51664],
  "temperature": 0.0, "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795,
  "no_speech_prob": 0.018705174326896667}, {"id": 341, "seek": 90788, "start": 933.88,
  "end": 934.88, "text": " Yeah.", "tokens": [51664, 865, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795,
  "no_speech_prob": 0.018705174326896667}, {"id": 342, "seek": 90788, "start": 934.88,
  "end": 936.88, "text": " And maybe, and then I figured out there is also", "tokens":
  [51714, 400, 1310, 11, 293, 550, 286, 8932, 484, 456, 307, 611, 51814], "temperature":
  0.0, "avg_logprob": -0.27774031687591033, "compression_ratio": 1.6794871794871795,
  "no_speech_prob": 0.018705174326896667}, {"id": 343, "seek": 93688, "start": 936.88,
  "end": 940.88, "text": " a mailing list was like, but is there a place where I can
  read", "tokens": [50364, 257, 41612, 1329, 390, 411, 11, 457, 307, 456, 257, 1081,
  689, 286, 393, 1401, 50564], "temperature": 0.0, "avg_logprob": -0.3190021667480469,
  "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.0600990392267704},
  {"id": 344, "seek": 93688, "start": 940.88, "end": 943.88, "text": " about solar
  besides Vicky pages because Vicky pages were not", "tokens": [50564, 466, 7936,
  11868, 691, 20539, 7183, 570, 691, 20539, 7183, 645, 406, 50714], "temperature":
  0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 345, "seek": 93688, "start": 943.88,
  "end": 945.88, "text": " kind of complete in a way?", "tokens": [50714, 733, 295,
  3566, 294, 257, 636, 30, 50814], "temperature": 0.0, "avg_logprob": -0.3190021667480469,
  "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.0600990392267704},
  {"id": 346, "seek": 93688, "start": 945.88, "end": 946.88, "text": " Yep.", "tokens":
  [50814, 7010, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3190021667480469,
  "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.0600990392267704},
  {"id": 347, "seek": 93688, "start": 946.88, "end": 947.88, "text": " Yep.", "tokens":
  [50864, 7010, 13, 50914], "temperature": 0.0, "avg_logprob": -0.3190021667480469,
  "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.0600990392267704},
  {"id": 348, "seek": 93688, "start": 947.88, "end": 949.88, "text": " I was like,
  and I found this, this book.", "tokens": [50914, 286, 390, 411, 11, 293, 286, 1352,
  341, 11, 341, 1446, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3190021667480469,
  "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.0600990392267704},
  {"id": 349, "seek": 93688, "start": 949.88, "end": 950.88, "text": " Oh my gosh.",
  "tokens": [51014, 876, 452, 6502, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.3190021667480469, "compression_ratio": 1.6457399103139014, "no_speech_prob":
  0.0600990392267704}, {"id": 350, "seek": 93688, "start": 950.88, "end": 952.88,
  "text": " One point four.", "tokens": [51064, 1485, 935, 1451, 13, 51164], "temperature":
  0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 351, "seek": 93688, "start": 952.88,
  "end": 953.88, "text": " Yeah.", "tokens": [51164, 865, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 352, "seek": 93688, "start": 953.88,
  "end": 955.88, "text": " A prior server data.", "tokens": [51214, 316, 4059, 7154,
  1412, 13, 51314], "temperature": 0.0, "avg_logprob": -0.3190021667480469, "compression_ratio":
  1.6457399103139014, "no_speech_prob": 0.0600990392267704}, {"id": 353, "seek": 93688,
  "start": 955.88, "end": 956.88, "text": " Yes.", "tokens": [51314, 1079, 13, 51364],
  "temperature": 0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 354, "seek": 93688, "start": 956.88,
  "end": 957.88, "text": " Yes.", "tokens": [51364, 1079, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 355, "seek": 93688, "start": 957.88,
  "end": 958.88, "text": " Yes.", "tokens": [51414, 1079, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 356, "seek": 93688, "start": 958.88,
  "end": 960.88, "text": " And I''ve read it covered to cover.", "tokens": [51464,
  400, 286, 600, 1401, 309, 5343, 281, 2060, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.3190021667480469, "compression_ratio": 1.6457399103139014, "no_speech_prob":
  0.0600990392267704}, {"id": 357, "seek": 93688, "start": 960.88, "end": 964.88,
  "text": " I have to say it because because I had one challenging task.", "tokens":
  [51564, 286, 362, 281, 584, 309, 570, 570, 286, 632, 472, 7595, 5633, 13, 51764],
  "temperature": 0.0, "avg_logprob": -0.3190021667480469, "compression_ratio": 1.6457399103139014,
  "no_speech_prob": 0.0600990392267704}, {"id": 358, "seek": 96488, "start": 964.88,
  "end": 969.88, "text": " I had to build what I suggest and that I would suggest
  had to abide to certain rules.", "tokens": [50364, 286, 632, 281, 1322, 437, 286,
  3402, 293, 300, 286, 576, 3402, 632, 281, 39663, 281, 1629, 4474, 13, 50614], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 359, "seek": 96488, "start": 969.88,
  "end": 971.88, "text": " And I was like, oh my god, how will I do it?", "tokens":
  [50614, 400, 286, 390, 411, 11, 1954, 452, 3044, 11, 577, 486, 286, 360, 309, 30,
  50714], "temperature": 0.0, "avg_logprob": -0.20491992510282075, "compression_ratio":
  1.7302158273381294, "no_speech_prob": 0.09609706699848175}, {"id": 360, "seek":
  96488, "start": 971.88, "end": 973.88, "text": " In the moment I did it, it was
  also slow.", "tokens": [50714, 682, 264, 1623, 286, 630, 309, 11, 309, 390, 611,
  2964, 13, 50814], "temperature": 0.0, "avg_logprob": -0.20491992510282075, "compression_ratio":
  1.7302158273381294, "no_speech_prob": 0.09609706699848175}, {"id": 361, "seek":
  96488, "start": 973.88, "end": 977.88, "text": " So I had to figure out on our data,
  on our version of model of data.", "tokens": [50814, 407, 286, 632, 281, 2573, 484,
  322, 527, 1412, 11, 322, 527, 3037, 295, 2316, 295, 1412, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 362, "seek": 96488, "start": 977.88,
  "end": 978.88, "text": " Right.", "tokens": [51014, 1779, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 363, "seek": 96488, "start": 978.88,
  "end": 979.88, "text": " Oh my god, this was so exciting.", "tokens": [51064, 876,
  452, 3044, 11, 341, 390, 370, 4670, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.20491992510282075, "compression_ratio": 1.7302158273381294, "no_speech_prob":
  0.09609706699848175}, {"id": 364, "seek": 96488, "start": 979.88, "end": 982.88,
  "text": " I was like going back and forth between the book.", "tokens": [51114,
  286, 390, 411, 516, 646, 293, 5220, 1296, 264, 1446, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 365, "seek": 96488, "start": 982.88,
  "end": 985.88, "text": " And then a bit of googling and then trying things.", "tokens":
  [51264, 400, 550, 257, 857, 295, 50061, 1688, 293, 550, 1382, 721, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 366, "seek": 96488, "start": 985.88,
  "end": 986.88, "text": " Ah, yes.", "tokens": [51414, 2438, 11, 2086, 13, 51464],
  "temperature": 0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 367, "seek": 96488, "start": 986.88,
  "end": 987.88, "text": " Fantastic.", "tokens": [51464, 21320, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 368, "seek": 96488, "start": 987.88,
  "end": 988.88, "text": " Wow.", "tokens": [51514, 3153, 13, 51564], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 369, "seek": 96488, "start": 988.88,
  "end": 989.88, "text": " Thanks for doing this.", "tokens": [51564, 2561, 337, 884,
  341, 13, 51614], "temperature": 0.0, "avg_logprob": -0.20491992510282075, "compression_ratio":
  1.7302158273381294, "no_speech_prob": 0.09609706699848175}, {"id": 370, "seek":
  96488, "start": 989.88, "end": 990.88, "text": " So you also the author.", "tokens":
  [51614, 407, 291, 611, 264, 3793, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.20491992510282075, "compression_ratio": 1.7302158273381294, "no_speech_prob":
  0.09609706699848175}, {"id": 371, "seek": 96488, "start": 990.88, "end": 991.88,
  "text": " You also the author.", "tokens": [51664, 509, 611, 264, 3793, 13, 51714],
  "temperature": 0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 372, "seek": 96488, "start": 991.88,
  "end": 992.88, "text": " Yeah.", "tokens": [51714, 865, 13, 51764], "temperature":
  0.0, "avg_logprob": -0.20491992510282075, "compression_ratio": 1.7302158273381294,
  "no_speech_prob": 0.09609706699848175}, {"id": 373, "seek": 99288, "start": 992.88,
  "end": 993.88, "text": " Yeah.", "tokens": [50364, 865, 13, 50414], "temperature":
  0.0, "avg_logprob": -0.1467973153422198, "compression_ratio": 1.6640625, "no_speech_prob":
  0.0089711369946599}, {"id": 374, "seek": 99288, "start": 993.88, "end": 994.88,
  "text": " Yeah.", "tokens": [50414, 865, 13, 50464], "temperature": 0.0, "avg_logprob":
  -0.1467973153422198, "compression_ratio": 1.6640625, "no_speech_prob": 0.0089711369946599},
  {"id": 375, "seek": 99288, "start": 994.88, "end": 995.88, "text": " Yeah.", "tokens":
  [50464, 865, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1467973153422198,
  "compression_ratio": 1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 376,
  "seek": 99288, "start": 995.88, "end": 996.88, "text": " Yeah.", "tokens": [50514,
  865, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1467973153422198, "compression_ratio":
  1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 377, "seek": 99288, "start":
  996.88, "end": 997.88, "text": " So we did that book.", "tokens": [50564, 407, 321,
  630, 300, 1446, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1467973153422198,
  "compression_ratio": 1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 378,
  "seek": 99288, "start": 997.88, "end": 998.88, "text": " We did it.", "tokens":
  [50614, 492, 630, 309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1467973153422198,
  "compression_ratio": 1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 379,
  "seek": 99288, "start": 998.88, "end": 1000.88, "text": " We did a second version
  of it for updated solar.", "tokens": [50664, 492, 630, 257, 1150, 3037, 295, 309,
  337, 10588, 7936, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1467973153422198,
  "compression_ratio": 1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 380,
  "seek": 99288, "start": 1000.88, "end": 1002.88, "text": " But that was quite a
  few years ago.", "tokens": [50764, 583, 300, 390, 1596, 257, 1326, 924, 2057, 13,
  50864], "temperature": 0.0, "avg_logprob": -0.1467973153422198, "compression_ratio":
  1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 381, "seek": 99288, "start":
  1002.88, "end": 1006.88, "text": " I am kind of curious what''s going to happen
  with technical books.", "tokens": [50864, 286, 669, 733, 295, 6369, 437, 311, 516,
  281, 1051, 365, 6191, 3642, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1467973153422198,
  "compression_ratio": 1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 382,
  "seek": 99288, "start": 1006.88, "end": 1007.88, "text": " Right.", "tokens": [51064,
  1779, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1467973153422198, "compression_ratio":
  1.6640625, "no_speech_prob": 0.0089711369946599}, {"id": 383, "seek": 99288, "start":
  1007.88, "end": 1015.88, "text": " I mean, in the solar community, we got the ref
  guide, which is, I think, pretty darn good considering how it''s written.", "tokens":
  [51114, 286, 914, 11, 294, 264, 7936, 1768, 11, 321, 658, 264, 1895, 5934, 11, 597,
  307, 11, 286, 519, 11, 1238, 29063, 665, 8079, 577, 309, 311, 3720, 13, 51514],
  "temperature": 0.0, "avg_logprob": -0.1467973153422198, "compression_ratio": 1.6640625,
  "no_speech_prob": 0.0089711369946599}, {"id": 384, "seek": 99288, "start": 1015.88,
  "end": 1021.88, "text": " I do sort of wonder what the future of technical books
  will be with open source communities.", "tokens": [51514, 286, 360, 1333, 295, 2441,
  437, 264, 2027, 295, 6191, 3642, 486, 312, 365, 1269, 4009, 4456, 13, 51814], "temperature":
  0.0, "avg_logprob": -0.1467973153422198, "compression_ratio": 1.6640625, "no_speech_prob":
  0.0089711369946599}, {"id": 385, "seek": 102188, "start": 1021.88, "end": 1024.88,
  "text": " And what do we do?", "tokens": [50364, 400, 437, 360, 321, 360, 30, 50514],
  "temperature": 0.0, "avg_logprob": -0.21024766489237295, "compression_ratio": 1.691358024691358,
  "no_speech_prob": 0.015546152368187904}, {"id": 386, "seek": 102188, "start": 1024.88,
  "end": 1035.88, "text": " So maybe like cookbooks, you know, like that you have
  specific cases and like, how would you come about building these things and maybe
  real data so people can actually try things, right?", "tokens": [50514, 407, 1310,
  411, 2543, 15170, 11, 291, 458, 11, 411, 300, 291, 362, 2685, 3331, 293, 411, 11,
  577, 576, 291, 808, 466, 2390, 613, 721, 293, 1310, 957, 1412, 370, 561, 393, 767,
  853, 721, 11, 558, 30, 51064], "temperature": 0.0, "avg_logprob": -0.21024766489237295,
  "compression_ratio": 1.691358024691358, "no_speech_prob": 0.015546152368187904},
  {"id": 387, "seek": 102188, "start": 1035.88, "end": 1036.88, "text": " Yeah.",
  "tokens": [51064, 865, 13, 51114], "temperature": 0.0, "avg_logprob": -0.21024766489237295,
  "compression_ratio": 1.691358024691358, "no_speech_prob": 0.015546152368187904},
  {"id": 388, "seek": 102188, "start": 1036.88, "end": 1037.88, "text": " Yeah.",
  "tokens": [51114, 865, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21024766489237295,
  "compression_ratio": 1.691358024691358, "no_speech_prob": 0.015546152368187904},
  {"id": 389, "seek": 102188, "start": 1037.88, "end": 1038.88, "text": " Yeah.",
  "tokens": [51164, 865, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21024766489237295,
  "compression_ratio": 1.691358024691358, "no_speech_prob": 0.015546152368187904},
  {"id": 390, "seek": 102188, "start": 1038.88, "end": 1041.88, "text": " I mean,
  it has gotten a lot easier to publish on the web, right?", "tokens": [51214, 286,
  914, 11, 309, 575, 5768, 257, 688, 3571, 281, 11374, 322, 264, 3670, 11, 558, 30,
  51364], "temperature": 0.0, "avg_logprob": -0.21024766489237295, "compression_ratio":
  1.691358024691358, "no_speech_prob": 0.015546152368187904}, {"id": 391, "seek":
  102188, "start": 1041.88, "end": 1042.88, "text": " Yeah.", "tokens": [51364, 865,
  13, 51414], "temperature": 0.0, "avg_logprob": -0.21024766489237295, "compression_ratio":
  1.691358024691358, "no_speech_prob": 0.015546152368187904}, {"id": 392, "seek":
  102188, "start": 1042.88, "end": 1043.88, "text": " Have something.", "tokens":
  [51414, 3560, 746, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21024766489237295,
  "compression_ratio": 1.691358024691358, "no_speech_prob": 0.015546152368187904},
  {"id": 393, "seek": 102188, "start": 1043.88, "end": 1049.88, "text": " But yeah,
  what, you know, I think a lot of people write a book sort of as a writer passage
  as well.", "tokens": [51464, 583, 1338, 11, 437, 11, 291, 458, 11, 286, 519, 257,
  688, 295, 561, 2464, 257, 1446, 1333, 295, 382, 257, 9936, 11497, 382, 731, 13,
  51764], "temperature": 0.0, "avg_logprob": -0.21024766489237295, "compression_ratio":
  1.691358024691358, "no_speech_prob": 0.015546152368187904}, {"id": 394, "seek":
  104988, "start": 1049.88, "end": 1050.88, "text": " Right.", "tokens": [50364, 1779,
  13, 50414], "temperature": 0.0, "avg_logprob": -0.17917386894552118, "compression_ratio":
  1.5663716814159292, "no_speech_prob": 0.022632339969277382}, {"id": 395, "seek":
  104988, "start": 1050.88, "end": 1057.88, "text": " So it''s a book, a little different
  thing writing a book for an open source project reference.", "tokens": [50414, 407,
  309, 311, 257, 1446, 11, 257, 707, 819, 551, 3579, 257, 1446, 337, 364, 1269, 4009,
  1716, 6408, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17917386894552118,
  "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.022632339969277382},
  {"id": 396, "seek": 104988, "start": 1057.88, "end": 1058.88, "text": " Right.",
  "tokens": [50764, 1779, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17917386894552118,
  "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.022632339969277382},
  {"id": 397, "seek": 104988, "start": 1058.88, "end": 1059.88, "text": " For sure.",
  "tokens": [50814, 1171, 988, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17917386894552118,
  "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.022632339969277382},
  {"id": 398, "seek": 104988, "start": 1059.88, "end": 1060.88, "text": " How to make
  them printable.", "tokens": [50864, 1012, 281, 652, 552, 4482, 712, 13, 50914],
  "temperature": 0.0, "avg_logprob": -0.17917386894552118, "compression_ratio": 1.5663716814159292,
  "no_speech_prob": 0.022632339969277382}, {"id": 399, "seek": 104988, "start": 1060.88,
  "end": 1063.88, "text": " So you can say I wrote the book for this open source project.",
  "tokens": [50914, 407, 291, 393, 584, 286, 4114, 264, 1446, 337, 341, 1269, 4009,
  1716, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17917386894552118, "compression_ratio":
  1.5663716814159292, "no_speech_prob": 0.022632339969277382}, {"id": 400, "seek":
  104988, "start": 1063.88, "end": 1064.88, "text": " But we''ll see.", "tokens":
  [51064, 583, 321, 603, 536, 13, 51114], "temperature": 0.0, "avg_logprob": -0.17917386894552118,
  "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.022632339969277382},
  {"id": 401, "seek": 104988, "start": 1064.88, "end": 1065.88, "text": " Yeah.",
  "tokens": [51114, 865, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17917386894552118,
  "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.022632339969277382},
  {"id": 402, "seek": 104988, "start": 1065.88, "end": 1066.88, "text": " That''s
  exciting.", "tokens": [51164, 663, 311, 4670, 13, 51214], "temperature": 0.0, "avg_logprob":
  -0.17917386894552118, "compression_ratio": 1.5663716814159292, "no_speech_prob":
  0.022632339969277382}, {"id": 403, "seek": 104988, "start": 1066.88, "end": 1068.88,
  "text": " But you also wanted to show something.", "tokens": [51214, 583, 291, 611,
  1415, 281, 855, 746, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17917386894552118,
  "compression_ratio": 1.5663716814159292, "no_speech_prob": 0.022632339969277382},
  {"id": 404, "seek": 104988, "start": 1068.88, "end": 1069.88, "text": " Let''s demo.",
  "tokens": [51314, 961, 311, 10723, 13, 51364], "temperature": 0.0, "avg_logprob":
  -0.17917386894552118, "compression_ratio": 1.5663716814159292, "no_speech_prob":
  0.022632339969277382}, {"id": 405, "seek": 104988, "start": 1069.88, "end": 1070.88,
  "text": " I''d love to.", "tokens": [51364, 286, 1116, 959, 281, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.17917386894552118, "compression_ratio": 1.5663716814159292,
  "no_speech_prob": 0.022632339969277382}, {"id": 406, "seek": 104988, "start": 1070.88,
  "end": 1071.88, "text": " Yeah.", "tokens": [51414, 865, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.17917386894552118, "compression_ratio": 1.5663716814159292,
  "no_speech_prob": 0.022632339969277382}, {"id": 407, "seek": 104988, "start": 1071.88,
  "end": 1074.88, "text": " So we touched briefly on Cuban, right?", "tokens": [51464,
  407, 321, 9828, 10515, 322, 31547, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob":
  -0.17917386894552118, "compression_ratio": 1.5663716814159292, "no_speech_prob":
  0.022632339969277382}, {"id": 408, "seek": 107488, "start": 1074.88, "end": 1081.88,
  "text": " The first one of the stewards of the project and historically for those
  of here, I''ll just go ahead.", "tokens": [50364, 440, 700, 472, 295, 264, 36270,
  295, 264, 1716, 293, 16180, 337, 729, 295, 510, 11, 286, 603, 445, 352, 2286, 13,
  50714], "temperature": 0.4, "avg_logprob": -0.265173817728902, "compression_ratio":
  1.6029411764705883, "no_speech_prob": 0.22749660909175873}, {"id": 409, "seek":
  107488, "start": 1081.88, "end": 1091.88, "text": " For those of you who''ve used
  Cuban in the past, the way it has worked is I''ll just I''ll just bring up my local
  host.", "tokens": [50714, 1171, 729, 295, 291, 567, 600, 1143, 31547, 294, 264,
  1791, 11, 264, 636, 309, 575, 2732, 307, 286, 603, 445, 286, 603, 445, 1565, 493,
  452, 2654, 3975, 13, 51214], "temperature": 0.4, "avg_logprob": -0.265173817728902,
  "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.22749660909175873},
  {"id": 410, "seek": 107488, "start": 1091.88, "end": 1092.88, "text": " Here we
  go.", "tokens": [51214, 1692, 321, 352, 13, 51264], "temperature": 0.4, "avg_logprob":
  -0.265173817728902, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.22749660909175873},
  {"id": 411, "seek": 107488, "start": 1092.88, "end": 1093.88, "text": " Right.",
  "tokens": [51264, 1779, 13, 51314], "temperature": 0.4, "avg_logprob": -0.265173817728902,
  "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.22749660909175873},
  {"id": 412, "seek": 107488, "start": 1093.88, "end": 1098.88, "text": " So one of
  the things that we batted in the not in recent, this is the development version.",
  "tokens": [51314, 407, 472, 295, 264, 721, 300, 321, 9591, 292, 294, 264, 406, 294,
  5162, 11, 341, 307, 264, 3250, 3037, 13, 51564], "temperature": 0.4, "avg_logprob":
  -0.265173817728902, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.22749660909175873},
  {"id": 413, "seek": 109888, "start": 1098.88, "end": 1104.88, "text": " I''m going
  to use it with realistic activity and Cuban is who I pulled up and I got a couple
  of cases here.", "tokens": [50364, 286, 478, 516, 281, 764, 309, 365, 12465, 5191,
  293, 31547, 307, 567, 286, 7373, 493, 293, 286, 658, 257, 1916, 295, 3331, 510,
  13, 50664], "temperature": 0.0, "avg_logprob": -0.18941512063284902, "compression_ratio":
  1.580188679245283, "no_speech_prob": 0.178276926279068}, {"id": 414, "seek": 109888,
  "start": 1104.88, "end": 1109.88, "text": " But you know, in Cuban, it works well.",
  "tokens": [50664, 583, 291, 458, 11, 294, 31547, 11, 309, 1985, 731, 13, 50914],
  "temperature": 0.0, "avg_logprob": -0.18941512063284902, "compression_ratio": 1.580188679245283,
  "no_speech_prob": 0.178276926279068}, {"id": 415, "seek": 109888, "start": 1109.88,
  "end": 1110.88, "text": " I''m going to bring up a case.", "tokens": [50914, 286,
  478, 516, 281, 1565, 493, 257, 1389, 13, 50964], "temperature": 0.0, "avg_logprob":
  -0.18941512063284902, "compression_ratio": 1.580188679245283, "no_speech_prob":
  0.178276926279068}, {"id": 416, "seek": 109888, "start": 1110.88, "end": 1111.88,
  "text": " Right.", "tokens": [50964, 1779, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.18941512063284902, "compression_ratio": 1.580188679245283, "no_speech_prob":
  0.178276926279068}, {"id": 417, "seek": 109888, "start": 1111.88, "end": 1112.88,
  "text": " Here''s a case.", "tokens": [51014, 1692, 311, 257, 1389, 13, 51064],
  "temperature": 0.0, "avg_logprob": -0.18941512063284902, "compression_ratio": 1.580188679245283,
  "no_speech_prob": 0.178276926279068}, {"id": 418, "seek": 109888, "start": 1112.88,
  "end": 1116.88, "text": " I''m going to search for milk.", "tokens": [51064, 286,
  478, 516, 281, 3164, 337, 5392, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18941512063284902,
  "compression_ratio": 1.580188679245283, "no_speech_prob": 0.178276926279068}, {"id":
  419, "seek": 109888, "start": 1116.88, "end": 1118.88, "text": " I did a query for
  milk.", "tokens": [51264, 286, 630, 257, 14581, 337, 5392, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.18941512063284902, "compression_ratio": 1.580188679245283,
  "no_speech_prob": 0.178276926279068}, {"id": 420, "seek": 109888, "start": 1118.88,
  "end": 1122.88, "text": " This is using sort of a random data set here.", "tokens":
  [51364, 639, 307, 1228, 1333, 295, 257, 4974, 1412, 992, 510, 13, 51564], "temperature":
  0.0, "avg_logprob": -0.18941512063284902, "compression_ratio": 1.580188679245283,
  "no_speech_prob": 0.178276926279068}, {"id": 421, "seek": 109888, "start": 1122.88,
  "end": 1126.88, "text": " It''s backed by a solar search engine.", "tokens": [51564,
  467, 311, 20391, 538, 257, 7936, 3164, 2848, 13, 51764], "temperature": 0.0, "avg_logprob":
  -0.18941512063284902, "compression_ratio": 1.580188679245283, "no_speech_prob":
  0.178276926279068}, {"id": 422, "seek": 112688, "start": 1126.88, "end": 1127.88,
  "text": " And there''s a survey right there.", "tokens": [50364, 400, 456, 311,
  257, 8984, 558, 456, 13, 50414], "temperature": 0.0, "avg_logprob": -0.3001977169152462,
  "compression_ratio": 1.4918032786885247, "no_speech_prob": 0.02273700200021267},
  {"id": 423, "seek": 112688, "start": 1127.88, "end": 1129.88, "text": " There''s
  my search engine.", "tokens": [50414, 821, 311, 452, 3164, 2848, 13, 50514], "temperature":
  0.0, "avg_logprob": -0.3001977169152462, "compression_ratio": 1.4918032786885247,
  "no_speech_prob": 0.02273700200021267}, {"id": 424, "seek": 112688, "start": 1129.88,
  "end": 1140.88, "text": " And Cuban works great for a relatively small number of
  queries up to hundreds, right?", "tokens": [50514, 400, 31547, 1985, 869, 337, 257,
  7226, 1359, 1230, 295, 24109, 493, 281, 6779, 11, 558, 30, 51064], "temperature":
  0.0, "avg_logprob": -0.3001977169152462, "compression_ratio": 1.4918032786885247,
  "no_speech_prob": 0.02273700200021267}, {"id": 425, "seek": 112688, "start": 1140.88,
  "end": 1151.88, "text": " And one of the things that we found is that this interface
  works well, especially if a search engine super fast and responsive.", "tokens":
  [51064, 400, 472, 295, 264, 721, 300, 321, 1352, 307, 300, 341, 9226, 1985, 731,
  11, 2318, 498, 257, 3164, 2848, 1687, 2370, 293, 21826, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.3001977169152462, "compression_ratio": 1.4918032786885247,
  "no_speech_prob": 0.02273700200021267}, {"id": 426, "seek": 115188, "start": 1151.88,
  "end": 1159.88, "text": " It''s a rich single page JavaScript application that''s
  making queries in real time to a search engine.", "tokens": [50364, 467, 311, 257,
  4593, 2167, 3028, 15778, 3861, 300, 311, 1455, 24109, 294, 957, 565, 281, 257, 3164,
  2848, 13, 50764], "temperature": 0.0, "avg_logprob": -0.16237482210484946, "compression_ratio":
  1.5093457943925233, "no_speech_prob": 0.3519994914531708}, {"id": 427, "seek": 115188,
  "start": 1159.88, "end": 1169.88, "text": " If you have a thousand queries, like
  the people I mentioned before, takes like 15, 20 minutes, but as you wide load up
  and all the queries to be run.", "tokens": [50764, 759, 291, 362, 257, 4714, 24109,
  11, 411, 264, 561, 286, 2835, 949, 11, 2516, 411, 2119, 11, 945, 2077, 11, 457,
  382, 291, 4874, 3677, 493, 293, 439, 264, 24109, 281, 312, 1190, 13, 51264], "temperature":
  0.0, "avg_logprob": -0.16237482210484946, "compression_ratio": 1.5093457943925233,
  "no_speech_prob": 0.3519994914531708}, {"id": 428, "seek": 115188, "start": 1169.88,
  "end": 1175.88, "text": " And we know that lots of people want to run more queries,
  5,000, right?", "tokens": [51264, 400, 321, 458, 300, 3195, 295, 561, 528, 281,
  1190, 544, 24109, 11, 1025, 11, 1360, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob":
  -0.16237482210484946, "compression_ratio": 1.5093457943925233, "no_speech_prob":
  0.3519994914531708}, {"id": 429, "seek": 117588, "start": 1175.88, "end": 1177.88,
  "text": " People ask how many queries should I be measuring?", "tokens": [50364,
  3432, 1029, 577, 867, 24109, 820, 286, 312, 13389, 30, 50464], "temperature": 0.0,
  "avg_logprob": -0.12499410098360986, "compression_ratio": 1.5136363636363637, "no_speech_prob":
  0.027469759806990623}, {"id": 430, "seek": 117588, "start": 1177.88, "end": 1180.88,
  "text": " I''m like, well, start out with what you can.", "tokens": [50464, 286,
  478, 411, 11, 731, 11, 722, 484, 365, 437, 291, 393, 13, 50614], "temperature":
  0.0, "avg_logprob": -0.12499410098360986, "compression_ratio": 1.5136363636363637,
  "no_speech_prob": 0.027469759806990623}, {"id": 431, "seek": 117588, "start": 1180.88,
  "end": 1183.88, "text": " If that''s 25 and 50, that''s better than zero.", "tokens":
  [50614, 759, 300, 311, 3552, 293, 2625, 11, 300, 311, 1101, 813, 4018, 13, 50764],
  "temperature": 0.0, "avg_logprob": -0.12499410098360986, "compression_ratio": 1.5136363636363637,
  "no_speech_prob": 0.027469759806990623}, {"id": 432, "seek": 117588, "start": 1183.88,
  "end": 1189.88, "text": " Think about 200, maybe 300, maybe a thousand, 5,000, right?",
  "tokens": [50764, 6557, 466, 2331, 11, 1310, 6641, 11, 1310, 257, 4714, 11, 1025,
  11, 1360, 11, 558, 30, 51064], "temperature": 0.0, "avg_logprob": -0.12499410098360986,
  "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.027469759806990623},
  {"id": 433, "seek": 117588, "start": 1189.88, "end": 1195.88, "text": " And then
  above 5,000, that''s sort of only for the most sophisticated teams.", "tokens":
  [51064, 400, 550, 3673, 1025, 11, 1360, 11, 300, 311, 1333, 295, 787, 337, 264,
  881, 16950, 5491, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12499410098360986,
  "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.027469759806990623},
  {"id": 434, "seek": 117588, "start": 1195.88, "end": 1201.88, "text": " But Cuban
  kind of tops out at maybe a thousand queries.", "tokens": [51364, 583, 31547, 733,
  295, 22836, 484, 412, 1310, 257, 4714, 24109, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.12499410098360986, "compression_ratio": 1.5136363636363637, "no_speech_prob":
  0.027469759806990623}, {"id": 435, "seek": 120188, "start": 1201.88, "end": 1210.88,
  "text": " And so we''ve been doing a lot of work to think about how do we support
  larger data sets, right?", "tokens": [50364, 400, 370, 321, 600, 668, 884, 257,
  688, 295, 589, 281, 519, 466, 577, 360, 321, 1406, 4833, 1412, 6352, 11, 558, 30,
  50814], "temperature": 0.0, "avg_logprob": -0.08426718168620821, "compression_ratio":
  1.5305164319248827, "no_speech_prob": 0.09922218322753906}, {"id": 436, "seek":
  120188, "start": 1210.88, "end": 1213.88, "text": " Larger query sets.", "tokens":
  [50814, 11569, 1321, 14581, 6352, 13, 50964], "temperature": 0.0, "avg_logprob":
  -0.08426718168620821, "compression_ratio": 1.5305164319248827, "no_speech_prob":
  0.09922218322753906}, {"id": 437, "seek": 120188, "start": 1213.88, "end": 1218.88,
  "text": " And what''s been really fun is to work on introducing background processing,
  right?", "tokens": [50964, 400, 437, 311, 668, 534, 1019, 307, 281, 589, 322, 15424,
  3678, 9007, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.08426718168620821,
  "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.09922218322753906},
  {"id": 438, "seek": 120188, "start": 1218.88, "end": 1226.88, "text": " Instead
  of everything being limited by the request, response cycle of your web browser,
  what if we can run some background jobs?", "tokens": [51214, 7156, 295, 1203, 885,
  5567, 538, 264, 5308, 11, 4134, 6586, 295, 428, 3670, 11185, 11, 437, 498, 321,
  393, 1190, 512, 3678, 4782, 30, 51614], "temperature": 0.0, "avg_logprob": -0.08426718168620821,
  "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.09922218322753906},
  {"id": 439, "seek": 122688, "start": 1226.88, "end": 1230.88, "text": " And so I''m
  just going to show really quick.", "tokens": [50364, 400, 370, 286, 478, 445, 516,
  281, 855, 534, 1702, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12992204107889316,
  "compression_ratio": 1.505952380952381, "no_speech_prob": 0.26714858412742615},
  {"id": 440, "seek": 122688, "start": 1230.88, "end": 1234.88, "text": " I''m going
  to go and bring up all the books.", "tokens": [50564, 286, 478, 516, 281, 352, 293,
  1565, 493, 439, 264, 3642, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12992204107889316,
  "compression_ratio": 1.505952380952381, "no_speech_prob": 0.26714858412742615},
  {"id": 441, "seek": 122688, "start": 1234.88, "end": 1237.88, "text": " And I''ve
  got an import feature.", "tokens": [50764, 400, 286, 600, 658, 364, 974, 4111, 13,
  50914], "temperature": 0.0, "avg_logprob": -0.12992204107889316, "compression_ratio":
  1.505952380952381, "no_speech_prob": 0.26714858412742615}, {"id": 442, "seek": 122688,
  "start": 1237.88, "end": 1242.88, "text": " So we have exported a book book export
  39.", "tokens": [50914, 407, 321, 362, 42055, 257, 1446, 1446, 10725, 15238, 13,
  51164], "temperature": 0.0, "avg_logprob": -0.12992204107889316, "compression_ratio":
  1.505952380952381, "no_speech_prob": 0.26714858412742615}, {"id": 443, "seek": 122688,
  "start": 1242.88, "end": 1246.88, "text": " It''s a 62 megabyte JSON file.", "tokens":
  [51164, 467, 311, 257, 24536, 10816, 34529, 31828, 3991, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.12992204107889316, "compression_ratio": 1.505952380952381,
  "no_speech_prob": 0.26714858412742615}, {"id": 444, "seek": 122688, "start": 1246.88,
  "end": 1248.88, "text": " So 62 megabytes.", "tokens": [51364, 407, 24536, 10816,
  24538, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12992204107889316, "compression_ratio":
  1.505952380952381, "no_speech_prob": 0.26714858412742615}, {"id": 445, "seek": 122688,
  "start": 1248.88, "end": 1251.88, "text": " And I''m going to go ahead and click
  upload.", "tokens": [51464, 400, 286, 478, 516, 281, 352, 2286, 293, 2052, 6580,
  13, 51614], "temperature": 0.0, "avg_logprob": -0.12992204107889316, "compression_ratio":
  1.505952380952381, "no_speech_prob": 0.26714858412742615}, {"id": 446, "seek": 125188,
  "start": 1251.88, "end": 1260.88, "text": " And now in cube bid, what we''re starting
  to do is we can take large files based on files predominantly.", "tokens": [50364,
  400, 586, 294, 10057, 68, 12957, 11, 437, 321, 434, 2891, 281, 360, 307, 321, 393,
  747, 2416, 7098, 2361, 322, 7098, 29893, 13, 50814], "temperature": 0.0, "avg_logprob":
  -0.1623751212810648, "compression_ratio": 1.6384976525821595, "no_speech_prob":
  0.02960802987217903}, {"id": 447, "seek": 125188, "start": 1260.88, "end": 1265.88,
  "text": " And we storm in the background and we kick off a process, a background
  job.", "tokens": [50814, 400, 321, 7679, 294, 264, 3678, 293, 321, 4437, 766, 257,
  1399, 11, 257, 3678, 1691, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1623751212810648,
  "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.02960802987217903},
  {"id": 448, "seek": 125188, "start": 1265.88, "end": 1272.88, "text": " And there
  you can see, right there we are loading a whole bunch of queries, right?", "tokens":
  [51064, 400, 456, 291, 393, 536, 11, 558, 456, 321, 366, 15114, 257, 1379, 3840,
  295, 24109, 11, 558, 30, 51414], "temperature": 0.0, "avg_logprob": -0.1623751212810648,
  "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.02960802987217903},
  {"id": 449, "seek": 125188, "start": 1272.88, "end": 1278.88, "text": " And these
  are all sort of scientific queries, some very complex ones and simpler ones.", "tokens":
  [51414, 400, 613, 366, 439, 1333, 295, 8134, 24109, 11, 512, 588, 3997, 2306, 293,
  18587, 2306, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1623751212810648,
  "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.02960802987217903},
  {"id": 450, "seek": 127888, "start": 1278.88, "end": 1288.88, "text": " And you
  can see it''s going to take a while because this had what 28,000 query dock pairs,
  right?", "tokens": [50364, 400, 291, 393, 536, 309, 311, 516, 281, 747, 257, 1339,
  570, 341, 632, 437, 7562, 11, 1360, 14581, 20929, 15494, 11, 558, 30, 50864], "temperature":
  0.0, "avg_logprob": -0.11332834502797068, "compression_ratio": 1.4952380952380953,
  "no_speech_prob": 0.003010433167219162}, {"id": 451, "seek": 127888, "start": 1288.88,
  "end": 1292.88, "text": " So that are being loaded along with their judgments.",
  "tokens": [50864, 407, 300, 366, 885, 13210, 2051, 365, 641, 40337, 13, 51064],
  "temperature": 0.0, "avg_logprob": -0.11332834502797068, "compression_ratio": 1.4952380952380953,
  "no_speech_prob": 0.003010433167219162}, {"id": 452, "seek": 127888, "start": 1292.88,
  "end": 1299.88, "text": " So, but what sort of fun with the new background jobs
  and using web sockets.", "tokens": [51064, 407, 11, 457, 437, 1333, 295, 1019, 365,
  264, 777, 3678, 4782, 293, 1228, 3670, 370, 11984, 13, 51414], "temperature": 0.0,
  "avg_logprob": -0.11332834502797068, "compression_ratio": 1.4952380952380953, "no_speech_prob":
  0.003010433167219162}, {"id": 453, "seek": 127888, "start": 1299.88, "end": 1305.88,
  "text": " We''re also able to push up updates to you as background jobs are happening
  inside cube.", "tokens": [51414, 492, 434, 611, 1075, 281, 2944, 493, 9205, 281,
  291, 382, 3678, 4782, 366, 2737, 1854, 10057, 68, 13, 51714], "temperature": 0.0,
  "avg_logprob": -0.11332834502797068, "compression_ratio": 1.4952380952380953, "no_speech_prob":
  0.003010433167219162}, {"id": 454, "seek": 130588, "start": 1305.88, "end": 1311.88,
  "text": " So right here, there we are, and we are loading a whole bunch of data.",
  "tokens": [50364, 407, 558, 510, 11, 456, 321, 366, 11, 293, 321, 366, 15114, 257,
  1379, 3840, 295, 1412, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11844118179813508,
  "compression_ratio": 1.513157894736842, "no_speech_prob": 0.001832729671150446},
  {"id": 455, "seek": 130588, "start": 1311.88, "end": 1319.88, "text": " Now, yes,
  it would be nice if it was a parquet file, not a MySQL database that we were using.",
  "tokens": [50664, 823, 11, 2086, 11, 309, 576, 312, 1481, 498, 309, 390, 257, 971,
  19343, 3991, 11, 406, 257, 1222, 39934, 8149, 300, 321, 645, 1228, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.11844118179813508, "compression_ratio": 1.513157894736842,
  "no_speech_prob": 0.001832729671150446}, {"id": 456, "seek": 130588, "start": 1319.88,
  "end": 1322.88, "text": " So we''ll have to think about some of those things.",
  "tokens": [51064, 407, 321, 603, 362, 281, 519, 466, 512, 295, 729, 721, 13, 51214],
  "temperature": 0.0, "avg_logprob": -0.11844118179813508, "compression_ratio": 1.513157894736842,
  "no_speech_prob": 0.001832729671150446}, {"id": 457, "seek": 130588, "start": 1322.88,
  "end": 1334.88, "text": " But this is starting to open up the door to moving larger
  data sets and being really comfortable with that sort of 5,000 queries,", "tokens":
  [51214, 583, 341, 307, 2891, 281, 1269, 493, 264, 2853, 281, 2684, 4833, 1412, 6352,
  293, 885, 534, 4619, 365, 300, 1333, 295, 1025, 11, 1360, 24109, 11, 51814], "temperature":
  0.0, "avg_logprob": -0.11844118179813508, "compression_ratio": 1.513157894736842,
  "no_speech_prob": 0.001832729671150446}, {"id": 458, "seek": 133488, "start": 1334.88,
  "end": 1338.88, "text": " 50,000 query dock pairs kind of data.", "tokens": [50364,
  2625, 11, 1360, 14581, 20929, 15494, 733, 295, 1412, 13, 50564], "temperature":
  0.0, "avg_logprob": -0.14422721641008243, "compression_ratio": 1.515695067264574,
  "no_speech_prob": 0.013159526512026787}, {"id": 459, "seek": 133488, "start": 1338.88,
  "end": 1345.88, "text": " Not going to manage the 100,000 queries or quarter million
  documents those data sets.", "tokens": [50564, 1726, 516, 281, 3067, 264, 2319,
  11, 1360, 24109, 420, 6555, 2459, 8512, 729, 1412, 6352, 13, 50914], "temperature":
  0.0, "avg_logprob": -0.14422721641008243, "compression_ratio": 1.515695067264574,
  "no_speech_prob": 0.013159526512026787}, {"id": 460, "seek": 133488, "start": 1345.88,
  "end": 1351.88, "text": " Jason is not the right format, but we''re at least scaling
  it up to get a broader set.", "tokens": [50914, 11181, 307, 406, 264, 558, 7877,
  11, 457, 321, 434, 412, 1935, 21589, 309, 493, 281, 483, 257, 13227, 992, 13, 51214],
  "temperature": 0.0, "avg_logprob": -0.14422721641008243, "compression_ratio": 1.515695067264574,
  "no_speech_prob": 0.013159526512026787}, {"id": 461, "seek": 133488, "start": 1351.88,
  "end": 1360.88, "text": " The other thing that I''m also excited about is we''re
  getting closer to be able to run these analytics on a regular basis, right?", "tokens":
  [51214, 440, 661, 551, 300, 286, 478, 611, 2919, 466, 307, 321, 434, 1242, 4966,
  281, 312, 1075, 281, 1190, 613, 15370, 322, 257, 3890, 5143, 11, 558, 30, 51664],
  "temperature": 0.0, "avg_logprob": -0.14422721641008243, "compression_ratio": 1.515695067264574,
  "no_speech_prob": 0.013159526512026787}, {"id": 462, "seek": 136088, "start": 1360.88,
  "end": 1370.88, "text": " Now that we have some background processing, we could
  think about every night we rerun all 1000 documents.", "tokens": [50364, 823, 300,
  321, 362, 512, 3678, 9007, 11, 321, 727, 519, 466, 633, 1818, 321, 43819, 409, 439,
  9714, 8512, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12743329398239714,
  "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.0031989929266273975},
  {"id": 463, "seek": 136088, "start": 1370.88, "end": 1373.88, "text": " And every
  night we could be storing them.", "tokens": [50864, 400, 633, 1818, 321, 727, 312,
  26085, 552, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12743329398239714,
  "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.0031989929266273975},
  {"id": 464, "seek": 136088, "start": 1373.88, "end": 1379.88, "text": " So these
  little charts here that you see that are sort of showing some basic scoring information.",
  "tokens": [51014, 407, 613, 707, 17767, 510, 300, 291, 536, 300, 366, 1333, 295,
  4099, 512, 3875, 22358, 1589, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12743329398239714,
  "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.0031989929266273975},
  {"id": 465, "seek": 136088, "start": 1379.88, "end": 1386.88, "text": " You could
  start using this to monitor it over time instead of having to roll your own dashboarding
  tools.", "tokens": [51314, 509, 727, 722, 1228, 341, 281, 6002, 309, 670, 565, 2602,
  295, 1419, 281, 3373, 428, 1065, 18342, 278, 3873, 13, 51664], "temperature": 0.0,
  "avg_logprob": -0.12743329398239714, "compression_ratio": 1.6073059360730593, "no_speech_prob":
  0.0031989929266273975}, {"id": 466, "seek": 138688, "start": 1386.88, "end": 1390.88,
  "text": " So that''s something I''m really excited about.", "tokens": [50364, 407,
  300, 311, 746, 286, 478, 534, 2919, 466, 13, 50564], "temperature": 0.0, "avg_logprob":
  -0.20580493426713786, "compression_ratio": 1.3395061728395061, "no_speech_prob":
  0.031168514862656593}, {"id": 467, "seek": 138688, "start": 1390.88, "end": 1399.88,
  "text": " I''m also going to point out to two PR so GitHub.com 19 sqbid is the open
  source project.", "tokens": [50564, 286, 478, 611, 516, 281, 935, 484, 281, 732,
  11568, 370, 23331, 13, 1112, 1294, 262, 80, 65, 327, 307, 264, 1269, 4009, 1716,
  13, 51014], "temperature": 0.0, "avg_logprob": -0.20580493426713786, "compression_ratio":
  1.3395061728395061, "no_speech_prob": 0.031168514862656593}, {"id": 468, "seek":
  138688, "start": 1399.88, "end": 1409.88, "text": " And a couple of pull requests
  that are in progress, but looking to land them soon.", "tokens": [51014, 400, 257,
  1916, 295, 2235, 12475, 300, 366, 294, 4205, 11, 457, 1237, 281, 2117, 552, 2321,
  13, 51514], "temperature": 0.0, "avg_logprob": -0.20580493426713786, "compression_ratio":
  1.3395061728395061, "no_speech_prob": 0.031168514862656593}, {"id": 469, "seek":
  140988, "start": 1409.88, "end": 1413.88, "text": " Right here is this pull request
  976.", "tokens": [50364, 1779, 510, 307, 341, 2235, 5308, 23399, 21, 13, 50564],
  "temperature": 0.0, "avg_logprob": -0.27725936488101355, "compression_ratio": 1.4730290456431536,
  "no_speech_prob": 0.1089719831943512}, {"id": 470, "seek": 140988, "start": 1413.88,
  "end": 1417.88, "text": " Imagine if we could run thousands of queries nightly and
  cupid.", "tokens": [50564, 11739, 498, 321, 727, 1190, 5383, 295, 24109, 1818, 356,
  293, 4414, 327, 13, 50764], "temperature": 0.0, "avg_logprob": -0.27725936488101355,
  "compression_ratio": 1.4730290456431536, "no_speech_prob": 0.1089719831943512},
  {"id": 471, "seek": 140988, "start": 1417.88, "end": 1423.88, "text": " Now that
  we''ve got background jobs working and communicating with the user right of state.",
  "tokens": [50764, 823, 300, 321, 600, 658, 3678, 4782, 1364, 293, 17559, 365, 264,
  4195, 558, 295, 1785, 13, 51064], "temperature": 0.0, "avg_logprob": -0.27725936488101355,
  "compression_ratio": 1.4730290456431536, "no_speech_prob": 0.1089719831943512},
  {"id": 472, "seek": 140988, "start": 1423.88, "end": 1425.88, "text": " This will
  be coming pretty soon.", "tokens": [51064, 639, 486, 312, 1348, 1238, 2321, 13,
  51164], "temperature": 0.0, "avg_logprob": -0.27725936488101355, "compression_ratio":
  1.4730290456431536, "no_speech_prob": 0.1089719831943512}, {"id": 473, "seek": 140988,
  "start": 1425.88, "end": 1429.88, "text": " Pretty soon in open source time, which
  means.", "tokens": [51164, 10693, 2321, 294, 1269, 4009, 565, 11, 597, 1355, 13,
  51364], "temperature": 0.0, "avg_logprob": -0.27725936488101355, "compression_ratio":
  1.4730290456431536, "no_speech_prob": 0.1089719831943512}, {"id": 474, "seek": 140988,
  "start": 1429.88, "end": 1431.88, "text": " I don''t know. We''ll see next few months.",
  "tokens": [51364, 286, 500, 380, 458, 13, 492, 603, 536, 958, 1326, 2493, 13, 51464],
  "temperature": 0.0, "avg_logprob": -0.27725936488101355, "compression_ratio": 1.4730290456431536,
  "no_speech_prob": 0.1089719831943512}, {"id": 475, "seek": 140988, "start": 1431.88,
  "end": 1434.88, "text": " And so I''m glad people helping and testing.", "tokens":
  [51464, 400, 370, 286, 478, 5404, 561, 4315, 293, 4997, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.27725936488101355, "compression_ratio": 1.4730290456431536,
  "no_speech_prob": 0.1089719831943512}, {"id": 476, "seek": 143488, "start": 1434.88,
  "end": 1437.88, "text": " So this one''s super exciting.", "tokens": [50364, 407,
  341, 472, 311, 1687, 4670, 13, 50514], "temperature": 0.0, "avg_logprob": -0.20270405983438297,
  "compression_ratio": 1.5246636771300448, "no_speech_prob": 0.10917375236749649},
  {"id": 477, "seek": 143488, "start": 1437.88, "end": 1439.88, "text": " Let''s go
  back and see how we''re doing.", "tokens": [50514, 961, 311, 352, 646, 293, 536,
  577, 321, 434, 884, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20270405983438297,
  "compression_ratio": 1.5246636771300448, "no_speech_prob": 0.10917375236749649},
  {"id": 478, "seek": 143488, "start": 1439.88, "end": 1442.88, "text": " And they''re
  doing.", "tokens": [50614, 400, 436, 434, 884, 13, 50764], "temperature": 0.0, "avg_logprob":
  -0.20270405983438297, "compression_ratio": 1.5246636771300448, "no_speech_prob":
  0.10917375236749649}, {"id": 479, "seek": 143488, "start": 1442.88, "end": 1450.88,
  "text": " So there we go. We''re up to 4968 query dock pairs as we kind of count
  down.", "tokens": [50764, 407, 456, 321, 352, 13, 492, 434, 493, 281, 16513, 27102,
  14581, 20929, 15494, 382, 321, 733, 295, 1207, 760, 13, 51164], "temperature": 0.0,
  "avg_logprob": -0.20270405983438297, "compression_ratio": 1.5246636771300448, "no_speech_prob":
  0.10917375236749649}, {"id": 480, "seek": 143488, "start": 1450.88, "end": 1456.88,
  "text": " So yeah, this is all through the magic of Web sockets, which has been
  really cool to see.", "tokens": [51164, 407, 1338, 11, 341, 307, 439, 807, 264,
  5585, 295, 9573, 370, 11984, 11, 597, 575, 668, 534, 1627, 281, 536, 13, 51464],
  "temperature": 0.0, "avg_logprob": -0.20270405983438297, "compression_ratio": 1.5246636771300448,
  "no_speech_prob": 0.10917375236749649}, {"id": 481, "seek": 143488, "start": 1456.88,
  "end": 1461.88, "text": " And as you are loading this here, are you also executing
  it against the search engine?", "tokens": [51464, 400, 382, 291, 366, 15114, 341,
  510, 11, 366, 291, 611, 32368, 309, 1970, 264, 3164, 2848, 30, 51714], "temperature":
  0.0, "avg_logprob": -0.20270405983438297, "compression_ratio": 1.5246636771300448,
  "no_speech_prob": 0.10917375236749649}, {"id": 482, "seek": 146188, "start": 1461.88,
  "end": 1465.88, "text": " Or are you here because we had all static data.", "tokens":
  [50364, 1610, 366, 291, 510, 570, 321, 632, 439, 13437, 1412, 13, 50564], "temperature":
  0.0, "avg_logprob": -0.18150377834544462, "compression_ratio": 1.574468085106383,
  "no_speech_prob": 0.03339112177491188}, {"id": 483, "seek": 146188, "start": 1465.88,
  "end": 1467.88, "text": " Yes, static data.", "tokens": [50564, 1079, 11, 13437,
  1412, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18150377834544462, "compression_ratio":
  1.574468085106383, "no_speech_prob": 0.03339112177491188}, {"id": 484, "seek": 146188,
  "start": 1467.88, "end": 1472.88, "text": " A book represents the query dock pairs
  with all of the data.", "tokens": [50664, 316, 1446, 8855, 264, 14581, 20929, 15494,
  365, 439, 295, 264, 1412, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18150377834544462,
  "compression_ratio": 1.574468085106383, "no_speech_prob": 0.03339112177491188},
  {"id": 485, "seek": 146188, "start": 1472.88, "end": 1475.88, "text": " Whereas
  the case is what we do the real time querying.", "tokens": [50914, 13813, 264, 1389,
  307, 437, 321, 360, 264, 957, 565, 7083, 1840, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.18150377834544462, "compression_ratio": 1.574468085106383, "no_speech_prob":
  0.03339112177491188}, {"id": 486, "seek": 146188, "start": 1475.88, "end": 1479.88,
  "text": " And now that we have this one working.", "tokens": [51064, 400, 586, 300,
  321, 362, 341, 472, 1364, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18150377834544462,
  "compression_ratio": 1.574468085106383, "no_speech_prob": 0.03339112177491188},
  {"id": 487, "seek": 146188, "start": 1479.88, "end": 1487.88, "text": " Once we
  have this PR, then you''ll be able to run a background job in cupid.", "tokens":
  [51264, 3443, 321, 362, 341, 11568, 11, 550, 291, 603, 312, 1075, 281, 1190, 257,
  3678, 1691, 294, 4414, 327, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18150377834544462,
  "compression_ratio": 1.574468085106383, "no_speech_prob": 0.03339112177491188},
  {"id": 488, "seek": 148788, "start": 1487.88, "end": 1495.88, "text": " With a similar
  counter, maybe it up here next to one of your cases that says we''re running queries,
  5,000 queries.", "tokens": [50364, 2022, 257, 2531, 5682, 11, 1310, 309, 493, 510,
  958, 281, 472, 295, 428, 3331, 300, 1619, 321, 434, 2614, 24109, 11, 1025, 11, 1360,
  24109, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3380036570809104, "compression_ratio":
  1.5398230088495575, "no_speech_prob": 0.030313337221741676}, {"id": 489, "seek":
  148788, "start": 1495.88, "end": 1500.88, "text": " And this is our progress for
  the number of the error out.", "tokens": [50764, 400, 341, 307, 527, 4205, 337,
  264, 1230, 295, 264, 6713, 484, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3380036570809104,
  "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.030313337221741676},
  {"id": 490, "seek": 148788, "start": 1500.88, "end": 1511.88, "text": " But of course,
  for listeners to understand, like what takes time is basically, of course, also
  in searching this data into cupids database is like my sequel.", "tokens": [51014,
  583, 295, 1164, 11, 337, 23274, 281, 1223, 11, 411, 437, 2516, 565, 307, 1936, 11,
  295, 1164, 11, 611, 294, 10808, 341, 1412, 666, 4414, 3742, 8149, 307, 411, 452,
  20622, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3380036570809104, "compression_ratio":
  1.5398230088495575, "no_speech_prob": 0.030313337221741676}, {"id": 491, "seek":
  148788, "start": 1511.88, "end": 1513.88, "text": " Right. And ready.", "tokens":
  [51564, 1779, 13, 400, 1919, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3380036570809104,
  "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.030313337221741676},
  {"id": 492, "seek": 151388, "start": 1513.88, "end": 1515.88, "text": " So have
  you stopped using it already?", "tokens": [50364, 407, 362, 291, 5936, 1228, 309,
  1217, 30, 50464], "temperature": 0.0, "avg_logprob": -0.25254138465066556, "compression_ratio":
  1.6059322033898304, "no_speech_prob": 0.03787301108241081}, {"id": 493, "seek":
  151388, "start": 1515.88, "end": 1519.88, "text": " So we''re actually, so we''re
  using my sequels or database.", "tokens": [50464, 407, 321, 434, 767, 11, 370, 321,
  434, 1228, 452, 5123, 1625, 420, 8149, 13, 50664], "temperature": 0.0, "avg_logprob":
  -0.25254138465066556, "compression_ratio": 1.6059322033898304, "no_speech_prob":
  0.03787301108241081}, {"id": 494, "seek": 151388, "start": 1519.88, "end": 1524.88,
  "text": " However, what manages this communication web sockets is all in red.",
  "tokens": [50664, 2908, 11, 437, 22489, 341, 6101, 3670, 370, 11984, 307, 439, 294,
  2182, 13, 50914], "temperature": 0.0, "avg_logprob": -0.25254138465066556, "compression_ratio":
  1.6059322033898304, "no_speech_prob": 0.03787301108241081}, {"id": 495, "seek":
  151388, "start": 1524.88, "end": 1535.88, "text": " So as the bat and it''s our
  background jobs and our front end jobs and our web browsers keep track of each other
  is through red.", "tokens": [50914, 407, 382, 264, 7362, 293, 309, 311, 527, 3678,
  4782, 293, 527, 1868, 917, 4782, 293, 527, 3670, 36069, 1066, 2837, 295, 1184, 661,
  307, 807, 2182, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25254138465066556,
  "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.03787301108241081},
  {"id": 496, "seek": 151388, "start": 1535.88, "end": 1542.88, "text": " Yeah, so
  if I actually, so if you, you know, I''m running local hosts, you won''t see it.",
  "tokens": [51464, 865, 11, 370, 498, 286, 767, 11, 370, 498, 291, 11, 291, 458,
  11, 286, 478, 2614, 2654, 21573, 11, 291, 1582, 380, 536, 309, 13, 51814], "temperature":
  0.0, "avg_logprob": -0.25254138465066556, "compression_ratio": 1.6059322033898304,
  "no_speech_prob": 0.03787301108241081}, {"id": 497, "seek": 154288, "start": 1542.88,
  "end": 1549.88, "text": " So everybody who is connected, who has permissions for
  this book, everybody would be seeing these messages.", "tokens": [50364, 407, 2201,
  567, 307, 4582, 11, 567, 575, 32723, 337, 341, 1446, 11, 2201, 576, 312, 2577, 613,
  7897, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23674129304431735, "compression_ratio":
  1.5343137254901962, "no_speech_prob": 0.03055999055504799}, {"id": 498, "seek":
  154288, "start": 1549.88, "end": 1552.88, "text": " Yeah, yeah. So it''s kind of
  broadcasting to everyone.", "tokens": [50714, 865, 11, 1338, 13, 407, 309, 311,
  733, 295, 30024, 281, 1518, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23674129304431735,
  "compression_ratio": 1.5343137254901962, "no_speech_prob": 0.03055999055504799},
  {"id": 499, "seek": 154288, "start": 1552.88, "end": 1553.88, "text": " Yeah, cool.",
  "tokens": [50864, 865, 11, 1627, 13, 50914], "temperature": 0.0, "avg_logprob":
  -0.23674129304431735, "compression_ratio": 1.5343137254901962, "no_speech_prob":
  0.03055999055504799}, {"id": 500, "seek": 154288, "start": 1553.88, "end": 1554.88,
  "text": " Exactly.", "tokens": [50914, 7587, 13, 50964], "temperature": 0.0, "avg_logprob":
  -0.23674129304431735, "compression_ratio": 1.5343137254901962, "no_speech_prob":
  0.03055999055504799}, {"id": 501, "seek": 154288, "start": 1554.88, "end": 1557.88,
  "text": " So that''s something I''m really, really excited about.", "tokens": [50964,
  407, 300, 311, 746, 286, 478, 534, 11, 534, 2919, 466, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.23674129304431735, "compression_ratio": 1.5343137254901962,
  "no_speech_prob": 0.03055999055504799}, {"id": 502, "seek": 154288, "start": 1557.88,
  "end": 1564.88, "text": " The other thing that I''m really excited to be is LLM
  based judgments, right?", "tokens": [51114, 440, 661, 551, 300, 286, 478, 534, 2919,
  281, 312, 307, 441, 43, 44, 2361, 40337, 11, 558, 30, 51464], "temperature": 0.0,
  "avg_logprob": -0.23674129304431735, "compression_ratio": 1.5343137254901962, "no_speech_prob":
  0.03055999055504799}, {"id": 503, "seek": 156488, "start": 1564.88, "end": 1570.88,
  "text": " So I''m going to start out this conversation about using cupid with human
  judges annotators, right?", "tokens": [50364, 407, 286, 478, 516, 281, 722, 484,
  341, 3761, 466, 1228, 4414, 327, 365, 1952, 14449, 25339, 3391, 11, 558, 30, 50664],
  "temperature": 0.0, "avg_logprob": -0.22117931192571466, "compression_ratio": 1.497991967871486,
  "no_speech_prob": 0.008472356013953686}, {"id": 504, "seek": 156488, "start": 1570.88,
  "end": 1572.88, "text": " And gathering quite quality data.", "tokens": [50664,
  400, 13519, 1596, 3125, 1412, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22117931192571466,
  "compression_ratio": 1.497991967871486, "no_speech_prob": 0.008472356013953686},
  {"id": 505, "seek": 156488, "start": 1572.88, "end": 1581.88, "text": " But as we
  all know, human judges is expensive, not every organization can do it.", "tokens":
  [50764, 583, 382, 321, 439, 458, 11, 1952, 14449, 307, 5124, 11, 406, 633, 4475,
  393, 360, 309, 13, 51214], "temperature": 0.0, "avg_logprob": -0.22117931192571466,
  "compression_ratio": 1.497991967871486, "no_speech_prob": 0.008472356013953686},
  {"id": 506, "seek": 156488, "start": 1581.88, "end": 1593.88, "text": " My colleague
  Scott Stoltz last year did some interesting work playing around with chat GPT when
  it first came out to evaluate, is this query and this document.", "tokens": [51214,
  1222, 13532, 6659, 745, 4837, 89, 1036, 1064, 630, 512, 1880, 589, 2433, 926, 365,
  5081, 26039, 51, 562, 309, 700, 1361, 484, 281, 13059, 11, 307, 341, 14581, 293,
  341, 4166, 13, 51814], "temperature": 0.0, "avg_logprob": -0.22117931192571466,
  "compression_ratio": 1.497991967871486, "no_speech_prob": 0.008472356013953686},
  {"id": 507, "seek": 159388, "start": 1593.88, "end": 1613.88, "text": " And then
  we''ve been working with Moody''s on their BG solution and using what we''ve been
  calling judge Judy, an LLM to evaluate what that lets us do is.", "tokens": [50364,
  400, 550, 321, 600, 668, 1364, 365, 3335, 843, 311, 322, 641, 363, 38, 3827, 293,
  1228, 437, 321, 600, 668, 5141, 6995, 24577, 11, 364, 441, 43, 44, 281, 13059, 437,
  300, 6653, 505, 360, 307, 13, 51364], "temperature": 0.0, "avg_logprob": -0.4019261768886021,
  "compression_ratio": 1.26890756302521, "no_speech_prob": 0.006714065559208393},
  {"id": 508, "seek": 161388, "start": 1613.88, "end": 1620.88, "text": " We''re basically
  using a small set of human judges to validate our LLM judge judge Judy.", "tokens":
  [50364, 492, 434, 1936, 1228, 257, 1359, 992, 295, 1952, 14449, 281, 29562, 527,
  441, 43, 44, 6995, 6995, 24577, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18312058797696742,
  "compression_ratio": 1.5260663507109005, "no_speech_prob": 0.09734303504228592},
  {"id": 509, "seek": 161388, "start": 1620.88, "end": 1640.88, "text": " And if we
  have good correlation, right, our inner rate of reliability looks good, you know,
  flights, Kappa, Coens, all those metrics look good, then this gives us confidence
  to go ahead and scale up the judgments, right, using an LLM.", "tokens": [50714,
  400, 498, 321, 362, 665, 20009, 11, 558, 11, 527, 7284, 3314, 295, 24550, 1542,
  665, 11, 291, 458, 11, 21089, 11, 591, 25637, 11, 3066, 694, 11, 439, 729, 16367,
  574, 665, 11, 550, 341, 2709, 505, 6687, 281, 352, 2286, 293, 4373, 493, 264, 40337,
  11, 558, 11, 1228, 364, 441, 43, 44, 13, 51714], "temperature": 0.0, "avg_logprob":
  -0.18312058797696742, "compression_ratio": 1.5260663507109005, "no_speech_prob":
  0.09734303504228592}, {"id": 510, "seek": 164088, "start": 1640.88, "end": 1646.88,
  "text": " So today, that is a bunch of pandas notebooks and kind of custom code.",
  "tokens": [50364, 407, 965, 11, 300, 307, 257, 3840, 295, 4565, 296, 43782, 293,
  733, 295, 2375, 3089, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14148697419600054,
  "compression_ratio": 1.3518518518518519, "no_speech_prob": 0.02278565615415573},
  {"id": 511, "seek": 164088, "start": 1646.88, "end": 1659.88, "text": " However,
  the other pull requests that I''m really excited about, right, is this meat judge
  Judy, she is your AI powered subject matter expert, right?", "tokens": [50664, 2908,
  11, 264, 661, 2235, 12475, 300, 286, 478, 534, 2919, 466, 11, 558, 11, 307, 341,
  4615, 6995, 24577, 11, 750, 307, 428, 7318, 17786, 3983, 1871, 5844, 11, 558, 30,
  51314], "temperature": 0.0, "avg_logprob": -0.14148697419600054, "compression_ratio":
  1.3518518518518519, "no_speech_prob": 0.02278565615415573}, {"id": 512, "seek":
  165988, "start": 1659.88, "end": 1673.88, "text": " And so in the not too distant
  future, you will be able to, let me go ahead and bring up this case, right, here
  we have one person who''s been the judge.", "tokens": [50364, 400, 370, 294, 264,
  406, 886, 17275, 2027, 11, 291, 486, 312, 1075, 281, 11, 718, 385, 352, 2286, 293,
  1565, 493, 341, 1389, 11, 558, 11, 510, 321, 362, 472, 954, 567, 311, 668, 264,
  6995, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13137922658548726, "compression_ratio":
  1.5425531914893618, "no_speech_prob": 0.8400723338127136}, {"id": 513, "seek": 165988,
  "start": 1673.88, "end": 1685.88, "text": " But soon, you''ll have a second column
  next to it, judge Judy, right, using whatever prompt you''ve typed in, right, or
  provided is judging.", "tokens": [51064, 583, 2321, 11, 291, 603, 362, 257, 1150,
  7738, 958, 281, 309, 11, 6995, 24577, 11, 558, 11, 1228, 2035, 12391, 291, 600,
  33941, 294, 11, 558, 11, 420, 5649, 307, 23587, 13, 51664], "temperature": 0.0,
  "avg_logprob": -0.13137922658548726, "compression_ratio": 1.5425531914893618, "no_speech_prob":
  0.8400723338127136}, {"id": 514, "seek": 168588, "start": 1685.88, "end": 1695.88,
  "text": " So that''s the other big, how do we scale up, cupid and make it relevant
  in our gen AI world, right, those are sort of the two big things.", "tokens": [50364,
  407, 300, 311, 264, 661, 955, 11, 577, 360, 321, 4373, 493, 11, 4414, 327, 293,
  652, 309, 7340, 294, 527, 1049, 7318, 1002, 11, 558, 11, 729, 366, 1333, 295, 264,
  732, 955, 721, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18723144112052498,
  "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.20294906198978424},
  {"id": 515, "seek": 168588, "start": 1695.88, "end": 1700.88, "text": " This is
  fantastic. This is really fantastic. Yeah. Wow.", "tokens": [50864, 639, 307, 5456,
  13, 639, 307, 534, 5456, 13, 865, 13, 3153, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.18723144112052498, "compression_ratio": 1.5530973451327434, "no_speech_prob":
  0.20294906198978424}, {"id": 516, "seek": 168588, "start": 1700.88, "end": 1710.88,
  "text": " I hope this PRs will land really soon, especially the LLM one, right,
  because this allows people to really quickly hit the ground running and start labeling.",
  "tokens": [51114, 286, 1454, 341, 11568, 82, 486, 2117, 534, 2321, 11, 2318, 264,
  441, 43, 44, 472, 11, 558, 11, 570, 341, 4045, 561, 281, 534, 2661, 2045, 264, 2727,
  2614, 293, 722, 40244, 13, 51614], "temperature": 0.0, "avg_logprob": -0.18723144112052498,
  "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.20294906198978424},
  {"id": 517, "seek": 171088, "start": 1710.88, "end": 1723.88, "text": " Actually,
  someone will label in a way, but exactly exactly the trick is having the right props,
  right, and having the right set of positive examples and negative examples, right.",
  "tokens": [50364, 5135, 11, 1580, 486, 7645, 294, 257, 636, 11, 457, 2293, 2293,
  264, 4282, 307, 1419, 264, 558, 26173, 11, 558, 11, 293, 1419, 264, 558, 992, 295,
  3353, 5110, 293, 3671, 5110, 11, 558, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.16214269085934288, "compression_ratio": 1.6701570680628273, "no_speech_prob":
  0.12435764819383621}, {"id": 518, "seek": 171088, "start": 1723.88, "end": 1734.88,
  "text": " But one of the things that I were working on, so cupid, right, ships with
  a set of data science notebooks, they need a little bit more work.", "tokens": [51014,
  583, 472, 295, 264, 721, 300, 286, 645, 1364, 322, 11, 370, 4414, 327, 11, 558,
  11, 11434, 365, 257, 992, 295, 1412, 3497, 43782, 11, 436, 643, 257, 707, 857, 544,
  589, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16214269085934288, "compression_ratio":
  1.6701570680628273, "no_speech_prob": 0.12435764819383621}, {"id": 519, "seek":
  173488, "start": 1734.88, "end": 1740.88, "text": " See if this comes up in my diversion,
  I don''t ship that. So I''m going to switch to the production cupid.", "tokens":
  [50364, 3008, 498, 341, 1487, 493, 294, 452, 49422, 11, 286, 500, 380, 5374, 300,
  13, 407, 286, 478, 516, 281, 3679, 281, 264, 4265, 4414, 327, 13, 50664], "temperature":
  0.0, "avg_logprob": -0.31818225771881814, "compression_ratio": 1.191304347826087,
  "no_speech_prob": 0.2217974215745926}, {"id": 520, "seek": 173488, "start": 1740.88,
  "end": 1742.88, "text": " Yeah, no worries.", "tokens": [50664, 865, 11, 572, 16340,
  13, 50764], "temperature": 0.0, "avg_logprob": -0.31818225771881814, "compression_ratio":
  1.191304347826087, "no_speech_prob": 0.2217974215745926}, {"id": 521, "seek": 173488,
  "start": 1742.88, "end": 1746.88, "text": " And notebooks.", "tokens": [50764, 400,
  43782, 13, 50964], "temperature": 0.0, "avg_logprob": -0.31818225771881814, "compression_ratio":
  1.191304347826087, "no_speech_prob": 0.2217974215745926}, {"id": 522, "seek": 174688,
  "start": 1746.88, "end": 1764.88, "text": " So in this example''s folder, we''re
  actually shipping a couple of notebooks for you to use, flash capa, jacquard and
  RBO comparison, multi-radar analysis, right.", "tokens": [50364, 407, 294, 341,
  1365, 311, 10820, 11, 321, 434, 767, 14122, 257, 1916, 295, 43782, 337, 291, 281,
  764, 11, 7319, 1410, 64, 11, 361, 326, 358, 515, 293, 497, 15893, 9660, 11, 4825,
  12, 6206, 289, 5215, 11, 558, 13, 51264], "temperature": 0.0, "avg_logprob": -0.42345521714952256,
  "compression_ratio": 1.2403100775193798, "no_speech_prob": 0.5203595161437988},
  {"id": 523, "seek": 176488, "start": 1764.88, "end": 1775.88, "text": " And these
  notebooks here, you can directly use with your cupid book of judgments to evaluate
  how we''re doing overall.", "tokens": [50364, 400, 613, 43782, 510, 11, 291, 393,
  3838, 764, 365, 428, 4414, 327, 1446, 295, 40337, 281, 13059, 577, 321, 434, 884,
  4787, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1220998646300516, "compression_ratio":
  1.6439024390243901, "no_speech_prob": 0.6272432804107666}, {"id": 524, "seek": 176488,
  "start": 1775.88, "end": 1782.88, "text": " And so this can let you take your human
  judgments, understand how good or bad they are.", "tokens": [50914, 400, 370, 341,
  393, 718, 291, 747, 428, 1952, 40337, 11, 1223, 577, 665, 420, 1578, 436, 366, 13,
  51264], "temperature": 0.0, "avg_logprob": -0.1220998646300516, "compression_ratio":
  1.6439024390243901, "no_speech_prob": 0.6272432804107666}, {"id": 525, "seek": 176488,
  "start": 1782.88, "end": 1791.88, "text": " And then when you bring the LLM power
  judge in compare the LLM judge to what your human judges were doing and feel some
  confidence.", "tokens": [51264, 400, 550, 562, 291, 1565, 264, 441, 43, 44, 1347,
  6995, 294, 6794, 264, 441, 43, 44, 6995, 281, 437, 428, 1952, 14449, 645, 884, 293,
  841, 512, 6687, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1220998646300516,
  "compression_ratio": 1.6439024390243901, "no_speech_prob": 0.6272432804107666},
  {"id": 526, "seek": 179188, "start": 1791.88, "end": 1797.88, "text": " So I''m
  really excited to be shipping these because I think it''s going to lower the barrier
  to getting judgments.", "tokens": [50364, 407, 286, 478, 534, 2919, 281, 312, 14122,
  613, 570, 286, 519, 309, 311, 516, 281, 3126, 264, 13357, 281, 1242, 40337, 13,
  50664], "temperature": 0.0, "avg_logprob": -0.10515315481956969, "compression_ratio":
  1.6590909090909092, "no_speech_prob": 0.06702517718076706}, {"id": 527, "seek":
  179188, "start": 1797.88, "end": 1804.88, "text": " And that''s something that a
  lot of search teams are like, I would love to use cute, but I would love to do this.",
  "tokens": [50664, 400, 300, 311, 746, 300, 257, 688, 295, 3164, 5491, 366, 411,
  11, 286, 576, 959, 281, 764, 4052, 11, 457, 286, 576, 959, 281, 360, 341, 13, 51014],
  "temperature": 0.0, "avg_logprob": -0.10515315481956969, "compression_ratio": 1.6590909090909092,
  "no_speech_prob": 0.06702517718076706}, {"id": 528, "seek": 179188, "start": 1804.88,
  "end": 1812.88, "text": " But I can''t do any of this until I have judgments and
  I don''t know where to get them or I don''t have the domain experts that I need,
  right.", "tokens": [51014, 583, 286, 393, 380, 360, 604, 295, 341, 1826, 286, 362,
  40337, 293, 286, 500, 380, 458, 689, 281, 483, 552, 420, 286, 500, 380, 362, 264,
  9274, 8572, 300, 286, 643, 11, 558, 13, 51414], "temperature": 0.0, "avg_logprob":
  -0.10515315481956969, "compression_ratio": 1.6590909090909092, "no_speech_prob":
  0.06702517718076706}, {"id": 529, "seek": 181288, "start": 1812.88, "end": 1824.88,
  "text": " And you know, search oriented organizations often have that figured out,
  but a lot of other teams are like, we just see a search engine that works what you
  know reasonably well and we don''t have that.", "tokens": [50364, 400, 291, 458,
  11, 3164, 21841, 6150, 2049, 362, 300, 8932, 484, 11, 457, 257, 688, 295, 661, 5491,
  366, 411, 11, 321, 445, 536, 257, 3164, 2848, 300, 1985, 437, 291, 458, 23551, 731,
  293, 321, 500, 380, 362, 300, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18047244593782244,
  "compression_ratio": 1.690909090909091, "no_speech_prob": 0.6045592427253723}, {"id":
  530, "seek": 181288, "start": 1824.88, "end": 1830.88, "text": " So we got a lower
  the barrier to getting judgments in judgments and I''m excited about this.", "tokens":
  [50964, 407, 321, 658, 257, 3126, 264, 13357, 281, 1242, 40337, 294, 40337, 293,
  286, 478, 2919, 466, 341, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18047244593782244,
  "compression_ratio": 1.690909090909091, "no_speech_prob": 0.6045592427253723}, {"id":
  531, "seek": 181288, "start": 1830.88, "end": 1841.88, "text": " This is fantastic,
  but I can also add from my personal experience, you know, that yes, you''re absolutely
  right that there is this sometimes there is even a friction, right.", "tokens":
  [51264, 639, 307, 5456, 11, 457, 286, 393, 611, 909, 490, 452, 2973, 1752, 11, 291,
  458, 11, 300, 2086, 11, 291, 434, 3122, 558, 300, 456, 307, 341, 2171, 456, 307,
  754, 257, 17710, 11, 558, 13, 51814], "temperature": 0.0, "avg_logprob": -0.18047244593782244,
  "compression_ratio": 1.690909090909091, "no_speech_prob": 0.6045592427253723}, {"id":
  532, "seek": 184188, "start": 1841.88, "end": 1852.88, "text": " The search engineer
  says, no, I don''t want to label I''m a search engineer, I''m developing the algorithm,
  but they will get so many more insights, so much more insights if they actually
  label.", "tokens": [50364, 440, 3164, 11403, 1619, 11, 572, 11, 286, 500, 380, 528,
  281, 7645, 286, 478, 257, 3164, 11403, 11, 286, 478, 6416, 264, 9284, 11, 457, 436,
  486, 483, 370, 867, 544, 14310, 11, 370, 709, 544, 14310, 498, 436, 767, 7645, 13,
  50914], "temperature": 0.0, "avg_logprob": -0.1576925415590585, "compression_ratio":
  1.6804123711340206, "no_speech_prob": 0.30825942754745483}, {"id": 533, "seek":
  184188, "start": 1852.88, "end": 1861.88, "text": " And in our teams, you know,
  if you have, I don''t know, 10 people and if each will label 10 queries, you will
  have 100 queries labeled.", "tokens": [50914, 400, 294, 527, 5491, 11, 291, 458,
  11, 498, 291, 362, 11, 286, 500, 380, 458, 11, 1266, 561, 293, 498, 1184, 486, 7645,
  1266, 24109, 11, 291, 486, 362, 2319, 24109, 21335, 13, 51364], "temperature": 0.0,
  "avg_logprob": -0.1576925415590585, "compression_ratio": 1.6804123711340206, "no_speech_prob":
  0.30825942754745483}, {"id": 534, "seek": 186188, "start": 1861.88, "end": 1871.88,
  "text": " So of course, if you don''t go for overlapping and stuff like that, but
  if you go, then yeah, it''s another story, but you know, and then all of us, all
  of a sudden get all this insights, right.", "tokens": [50364, 407, 295, 1164, 11,
  498, 291, 500, 380, 352, 337, 33535, 293, 1507, 411, 300, 11, 457, 498, 291, 352,
  11, 550, 1338, 11, 309, 311, 1071, 1657, 11, 457, 291, 458, 11, 293, 550, 439, 295,
  505, 11, 439, 295, 257, 3990, 483, 439, 341, 14310, 11, 558, 13, 50864], "temperature":
  0.0, "avg_logprob": -0.15341481295498935, "compression_ratio": 1.7237354085603114,
  "no_speech_prob": 0.5622115731239319}, {"id": 535, "seek": 186188, "start": 1871.88,
  "end": 1887.88, "text": " Now, now the LLM thing can actually help you scale this
  right and then of course all this prompting and in label studio, by the way, they
  have released a maybe something to think about a capability where an agent will
  learn from user feedback, right.", "tokens": [50864, 823, 11, 586, 264, 441, 43,
  44, 551, 393, 767, 854, 291, 4373, 341, 558, 293, 550, 295, 1164, 439, 341, 12391,
  278, 293, 294, 7645, 6811, 11, 538, 264, 636, 11, 436, 362, 4736, 257, 1310, 746,
  281, 519, 466, 257, 13759, 689, 364, 9461, 486, 1466, 490, 4195, 5824, 11, 558,
  13, 51664], "temperature": 0.0, "avg_logprob": -0.15341481295498935, "compression_ratio":
  1.7237354085603114, "no_speech_prob": 0.5622115731239319}, {"id": 536, "seek": 188788,
  "start": 1887.88, "end": 1900.88, "text": " So let''s say they label and then so
  LLM will label make make some mistakes and then the main expert will correct them
  and so it takes it in as a feedback and then it becomes better over time.", "tokens":
  [50364, 407, 718, 311, 584, 436, 7645, 293, 550, 370, 441, 43, 44, 486, 7645, 652,
  652, 512, 8038, 293, 550, 264, 2135, 5844, 486, 3006, 552, 293, 370, 309, 2516,
  309, 294, 382, 257, 5824, 293, 550, 309, 3643, 1101, 670, 565, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.20396795272827148, "compression_ratio": 1.625615763546798,
  "no_speech_prob": 0.5232328772544861}, {"id": 537, "seek": 188788, "start": 1900.88,
  "end": 1909.88, "text": " So it''s basically you can kind of support it''s like
  you''re not copilot, someone said, seed prop stain in previous episode said, confident.",
  "tokens": [51014, 407, 309, 311, 1936, 291, 393, 733, 295, 1406, 309, 311, 411,
  291, 434, 406, 2971, 31516, 11, 1580, 848, 11, 8871, 2365, 16441, 294, 3894, 3500,
  848, 11, 6679, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20396795272827148,
  "compression_ratio": 1.625615763546798, "no_speech_prob": 0.5232328772544861}, {"id":
  538, "seek": 190988, "start": 1909.88, "end": 1919.88, "text": " So you kind of
  like give these things you collaborate in a way, right. So that would be this is
  fantastic direction.", "tokens": [50364, 407, 291, 733, 295, 411, 976, 613, 721,
  291, 18338, 294, 257, 636, 11, 558, 13, 407, 300, 576, 312, 341, 307, 5456, 3513,
  13, 50864], "temperature": 0.0, "avg_logprob": -0.22305779708059212, "compression_ratio":
  1.4825581395348837, "no_speech_prob": 0.5416343808174133}, {"id": 539, "seek": 190988,
  "start": 1919.88, "end": 1929.88, "text": " Yeah. So I mean, this is definitely
  very much around that more narrow relevance judging versus generic labeling way
  label studio is right.", "tokens": [50864, 865, 13, 407, 286, 914, 11, 341, 307,
  2138, 588, 709, 926, 300, 544, 9432, 32684, 23587, 5717, 19577, 40244, 636, 7645,
  6811, 307, 558, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22305779708059212,
  "compression_ratio": 1.4825581395348837, "no_speech_prob": 0.5416343808174133},
  {"id": 540, "seek": 192988, "start": 1929.88, "end": 1939.88, "text": " But there''s
  definitely room for inspiration from both label studio. I''ve been looking at more
  as well as ragas and how it''s doing some of the new metrics.", "tokens": [50364,
  583, 456, 311, 2138, 1808, 337, 10249, 490, 1293, 7645, 6811, 13, 286, 600, 668,
  1237, 412, 544, 382, 731, 382, 17539, 296, 293, 577, 309, 311, 884, 512, 295, 264,
  777, 16367, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15489954106947956,
  "compression_ratio": 1.5148936170212766, "no_speech_prob": 0.08198297768831253},
  {"id": 541, "seek": 192988, "start": 1939.88, "end": 1953.88, "text": " Yeah, it''s
  interesting. So yeah, exactly. What I love about Cupid is that I can really connect
  it to the live search engine. I mean, not necessarily in production can be some
  development version of it.", "tokens": [50864, 865, 11, 309, 311, 1880, 13, 407,
  1338, 11, 2293, 13, 708, 286, 959, 466, 383, 6127, 307, 300, 286, 393, 534, 1745,
  309, 281, 264, 1621, 3164, 2848, 13, 286, 914, 11, 406, 4725, 294, 4265, 393, 312,
  512, 3250, 3037, 295, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15489954106947956,
  "compression_ratio": 1.5148936170212766, "no_speech_prob": 0.08198297768831253},
  {"id": 542, "seek": 195388, "start": 1953.88, "end": 1967.88, "text": " And I can
  start labeling and queering and as you said, search is the interface to big data,
  right. So Cupid becomes interface to your search, which is the interface to your
  big data and all the unknowns there.", "tokens": [50364, 400, 286, 393, 722, 40244,
  293, 631, 1794, 293, 382, 291, 848, 11, 3164, 307, 264, 9226, 281, 955, 1412, 11,
  558, 13, 407, 383, 6127, 3643, 9226, 281, 428, 3164, 11, 597, 307, 264, 9226, 281,
  428, 955, 1412, 293, 439, 264, 46048, 456, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.12989444732666017, "compression_ratio": 1.5833333333333333, "no_speech_prob":
  0.2224840372800827}, {"id": 543, "seek": 196788, "start": 1967.88, "end": 1979.88,
  "text": " And when this terrible that one looks to OK, that one looks OK, that one
  looks terrible, right. We can immediately start building.", "tokens": [50364, 400,
  562, 341, 6237, 300, 472, 1542, 281, 2264, 11, 300, 472, 1542, 2264, 11, 300, 472,
  1542, 6237, 11, 558, 13, 492, 393, 4258, 722, 2390, 13, 50964], "temperature": 0.0,
  "avg_logprob": -0.29720140676029394, "compression_ratio": 1.8309859154929577, "no_speech_prob":
  0.24868164956569672}, {"id": 544, "seek": 196788, "start": 1979.88, "end": 1990.88,
  "text": " Yeah, maybe that one''s OK, that one doesn''t look it right we can immediately
  start building some sort of understanding right now.", "tokens": [50964, 865, 11,
  1310, 300, 472, 311, 2264, 11, 300, 472, 1177, 380, 574, 309, 558, 321, 393, 4258,
  722, 2390, 512, 1333, 295, 3701, 558, 586, 13, 51514], "temperature": 0.0, "avg_logprob":
  -0.29720140676029394, "compression_ratio": 1.8309859154929577, "no_speech_prob":
  0.24868164956569672}, {"id": 545, "seek": 199088, "start": 1990.88, "end": 2000.88,
  "text": " So quick little binary one right we''re going to start building that and
  get it get a sense of what our score is going to be exactly exactly.", "tokens":
  [50364, 407, 1702, 707, 17434, 472, 558, 321, 434, 516, 281, 722, 2390, 300, 293,
  483, 309, 483, 257, 2020, 295, 437, 527, 6175, 307, 516, 281, 312, 2293, 2293, 13,
  50864], "temperature": 0.0, "avg_logprob": -0.24190364250769983, "compression_ratio":
  1.5508021390374331, "no_speech_prob": 0.5269076824188232}, {"id": 546, "seek": 199088,
  "start": 2000.88, "end": 2009.88, "text": " And that score is also customizable.
  We''ve done some little implementations in like JavaScript looking like language,
  right. I think it''s JavaScript.", "tokens": [50864, 400, 300, 6175, 307, 611, 47922,
  13, 492, 600, 1096, 512, 707, 4445, 763, 294, 411, 15778, 1237, 411, 2856, 11, 558,
  13, 286, 519, 309, 311, 15778, 13, 51314], "temperature": 0.0, "avg_logprob": -0.24190364250769983,
  "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.5269076824188232},
  {"id": 547, "seek": 200988, "start": 2009.88, "end": 2032.88, "text": " Yeah, but
  you just come in here and you take your score right there is so here''s classic
  NBC G 10, but you can change it. So like one recently, we wanted to know in this
  score right here, we''re being you know penalized because soy is returning zero
  results.", "tokens": [50364, 865, 11, 457, 291, 445, 808, 294, 510, 293, 291, 747,
  428, 6175, 558, 456, 307, 370, 510, 311, 7230, 31504, 460, 1266, 11, 457, 291, 393,
  1319, 309, 13, 407, 411, 472, 3938, 11, 321, 1415, 281, 458, 294, 341, 6175, 558,
  510, 11, 321, 434, 885, 291, 458, 13661, 1602, 570, 8812, 307, 12678, 4018, 3542,
  13, 51514], "temperature": 0.0, "avg_logprob": -0.2553687322707403, "compression_ratio":
  1.4855491329479769, "no_speech_prob": 0.3765116333961487}, {"id": 548, "seek": 203288,
  "start": 2032.88, "end": 2037.88, "text": " And so it''s giving us a zero. So it''s
  bringing down our average precision.", "tokens": [50364, 400, 370, 309, 311, 2902,
  505, 257, 4018, 13, 407, 309, 311, 5062, 760, 527, 4274, 18356, 13, 50614], "temperature":
  0.0, "avg_logprob": -0.17420241198962247, "compression_ratio": 1.5508021390374331,
  "no_speech_prob": 0.34471097588539124}, {"id": 549, "seek": 203288, "start": 2037.88,
  "end": 2044.88, "text": " But what if you wanted to know that it was supposed to
  be zero results zero results is actually the right.", "tokens": [50614, 583, 437,
  498, 291, 1415, 281, 458, 300, 309, 390, 3442, 281, 312, 4018, 3542, 4018, 3542,
  307, 767, 264, 558, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17420241198962247,
  "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.34471097588539124},
  {"id": 550, "seek": 203288, "start": 2044.88, "end": 2046.88, "text": " Yes, yes,
  yes.", "tokens": [50964, 1079, 11, 2086, 11, 2086, 13, 51064], "temperature": 0.0,
  "avg_logprob": -0.17420241198962247, "compression_ratio": 1.5508021390374331, "no_speech_prob":
  0.34471097588539124}, {"id": 551, "seek": 203288, "start": 2046.88, "end": 2058.88,
  "text": " So that one we actually went in and said we added an option a per query
  option should be ZSR.", "tokens": [51064, 407, 300, 472, 321, 767, 1437, 294, 293,
  848, 321, 3869, 364, 3614, 257, 680, 14581, 3614, 820, 312, 1176, 50, 49, 13, 51664],
  "temperature": 0.0, "avg_logprob": -0.17420241198962247, "compression_ratio": 1.5508021390374331,
  "no_speech_prob": 0.34471097588539124}, {"id": 552, "seek": 205888, "start": 2058.88,
  "end": 2063.88, "text": " Right, and we set that option and then in our custom score.",
  "tokens": [50364, 1779, 11, 293, 321, 992, 300, 3614, 293, 550, 294, 527, 2375,
  6175, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20145328393143214, "compression_ratio":
  1.6454545454545455, "no_speech_prob": 0.11811766028404236}, {"id": 553, "seek":
  205888, "start": 2063.88, "end": 2074.88, "text": " If it said should be ZSR is
  true and there were zero results then we gave it a one right because it''s working
  the way and vice versa.", "tokens": [50614, 759, 309, 848, 820, 312, 1176, 50, 49,
  307, 2074, 293, 456, 645, 4018, 3542, 550, 321, 2729, 309, 257, 472, 558, 570, 309,
  311, 1364, 264, 636, 293, 11964, 25650, 13, 51164], "temperature": 0.0, "avg_logprob":
  -0.20145328393143214, "compression_ratio": 1.6454545454545455, "no_speech_prob":
  0.11811766028404236}, {"id": 554, "seek": 205888, "start": 2074.88, "end": 2086.88,
  "text": " We had other situations where yeah, if we started returning results for
  soy, that would have been worse search right and so yeah that was a great use of
  a custom score.", "tokens": [51164, 492, 632, 661, 6851, 689, 1338, 11, 498, 321,
  1409, 12678, 3542, 337, 8812, 11, 300, 576, 362, 668, 5324, 3164, 558, 293, 370,
  1338, 300, 390, 257, 869, 764, 295, 257, 2375, 6175, 13, 51764], "temperature":
  0.0, "avg_logprob": -0.20145328393143214, "compression_ratio": 1.6454545454545455,
  "no_speech_prob": 0.11811766028404236}, {"id": 555, "seek": 208688, "start": 2086.88,
  "end": 2087.88, "text": " Yeah, fantastic.", "tokens": [50364, 865, 11, 5456, 13,
  50414], "temperature": 0.0, "avg_logprob": -0.23187308408776108, "compression_ratio":
  1.6594827586206897, "no_speech_prob": 0.08860106766223907}, {"id": 556, "seek":
  208688, "start": 2087.88, "end": 2090.88, "text": " We''re all about that because
  it was a great use sound.", "tokens": [50414, 492, 434, 439, 466, 300, 570, 309,
  390, 257, 869, 764, 1626, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23187308408776108,
  "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.08860106766223907},
  {"id": 557, "seek": 208688, "start": 2090.88, "end": 2095.88, "text": " Yeah, yeah,
  yeah, exactly. Also where Cupid helped us is sometimes you don''t speak that language.",
  "tokens": [50564, 865, 11, 1338, 11, 1338, 11, 2293, 13, 2743, 689, 383, 6127, 4254,
  505, 307, 2171, 291, 500, 380, 1710, 300, 2856, 13, 50814], "temperature": 0.0,
  "avg_logprob": -0.23187308408776108, "compression_ratio": 1.6594827586206897, "no_speech_prob":
  0.08860106766223907}, {"id": 558, "seek": 208688, "start": 2095.88, "end": 2109.88,
  "text": " So it could be Korean language that you don''t speak but you need to move
  and on one occasion we''ve sent a Cupid just to our Korean native speakers in the
  company and they''ve labeled and they told us how it looks so.", "tokens": [50814,
  407, 309, 727, 312, 6933, 2856, 300, 291, 500, 380, 1710, 457, 291, 643, 281, 1286,
  293, 322, 472, 9674, 321, 600, 2279, 257, 383, 6127, 445, 281, 527, 6933, 8470,
  9518, 294, 264, 2237, 293, 436, 600, 21335, 293, 436, 1907, 505, 577, 309, 1542,
  370, 13, 51514], "temperature": 0.0, "avg_logprob": -0.23187308408776108, "compression_ratio":
  1.6594827586206897, "no_speech_prob": 0.08860106766223907}, {"id": 559, "seek":
  210988, "start": 2109.88, "end": 2110.88, "text": " That work.", "tokens": [50364,
  663, 589, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2014806377353953, "compression_ratio":
  1.4733727810650887, "no_speech_prob": 0.422952800989151}, {"id": 560, "seek": 210988,
  "start": 2110.88, "end": 2119.88, "text": " So the other thing right so here we
  are we are happily loading up all these but I''ll go ahead and click judge right.",
  "tokens": [50414, 407, 264, 661, 551, 558, 370, 510, 321, 366, 321, 366, 19909,
  15114, 493, 439, 613, 457, 286, 603, 352, 2286, 293, 2052, 6995, 558, 13, 50864],
  "temperature": 0.0, "avg_logprob": -0.2014806377353953, "compression_ratio": 1.4733727810650887,
  "no_speech_prob": 0.422952800989151}, {"id": 561, "seek": 210988, "start": 2119.88,
  "end": 2127.88, "text": " So this is sort of an older approach to rating a zero
  a one to 10 wouldn''t do that now but that''s what we''ve been saying.", "tokens":
  [50864, 407, 341, 307, 1333, 295, 364, 4906, 3109, 281, 10990, 257, 4018, 257, 472,
  281, 1266, 2759, 380, 360, 300, 586, 457, 300, 311, 437, 321, 600, 668, 1566, 13,
  51264], "temperature": 0.0, "avg_logprob": -0.2014806377353953, "compression_ratio":
  1.4733727810650887, "no_speech_prob": 0.422952800989151}, {"id": 562, "seek": 212788,
  "start": 2127.88, "end": 2148.88, "text": " So there you can see a here is the human
  radar interface now I don''t know what is a good rating or not but here you can
  know the rates and documents kind of taking this from this is a recent add on which
  is if you''re if you can''t read it why right.", "tokens": [50364, 407, 456, 291,
  393, 536, 257, 510, 307, 264, 1952, 16544, 9226, 586, 286, 500, 380, 458, 437, 307,
  257, 665, 10990, 420, 406, 457, 510, 291, 393, 458, 264, 6846, 293, 8512, 733, 295,
  1940, 341, 490, 341, 307, 257, 5162, 909, 322, 597, 307, 498, 291, 434, 498, 291,
  393, 380, 1401, 309, 983, 558, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23937542207779422,
  "compression_ratio": 1.5796178343949046, "no_speech_prob": 0.6172176003456116},
  {"id": 563, "seek": 214888, "start": 2148.88, "end": 2158.88, "text": " I am a vet
  in there I am not a vet and don''t understand the science.", "tokens": [50364, 286,
  669, 257, 12423, 294, 456, 286, 669, 406, 257, 12423, 293, 500, 380, 1223, 264,
  3497, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24724134851674565, "compression_ratio":
  1.5633802816901408, "no_speech_prob": 0.512824535369873}, {"id": 564, "seek": 214888,
  "start": 2158.88, "end": 2161.88, "text": " Yeah in this square.", "tokens": [50864,
  865, 294, 341, 3732, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24724134851674565,
  "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.512824535369873}, {"id":
  565, "seek": 214888, "start": 2161.88, "end": 2172.88, "text": " Right and so I''ll
  skip judge in that and that and that that''s been that''s been helpful in just cranking
  out your human judgments so.", "tokens": [51014, 1779, 293, 370, 286, 603, 10023,
  6995, 294, 300, 293, 300, 293, 300, 300, 311, 668, 300, 311, 668, 4961, 294, 445,
  21263, 278, 484, 428, 1952, 40337, 370, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.24724134851674565, "compression_ratio": 1.5633802816901408, "no_speech_prob":
  0.512824535369873}, {"id": 566, "seek": 217288, "start": 2172.88, "end": 2194.88,
  "text": " Yeah go got just a couple of judgments mostly Jeff I yeah Jeff Scott 2500
  I''ve got four in here and I mark one is unreadable I can reset that which should
  throw it back in the pool right maybe we have a conversation about why it was unreadable
  and then throw it back in the.", "tokens": [50364, 865, 352, 658, 445, 257, 1916,
  295, 40337, 5240, 7506, 286, 1338, 7506, 6659, 41171, 286, 600, 658, 1451, 294,
  510, 293, 286, 1491, 472, 307, 517, 2538, 712, 286, 393, 14322, 300, 597, 820, 3507,
  309, 646, 294, 264, 7005, 558, 1310, 321, 362, 257, 3761, 466, 983, 309, 390, 517,
  2538, 712, 293, 550, 3507, 309, 646, 294, 264, 13, 51464], "temperature": 0.0, "avg_logprob":
  -0.23891633929628314, "compression_ratio": 1.5222222222222221, "no_speech_prob":
  0.27343299984931946}, {"id": 567, "seek": 219488, "start": 2194.88, "end": 2209.88,
  "text": " Almost there we are almost there right the background job is wonderful
  but it doesn''t necessarily mean it''s any faster right now I know I know at least
  watch it and watch the countdown so.", "tokens": [50364, 12627, 456, 321, 366, 1920,
  456, 558, 264, 3678, 1691, 307, 3715, 457, 309, 1177, 380, 4725, 914, 309, 311,
  604, 4663, 558, 586, 286, 458, 286, 458, 412, 1935, 1159, 309, 293, 1159, 264, 35985,
  370, 13, 51114], "temperature": 0.0, "avg_logprob": -0.24212326722986557, "compression_ratio":
  1.5833333333333333, "no_speech_prob": 0.41974183917045593}, {"id": 568, "seek":
  219488, "start": 2209.88, "end": 2216.88, "text": " Fantastic demo can you tell
  a bit more about the tech side of things we didn''t mention sequel my sequel already
  is.", "tokens": [51114, 21320, 10723, 393, 291, 980, 257, 857, 544, 466, 264, 7553,
  1252, 295, 721, 321, 994, 380, 2152, 20622, 452, 20622, 1217, 307, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.24212326722986557, "compression_ratio": 1.5833333333333333,
  "no_speech_prob": 0.41974183917045593}, {"id": 569, "seek": 221688, "start": 2216.88,
  "end": 2223.88, "text": " So if someone wants to jump in and start you know going
  and and sort of what is the level of effort they need to go through.", "tokens":
  [50364, 407, 498, 1580, 2738, 281, 3012, 294, 293, 722, 291, 458, 516, 293, 293,
  1333, 295, 437, 307, 264, 1496, 295, 4630, 436, 643, 281, 352, 807, 13, 50714],
  "temperature": 0.0, "avg_logprob": -0.16827677457760543, "compression_ratio": 1.6363636363636365,
  "no_speech_prob": 0.5191554427146912}, {"id": 570, "seek": 221688, "start": 2223.88,
  "end": 2239.88, "text": " It''s a little bit of a challenge right so most of us
  so this is a Ruby on rails web app right like it is a full stack web app and this
  is all just standard Ruby on rails the app is.", "tokens": [50714, 467, 311, 257,
  707, 857, 295, 257, 3430, 558, 370, 881, 295, 505, 370, 341, 307, 257, 19907, 322,
  27649, 3670, 724, 558, 411, 309, 307, 257, 1577, 8630, 3670, 724, 293, 341, 307,
  439, 445, 3832, 19907, 322, 27649, 264, 724, 307, 13, 51514], "temperature": 0.0,
  "avg_logprob": -0.16827677457760543, "compression_ratio": 1.6363636363636365, "no_speech_prob":
  0.5191554427146912}, {"id": 571, "seek": 223988, "start": 2239.88, "end": 2268.88,
  "text": " It''s been upgraded over the years to be with the latest standard and
  so if you do rails development everything''s going to feel very comfortable obviously
  a lot of us in the search or information retrieval world don''t have that expertise
  and that that''s just a challenge so one thing I will say is that if you join or
  ask questions on relevance slack pound cupid happy to answer those questions the
  core application that you play with in here.", "tokens": [50364, 467, 311, 668,
  24133, 670, 264, 924, 281, 312, 365, 264, 6792, 3832, 293, 370, 498, 291, 360, 27649,
  3250, 1203, 311, 516, 281, 841, 588, 4619, 2745, 257, 688, 295, 505, 294, 264, 3164,
  420, 1589, 19817, 3337, 1002, 500, 380, 362, 300, 11769, 293, 300, 300, 311, 445,
  257, 3430, 370, 472, 551, 286, 486, 584, 307, 300, 498, 291, 3917, 420, 1029, 1651,
  322, 32684, 29767, 12013, 4414, 327, 2055, 281, 1867, 729, 1651, 264, 4965, 3861,
  300, 291, 862, 365, 294, 510, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10352518270303915,
  "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.5748762488365173},
  {"id": 572, "seek": 226888, "start": 2268.88, "end": 2293.88, "text": " So it''s
  an old angular one works great no problems but it''s an angular one app and because
  it''s an open source project not a commercial product we sort of stayed away from
  attempting the big rewrite to update it to react or name your thing lots of examples
  it seems to work fine animals.", "tokens": [50364, 407, 309, 311, 364, 1331, 24413,
  472, 1985, 869, 572, 2740, 457, 309, 311, 364, 24413, 472, 724, 293, 570, 309, 311,
  364, 1269, 4009, 1716, 406, 257, 6841, 1674, 321, 1333, 295, 9181, 1314, 490, 22001,
  264, 955, 28132, 281, 5623, 309, 281, 4515, 420, 1315, 428, 551, 3195, 295, 5110,
  309, 2544, 281, 589, 2489, 4882, 13, 51614], "temperature": 0.0, "avg_logprob":
  -0.2175302505493164, "compression_ratio": 1.5944444444444446, "no_speech_prob":
  0.02821049839258194}, {"id": 573, "seek": 229388, "start": 2293.88, "end": 2318.88,
  "text": " So cupid angular one app for all of this and then outside of this this
  is all just a standard rails application lots of model view controller type screens
  that you can see right here all standard rails my SQL database redis for sort of
  the communication layer.", "tokens": [50364, 407, 4414, 327, 24413, 472, 724, 337,
  439, 295, 341, 293, 550, 2380, 295, 341, 341, 307, 439, 445, 257, 3832, 27649, 3861,
  3195, 295, 2316, 1910, 10561, 2010, 11171, 300, 291, 393, 536, 558, 510, 439, 3832,
  27649, 452, 19200, 8149, 2182, 271, 337, 1333, 295, 264, 6101, 4583, 13, 51614],
  "temperature": 0.0, "avg_logprob": -0.1355051734230735, "compression_ratio": 1.5568862275449102,
  "no_speech_prob": 0.02134743519127369}, {"id": 574, "seek": 231888, "start": 2318.88,
  "end": 2340.88, "text": " And it''s all built using Docker so if you want to so
  the read me has way too much developer centric set up right but if you have Docker
  then you run bin setup Docker yeah that will set you up with the development environment
  literally what I was just showing is the inside of Docker.", "tokens": [50364, 400,
  309, 311, 439, 3094, 1228, 33772, 370, 498, 291, 528, 281, 370, 264, 1401, 385,
  575, 636, 886, 709, 10754, 1489, 1341, 992, 493, 558, 457, 498, 291, 362, 33772,
  550, 291, 1190, 5171, 8657, 33772, 1338, 300, 486, 992, 291, 493, 365, 264, 3250,
  2823, 3736, 437, 286, 390, 445, 4099, 307, 264, 1854, 295, 33772, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.2526758587549603, "compression_ratio": 1.6079545454545454,
  "no_speech_prob": 0.2333473414182663}, {"id": 575, "seek": 234088, "start": 2340.88,
  "end": 2355.88, "text": " And then you fire it up locally with bin Docker server
  and that runs it locally so there''s a lot of docs in here for all the different
  parts that can be a little overwhelming I think we have to rework some of this documentation
  but it''s all there.", "tokens": [50364, 400, 550, 291, 2610, 309, 493, 16143, 365,
  5171, 33772, 7154, 293, 300, 6676, 309, 16143, 370, 456, 311, 257, 688, 295, 45623,
  294, 510, 337, 439, 264, 819, 3166, 300, 393, 312, 257, 707, 13373, 286, 519, 321,
  362, 281, 48376, 512, 295, 341, 14333, 457, 309, 311, 439, 456, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.1522289855139596, "compression_ratio": 1.496969696969697,
  "no_speech_prob": 0.034187767654657364}, {"id": 576, "seek": 235588, "start": 2355.88,
  "end": 2381.88, "text": " Now a couple of things I''ll show off we actually have
  an API now so right here you have a you come here and you generate your personal
  access token like that and just for fun by and and this curl command will show you
  your user so we have authentication API.", "tokens": [50364, 823, 257, 1916, 295,
  721, 286, 603, 855, 766, 321, 767, 362, 364, 9362, 586, 370, 558, 510, 291, 362,
  257, 291, 808, 510, 293, 291, 8460, 428, 2973, 2105, 14862, 411, 300, 293, 445,
  337, 1019, 538, 293, 293, 341, 22591, 5622, 486, 855, 291, 428, 4195, 370, 321,
  362, 26643, 9362, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18031955587452855,
  "compression_ratio": 1.5266272189349113, "no_speech_prob": 0.207333043217659}, {"id":
  577, "seek": 238188, "start": 2381.88, "end": 2393.88, "text": " And we''re slowly
  working on documenting all of those API API API API.", "tokens": [50364, 400, 321,
  434, 5692, 1364, 322, 42360, 439, 295, 729, 9362, 9362, 9362, 9362, 13, 50964],
  "temperature": 0.0, "avg_logprob": -0.3627154450667532, "compression_ratio": 1.078125,
  "no_speech_prob": 0.06112031638622284}, {"id": 578, "seek": 239388, "start": 2394.88,
  "end": 2396.88, "text": " I''m doing well.", "tokens": [50414, 286, 478, 884, 731,
  13, 50514], "temperature": 0.0, "avg_logprob": -0.20875022218034073, "compression_ratio":
  1.5544554455445545, "no_speech_prob": 0.02981564961373806}, {"id": 579, "seek":
  239388, "start": 2400.88, "end": 2422.88, "text": " So there we go API API slash
  we''re slowly documenting all the APIs and so one of the things that I encourage
  people right is maybe Cupid doesn''t do everything you need to do and so you''re
  building some scripts outside of it or in some notebooks but you can use Cupid as
  your shared source of truth.", "tokens": [50714, 407, 456, 321, 352, 9362, 9362,
  17330, 321, 434, 5692, 42360, 439, 264, 21445, 293, 370, 472, 295, 264, 721, 300,
  286, 5373, 561, 558, 307, 1310, 383, 6127, 1177, 380, 360, 1203, 291, 643, 281,
  360, 293, 370, 291, 434, 2390, 512, 23294, 2380, 295, 309, 420, 294, 512, 43782,
  457, 291, 393, 764, 383, 6127, 382, 428, 5507, 4009, 295, 3494, 13, 51814], "temperature":
  0.0, "avg_logprob": -0.20875022218034073, "compression_ratio": 1.5544554455445545,
  "no_speech_prob": 0.02981564961373806}, {"id": 580, "seek": 242388, "start": 2423.88,
  "end": 2443.88, "text": " So maybe you have a case that represents your golden set
  of queries right you in your notebook can go and grab all the query so and so we''re
  adding sort of more and more documentation on all of these different API so that''s
  fantastic yeah.", "tokens": [50364, 407, 1310, 291, 362, 257, 1389, 300, 8855, 428,
  9729, 992, 295, 24109, 558, 291, 294, 428, 21060, 393, 352, 293, 4444, 439, 264,
  14581, 370, 293, 370, 321, 434, 5127, 1333, 295, 544, 293, 544, 14333, 322, 439,
  295, 613, 819, 9362, 370, 300, 311, 5456, 1338, 13, 51364], "temperature": 0.0,
  "avg_logprob": -0.08215355423261535, "compression_ratio": 1.4573170731707317, "no_speech_prob":
  0.0008513920474797487}, {"id": 581, "seek": 244388, "start": 2443.88, "end": 2454.88,
  "text": " So make it a little bit easier for people to understand so I can look
  at this here''s case for but I can also look at it like this.", "tokens": [50364,
  407, 652, 309, 257, 707, 857, 3571, 337, 561, 281, 1223, 370, 286, 393, 574, 412,
  341, 510, 311, 1389, 337, 457, 286, 393, 611, 574, 412, 309, 411, 341, 13, 50914],
  "temperature": 0.0, "avg_logprob": -0.15308488070309817, "compression_ratio": 1.662037037037037,
  "no_speech_prob": 0.010321793146431446}, {"id": 582, "seek": 244388, "start": 2454.88,
  "end": 2456.88, "text": " That''s a Jason right.", "tokens": [50914, 663, 311, 257,
  11181, 558, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15308488070309817,
  "compression_ratio": 1.662037037037037, "no_speech_prob": 0.010321793146431446},
  {"id": 583, "seek": 244388, "start": 2456.88, "end": 2471.88, "text": " This should
  give me back my Jason right it''s all my Jason data right there''s all my different
  scores etc so if Cupid provides a value but doesn''t do everything you need to do
  you can read him right from it.", "tokens": [51014, 639, 820, 976, 385, 646, 452,
  11181, 558, 309, 311, 439, 452, 11181, 1412, 558, 456, 311, 439, 452, 819, 13444,
  5183, 370, 498, 383, 6127, 6417, 257, 2158, 457, 1177, 380, 360, 1203, 291, 643,
  281, 360, 291, 393, 1401, 796, 558, 490, 309, 13, 51764], "temperature": 0.0, "avg_logprob":
  -0.15308488070309817, "compression_ratio": 1.662037037037037, "no_speech_prob":
  0.010321793146431446}, {"id": 584, "seek": 247188, "start": 2471.88, "end": 2481.88,
  "text": " So I''m going to do a lot of export name pork functions as well so yeah
  so it''s fantastic and yeah so it''s loaded it''s loaded.", "tokens": [50364, 407,
  286, 478, 516, 281, 360, 257, 688, 295, 10725, 1315, 10208, 6828, 382, 731, 370,
  1338, 370, 309, 311, 5456, 293, 1338, 370, 309, 311, 13210, 309, 311, 13210, 13,
  50864], "temperature": 0.0, "avg_logprob": -0.46937929119980126, "compression_ratio":
  1.36, "no_speech_prob": 0.23623323440551758}, {"id": 585, "seek": 247188, "start":
  2481.88, "end": 2492.88, "text": " Like there we go 29,000 or 87 query document
  pairs and 29,291 judgments right.", "tokens": [50864, 1743, 456, 321, 352, 9413,
  11, 1360, 420, 27990, 14581, 4166, 15494, 293, 9413, 11, 11871, 16, 40337, 558,
  13, 51414], "temperature": 0.0, "avg_logprob": -0.46937929119980126, "compression_ratio":
  1.36, "no_speech_prob": 0.23623323440551758}, {"id": 586, "seek": 249288, "start":
  2492.88, "end": 2497.88, "text": " So there is all preserved so.", "tokens": [50364,
  407, 456, 307, 439, 22242, 370, 13, 50614], "temperature": 0.0, "avg_logprob": -0.34124400697905444,
  "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.33454883098602295},
  {"id": 587, "seek": 249288, "start": 2497.88, "end": 2511.88, "text": " There you
  go this is fantastic thanks for the demo Eric I learned because I wasn''t keeping
  up as closely I think we also are writing an outdated version of Cupid so I will
  ask the team to to upgrade obviously because.", "tokens": [50614, 821, 291, 352,
  341, 307, 5456, 3231, 337, 264, 10723, 9336, 286, 3264, 570, 286, 2067, 380, 5145,
  493, 382, 8185, 286, 519, 321, 611, 366, 3579, 364, 36313, 3037, 295, 383, 6127,
  370, 286, 486, 1029, 264, 1469, 281, 281, 11484, 2745, 570, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.34124400697905444, "compression_ratio": 1.4529411764705882,
  "no_speech_prob": 0.33454883098602295}, {"id": 588, "seek": 251188, "start": 2511.88,
  "end": 2525.88, "text": " Yeah we should yeah yeah the release cadence is fairly
  fast so make sure your deployment model is pretty simplistic and automated so it''s
  keep up yeah exactly.", "tokens": [50364, 865, 321, 820, 1338, 1338, 264, 4374,
  46109, 307, 6457, 2370, 370, 652, 988, 428, 19317, 2316, 307, 1238, 44199, 293,
  18473, 370, 309, 311, 1066, 493, 1338, 2293, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.15242340625860754, "compression_ratio": 1.59375, "no_speech_prob": 0.17828050255775452},
  {"id": 589, "seek": 251188, "start": 2525.88, "end": 2536.88, "text": " This is
  fantastic i''m sure we can talk more about your other projects and we will save
  it for another episode yeah but I was also thinking I like to ask this question
  and now I get the chance yeah.", "tokens": [51064, 639, 307, 5456, 741, 478, 988,
  321, 393, 751, 544, 466, 428, 661, 4455, 293, 321, 486, 3155, 309, 337, 1071, 3500,
  1338, 457, 286, 390, 611, 1953, 286, 411, 281, 1029, 341, 1168, 293, 586, 286, 483,
  264, 2931, 1338, 13, 51614], "temperature": 0.0, "avg_logprob": -0.15242340625860754,
  "compression_ratio": 1.59375, "no_speech_prob": 0.17828050255775452}, {"id": 590,
  "seek": 253688, "start": 2536.88, "end": 2558.88, "text": " Why the the question
  of why I call it or the the motivational what keeps you up and at night so to say
  why you are still in search Eric you''ve spent so many years do you think it''s
  still unsolved or what what keeps you going in in this topic yeah so what I love
  about search is it it kind of reinvents itself every.", "tokens": [50364, 1545,
  264, 264, 1168, 295, 983, 286, 818, 309, 420, 264, 264, 48186, 437, 5965, 291, 493,
  293, 412, 1818, 370, 281, 584, 983, 291, 366, 920, 294, 3164, 9336, 291, 600, 4418,
  370, 867, 924, 360, 291, 519, 309, 311, 920, 2693, 29110, 420, 437, 437, 5965, 291,
  516, 294, 294, 341, 4829, 1338, 370, 437, 286, 959, 466, 3164, 307, 309, 309, 733,
  295, 6561, 85, 791, 2564, 633, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15960806294491417,
  "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.5152212381362915},
  {"id": 591, "seek": 255888, "start": 2558.88, "end": 2582.88, "text": " I mean seven
  years five to seven years it sort of reinvents itself every seven years right I
  sort of started out with saying at one time it was exciting just to have an open
  source search engine right in a world of big expensive commercial search engines
  and then it was really exciting to get into big data from the search perspective.",
  "tokens": [50364, 286, 914, 3407, 924, 1732, 281, 3407, 924, 309, 1333, 295, 6561,
  85, 791, 2564, 633, 3407, 924, 558, 286, 1333, 295, 1409, 484, 365, 1566, 412, 472,
  565, 309, 390, 4670, 445, 281, 362, 364, 1269, 4009, 3164, 2848, 558, 294, 257,
  1002, 295, 955, 5124, 6841, 3164, 12982, 293, 550, 309, 390, 534, 4670, 281, 483,
  666, 955, 1412, 490, 264, 3164, 4585, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.12751359939575196, "compression_ratio": 1.7591623036649215, "no_speech_prob":
  0.34598419070243835}, {"id": 592, "seek": 258288, "start": 2582.88, "end": 2603.88,
  "text": " becoming a data scientist right I mean I I I pretend to be a data scientist
  I pretend to be a machine learning guy right through search right so it reinvented
  itself and now i''m a prompt engineer and generative AI person through search and
  so I love that the field reinvents itself.", "tokens": [50364, 5617, 257, 1412,
  12662, 558, 286, 914, 286, 286, 286, 11865, 281, 312, 257, 1412, 12662, 286, 11865,
  281, 312, 257, 3479, 2539, 2146, 558, 807, 3164, 558, 370, 309, 33477, 292, 2564,
  293, 586, 741, 478, 257, 12391, 11403, 293, 1337, 1166, 7318, 954, 807, 3164, 293,
  370, 286, 959, 300, 264, 2519, 6561, 85, 791, 2564, 13, 51414], "temperature": 0.0,
  "avg_logprob": -0.19884583306691003, "compression_ratio": 1.7407407407407407, "no_speech_prob":
  0.03838794678449631}, {"id": 593, "seek": 260388, "start": 2603.88, "end": 2630.88,
  "text": " But also certain long standing principles around measurement experimentation
  appear to remain relevant even though it reinvents itself every seven years right
  and it''s been really, really exciting like I like that what i''m doing now is not
  what I was doing seven years ago and I suspect I won''t be doing it in another seven
  years.", "tokens": [50364, 583, 611, 1629, 938, 4877, 9156, 926, 13160, 37142, 4204,
  281, 6222, 7340, 754, 1673, 309, 6561, 85, 791, 2564, 633, 3407, 924, 558, 293,
  309, 311, 668, 534, 11, 534, 4670, 411, 286, 411, 300, 437, 741, 478, 884, 586,
  307, 406, 437, 286, 390, 884, 3407, 924, 2057, 293, 286, 9091, 286, 1582, 380, 312,
  884, 309, 294, 1071, 3407, 924, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1421948320725385,
  "compression_ratio": 1.6751269035532994, "no_speech_prob": 0.002866325667127967},
  {"id": 594, "seek": 263088, "start": 2630.88, "end": 2650.88, "text": " And that
  I like making things happen I like solving problems and search remains sort of the
  way people interact with technology systems right I am really intrigued or looking
  forward to when.", "tokens": [50364, 400, 300, 286, 411, 1455, 721, 1051, 286, 411,
  12606, 2740, 293, 3164, 7023, 1333, 295, 264, 636, 561, 4648, 365, 2899, 3652, 558,
  286, 669, 534, 35140, 420, 1237, 2128, 281, 562, 13, 51364], "temperature": 0.0,
  "avg_logprob": -0.1697426720669395, "compression_ratio": 1.3741007194244603, "no_speech_prob":
  0.0033195093274116516}, {"id": 595, "seek": 265088, "start": 2650.88, "end": 2663.88,
  "text": " Search isn''t just I ask a question get a response but I ask a question
  get a response then I have another conversation and the search engine understands
  that we actually have we we talk about search as a conversation but.", "tokens":
  [50364, 17180, 1943, 380, 445, 286, 1029, 257, 1168, 483, 257, 4134, 457, 286, 1029,
  257, 1168, 483, 257, 4134, 550, 286, 362, 1071, 3761, 293, 264, 3164, 2848, 15146,
  300, 321, 767, 362, 321, 321, 751, 466, 3164, 382, 257, 3761, 457, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.14438152313232422, "compression_ratio": 1.805668016194332,
  "no_speech_prob": 0.27710720896720886}, {"id": 596, "seek": 265088, "start": 2663.88,
  "end": 2678.88, "text": " We don''t normally do that we just pretend it''s a one
  shot kind of thing I look forward to that side of things and then what are the new
  use cases we''re going to enable right i''m going with my family to Spain for three
  weeks.", "tokens": [51014, 492, 500, 380, 5646, 360, 300, 321, 445, 11865, 309,
  311, 257, 472, 3347, 733, 295, 551, 286, 574, 2128, 281, 300, 1252, 295, 721, 293,
  550, 437, 366, 264, 777, 764, 3331, 321, 434, 516, 281, 9528, 558, 741, 478, 516,
  365, 452, 1605, 281, 12838, 337, 1045, 3259, 13, 51764], "temperature": 0.0, "avg_logprob":
  -0.14438152313232422, "compression_ratio": 1.805668016194332, "no_speech_prob":
  0.27710720896720886}, {"id": 597, "seek": 267888, "start": 2678.88, "end": 2707.88,
  "text": " In July got my plane tickets booked I got not great flights but cheap
  flights imagine that there was a search engine out there that knew what my plane
  flights were knew what my wife''s personal tolerances are and if it was constantly
  shopping for a cheaper flight and actually cancel current flight and gave bought
  the new one and you know just let me know by the way I saved you.", "tokens": [50364,
  682, 7370, 658, 452, 5720, 12628, 26735, 286, 658, 406, 869, 21089, 457, 7084, 21089,
  3811, 300, 456, 390, 257, 3164, 2848, 484, 456, 300, 2586, 437, 452, 5720, 21089,
  645, 2586, 437, 452, 3836, 311, 2973, 11125, 2676, 366, 293, 498, 309, 390, 6460,
  8688, 337, 257, 12284, 7018, 293, 767, 10373, 2190, 7018, 293, 2729, 4243, 264,
  777, 472, 293, 291, 458, 445, 718, 385, 458, 538, 264, 636, 286, 6624, 291, 13,
  51814], "temperature": 0.0, "avg_logprob": -0.1499687870846519, "compression_ratio":
  1.7546296296296295, "no_speech_prob": 0.3149184584617615}, {"id": 598, "seek": 270788,
  "start": 2707.88, "end": 2729.88, "text": " Another 400 bucks for your family of
  four or I found a better flight or there was an upgrade right like wouldn''t be
  amazing if once you kind of gave it the parameters is doing that and I suspect that''s
  going to kind of look like a search experience right it''s going to be a query with
  a bunch of parameters.", "tokens": [50364, 3996, 8423, 11829, 337, 428, 1605, 295,
  1451, 420, 286, 1352, 257, 1101, 7018, 420, 456, 390, 364, 11484, 558, 411, 2759,
  380, 312, 2243, 498, 1564, 291, 733, 295, 2729, 309, 264, 9834, 307, 884, 300, 293,
  286, 9091, 300, 311, 516, 281, 733, 295, 574, 411, 257, 3164, 1752, 558, 309, 311,
  516, 281, 312, 257, 14581, 365, 257, 3840, 295, 9834, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.07651544653851053, "compression_ratio": 1.5743589743589743,
  "no_speech_prob": 0.001953707542270422}, {"id": 599, "seek": 272988, "start": 2729.88,
  "end": 2752.88, "text": " It understands what my preferences and tolerances and
  risks are right and that''s going to be a really interesting thing to measure and
  I think it''ll be really powerful so so excited about that future I suspect that''s
  the next thing that we get to once we get through kind of the current generative
  AI stuff.", "tokens": [50364, 467, 15146, 437, 452, 21910, 293, 11125, 2676, 293,
  10888, 366, 558, 293, 300, 311, 516, 281, 312, 257, 534, 1880, 551, 281, 3481, 293,
  286, 519, 309, 603, 312, 534, 4005, 370, 370, 2919, 466, 300, 2027, 286, 9091, 300,
  311, 264, 958, 551, 300, 321, 483, 281, 1564, 321, 483, 807, 733, 295, 264, 2190,
  1337, 1166, 7318, 1507, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11063784541505756,
  "compression_ratio": 1.641711229946524, "no_speech_prob": 0.22453458607196808},
  {"id": 600, "seek": 275288, "start": 2752.88, "end": 2769.88, "text": " That''s
  a beautiful answer thanks so much really I''ve learned a lot today I''m sure we''ll
  repeat this let''s do it I know you have another topic to talk about from your conference
  talk and another project you''re working on and I''m sure keep it keep it continues
  to be.", "tokens": [50364, 663, 311, 257, 2238, 1867, 3231, 370, 709, 534, 286,
  600, 3264, 257, 688, 965, 286, 478, 988, 321, 603, 7149, 341, 718, 311, 360, 309,
  286, 458, 291, 362, 1071, 4829, 281, 751, 466, 490, 428, 7586, 751, 293, 1071, 1716,
  291, 434, 1364, 322, 293, 286, 478, 988, 1066, 309, 1066, 309, 6515, 281, 312, 13,
  51214], "temperature": 0.0, "avg_logprob": -0.15784005195863784, "compression_ratio":
  1.5497076023391814, "no_speech_prob": 0.14440293610095978}, {"id": 601, "seek":
  276988, "start": 2769.88, "end": 2796.88, "text": " Really relevant to what we do
  it''s it''s a it''s a toolbox right it''s it''s it''s all in your toolbox or maybe
  it''s a toolbox of full of tools but I think it''s it''s fantastic one to have to
  really complete your search journey because if you are only writing code and you''re
  never looking at queries you''re never labeling you never here would you know how
  how does it feel like you know using this change and you will not get far so please
  use it.", "tokens": [50364, 4083, 7340, 281, 437, 321, 360, 309, 311, 309, 311,
  257, 309, 311, 257, 44593, 558, 309, 311, 309, 311, 309, 311, 439, 294, 428, 44593,
  420, 1310, 309, 311, 257, 44593, 295, 1577, 295, 3873, 457, 286, 519, 309, 311,
  309, 311, 5456, 472, 281, 362, 281, 534, 3566, 428, 3164, 4671, 570, 498, 291, 366,
  787, 3579, 3089, 293, 291, 434, 1128, 1237, 412, 24109, 291, 434, 1128, 40244, 291,
  1128, 510, 576, 291, 458, 577, 577, 775, 309, 841, 411, 291, 458, 1228, 341, 1319,
  293, 291, 486, 406, 483, 1400, 370, 1767, 764, 309, 13, 51714], "temperature": 0.0,
  "avg_logprob": -0.1700312605181944, "compression_ratio": 1.8571428571428572, "no_speech_prob":
  0.5359926819801331}, {"id": 602, "seek": 279688, "start": 2796.88, "end": 2813.88,
  "text": " I mean of course you can set up something you know in the kitchen with
  Excel but the Microsoft Excel whatever Google spreadsheets but maybe that''s not
  scalable enough and not repeatable and yeah why waste time if they''re already cool
  tools like keep it open source really excited about this.", "tokens": [50364, 286,
  914, 295, 1164, 291, 393, 992, 493, 746, 291, 458, 294, 264, 6525, 365, 19060, 457,
  264, 8116, 19060, 2035, 3329, 23651, 1385, 457, 1310, 300, 311, 406, 38481, 1547,
  293, 406, 7149, 712, 293, 1338, 983, 5964, 565, 498, 436, 434, 1217, 1627, 3873,
  411, 1066, 309, 1269, 4009, 534, 2919, 466, 341, 13, 51214], "temperature": 0.0,
  "avg_logprob": -0.18147932688395182, "compression_ratio": 1.5077720207253886, "no_speech_prob":
  0.5349492430686951}, {"id": 603, "seek": 281388, "start": 2813.88, "end": 2828.88,
  "text": " That''s great that''s great yeah the scaling up is super great super exciting
  so yeah it will be interesting to make sure that keep it remains true to what it
  does and doesn''t try to become all things to all people we''ll see what happens.",
  "tokens": [50364, 663, 311, 869, 300, 311, 869, 1338, 264, 21589, 493, 307, 1687,
  869, 1687, 4670, 370, 1338, 309, 486, 312, 1880, 281, 652, 988, 300, 1066, 309,
  7023, 2074, 281, 437, 309, 775, 293, 1177, 380, 853, 281, 1813, 439, 721, 281, 439,
  561, 321, 603, 536, 437, 2314, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1233453523545038,
  "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.43677860498428345},
  {"id": 604, "seek": 281388, "start": 2828.88, "end": 2838.88, "text": " Absolutely
  yes and you you as a listener have a chance to contribute it''s open source exactly
  exactly thanks so much Eric I really enjoyed it.", "tokens": [51114, 7021, 2086,
  293, 291, 291, 382, 257, 31569, 362, 257, 2931, 281, 10586, 309, 311, 1269, 4009,
  2293, 2293, 3231, 370, 709, 9336, 286, 534, 4626, 309, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.1233453523545038, "compression_ratio": 1.6406926406926408,
  "no_speech_prob": 0.43677860498428345}, {"id": 605, "seek": 283888, "start": 2838.88,
  "end": 2842.88, "text": " Thank you bye bye cheers.", "tokens": [50364, 1044, 291,
  6543, 6543, 15301, 13, 50564], "temperature": 0.0, "avg_logprob": -0.5859371821085612,
  "compression_ratio": 0.8620689655172413, "no_speech_prob": 0.32112786173820496}]'
---

Hello there, vector podcast season 3. In this season I made one simple promise. I will try to stick to 30 minute episodes. Let's see how well I will do it. It's not always easy, especially when you have guests like Eric Pugh that I'm really having a pleasure to talk to today.
I can say that we've been working together on Cupid, on ideation, on things. And I've learned a ton from you. Yeah, yeah, I'm super excited. So when did I come visit you? I think it was two years ago or some two years ago. I think so. It was pandemic, I guess.
Yeah, it was the very end of the pandemic. Right. I remember getting my, yeah, so it was still pandemic. It was still pandemic. Yeah, it's still pandemic, right? Because I had to get Cupid to say, yeah, so I was, yeah, I was like, I want to meet to meet you in person.
And I called you and said, I'm going to come to Helsinki and visit you. And I think you were like, why? I mean, we don't work together or say we worked on Cupid though. Quite a few evenings together, right? I think it was like nine o'clock your time, Helsinki time. Yes. Yes.
Who was it? And it was Friday. I remember vividly Friday. What else to do? So I went camping with my family. Can I screen share? Did you meet? Yes, yes. Of course. You can give me permissions. I went camping with my family.
And if you think back to my visit to you, you and your wife gave me a little gift. Yeah, give me a free share. I can only do you host. Let's do a host and you can screen share. Yeah, I can. All right. And so I just wanted to share off this, this cup. Oh, there it is.
So we've had that little wooden cup. I think it's a traditional finish drinking vessel when you're out in nature. And there it is with coffee.
And then I'm also showing off my metal ceramic metal enameled cup that I picked up at OpenSearchCon EU a couple weeks ago in Berlin that Zeta Alpha shared had some great conversations about search, relevancy and measurement with them.
So we took these two cups on our family camping trip the other week. I wanted to show those off to you. This is lovely. This is lovely. And I'm glad you're putting this in good news. Yep. It goes with us. So fantastic. Yes. Yes, where we start. First of all, hello. Welcome. Welcome. Yeah.
Thank you very much for having me. It's long overdue. And usually we start with a little bit of a background. Obviously, people can go. I think you even have a Wikipedia page about you. I think so. I don't know. That is a lot of people. Right. That is a lot of people to get to a Wikipedia page.
I don't know that I'm quite there yet. Yes. So my name's Eric Pugh. Been doing search for about, I don't know. We're like getting 15 years. And I was there for when a search was like first, oh, you have your own search engine. It was very exotic. And there was nothing open source.
It was all commercial. And then cut my teeth in search going through the big data time period. Right. When, as Grant Ingersoll said once, search is the UI to big data. And it was all about data.
Can we handle and how do we store it and scale up our search engines? And that was great and kind of led into the machine learning time period. We're really at that point, it was like, OK, we have lots of data. We can now search it.
What does it mean? What are people looking for? It wasn't enough to have fast search with 10 blue links.
It was all of a sudden became really important to be like, am I giving my users what they want or not? And machine learning and data science really kind of came along and helped us make those determinations.
So really, and that's when open source connections, the company I was one of the co-founders of, and I'm one of the leaders of really kind of focusing on the value side of search, relevancy.
Am I giving people what they're looking for? How do I drive more revenue in e-commerce? How do I help people use my SaaS products? Are they subscribed and renew their subscriptions? All of this, right? And yeah, machine learning was awesome. Data science was awesome.
Really got into a whole measurement thing. And that was kind of one of the products that I stored, Cupid, we know each other, came out of that time period because we said, why are we building custom tooling for every project, maybe we could share some things.
So, and then yeah, today it's really been exciting to see sort of generative AI come along and vectors.
And it's interesting because I still feel, you know, for a little while I was like, is search still gonna be a domain? And you know, search is totally changed, but it's still how people interact with systems, right?
Whether it's a spot and a retrieval augmented generation or a more traditional keyword search, using LLMs, using models, using vectors, still a search engine in the middle of it, mediating, moderating that conversation.
So really excited about what Gen AI has let us do. And I think my big takeaway right now is that historically search was fairly mediocre. You could make it a little better, you could make it a little worse, but it was always like people understood it was fairly explainable.
Why I'm really excited about measurement and understanding these days is because now with Gen AI, we have much better tools. We don't have to have mediocre search kind of better, kind of worse. Instead we can have amazing, accurate search results that really understand what you're looking for.
And you're like, yes, this is exactly what I wanted. But, whoops side of it is sometimes those search results are back shit crazy and you know, no idea why it came back with it and you made me lose trust.
And so now instead of all search results sort of being in the middle sort of, yeah, a little better, little worse, we're now really polarized. Sometimes they're amazing, sometimes they're terrible.
And we need to understand what that curve looks like and make sure that the amount of terrible is something that we're willing to deal with, right?
Terrible results, one in 10,000, one in 5,000, one in a million, depending on your domain, it may need to be one in a billion is a terrible, right, depending on what you're doing.
So exciting times, really exciting. Yeah, it's amazing, it's amazing story. And of course, I'm very pleased to also being able to pick up, keep it with you early on, where I tried to pioneer it two companies ago and I was leaving actually. But it was almost ready.
And then the next company I actually deployed it. And we, I remember we generated 70 G-RAT tickets just by looking at queries in Cupid because you know how it usually goes.
People develop software, other people check on it, other people are just project managing and things like this and no one really takes the lead on looking at the queries. And this is actually the most fun sometimes to look at queries and sort of you know investigate what's going on.
Do you even like these results? How do you feel about them? You know let alone setting up a team around it where some annotators can actually go and label with some domain expertise, you know, or maybe pretending to be users and things like this.
So it's an amazing system and we continue to use it today. Of course this was the first thing I pioneered at TomTom and it's still there. It's fantastic, that is wonderful. I mean, it's been great to see sort of the adoption of the product and then people have been using it for a long time.
So I'm going to show a query set today that is a thousand queries and maybe a thousand queries that have been judged 10 deep right by hand for three years. Almost four years.
This one organization that Nerry Information Network has been using Cupid for years and now they built up this massive body of ratings and they have tons of data and trend lines for what did search look like four years ago? What did it look like last year? What does it look like today?
It's really been exciting to see them.
They've just been using the little hosted Cupid app.cupid.com and but it's worked for them. So a thousand queries definitely takes a long time to work your way through. But these days they're just kind of keeping an eye on what's changing, right? Barring a major algorithm change.
It's just sort of staying on top of it and keeping everything right. But yeah, so it's really exciting to see people using it. Yeah.
Definitely I'm having a little bit of thoughts about where does Cupid live in our generative AI future? Been playing a lot with tools like Ragus and some of the other ones, right? And it's interesting to see what tooling and where does Cupid do things? Well, where does it have challenges?
Where do we want to go with? So yeah, for sure.
And for those who don't know Cupid, I mean, I can give my short intro, but obviously feel free to augment. But like the way I see it is that it's basically instead of hearsay and sort of someone saying, your search doesn't work. And here is one anecdotal example.
What you can do is that, oh, vice versa, you could say I improved search.
And here is one anecdotal example where it really shines, right? Now what should we ship it? So basically I think Cupid really gives you the tooling and you can actually, even if you want, you can even do it in an unbiased way, as possible where you will do blind labeling in some sense, right?
So I've done it actually just recently.
And basically you allow your users, well, your domain experts actually, but maybe even developers to go label queries.
And it also has this sandbox where you can actually, well, you can plug in your own engine, but you can also plug in those standard engines like Elastic Search Solar, Open Search and others.
And I think you even added some vector search engines recently, right? Yeah, so we have a Vectara, which is a pure vector search engine. We've got out the only app.
And then Open Search, Elastic Search Solar, the Lucine Bay search engines, and then kind of exciting, you can also now plug in your own search API. And so you can just talk to any API, a restful Git post JSON sort of API, you can use Cupid as well. So that's been really good. Fantastic.
I love this YCupid. This is sort of the origin story Doug Turmbolt, who many of you may know, right, from his book Relevant Search. He created Cupid. And we're looking at like a decade ago at this point.
And it was because, you know, it was difficult to measure and improve search, right? Lots of spreadsheets going back, lots of conversations. You fix one thing, break another. And Doug and Arena were working together on a project. And it was literally, this is the origin story for Cupid.
So Cupid's all about making collaboration better, making your testing more accurate, and making things go faster, right? Because we need to iterate and experiment quickly, right?
The one thing I know is that the team that can experiment quickly and effectively is the team that's going to win out, right? It's not about specific technology choices or technical expertise.
It's experimentation. Can you do it quickly? So yeah, so Cupid.com has the advertising free hosted version, really excited. It sort of continues to be useful in today's world. Absolutely. And it's also open source, right? So you don't have to be buying anything, whatever.
It used to be a product though. It used to be generating revenue. Yeah, I mean, you told me. We're consulting soon. So yeah, we used to sell it. We used to sell it for $10,000 a year for an enterprise license. And we had customers and it was great.
But I think then we figured out we were making, I don't know, $80,000 a year, which sounds like a lot, but then investing $150,000 in salary, supporting it. And it was like, yeah, we're not a product company. And we are open source connections, having a commercial product just didn't fit naturally.
And since we're all about training our clients and empowering search teams, right? Doesn't necessarily feel empowering to be like, yes, we've empowered you, but you have to pay us money every month for this one product, right? Just felt more natural to have it as an open source project.
Yeah, absolutely. And it also fits your, well, how should I say, your professional line at UI commuter. You've seen solar commuter, right? Yeah, so I am a commuter, not active on Lucene, that's just a level of technical expertise. But I am a commuter on solar.
And then interesting as like an interesting personal professional development, I've been really gotten much more involved with the open search community over the whole year.
And so I'm now a, they call it a maintainer instead of commuter, but I am a maintainer for open search documentation, which has really been really a lot fun to work on. And we're talking about it maybe in another podcast, but contributing some new features to open search, the open source product.
So really excited about that. Sam. Actually, give me one second. I have one thing to confess, one second. I have to confess or share one personal bit that when I started in search, it was, of course, it was early. It was like 2003 about when I wrote my own search engine.
But when I started doing search in the industry, right? It was 2010. And it was a patch of solar. And when you Google a patch of solar, you would mostly find Java, Java dog. Yeah.
And maybe, and then I figured out there is also a mailing list was like, but is there a place where I can read about solar besides Vicky pages because Vicky pages were not kind of complete in a way? Yep. Yep. I was like, and I found this, this book. Oh my gosh. One point four. Yeah.
A prior server data. Yes. Yes. Yes. And I've read it covered to cover. I have to say it because because I had one challenging task. I had to build what I suggest and that I would suggest had to abide to certain rules.
And I was like, oh my god, how will I do it? In the moment I did it, it was also slow. So I had to figure out on our data, on our version of model of data. Right. Oh my god, this was so exciting. I was like going back and forth between the book. And then a bit of googling and then trying things.
Ah, yes. Fantastic. Wow. Thanks for doing this. So you also the author. You also the author. Yeah. Yeah. Yeah. Yeah. Yeah. So we did that book. We did it. We did a second version of it for updated solar. But that was quite a few years ago.
I am kind of curious what's going to happen with technical books. Right. I mean, in the solar community, we got the ref guide, which is, I think, pretty darn good considering how it's written. I do sort of wonder what the future of technical books will be with open source communities.
And what do we do? So maybe like cookbooks, you know, like that you have specific cases and like, how would you come about building these things and maybe real data so people can actually try things, right? Yeah. Yeah. Yeah. I mean, it has gotten a lot easier to publish on the web, right? Yeah.
Have something. But yeah, what, you know, I think a lot of people write a book sort of as a writer passage as well. Right. So it's a book, a little different thing writing a book for an open source project reference. Right. For sure. How to make them printable.
So you can say I wrote the book for this open source project. But we'll see. Yeah. That's exciting. But you also wanted to show something. Let's demo. I'd love to. Yeah.
So we touched briefly on Cuban, right? The first one of the stewards of the project and historically for those of here, I'll just go ahead. For those of you who've used Cuban in the past, the way it has worked is I'll just I'll just bring up my local host. Here we go. Right.
So one of the things that we batted in the not in recent, this is the development version. I'm going to use it with realistic activity and Cuban is who I pulled up and I got a couple of cases here. But you know, in Cuban, it works well. I'm going to bring up a case. Right. Here's a case.
I'm going to search for milk. I did a query for milk. This is using sort of a random data set here. It's backed by a solar search engine. And there's a survey right there. There's my search engine.
And Cuban works great for a relatively small number of queries up to hundreds, right? And one of the things that we found is that this interface works well, especially if a search engine super fast and responsive.
It's a rich single page JavaScript application that's making queries in real time to a search engine. If you have a thousand queries, like the people I mentioned before, takes like 15, 20 minutes, but as you wide load up and all the queries to be run.
And we know that lots of people want to run more queries, 5,000, right? People ask how many queries should I be measuring? I'm like, well, start out with what you can. If that's 25 and 50, that's better than zero.
Think about 200, maybe 300, maybe a thousand, 5,000, right? And then above 5,000, that's sort of only for the most sophisticated teams. But Cuban kind of tops out at maybe a thousand queries.
And so we've been doing a lot of work to think about how do we support larger data sets, right? Larger query sets.
And what's been really fun is to work on introducing background processing, right? Instead of everything being limited by the request, response cycle of your web browser, what if we can run some background jobs? And so I'm just going to show really quick. I'm going to go and bring up all the books.
And I've got an import feature. So we have exported a book book export 39. It's a 62 megabyte JSON file. So 62 megabytes. And I'm going to go ahead and click upload. And now in cube bid, what we're starting to do is we can take large files based on files predominantly.
And we storm in the background and we kick off a process, a background job. And there you can see, right there we are loading a whole bunch of queries, right? And these are all sort of scientific queries, some very complex ones and simpler ones.
And you can see it's going to take a while because this had what 28,000 query dock pairs, right? So that are being loaded along with their judgments. So, but what sort of fun with the new background jobs and using web sockets.
We're also able to push up updates to you as background jobs are happening inside cube. So right here, there we are, and we are loading a whole bunch of data. Now, yes, it would be nice if it was a parquet file, not a MySQL database that we were using.
So we'll have to think about some of those things. But this is starting to open up the door to moving larger data sets and being really comfortable with that sort of 5,000 queries, 50,000 query dock pairs kind of data.
Not going to manage the 100,000 queries or quarter million documents those data sets. Jason is not the right format, but we're at least scaling it up to get a broader set.
The other thing that I'm also excited about is we're getting closer to be able to run these analytics on a regular basis, right? Now that we have some background processing, we could think about every night we rerun all 1000 documents. And every night we could be storing them.
So these little charts here that you see that are sort of showing some basic scoring information. You could start using this to monitor it over time instead of having to roll your own dashboarding tools. So that's something I'm really excited about. I'm also going to point out to two PR so GitHub.
com 19 sqbid is the open source project. And a couple of pull requests that are in progress, but looking to land them soon. Right here is this pull request 976. Imagine if we could run thousands of queries nightly and cupid.
Now that we've got background jobs working and communicating with the user right of state. This will be coming pretty soon. Pretty soon in open source time, which means. I don't know. We'll see next few months. And so I'm glad people helping and testing. So this one's super exciting.
Let's go back and see how we're doing. And they're doing. So there we go. We're up to 4968 query dock pairs as we kind of count down. So yeah, this is all through the magic of Web sockets, which has been really cool to see.
And as you are loading this here, are you also executing it against the search engine? Or are you here because we had all static data. Yes, static data. A book represents the query dock pairs with all of the data. Whereas the case is what we do the real time querying.
And now that we have this one working. Once we have this PR, then you'll be able to run a background job in cupid. With a similar counter, maybe it up here next to one of your cases that says we're running queries, 5,000 queries. And this is our progress for the number of the error out.
But of course, for listeners to understand, like what takes time is basically, of course, also in searching this data into cupids database is like my sequel. Right. And ready. So have you stopped using it already? So we're actually, so we're using my sequels or database.
However, what manages this communication web sockets is all in red. So as the bat and it's our background jobs and our front end jobs and our web browsers keep track of each other is through red. Yeah, so if I actually, so if you, you know, I'm running local hosts, you won't see it.
So everybody who is connected, who has permissions for this book, everybody would be seeing these messages. Yeah, yeah. So it's kind of broadcasting to everyone. Yeah, cool. Exactly. So that's something I'm really, really excited about.
The other thing that I'm really excited to be is LLM based judgments, right? So I'm going to start out this conversation about using cupid with human judges annotators, right? And gathering quite quality data. But as we all know, human judges is expensive, not every organization can do it.
My colleague Scott Stoltz last year did some interesting work playing around with chat GPT when it first came out to evaluate, is this query and this document.
And then we've been working with Moody's on their BG solution and using what we've been calling judge Judy, an LLM to evaluate what that lets us do is. We're basically using a small set of human judges to validate our LLM judge judge Judy.
And if we have good correlation, right, our inner rate of reliability looks good, you know, flights, Kappa, Coens, all those metrics look good, then this gives us confidence to go ahead and scale up the judgments, right, using an LLM.
So today, that is a bunch of pandas notebooks and kind of custom code.
However, the other pull requests that I'm really excited about, right, is this meat judge Judy, she is your AI powered subject matter expert, right?
And so in the not too distant future, you will be able to, let me go ahead and bring up this case, right, here we have one person who's been the judge.
But soon, you'll have a second column next to it, judge Judy, right, using whatever prompt you've typed in, right, or provided is judging. So that's the other big, how do we scale up, cupid and make it relevant in our gen AI world, right, those are sort of the two big things. This is fantastic.
This is really fantastic. Yeah. Wow. I hope this PRs will land really soon, especially the LLM one, right, because this allows people to really quickly hit the ground running and start labeling.
Actually, someone will label in a way, but exactly exactly the trick is having the right props, right, and having the right set of positive examples and negative examples, right.
But one of the things that I were working on, so cupid, right, ships with a set of data science notebooks, they need a little bit more work. See if this comes up in my diversion, I don't ship that. So I'm going to switch to the production cupid. Yeah, no worries. And notebooks.
So in this example's folder, we're actually shipping a couple of notebooks for you to use, flash capa, jacquard and RBO comparison, multi-radar analysis, right. And these notebooks here, you can directly use with your cupid book of judgments to evaluate how we're doing overall.
And so this can let you take your human judgments, understand how good or bad they are. And then when you bring the LLM power judge in compare the LLM judge to what your human judges were doing and feel some confidence.
So I'm really excited to be shipping these because I think it's going to lower the barrier to getting judgments. And that's something that a lot of search teams are like, I would love to use cute, but I would love to do this.
But I can't do any of this until I have judgments and I don't know where to get them or I don't have the domain experts that I need, right.
And you know, search oriented organizations often have that figured out, but a lot of other teams are like, we just see a search engine that works what you know reasonably well and we don't have that. So we got a lower the barrier to getting judgments in judgments and I'm excited about this.
This is fantastic, but I can also add from my personal experience, you know, that yes, you're absolutely right that there is this sometimes there is even a friction, right.
The search engineer says, no, I don't want to label I'm a search engineer, I'm developing the algorithm, but they will get so many more insights, so much more insights if they actually label.
And in our teams, you know, if you have, I don't know, 10 people and if each will label 10 queries, you will have 100 queries labeled.
So of course, if you don't go for overlapping and stuff like that, but if you go, then yeah, it's another story, but you know, and then all of us, all of a sudden get all this insights, right.
Now, now the LLM thing can actually help you scale this right and then of course all this prompting and in label studio, by the way, they have released a maybe something to think about a capability where an agent will learn from user feedback, right.
So let's say they label and then so LLM will label make make some mistakes and then the main expert will correct them and so it takes it in as a feedback and then it becomes better over time.
So it's basically you can kind of support it's like you're not copilot, someone said, seed prop stain in previous episode said, confident. So you kind of like give these things you collaborate in a way, right. So that would be this is fantastic direction. Yeah.
So I mean, this is definitely very much around that more narrow relevance judging versus generic labeling way label studio is right. But there's definitely room for inspiration from both label studio. I've been looking at more as well as ragas and how it's doing some of the new metrics.
Yeah, it's interesting. So yeah, exactly. What I love about Cupid is that I can really connect it to the live search engine. I mean, not necessarily in production can be some development version of it.
And I can start labeling and queering and as you said, search is the interface to big data, right. So Cupid becomes interface to your search, which is the interface to your big data and all the unknowns there.
And when this terrible that one looks to OK, that one looks OK, that one looks terrible, right. We can immediately start building. Yeah, maybe that one's OK, that one doesn't look it right we can immediately start building some sort of understanding right now.
So quick little binary one right we're going to start building that and get it get a sense of what our score is going to be exactly exactly. And that score is also customizable. We've done some little implementations in like JavaScript looking like language, right. I think it's JavaScript.
Yeah, but you just come in here and you take your score right there is so here's classic NBC G 10, but you can change it. So like one recently, we wanted to know in this score right here, we're being you know penalized because soy is returning zero results. And so it's giving us a zero.
So it's bringing down our average precision. But what if you wanted to know that it was supposed to be zero results zero results is actually the right. Yes, yes, yes. So that one we actually went in and said we added an option a per query option should be ZSR.
Right, and we set that option and then in our custom score. If it said should be ZSR is true and there were zero results then we gave it a one right because it's working the way and vice versa.
We had other situations where yeah, if we started returning results for soy, that would have been worse search right and so yeah that was a great use of a custom score. Yeah, fantastic. We're all about that because it was a great use sound. Yeah, yeah, yeah, exactly.
Also where Cupid helped us is sometimes you don't speak that language. So it could be Korean language that you don't speak but you need to move and on one occasion we've sent a Cupid just to our Korean native speakers in the company and they've labeled and they told us how it looks so. That work.
So the other thing right so here we are we are happily loading up all these but I'll go ahead and click judge right. So this is sort of an older approach to rating a zero a one to 10 wouldn't do that now but that's what we've been saying.
So there you can see a here is the human radar interface now I don't know what is a good rating or not but here you can know the rates and documents kind of taking this from this is a recent add on which is if you're if you can't read it why right.
I am a vet in there I am not a vet and don't understand the science. Yeah in this square. Right and so I'll skip judge in that and that and that that's been that's been helpful in just cranking out your human judgments so.
Yeah go got just a couple of judgments mostly Jeff I yeah Jeff Scott 2500 I've got four in here and I mark one is unreadable I can reset that which should throw it back in the pool right maybe we have a conversation about why it was unreadable and then throw it back in the.
Almost there we are almost there right the background job is wonderful but it doesn't necessarily mean it's any faster right now I know I know at least watch it and watch the countdown so.
Fantastic demo can you tell a bit more about the tech side of things we didn't mention sequel my sequel already is. So if someone wants to jump in and start you know going and and sort of what is the level of effort they need to go through.
It's a little bit of a challenge right so most of us so this is a Ruby on rails web app right like it is a full stack web app and this is all just standard Ruby on rails the app is.
 It's been upgraded over the years to be with the latest standard and so if you do rails development everything's going to feel very comfortable obviously a lot of us in the search or information retrieval world don't have that expertise and that that's just a challenge so one thing I will say is that if you join or ask questions on relevance slack pound cupid happy to answer those questions the core application that you play with in here.
So it's an old angular one works great no problems but it's an angular one app and because it's an open source project not a commercial product we sort of stayed away from attempting the big rewrite to update it to react or name your thing lots of examples it seems to work fine animals.
So cupid angular one app for all of this and then outside of this this is all just a standard rails application lots of model view controller type screens that you can see right here all standard rails my SQL database redis for sort of the communication layer.
And it's all built using Docker so if you want to so the read me has way too much developer centric set up right but if you have Docker then you run bin setup Docker yeah that will set you up with the development environment literally what I was just showing is the inside of Docker.
And then you fire it up locally with bin Docker server and that runs it locally so there's a lot of docs in here for all the different parts that can be a little overwhelming I think we have to rework some of this documentation but it's all there.
Now a couple of things I'll show off we actually have an API now so right here you have a you come here and you generate your personal access token like that and just for fun by and and this curl command will show you your user so we have authentication API.
And we're slowly working on documenting all of those API API API API. I'm doing well.
So there we go API API slash we're slowly documenting all the APIs and so one of the things that I encourage people right is maybe Cupid doesn't do everything you need to do and so you're building some scripts outside of it or in some notebooks but you can use Cupid as your shared source of truth.
So maybe you have a case that represents your golden set of queries right you in your notebook can go and grab all the query so and so we're adding sort of more and more documentation on all of these different API so that's fantastic yeah.
So make it a little bit easier for people to understand so I can look at this here's case for but I can also look at it like this. That's a Jason right.
This should give me back my Jason right it's all my Jason data right there's all my different scores etc so if Cupid provides a value but doesn't do everything you need to do you can read him right from it.
So I'm going to do a lot of export name pork functions as well so yeah so it's fantastic and yeah so it's loaded it's loaded. Like there we go 29,000 or 87 query document pairs and 29,291 judgments right. So there is all preserved so.
There you go this is fantastic thanks for the demo Eric I learned because I wasn't keeping up as closely I think we also are writing an outdated version of Cupid so I will ask the team to to upgrade obviously because.
Yeah we should yeah yeah the release cadence is fairly fast so make sure your deployment model is pretty simplistic and automated so it's keep up yeah exactly.
This is fantastic i'm sure we can talk more about your other projects and we will save it for another episode yeah but I was also thinking I like to ask this question and now I get the chance yeah.
 Why the the question of why I call it or the the motivational what keeps you up and at night so to say why you are still in search Eric you've spent so many years do you think it's still unsolved or what what keeps you going in in this topic yeah so what I love about search is it it kind of reinvents itself every.
 I mean seven years five to seven years it sort of reinvents itself every seven years right I sort of started out with saying at one time it was exciting just to have an open source search engine right in a world of big expensive commercial search engines and then it was really exciting to get into big data from the search perspective.
becoming a data scientist right I mean I I I pretend to be a data scientist I pretend to be a machine learning guy right through search right so it reinvented itself and now i'm a prompt engineer and generative AI person through search and so I love that the field reinvents itself.
 But also certain long standing principles around measurement experimentation appear to remain relevant even though it reinvents itself every seven years right and it's been really, really exciting like I like that what i'm doing now is not what I was doing seven years ago and I suspect I won't be doing it in another seven years.
And that I like making things happen I like solving problems and search remains sort of the way people interact with technology systems right I am really intrigued or looking forward to when.
Search isn't just I ask a question get a response but I ask a question get a response then I have another conversation and the search engine understands that we actually have we we talk about search as a conversation but.
We don't normally do that we just pretend it's a one shot kind of thing I look forward to that side of things and then what are the new use cases we're going to enable right i'm going with my family to Spain for three weeks.
 In July got my plane tickets booked I got not great flights but cheap flights imagine that there was a search engine out there that knew what my plane flights were knew what my wife's personal tolerances are and if it was constantly shopping for a cheaper flight and actually cancel current flight and gave bought the new one and you know just let me know by the way I saved you.
 Another 400 bucks for your family of four or I found a better flight or there was an upgrade right like wouldn't be amazing if once you kind of gave it the parameters is doing that and I suspect that's going to kind of look like a search experience right it's going to be a query with a bunch of parameters.
 It understands what my preferences and tolerances and risks are right and that's going to be a really interesting thing to measure and I think it'll be really powerful so so excited about that future I suspect that's the next thing that we get to once we get through kind of the current generative AI stuff.
That's a beautiful answer thanks so much really I've learned a lot today I'm sure we'll repeat this let's do it I know you have another topic to talk about from your conference talk and another project you're working on and I'm sure keep it keep it continues to be.
 Really relevant to what we do it's it's a it's a toolbox right it's it's it's all in your toolbox or maybe it's a toolbox of full of tools but I think it's it's fantastic one to have to really complete your search journey because if you are only writing code and you're never looking at queries you're never labeling you never here would you know how how does it feel like you know using this change and you will not get far so please use it.
I mean of course you can set up something you know in the kitchen with Excel but the Microsoft Excel whatever Google spreadsheets but maybe that's not scalable enough and not repeatable and yeah why waste time if they're already cool tools like keep it open source really excited about this.
That's great that's great yeah the scaling up is super great super exciting so yeah it will be interesting to make sure that keep it remains true to what it does and doesn't try to become all things to all people we'll see what happens.
Absolutely yes and you you as a listener have a chance to contribute it's open source exactly exactly thanks so much Eric I really enjoyed it. Thank you bye bye cheers.