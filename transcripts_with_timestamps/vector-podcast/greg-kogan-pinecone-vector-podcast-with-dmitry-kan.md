---
description: '<p><strong>Show notes</strong>:</p><p>1. Pinecone 2.0: <a href="https://www.pinecone.io/learn/pinecon..."
  rel="noopener noreferrer nofollow">https://www.pinecone.io/learn/pinecon...</a>
  It is GA and free: <a href="https://www.pinecone.io/learn/v2-pric..." rel="noopener
  noreferrer nofollow">https://www.pinecone.io/learn/v2-pric...</a></p><p>2. Get your
  “Love Thy Nearest Neighbour” t-shirt :) shoot an email to greg@pinecone.io</p><p>3.
  Billion-Scale Approximate Nearest Neighbour Search Challenge: <a href="https://big-ann-benchmarks.com/index...."
  rel="noopener noreferrer nofollow">https://big-ann-benchmarks.com/index....</a>
  </p><p>4. ANNOY: <a href="https://github.com/spotify/annoy" rel="noopener noreferrer
  nofollow">https://github.com/spotify/annoy</a></p><p>5. FAISS: <a href="https://github.com/facebookresearch/f..."
  rel="noopener noreferrer nofollow">https://github.com/facebookresearch/f...</a>
  </p><p>6. HNSW: <a href="https://github.com/nmslib/hnswlib" rel="noopener noreferrer
  nofollow">https://github.com/nmslib/hnswlib</a> </p><p>7. “How Zero Results Are
  Killing Ecommerce Conversions” <a href="https://lucidworks.com/post/how-zero-..."
  rel="noopener noreferrer nofollow">https://lucidworks.com/post/how-zero-...</a>
  </p><p>8. Try out Pinecone vector DB: <a href="https://app.pinecone.io/" rel="noopener
  noreferrer nofollow">https://app.pinecone.io/</a> </p><p>9. Twitter: <a href="https://twitter.com/Pinecone_io"
  rel="noopener noreferrer nofollow">https://twitter.com/Pinecone_io</a> </p><p>10.
  LinkedIn: <a href="https://www.linkedin.com/company/pine..." rel="noopener noreferrer
  nofollow">https://www.linkedin.com/company/pine...</a> </p><p>11. Greg’s Twitter:
  <a href="https://twitter.com/grigoriy_kogan" rel="noopener noreferrer nofollow">https://twitter.com/grigoriy_kogan</a>
  </p><p>12. Dmitry''s Twitter: <a href="https://twitter.com/DmitryKan" rel="noopener
  noreferrer nofollow">https://twitter.com/DmitryKan</a></p><p>Watch on YouTube: <a
  href="https://www.youtube.com/watch?v=jT3i7NLwJ8w" rel="noopener noreferrer nofollow">https://www.youtube.com/watch?v=jT3i7NLwJ8w</a></p>'
image_url: https://media.rss.com/vector-podcast/20211206_061204_ed150262b3f862f73666d3cce317fc98.jpg
pub_date: Mon, 06 Dec 2021 18:00:04 GMT
title: Greg Kogan - Pinecone - Vector Podcast with Dmitry Kan
url: https://rss.com/podcasts/vector-podcast/334671
whisper_segments: '[{"id": 0, "seek": 0, "start": 0.0, "end": 22.0, "text": " Hello
  everyone, so, Dr. Podcast here. Today I have Greg Coggen with the charter of marketing.",
  "tokens": [50364, 2425, 1518, 11, 370, 11, 2491, 13, 29972, 510, 13, 2692, 286,
  362, 11490, 383, 664, 1766, 365, 264, 27472, 295, 6370, 13, 51464], "temperature":
  0.0, "avg_logprob": -0.6521179764359085, "compression_ratio": 1.0568181818181819,
  "no_speech_prob": 0.08461221307516098}, {"id": 1, "seek": 2200, "start": 22.0, "end":
  31.0, "text": " He works for Pinecon. So today we will dive into Pinecon and maybe
  Greg will give us some highlights as well. Hi Greg.", "tokens": [50364, 634, 1985,
  337, 33531, 1671, 13, 407, 965, 321, 486, 9192, 666, 33531, 1671, 293, 1310, 11490,
  486, 976, 505, 512, 14254, 382, 731, 13, 2421, 11490, 13, 50814], "temperature":
  0.0, "avg_logprob": -0.2748660077952375, "compression_ratio": 1.6431372549019607,
  "no_speech_prob": 0.5747199654579163}, {"id": 2, "seek": 2200, "start": 31.0, "end":
  34.0, "text": " It''s me, Tree. Thanks for having me.", "tokens": [50814, 467, 311,
  385, 11, 22291, 13, 2561, 337, 1419, 385, 13, 50964], "temperature": 0.0, "avg_logprob":
  -0.2748660077952375, "compression_ratio": 1.6431372549019607, "no_speech_prob":
  0.5747199654579163}, {"id": 3, "seek": 2200, "start": 34.0, "end": 49.0, "text":
  " Yeah, awesome. Thanks for joining. So I was thinking maybe you can introduce yourself
  to our audience because actually I personally was quite impressed that you''re so
  technical and even though you''re in charge of marketing, you''re like your lingo
  is so technical.", "tokens": [50964, 865, 11, 3476, 13, 2561, 337, 5549, 13, 407,
  286, 390, 1953, 1310, 291, 393, 5366, 1803, 281, 527, 4034, 570, 767, 286, 5665,
  390, 1596, 11679, 300, 291, 434, 370, 6191, 293, 754, 1673, 291, 434, 294, 4602,
  295, 6370, 11, 291, 434, 411, 428, 287, 18459, 307, 370, 6191, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.2748660077952375, "compression_ratio": 1.6431372549019607,
  "no_speech_prob": 0.5747199654579163}, {"id": 4, "seek": 4900, "start": 49.0, "end":
  53.0, "text": " So technical, so can you do have some technical background?", "tokens":
  [50364, 407, 6191, 11, 370, 393, 291, 360, 362, 512, 6191, 3678, 30, 50564], "temperature":
  0.0, "avg_logprob": -0.1855557131212811, "compression_ratio": 1.3533834586466165,
  "no_speech_prob": 0.013169613666832447}, {"id": 5, "seek": 4900, "start": 53.0,
  "end": 63.0, "text": " Yeah, I actually have a degree in naval architecture. It''s
  an engineering degree and that was my career for three years.", "tokens": [50564,
  865, 11, 286, 767, 362, 257, 4314, 294, 33050, 9482, 13, 467, 311, 364, 7043, 4314,
  293, 300, 390, 452, 3988, 337, 1045, 924, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.1855557131212811, "compression_ratio": 1.3533834586466165, "no_speech_prob":
  0.013169613666832447}, {"id": 6, "seek": 6300, "start": 63.0, "end": 86.0, "text":
  " And I did systems engineering and mechanical engineering electrical and so on.
  While I was doing that, I also was moonlighting as a web developer and taught myself
  PHP and things like that and reading about startups and eventually became clear
  that I should make my day jobs related to startups.", "tokens": [50364, 400, 286,
  630, 3652, 7043, 293, 12070, 7043, 12147, 293, 370, 322, 13, 3987, 286, 390, 884,
  300, 11, 286, 611, 390, 48058, 278, 382, 257, 3670, 10754, 293, 5928, 2059, 47298,
  293, 721, 411, 300, 293, 3760, 466, 28041, 293, 4728, 3062, 1850, 300, 286, 820,
  652, 452, 786, 4782, 4077, 281, 28041, 13, 51514], "temperature": 0.0, "avg_logprob":
  -0.11429223367723368, "compression_ratio": 1.5691489361702127, "no_speech_prob":
  0.05036507546901703}, {"id": 7, "seek": 8600, "start": 86.0, "end": 98.0, "text":
  " And so I left my engineering career and went to work with startups with marketing
  and I fell in love with it. That was about nine years ago.", "tokens": [50364, 400,
  370, 286, 1411, 452, 7043, 3988, 293, 1437, 281, 589, 365, 28041, 365, 6370, 293,
  286, 5696, 294, 959, 365, 309, 13, 663, 390, 466, 4949, 924, 2057, 13, 50964], "temperature":
  0.0, "avg_logprob": -0.11116004812306371, "compression_ratio": 1.5705521472392638,
  "no_speech_prob": 0.011474424041807652}, {"id": 8, "seek": 8600, "start": 98.0,
  "end": 109.0, "text": " And I''ve been working with for the past eight years. I
  was consulting and advising technical startups on marketing.", "tokens": [50964,
  400, 286, 600, 668, 1364, 365, 337, 264, 1791, 3180, 924, 13, 286, 390, 23682, 293,
  35598, 6191, 28041, 322, 6370, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11116004812306371,
  "compression_ratio": 1.5705521472392638, "no_speech_prob": 0.011474424041807652},
  {"id": 9, "seek": 10900, "start": 109.0, "end": 120.0, "text": " And I loved it
  because I was able to use my engineering thinking and get along well with technical
  founders and the", "tokens": [50364, 400, 286, 4333, 309, 570, 286, 390, 1075, 281,
  764, 452, 7043, 1953, 293, 483, 2051, 731, 365, 6191, 25608, 293, 264, 50914], "temperature":
  0.0, "avg_logprob": -0.12089078625043233, "compression_ratio": 1.4507042253521127,
  "no_speech_prob": 0.006496563088148832}, {"id": 10, "seek": 10900, "start": 120.0,
  "end": 128.0, "text": " like the coding foundation I had allowed me to get a grasp
  for what it is the products do.", "tokens": [50914, 411, 264, 17720, 7030, 286,
  632, 4350, 385, 281, 483, 257, 21743, 337, 437, 309, 307, 264, 3383, 360, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.12089078625043233, "compression_ratio": 1.4507042253521127,
  "no_speech_prob": 0.006496563088148832}, {"id": 11, "seek": 12800, "start": 128.0,
  "end": 153.0, "text": " And last year I joined pineconous the VP of marketing and
  the engineering background certainly helps we have a technical product technical
  users and really everyone at the company has a very technical background, even our
  director of product has a PhD in electrical engineering just to give you a sense.",
  "tokens": [50364, 400, 1036, 1064, 286, 6869, 15113, 1671, 563, 264, 35812, 295,
  6370, 293, 264, 7043, 3678, 3297, 3665, 321, 362, 257, 6191, 1674, 6191, 5022, 293,
  534, 1518, 412, 264, 2237, 575, 257, 588, 6191, 3678, 11, 754, 527, 5391, 295, 1674,
  575, 257, 14476, 294, 12147, 7043, 445, 281, 976, 291, 257, 2020, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.21626839395296776, "compression_ratio": 1.6031746031746033,
  "no_speech_prob": 0.033137157559394836}, {"id": 12, "seek": 15300, "start": 153.0,
  "end": 156.0, "text": " And I was like, wow, that''s impressive.", "tokens": [50364,
  400, 286, 390, 411, 11, 6076, 11, 300, 311, 8992, 13, 50514], "temperature": 0.0,
  "avg_logprob": -0.5187439468671691, "compression_ratio": 1.3617021276595744, "no_speech_prob":
  0.3348621428012848}, {"id": 13, "seek": 15300, "start": 156.0, "end": 166.0, "text":
  " Yeah, that''s like you mentioned to the H.P. actually this was one of the first
  languages I called learned to code and decide Pearl, but yeah, this days.", "tokens":
  [50514, 865, 11, 300, 311, 411, 291, 2835, 281, 264, 389, 13, 47, 13, 767, 341,
  390, 472, 295, 264, 700, 8650, 286, 1219, 3264, 281, 3089, 293, 4536, 24639, 11,
  457, 1338, 11, 341, 1708, 13, 51014], "temperature": 0.0, "avg_logprob": -0.5187439468671691,
  "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.3348621428012848},
  {"id": 14, "seek": 16600, "start": 166.0, "end": 181.0, "text": " I''m almost I
  slowed down before before I told people I learned PHP because I know there''s a
  bit of stigma with it. It was like messy and it''s like, you know, not as pristine
  or.", "tokens": [50364, 286, 478, 1920, 286, 32057, 760, 949, 949, 286, 1907, 561,
  286, 3264, 47298, 570, 286, 458, 456, 311, 257, 857, 295, 27880, 365, 309, 13, 467,
  390, 411, 16191, 293, 309, 311, 411, 11, 291, 458, 11, 406, 382, 582, 42745, 420,
  13, 51114], "temperature": 0.0, "avg_logprob": -0.20353189328821694, "compression_ratio":
  1.5588235294117647, "no_speech_prob": 0.19927692413330078}, {"id": 15, "seek": 16600,
  "start": 181.0, "end": 190.0, "text": " Yeah, as fancy as something else, but they
  got the job job done like with with that foundation, a lot of other things made
  a lot more sense.", "tokens": [51114, 865, 11, 382, 10247, 382, 746, 1646, 11, 457,
  436, 658, 264, 1691, 1691, 1096, 411, 365, 365, 300, 7030, 11, 257, 688, 295, 661,
  721, 1027, 257, 688, 544, 2020, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20353189328821694,
  "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.19927692413330078},
  {"id": 16, "seek": 19000, "start": 190.0, "end": 207.0, "text": " Yeah, absolutely.
  Yeah, I mean, I also enjoyed actually like it was one of the first jobs I got was
  in PHP. So I built like a forum and every class in the code was starting with oops
  and I was asking the new engineer doesn''t mean all OP like object oriented programming.",
  "tokens": [50364, 865, 11, 3122, 13, 865, 11, 286, 914, 11, 286, 611, 4626, 767,
  411, 309, 390, 472, 295, 264, 700, 4782, 286, 658, 390, 294, 47298, 13, 407, 286,
  3094, 411, 257, 17542, 293, 633, 1508, 294, 264, 3089, 390, 2891, 365, 34166, 293,
  286, 390, 3365, 264, 777, 11403, 1177, 380, 914, 439, 23324, 411, 2657, 21841, 9410,
  13, 51214], "temperature": 0.0, "avg_logprob": -0.23643625699556792, "compression_ratio":
  1.583969465648855, "no_speech_prob": 0.09716351330280304}, {"id": 17, "seek": 19000,
  "start": 207.0, "end": 215.0, "text": " And he said, no, it just means oops, I''m
  not technical. So he wasn''t technical enough to know what is all P. But anyway,
  that was kind of funny.", "tokens": [51214, 400, 415, 848, 11, 572, 11, 309, 445,
  1355, 34166, 11, 286, 478, 406, 6191, 13, 407, 415, 2067, 380, 6191, 1547, 281,
  458, 437, 307, 439, 430, 13, 583, 4033, 11, 300, 390, 733, 295, 4074, 13, 51614],
  "temperature": 0.0, "avg_logprob": -0.23643625699556792, "compression_ratio": 1.583969465648855,
  "no_speech_prob": 0.09716351330280304}, {"id": 18, "seek": 21500, "start": 215.0,
  "end": 235.0, "text": " Yeah, that''s cool. So basically like you have the technical
  background. You also know how to explain things. I think it''s very important in
  our profession at large and sounds like you''ve been you''ve been advancing into
  this topic more and more to the level of becoming, you know, symbol or like BPO
  marketing actually to be precise, right.", "tokens": [50364, 865, 11, 300, 311,
  1627, 13, 407, 1936, 411, 291, 362, 264, 6191, 3678, 13, 509, 611, 458, 577, 281,
  2903, 721, 13, 286, 519, 309, 311, 588, 1021, 294, 527, 7032, 412, 2416, 293, 3263,
  411, 291, 600, 668, 291, 600, 668, 27267, 666, 341, 4829, 544, 293, 544, 281, 264,
  1496, 295, 5617, 11, 291, 458, 11, 5986, 420, 411, 363, 34885, 6370, 767, 281, 312,
  13600, 11, 558, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19429757720545718,
  "compression_ratio": 1.540909090909091, "no_speech_prob": 0.10594156384468079},
  {"id": 19, "seek": 23500, "start": 235.0, "end": 254.0, "text": " Yeah, that''s
  awesome. So tell me more a bit more about fine code like what what are you guys
  building and yeah, I know that you''ve recently had a major upgrade of fine code.
  Maybe if you wish you could highlight some of the improvements you guys made.",
  "tokens": [50364, 865, 11, 300, 311, 3476, 13, 407, 980, 385, 544, 257, 857, 544,
  466, 2489, 3089, 411, 437, 437, 366, 291, 1074, 2390, 293, 1338, 11, 286, 458, 300,
  291, 600, 3938, 632, 257, 2563, 11484, 295, 2489, 3089, 13, 2704, 498, 291, 3172,
  291, 727, 5078, 512, 295, 264, 13797, 291, 1074, 1027, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.2792580168125993, "compression_ratio": 1.4764705882352942,
  "no_speech_prob": 0.054512519389390945}, {"id": 20, "seek": 25400, "start": 254.0,
  "end": 266.0, "text": " Sure. So we''re building a vector database that makes it
  very easy to deploy to build and deploy the vector search into production applications.",
  "tokens": [50364, 4894, 13, 407, 321, 434, 2390, 257, 8062, 8149, 300, 1669, 309,
  588, 1858, 281, 7274, 281, 1322, 293, 7274, 264, 8062, 3164, 666, 4265, 5821, 13,
  50964], "temperature": 0.0, "avg_logprob": -0.09147703647613525, "compression_ratio":
  1.4863013698630136, "no_speech_prob": 0.008751542307436466}, {"id": 21, "seek":
  25400, "start": 266.0, "end": 274.0, "text": " This is especially useful for semantic
  search and recommendation systems.", "tokens": [50964, 639, 307, 2318, 4420, 337,
  47982, 3164, 293, 11879, 3652, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09147703647613525,
  "compression_ratio": 1.4863013698630136, "no_speech_prob": 0.008751542307436466},
  {"id": 22, "seek": 27400, "start": 275.0, "end": 289.0, "text": " There are, we
  saw, I should say the founders saw that there''s several ways of doing this to try
  and emulate the big companies like Facebook, Google, Microsoft and Spotify.", "tokens":
  [50414, 821, 366, 11, 321, 1866, 11, 286, 820, 584, 264, 25608, 1866, 300, 456,
  311, 2940, 2098, 295, 884, 341, 281, 853, 293, 45497, 264, 955, 3431, 411, 4384,
  11, 3329, 11, 8116, 293, 29036, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1673540472984314,
  "compression_ratio": 1.2573529411764706, "no_speech_prob": 0.016666073352098465},
  {"id": 23, "seek": 28900, "start": 289.0, "end": 315.0, "text": " They all involved
  a lot of engineering work and a lot of infrastructure work and maintenance to actually
  make it run in production, whether you''re a small startup and have better things
  to focus on or a big tech company and also have better things to focus on, especially
  when supporting your search and recommender systems would involve like a big team
  of engineers.", "tokens": [50364, 814, 439, 3288, 257, 688, 295, 7043, 589, 293,
  257, 688, 295, 6896, 589, 293, 11258, 281, 767, 652, 309, 1190, 294, 4265, 11, 1968,
  291, 434, 257, 1359, 18578, 293, 362, 1101, 721, 281, 1879, 322, 420, 257, 955,
  7553, 2237, 293, 611, 362, 1101, 721, 281, 1879, 322, 11, 2318, 562, 7231, 428,
  3164, 293, 2748, 260, 3652, 576, 9494, 411, 257, 955, 1469, 295, 11955, 13, 51664],
  "temperature": 0.0, "avg_logprob": -0.0883713813677226, "compression_ratio": 1.755980861244019,
  "no_speech_prob": 0.008265172131359577}, {"id": 24, "seek": 31500, "start": 315.0,
  "end": 341.0, "text": " So we recently announced pine cone 2.0 and that''s that''s
  a major release that gets us closer to helping companies deploy this in production.
  So one of the biggest things we''ve heard from users is that to get this in production,
  they need to emulate some of their traditional search features they had before,
  but they''re trying to replace.", "tokens": [50364, 407, 321, 3938, 7548, 15113,
  19749, 568, 13, 15, 293, 300, 311, 300, 311, 257, 2563, 4374, 300, 2170, 505, 4966,
  281, 4315, 3431, 7274, 341, 294, 4265, 13, 407, 472, 295, 264, 3880, 721, 321, 600,
  2198, 490, 5022, 307, 300, 281, 483, 341, 294, 4265, 11, 436, 643, 281, 45497, 512,
  295, 641, 5164, 3164, 4122, 436, 632, 949, 11, 457, 436, 434, 1382, 281, 7406, 13,
  51664], "temperature": 0.0, "avg_logprob": -0.10980924841475813, "compression_ratio":
  1.6018957345971565, "no_speech_prob": 0.0026685791090130806}, {"id": 25, "seek":
  34100, "start": 341.0, "end": 351.0, "text": " And that was specifically filtering.
  They wanted to have some control over the nearest neighbor search results that they
  were getting through pine cone.", "tokens": [50364, 400, 300, 390, 4682, 30822,
  13, 814, 1415, 281, 362, 512, 1969, 670, 264, 23831, 5987, 3164, 3542, 300, 436,
  645, 1242, 807, 15113, 19749, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10829769863801844,
  "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.004197240341454744},
  {"id": 26, "seek": 34100, "start": 351.0, "end": 369.0, "text": " Another thing
  was cost since typically vector search nearest neighbor searches are done in memory
  companies with millions and billions of items, which are the types of companies
  that benefit most from pine cone.", "tokens": [50864, 3996, 551, 390, 2063, 1670,
  5850, 8062, 3164, 23831, 5987, 26701, 366, 1096, 294, 4675, 3431, 365, 6803, 293,
  17375, 295, 4754, 11, 597, 366, 264, 3467, 295, 3431, 300, 5121, 881, 490, 15113,
  19749, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10829769863801844, "compression_ratio":
  1.7333333333333334, "no_speech_prob": 0.004197240341454744}, {"id": 27, "seek":
  36900, "start": 369.0, "end": 375.0, "text": " We''re finding it prohibitively expensive
  to do vector search not just on pine cone, but anywhere.", "tokens": [50364, 492,
  434, 5006, 309, 16015, 2187, 356, 5124, 281, 360, 8062, 3164, 406, 445, 322, 15113,
  19749, 11, 457, 4992, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14237532525692345,
  "compression_ratio": 1.3988095238095237, "no_speech_prob": 0.0013494844315573573},
  {"id": 28, "seek": 36900, "start": 375.0, "end": 387.0, "text": " And so for them,
  the barrier to getting into production wasn''t lack of engineering teams. It was
  like just astronomical cost projections.", "tokens": [50664, 400, 370, 337, 552,
  11, 264, 13357, 281, 1242, 666, 4265, 2067, 380, 5011, 295, 7043, 5491, 13, 467,
  390, 411, 445, 49035, 2063, 32371, 13, 51264], "temperature": 0.0, "avg_logprob":
  -0.14237532525692345, "compression_ratio": 1.3988095238095237, "no_speech_prob":
  0.0013494844315573573}, {"id": 29, "seek": 38700, "start": 387.0, "end": 407.0,
  "text": " And so for that, we are releasing hybrid storage, which stores part of
  the, which basically stores some data on disk and a smaller amount of data in memory,
  which reduces costs up to 10x, reduces infrastructure costs.", "tokens": [50364,
  400, 370, 337, 300, 11, 321, 366, 16327, 13051, 6725, 11, 597, 9512, 644, 295, 264,
  11, 597, 1936, 9512, 512, 1412, 322, 12355, 293, 257, 4356, 2372, 295, 1412, 294,
  4675, 11, 597, 18081, 5497, 493, 281, 1266, 87, 11, 18081, 6896, 5497, 13, 51364],
  "temperature": 0.0, "avg_logprob": -0.14196710197293028, "compression_ratio": 1.5174825174825175,
  "no_speech_prob": 0.035922158509492874}, {"id": 30, "seek": 40700, "start": 407.0,
  "end": 420.0, "text": " And we''re passing that along to users. So it''s going to
  reduce it or manage the infrastructure, but their costs are going to go down as
  well. And there''s some other things like sock to compliance.", "tokens": [50364,
  400, 321, 434, 8437, 300, 2051, 281, 5022, 13, 407, 309, 311, 516, 281, 5407, 309,
  420, 3067, 264, 6896, 11, 457, 641, 5497, 366, 516, 281, 352, 760, 382, 731, 13,
  400, 456, 311, 512, 661, 721, 411, 35302, 281, 15882, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.16702741257687834, "compression_ratio": 1.410071942446043,
  "no_speech_prob": 0.005396661348640919}, {"id": 31, "seek": 42000, "start": 420.0,
  "end": 425.0, "text": " They''re totally new rest API and Python client.", "tokens":
  [50364, 814, 434, 3879, 777, 1472, 9362, 293, 15329, 6423, 13, 50614], "temperature":
  0.0, "avg_logprob": -0.2201005959812599, "compression_ratio": 1.5196078431372548,
  "no_speech_prob": 0.2912045121192932}, {"id": 32, "seek": 42000, "start": 425.0,
  "end": 429.0, "text": " And console.", "tokens": [50614, 400, 11076, 13, 50814],
  "temperature": 0.0, "avg_logprob": -0.2201005959812599, "compression_ratio": 1.5196078431372548,
  "no_speech_prob": 0.2912045121192932}, {"id": 33, "seek": 42000, "start": 429.0,
  "end": 445.0, "text": " And a bunch of other things as well. So, yeah, and there''s
  even more I can''t announce just yet, but we''re our engineering team is growing
  in our development velocities picking up as well. So we''re going to have lots of
  new things to share very soon.", "tokens": [50814, 400, 257, 3840, 295, 661, 721,
  382, 731, 13, 407, 11, 1338, 11, 293, 456, 311, 754, 544, 286, 393, 380, 7478, 445,
  1939, 11, 457, 321, 434, 527, 7043, 1469, 307, 4194, 294, 527, 3250, 7806, 1088,
  8867, 493, 382, 731, 13, 407, 321, 434, 516, 281, 362, 3195, 295, 777, 721, 281,
  2073, 588, 2321, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2201005959812599,
  "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.2912045121192932},
  {"id": 34, "seek": 44500, "start": 445.0, "end": 459.0, "text": " Yeah, that''s
  fantastic. Can''t wait. And then compress on the on the 2.0 release. But I just
  noticed your t-shirt says love the nearest neighbor. Wow.", "tokens": [50364, 865,
  11, 300, 311, 5456, 13, 1664, 380, 1699, 13, 400, 550, 14778, 322, 264, 322, 264,
  568, 13, 15, 4374, 13, 583, 286, 445, 5694, 428, 256, 12, 15313, 1619, 959, 264,
  23831, 5987, 13, 3153, 13, 51064], "temperature": 0.0, "avg_logprob": -0.37235296689547026,
  "compression_ratio": 1.2945205479452055, "no_speech_prob": 0.23936359584331512},
  {"id": 35, "seek": 44500, "start": 459.0, "end": 464.0, "text": " This is so relevant
  to this discussion.", "tokens": [51064, 639, 307, 370, 7340, 281, 341, 5017, 13,
  51314], "temperature": 0.0, "avg_logprob": -0.37235296689547026, "compression_ratio":
  1.2945205479452055, "no_speech_prob": 0.23936359584331512}, {"id": 36, "seek": 46400,
  "start": 464.0, "end": 469.0, "text": " We have lots more of these.", "tokens":
  [50364, 492, 362, 3195, 544, 295, 613, 13, 50614], "temperature": 0.0, "avg_logprob":
  -0.3933400426592146, "compression_ratio": 1.3088235294117647, "no_speech_prob":
  0.4658838212490082}, {"id": 37, "seek": 46400, "start": 469.0, "end": 477.0, "text":
  " Anyone can send me an email. I got pine cone that I know and I''ll get your form
  to fill out to get one.", "tokens": [50614, 14643, 393, 2845, 385, 364, 3796, 13,
  286, 658, 15113, 19749, 300, 286, 458, 293, 286, 603, 483, 428, 1254, 281, 2836,
  484, 281, 483, 472, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3933400426592146,
  "compression_ratio": 1.3088235294117647, "no_speech_prob": 0.4658838212490082},
  {"id": 38, "seek": 46400, "start": 477.0, "end": 481.0, "text": " Oh, thanks. Thanks,
  Greg. I''ll gladly wear it.", "tokens": [51014, 876, 11, 3231, 13, 2561, 11, 11490,
  13, 286, 603, 47307, 3728, 309, 13, 51214], "temperature": 0.0, "avg_logprob": -0.3933400426592146,
  "compression_ratio": 1.3088235294117647, "no_speech_prob": 0.4658838212490082},
  {"id": 39, "seek": 48100, "start": 481.0, "end": 503.0, "text": " So yeah, I mean
  that that covers the value prop behind your product. So I mean the key element for
  me is also that as you said, you''re reducing cost and you know, like you provide
  fully managed, you know, solution to better search. So teams don''t have to kind
  of like run around, figure out some low level things and just get to business. That''s
  great.", "tokens": [50364, 407, 1338, 11, 286, 914, 300, 300, 10538, 264, 2158,
  2365, 2261, 428, 1674, 13, 407, 286, 914, 264, 2141, 4478, 337, 385, 307, 611, 300,
  382, 291, 848, 11, 291, 434, 12245, 2063, 293, 291, 458, 11, 411, 291, 2893, 4498,
  6453, 11, 291, 458, 11, 3827, 281, 1101, 3164, 13, 407, 5491, 500, 380, 362, 281,
  733, 295, 411, 1190, 926, 11, 2573, 484, 512, 2295, 1496, 721, 293, 445, 483, 281,
  1606, 13, 663, 311, 869, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16477466764904203,
  "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.353030264377594}, {"id":
  40, "seek": 50300, "start": 503.0, "end": 518.0, "text": " So the next thing I wanted
  to ask you like more like on the lines of how you know there are different ways
  of implementing vector search right and there are different algorithms. There is
  an end bench marks that will be big and then benchmarks soon as well.", "tokens":
  [50364, 407, 264, 958, 551, 286, 1415, 281, 1029, 291, 411, 544, 411, 322, 264,
  3876, 295, 577, 291, 458, 456, 366, 819, 2098, 295, 18114, 8062, 3164, 558, 293,
  456, 366, 819, 14642, 13, 821, 307, 364, 917, 10638, 10640, 300, 486, 312, 955,
  293, 550, 43751, 2321, 382, 731, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.2738764319621341, "compression_ratio": 1.6787564766839378, "no_speech_prob":
  0.06032079830765724}, {"id": 41, "seek": 50300, "start": 518.0, "end": 524.0, "text":
  " That competition is going for listeners outshare the link as well.", "tokens":
  [51114, 663, 6211, 307, 516, 337, 23274, 484, 2716, 543, 264, 2113, 382, 731, 13,
  51414], "temperature": 0.0, "avg_logprob": -0.2738764319621341, "compression_ratio":
  1.6787564766839378, "no_speech_prob": 0.06032079830765724}, {"id": 42, "seek": 52400,
  "start": 524.0, "end": 552.0, "text": " But what ways did you kind of consider to
  implement your tech. I know some parts of it are proprietary. So maybe you cannot
  share too much detail, but maybe you can share some things give us a clue how you
  do things on kind of like algorithmic side and also like kind of like speak to the
  product that large like, you know, you mentioned, so see two compliance. So it was
  very important for your customers, right.", "tokens": [50364, 583, 437, 2098, 630,
  291, 733, 295, 1949, 281, 4445, 428, 7553, 13, 286, 458, 512, 3166, 295, 309, 366,
  38992, 13, 407, 1310, 291, 2644, 2073, 886, 709, 2607, 11, 457, 1310, 291, 393,
  2073, 512, 721, 976, 505, 257, 13602, 577, 291, 360, 721, 322, 733, 295, 411, 9284,
  299, 1252, 293, 611, 411, 733, 295, 411, 1710, 281, 264, 1674, 300, 2416, 411, 11,
  291, 458, 11, 291, 2835, 11, 370, 536, 732, 15882, 13, 407, 309, 390, 588, 1021,
  337, 428, 4581, 11, 558, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15645420935846144,
  "compression_ratio": 1.699588477366255, "no_speech_prob": 0.03916977718472481},
  {"id": 43, "seek": 55200, "start": 552.0, "end": 557.0, "text": " So that also is
  kind of included in the how part.", "tokens": [50364, 407, 300, 611, 307, 733, 295,
  5556, 294, 264, 577, 644, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12182786729600695,
  "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0021915591787546873},
  {"id": 44, "seek": 55200, "start": 557.0, "end": 574.0, "text": " Yeah, I''ll be
  a little lighter on the technical side because I would rather, I''d rather point
  you to our docs and point people to our docs and some of the articles and examples
  we have, then say something that''s imprecise from a technical standpoint.", "tokens":
  [50614, 865, 11, 286, 603, 312, 257, 707, 11546, 322, 264, 6191, 1252, 570, 286,
  576, 2831, 11, 286, 1116, 2831, 935, 291, 281, 527, 45623, 293, 935, 561, 281, 527,
  45623, 293, 512, 295, 264, 11290, 293, 5110, 321, 362, 11, 550, 584, 746, 300, 311,
  704, 13867, 908, 490, 257, 6191, 15827, 13, 51464], "temperature": 0.0, "avg_logprob":
  -0.12182786729600695, "compression_ratio": 1.5957446808510638, "no_speech_prob":
  0.0021915591787546873}, {"id": 45, "seek": 57400, "start": 574.0, "end": 589.0,
  "text": " Generally that there are sort of three layers, we see three layers in
  the inside of vector search solution or vector database.", "tokens": [50364, 21082,
  300, 456, 366, 1333, 295, 1045, 7914, 11, 321, 536, 1045, 7914, 294, 264, 1854,
  295, 8062, 3164, 3827, 420, 8062, 8149, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.3259212630135672, "compression_ratio": 1.3263157894736841, "no_speech_prob":
  0.004582516849040985}, {"id": 46, "seek": 58900, "start": 589.0, "end": 598.0, "text":
  " The lowest layer is the near neighbor search algorithm like annoy or hnsw.", "tokens":
  [50364, 440, 12437, 4583, 307, 264, 2651, 5987, 3164, 9284, 411, 8759, 420, 276,
  3695, 86, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22692115604877472, "compression_ratio":
  1.6022727272727273, "no_speech_prob": 0.017932498827576637}, {"id": 47, "seek":
  58900, "start": 598.0, "end": 606.0, "text": " Then there''s an index library, which
  contains those algorithms and that''s like face.", "tokens": [50814, 1396, 456,
  311, 364, 8186, 6405, 11, 597, 8306, 729, 14642, 293, 300, 311, 411, 1851, 13, 51214],
  "temperature": 0.0, "avg_logprob": -0.22692115604877472, "compression_ratio": 1.6022727272727273,
  "no_speech_prob": 0.017932498827576637}, {"id": 48, "seek": 58900, "start": 606.0,
  "end": 615.0, "text": " And then there''s a shell around that, which we''re calling
  vector database that provides things like live index updates and", "tokens": [51214,
  400, 550, 456, 311, 257, 8720, 926, 300, 11, 597, 321, 434, 5141, 8062, 8149, 300,
  6417, 721, 411, 1621, 8186, 9205, 293, 51664], "temperature": 0.0, "avg_logprob":
  -0.22692115604877472, "compression_ratio": 1.6022727272727273, "no_speech_prob":
  0.017932498827576637}, {"id": 49, "seek": 61500, "start": 615.0, "end": 624.0, "text":
  " crowd operations on vectors and filtering and metadata storage and things like
  that.", "tokens": [50364, 6919, 7705, 322, 18875, 293, 30822, 293, 26603, 6725,
  293, 721, 411, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.3079881417123895,
  "compression_ratio": 1.3153153153153154, "no_speech_prob": 0.0026434902101755142},
  {"id": 50, "seek": 61500, "start": 624.0, "end": 635.0, "text": " So for the index,
  we, Pankoan does use face for exact search.", "tokens": [50814, 407, 337, 264, 8186,
  11, 321, 11, 430, 657, 78, 282, 775, 764, 1851, 337, 1900, 3164, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.3079881417123895, "compression_ratio": 1.3153153153153154,
  "no_speech_prob": 0.0026434902101755142}, {"id": 51, "seek": 63500, "start": 635.0,
  "end": 650.0, "text": " You can choose if what sort of engine you''re running and
  a proprietary index for approximate search, which is obviously the bulk of use cases
  for us.", "tokens": [50364, 509, 393, 2826, 498, 437, 1333, 295, 2848, 291, 434,
  2614, 293, 257, 38992, 8186, 337, 30874, 3164, 11, 597, 307, 2745, 264, 16139, 295,
  764, 3331, 337, 505, 13, 51114], "temperature": 0.0, "avg_logprob": -0.16239042843089385,
  "compression_ratio": 1.2735042735042734, "no_speech_prob": 0.007020191755145788},
  {"id": 52, "seek": 65000, "start": 650.0, "end": 667.0, "text": " And we thought
  a lot about performance comparisons, maybe even open sourcing that proprietary index
  so we can, so we can be included in an end benchmark.", "tokens": [50364, 400, 321,
  1194, 257, 688, 466, 3389, 33157, 11, 1310, 754, 1269, 11006, 2175, 300, 38992,
  8186, 370, 321, 393, 11, 370, 321, 393, 312, 5556, 294, 364, 917, 18927, 13, 51214],
  "temperature": 0.0, "avg_logprob": -0.17587409700666154, "compression_ratio": 1.3076923076923077,
  "no_speech_prob": 0.013330293819308281}, {"id": 53, "seek": 66700, "start": 667.0,
  "end": 682.0, "text": " While we were thinking about that, we learned from users
  that actually like eaking out slightly more slightly lower latencies or slightly
  higher recall from the index was not really what they were after.", "tokens": [50364,
  3987, 321, 645, 1953, 466, 300, 11, 321, 3264, 490, 5022, 300, 767, 411, 308, 2456,
  484, 4748, 544, 4748, 3126, 4465, 6464, 420, 4748, 2946, 9901, 490, 264, 8186, 390,
  406, 534, 437, 436, 645, 934, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1679224406971651,
  "compression_ratio": 1.6974358974358974, "no_speech_prob": 0.09428898990154266},
  {"id": 54, "seek": 66700, "start": 682.0, "end": 694.0, "text": " That''s not where
  they were stuck. They were stuck on downstream things like horizontal scaling and
  adding features to an index.", "tokens": [51114, 663, 311, 406, 689, 436, 645, 5541,
  13, 814, 645, 5541, 322, 30621, 721, 411, 12750, 21589, 293, 5127, 4122, 281, 364,
  8186, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1679224406971651, "compression_ratio":
  1.6974358974358974, "no_speech_prob": 0.09428898990154266}, {"id": 55, "seek": 69400,
  "start": 694.0, "end": 703.0, "text": " Setting up the infrastructure and managing
  it. And so since learning that and valid data that we focus much more on those things.",
  "tokens": [50364, 21063, 493, 264, 6896, 293, 11642, 309, 13, 400, 370, 1670, 2539,
  300, 293, 7363, 1412, 300, 321, 1879, 709, 544, 322, 729, 721, 13, 50814], "temperature":
  0.0, "avg_logprob": -0.2549197174781977, "compression_ratio": 1.4071428571428573,
  "no_speech_prob": 0.01194772869348526}, {"id": 56, "seek": 69400, "start": 703.0,
  "end": 709.0, "text": " And stayed with a proprietary index for the for approximate
  search.", "tokens": [50814, 400, 9181, 365, 257, 38992, 8186, 337, 264, 337, 30874,
  3164, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2549197174781977, "compression_ratio":
  1.4071428571428573, "no_speech_prob": 0.01194772869348526}, {"id": 57, "seek": 70900,
  "start": 709.0, "end": 726.0, "text": " And sure enough, we find that even people
  who ask a lot about this after they sign up and start using it, they really, you
  know, the solve their use case and they don''t ask us about it again after that
  from some other search or recommendation system to vector search.", "tokens": [50364,
  400, 988, 1547, 11, 321, 915, 300, 754, 561, 567, 1029, 257, 688, 466, 341, 934,
  436, 1465, 493, 293, 722, 1228, 309, 11, 436, 534, 11, 291, 458, 11, 264, 5039,
  641, 764, 1389, 293, 436, 500, 380, 1029, 505, 466, 309, 797, 934, 300, 490, 512,
  661, 3164, 420, 11879, 1185, 281, 8062, 3164, 13, 51214], "temperature": 0.0, "avg_logprob":
  -0.1411050544990288, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.08193209767341614},
  {"id": 58, "seek": 70900, "start": 726.0, "end": 734.0, "text": " And you''re just
  looking for an easy way to run it in production. So that''s the use case just implement
  vector search and production.", "tokens": [51214, 400, 291, 434, 445, 1237, 337,
  364, 1858, 636, 281, 1190, 309, 294, 4265, 13, 407, 300, 311, 264, 764, 1389, 445,
  4445, 8062, 3164, 293, 4265, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1411050544990288,
  "compression_ratio": 1.702127659574468, "no_speech_prob": 0.08193209767341614},
  {"id": 59, "seek": 73400, "start": 734.0, "end": 754.0, "text": " Or a lot of people
  come to us from from like an application side, which is they don''t even know they
  want to use vector search, but they know they want to replace their semantic their
  keyword search with semantic search or they want to implement", "tokens": [50364,
  1610, 257, 688, 295, 561, 808, 281, 505, 490, 490, 411, 364, 3861, 1252, 11, 597,
  307, 436, 500, 380, 754, 458, 436, 528, 281, 764, 8062, 3164, 11, 457, 436, 458,
  436, 528, 281, 7406, 641, 47982, 641, 20428, 3164, 365, 47982, 3164, 420, 436, 528,
  281, 4445, 51364], "temperature": 0.0, "avg_logprob": -0.14257531795861586, "compression_ratio":
  1.6896551724137931, "no_speech_prob": 0.019311560317873955}, {"id": 60, "seek":
  75400, "start": 754.0, "end": 764.0, "text": " image similarity search that will
  work on fuzzy matches or they want to do anomaly detection.", "tokens": [50364,
  3256, 32194, 3164, 300, 486, 589, 322, 34710, 10676, 420, 436, 528, 281, 360, 42737,
  17784, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22999132440445272, "compression_ratio":
  1.4701986754966887, "no_speech_prob": 0.07317647337913513}, {"id": 61, "seek": 75400,
  "start": 764.0, "end": 777.0, "text": " So and or classification and things like
  that. It really is it has as many applications as search information retrieval general.",
  "tokens": [50864, 407, 293, 420, 21538, 293, 721, 411, 300, 13, 467, 534, 307, 309,
  575, 382, 867, 5821, 382, 3164, 1589, 19817, 3337, 2674, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.22999132440445272, "compression_ratio": 1.4701986754966887,
  "no_speech_prob": 0.07317647337913513}, {"id": 62, "seek": 77700, "start": 777.0,
  "end": 783.0, "text": " A lot of people come to us for vectors, excuse me for semantic
  search.", "tokens": [50364, 316, 688, 295, 561, 808, 281, 505, 337, 18875, 11, 8960,
  385, 337, 47982, 3164, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17912373477465485,
  "compression_ratio": 1.6436170212765957, "no_speech_prob": 0.003295383183285594},
  {"id": 63, "seek": 77700, "start": 783.0, "end": 791.0, "text": " So they have their
  embedding models like bird or something like that.", "tokens": [50664, 407, 436,
  362, 641, 12240, 3584, 5245, 411, 5255, 420, 746, 411, 300, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.17912373477465485, "compression_ratio": 1.6436170212765957,
  "no_speech_prob": 0.003295383183285594}, {"id": 64, "seek": 77700, "start": 791.0,
  "end": 803.0, "text": " And they got it working in the lab, the data science team
  got semantic search working using embeddings. Now they''re like, okay, engineering
  team or ML engineering team.", "tokens": [51064, 400, 436, 658, 309, 1364, 294,
  264, 2715, 11, 264, 1412, 3497, 1469, 658, 47982, 3164, 1364, 1228, 12240, 29432,
  13, 823, 436, 434, 411, 11, 1392, 11, 7043, 1469, 420, 21601, 7043, 1469, 13, 51664],
  "temperature": 0.0, "avg_logprob": -0.17912373477465485, "compression_ratio": 1.6436170212765957,
  "no_speech_prob": 0.003295383183285594}, {"id": 65, "seek": 80300, "start": 803.0,
  "end": 811.0, "text": " How do we get this in our product? How do we make this?
  How do we keep latency below 200 milliseconds?", "tokens": [50364, 1012, 360, 321,
  483, 341, 294, 527, 1674, 30, 1012, 360, 321, 652, 341, 30, 1012, 360, 321, 1066,
  27043, 2507, 2331, 34184, 30, 50764], "temperature": 0.0, "avg_logprob": -0.17541929604350656,
  "compression_ratio": 1.5314285714285714, "no_speech_prob": 0.0005434759077616036},
  {"id": 66, "seek": 80300, "start": 811.0, "end": 815.0, "text": " How do we add
  filtering to this to give users control.", "tokens": [50764, 1012, 360, 321, 909,
  30822, 281, 341, 281, 976, 5022, 1969, 13, 50964], "temperature": 0.0, "avg_logprob":
  -0.17541929604350656, "compression_ratio": 1.5314285714285714, "no_speech_prob":
  0.0005434759077616036}, {"id": 67, "seek": 80300, "start": 815.0, "end": 823.0,
  "text": " And the ML engineering team is then goes out and finds like, oh, we can
  do this with something like bank home.", "tokens": [50964, 400, 264, 21601, 7043,
  1469, 307, 550, 1709, 484, 293, 10704, 411, 11, 1954, 11, 321, 393, 360, 341, 365,
  746, 411, 3765, 1280, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17541929604350656,
  "compression_ratio": 1.5314285714285714, "no_speech_prob": 0.0005434759077616036},
  {"id": 68, "seek": 82300, "start": 823.0, "end": 836.0, "text": " So those are those
  are the typical use cases, I would say semantic search, the most common or somebody
  just coming because they''re looking for vector search and regardless of what it''s
  for.", "tokens": [50364, 407, 729, 366, 729, 366, 264, 7476, 764, 3331, 11, 286,
  576, 584, 47982, 3164, 11, 264, 881, 2689, 420, 2618, 445, 1348, 570, 436, 434,
  1237, 337, 8062, 3164, 293, 10060, 295, 437, 309, 311, 337, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.17686812797289217, "compression_ratio": 1.6473214285714286,
  "no_speech_prob": 0.06906095147132874}, {"id": 69, "seek": 82300, "start": 836.0,
  "end": 841.0, "text": " Yeah, yeah, from from our from our perspective for pine
  cone.", "tokens": [51014, 865, 11, 1338, 11, 490, 490, 527, 490, 527, 4585, 337,
  15113, 19749, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17686812797289217,
  "compression_ratio": 1.6473214285714286, "no_speech_prob": 0.06906095147132874},
  {"id": 70, "seek": 82300, "start": 841.0, "end": 852.0, "text": " We don''t care
  what your data is like if it''s in an embedding format, you can index it and then
  you search through it.", "tokens": [51264, 492, 500, 380, 1127, 437, 428, 1412,
  307, 411, 498, 309, 311, 294, 364, 12240, 3584, 7877, 11, 291, 393, 8186, 309, 293,
  550, 291, 3164, 807, 309, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17686812797289217,
  "compression_ratio": 1.6473214285714286, "no_speech_prob": 0.06906095147132874},
  {"id": 71, "seek": 85200, "start": 852.0, "end": 867.0, "text": " Any it works with
  any model, any any, you know, initial data and because we have a rest API, you can
  call it from anywhere. So you can use it in a notebook, you can use it in the backend
  application.", "tokens": [50364, 2639, 309, 1985, 365, 604, 2316, 11, 604, 604,
  11, 291, 458, 11, 5883, 1412, 293, 570, 321, 362, 257, 1472, 9362, 11, 291, 393,
  818, 309, 490, 4992, 13, 407, 291, 393, 764, 309, 294, 257, 21060, 11, 291, 393,
  764, 309, 294, 264, 38087, 3861, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.1936218955300071, "compression_ratio": 1.6846153846153846, "no_speech_prob":
  0.001894969493150711}, {"id": 72, "seek": 85200, "start": 867.0, "end": 870.0, "text":
  " Yeah, we''re seeing a lot of interesting use cases.", "tokens": [51114, 865, 11,
  321, 434, 2577, 257, 688, 295, 1880, 764, 3331, 13, 51264], "temperature": 0.0,
  "avg_logprob": -0.1936218955300071, "compression_ratio": 1.6846153846153846, "no_speech_prob":
  0.001894969493150711}, {"id": 73, "seek": 85200, "start": 870.0, "end": 880.0, "text":
  " Yeah, sounds great. Sounds like a lot actually of use case that you mentioned.
  I mean, obviously it''s search, but then the answer to could also be like data science
  that they want to run.", "tokens": [51264, 865, 11, 3263, 869, 13, 14576, 411, 257,
  688, 767, 295, 764, 1389, 300, 291, 2835, 13, 286, 914, 11, 2745, 309, 311, 3164,
  11, 457, 550, 264, 1867, 281, 727, 611, 312, 411, 1412, 3497, 300, 436, 528, 281,
  1190, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1936218955300071, "compression_ratio":
  1.6846153846153846, "no_speech_prob": 0.001894969493150711}, {"id": 74, "seek":
  88000, "start": 880.0, "end": 892.0, "text": " If you take five, for instance, you
  know, metadata science teams, they run like large scale experiments using the library,
  but like obviously when that''s the data science part, that''s the exploration part.",
  "tokens": [50364, 759, 291, 747, 1732, 11, 337, 5197, 11, 291, 458, 11, 26603, 3497,
  5491, 11, 436, 1190, 411, 2416, 4373, 12050, 1228, 264, 6405, 11, 457, 411, 2745,
  562, 300, 311, 264, 1412, 3497, 644, 11, 300, 311, 264, 16197, 644, 13, 50964],
  "temperature": 0.0, "avg_logprob": -0.21556065877278646, "compression_ratio": 1.6444444444444444,
  "no_speech_prob": 0.01978985033929348}, {"id": 75, "seek": 88000, "start": 892.0,
  "end": 901.0, "text": " But the moment you want to put this out to prod, you''ll
  face a bunch of kind of like low level engineering concerns, like, oh, how do I
  do this? How do you do that?", "tokens": [50964, 583, 264, 1623, 291, 528, 281,
  829, 341, 484, 281, 15792, 11, 291, 603, 1851, 257, 3840, 295, 733, 295, 411, 2295,
  1496, 7043, 7389, 11, 411, 11, 1954, 11, 577, 360, 286, 360, 341, 30, 1012, 360,
  291, 360, 300, 30, 51414], "temperature": 0.0, "avg_logprob": -0.21556065877278646,
  "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.01978985033929348},
  {"id": 76, "seek": 90100, "start": 901.0, "end": 914.0, "text": " Reinventing the
  wheel isn''t ever fun. Well, sometimes it''s fun if it''s kind of like they''d work,
  but if you don''t have time, you kind of like when I''m both faster than obviously
  you will want to use an existing solution for that.", "tokens": [50364, 42116, 2475,
  278, 264, 5589, 1943, 380, 1562, 1019, 13, 1042, 11, 2171, 309, 311, 1019, 498,
  309, 311, 733, 295, 411, 436, 1116, 589, 11, 457, 498, 291, 500, 380, 362, 565,
  11, 291, 733, 295, 411, 562, 286, 478, 1293, 4663, 813, 2745, 291, 486, 528, 281,
  764, 364, 6741, 3827, 337, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.22148522563364315,
  "compression_ratio": 1.6, "no_speech_prob": 0.30482327938079834}, {"id": 77, "seek":
  90100, "start": 914.0, "end": 920.0, "text": " Yeah, we find that, you know, for
  the data science team, they don''t, it''s not their issue.", "tokens": [51014, 865,
  11, 321, 915, 300, 11, 291, 458, 11, 337, 264, 1412, 3497, 1469, 11, 436, 500, 380,
  11, 309, 311, 406, 641, 2734, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22148522563364315,
  "compression_ratio": 1.6, "no_speech_prob": 0.30482327938079834}, {"id": 78, "seek":
  92000, "start": 920.0, "end": 927.0, "text": " They need to develop the model and
  and prove that the method works.", "tokens": [50364, 814, 643, 281, 1499, 264, 2316,
  293, 293, 7081, 300, 264, 3170, 1985, 13, 50714], "temperature": 0.0, "avg_logprob":
  -0.16659649440220425, "compression_ratio": 1.5380952380952382, "no_speech_prob":
  0.040135666728019714}, {"id": 79, "seek": 92000, "start": 927.0, "end": 932.0, "text":
  " It becomes an engineering teams issue or the ML engineering teams issue.", "tokens":
  [50714, 467, 3643, 364, 7043, 5491, 2734, 420, 264, 21601, 7043, 5491, 2734, 13,
  50964], "temperature": 0.0, "avg_logprob": -0.16659649440220425, "compression_ratio":
  1.5380952380952382, "no_speech_prob": 0.040135666728019714}, {"id": 80, "seek":
  92000, "start": 932.0, "end": 948.0, "text": " And yeah, they''re often not exactly
  lacking things to do. So, some organizations are all about like focusing on the
  core product and trying to use managed services wherever possible.", "tokens": [50964,
  400, 1338, 11, 436, 434, 2049, 406, 2293, 20889, 721, 281, 360, 13, 407, 11, 512,
  6150, 366, 439, 466, 411, 8416, 322, 264, 4965, 1674, 293, 1382, 281, 764, 6453,
  3328, 8660, 1944, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16659649440220425,
  "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.040135666728019714},
  {"id": 81, "seek": 94800, "start": 948.0, "end": 964.0, "text": " Others like to
  develop things in house and prefer to take open source as much as possible. So I
  think it depends on your, you know, how you prioritize your focus and what kind
  of, you know, what''s your engineering culture at the company?", "tokens": [50364,
  20277, 411, 281, 1499, 721, 294, 1782, 293, 4382, 281, 747, 1269, 4009, 382, 709,
  382, 1944, 13, 407, 286, 519, 309, 5946, 322, 428, 11, 291, 458, 11, 577, 291, 25164,
  428, 1879, 293, 437, 733, 295, 11, 291, 458, 11, 437, 311, 428, 7043, 3713, 412,
  264, 2237, 30, 51164], "temperature": 0.0, "avg_logprob": -0.19071258293403373,
  "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.06385955214500427},
  {"id": 82, "seek": 94800, "start": 964.0, "end": 976.0, "text": " Yeah, absolutely.
  And sounds like you also address the elements of like, so see to and I believe you
  also will have GPR covered at some point already covered.", "tokens": [51164, 865,
  11, 3122, 13, 400, 3263, 411, 291, 611, 2985, 264, 4959, 295, 411, 11, 370, 536,
  281, 293, 286, 1697, 291, 611, 486, 362, 460, 15958, 5343, 412, 512, 935, 1217,
  5343, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19071258293403373, "compression_ratio":
  1.5776892430278884, "no_speech_prob": 0.06385955214500427}, {"id": 83, "seek": 97600,
  "start": 976.0, "end": 999.0, "text": " So we say we''re GDPR friendly, which means
  there''s no, there''s no official certification you can get for being GDPR, you
  can just be following the regulations and able to make the proper disclosures and
  able to act on requests for deletion and things like that.", "tokens": [50364, 407,
  321, 584, 321, 434, 460, 35, 15958, 9208, 11, 597, 1355, 456, 311, 572, 11, 456,
  311, 572, 4783, 21775, 291, 393, 483, 337, 885, 460, 35, 15958, 11, 291, 393, 445,
  312, 3480, 264, 12563, 293, 1075, 281, 652, 264, 2296, 2983, 9389, 1303, 293, 1075,
  281, 605, 322, 12475, 337, 1103, 302, 313, 293, 721, 411, 300, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.1907348192655123, "compression_ratio": 1.5174418604651163,
  "no_speech_prob": 0.002655997173860669}, {"id": 84, "seek": 99900, "start": 999.0,
  "end": 1014.0, "text": " These are the types of things like the security aspects.
  It''s another thing that a data science team might not force to when they''re developing
  like a factor search solutions to some application.", "tokens": [50364, 1981, 366,
  264, 3467, 295, 721, 411, 264, 3825, 7270, 13, 467, 311, 1071, 551, 300, 257, 1412,
  3497, 1469, 1062, 406, 3464, 281, 562, 436, 434, 6416, 411, 257, 5952, 3164, 6547,
  281, 512, 3861, 13, 51114], "temperature": 0.0, "avg_logprob": -0.16578189257917733,
  "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.07403605431318283},
  {"id": 85, "seek": 99900, "start": 1014.0, "end": 1020.0, "text": " But when it
  goes engineering when you start talking about getting it into production.", "tokens":
  [51114, 583, 562, 309, 1709, 7043, 562, 291, 722, 1417, 466, 1242, 309, 666, 4265,
  13, 51414], "temperature": 0.0, "avg_logprob": -0.16578189257917733, "compression_ratio":
  1.5271739130434783, "no_speech_prob": 0.07403605431318283}, {"id": 86, "seek": 102000,
  "start": 1020.0, "end": 1029.0, "text": " And depending on the company, you''re,
  yeah, you start, you know, all these things come up. Does it meet our security,
  does it pass our security review?", "tokens": [50364, 400, 5413, 322, 264, 2237,
  11, 291, 434, 11, 1338, 11, 291, 722, 11, 291, 458, 11, 439, 613, 721, 808, 493,
  13, 4402, 309, 1677, 527, 3825, 11, 775, 309, 1320, 527, 3825, 3131, 30, 50814],
  "temperature": 0.0, "avg_logprob": -0.18620049081197598, "compression_ratio": 1.6865671641791045,
  "no_speech_prob": 0.16128839552402496}, {"id": 87, "seek": 102000, "start": 1029.0,
  "end": 1043.0, "text": " Does it pass our reliability requirements? Who''s going
  to be on call if this thing goes down like all these things come up and we worry
  about those things so that the users don''t have to.", "tokens": [50814, 4402, 309,
  1320, 527, 24550, 7728, 30, 2102, 311, 516, 281, 312, 322, 818, 498, 341, 551, 1709,
  760, 411, 439, 613, 721, 808, 493, 293, 321, 3292, 466, 729, 721, 370, 300, 264,
  5022, 500, 380, 362, 281, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18620049081197598,
  "compression_ratio": 1.6865671641791045, "no_speech_prob": 0.16128839552402496},
  {"id": 88, "seek": 104300, "start": 1043.0, "end": 1050.0, "text": " Yeah, that''s
  a big benefit like to the users again to focus on what matters to them.", "tokens":
  [50364, 865, 11, 300, 311, 257, 955, 5121, 411, 281, 264, 5022, 797, 281, 1879,
  322, 437, 7001, 281, 552, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11077933060495478,
  "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.19690246880054474},
  {"id": 89, "seek": 104300, "start": 1050.0, "end": 1055.0, "text": " And by the
  way, I don''t want to just so this doesn''t come off as like promotional.", "tokens":
  [50714, 400, 538, 264, 636, 11, 286, 500, 380, 528, 281, 445, 370, 341, 1177, 380,
  808, 766, 382, 411, 41790, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11077933060495478,
  "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.19690246880054474},
  {"id": 90, "seek": 104300, "start": 1055.0, "end": 1072.0, "text": " Anyone listening
  to this can treat this as just heads up about what you should think about if you
  want to get vector search in your production, even if you''re using some other solution,
  like these are things you should plan for.", "tokens": [50964, 14643, 4764, 281,
  341, 393, 2387, 341, 382, 445, 8050, 493, 466, 437, 291, 820, 519, 466, 498, 291,
  528, 281, 483, 8062, 3164, 294, 428, 4265, 11, 754, 498, 291, 434, 1228, 512, 661,
  3827, 11, 411, 613, 366, 721, 291, 820, 1393, 337, 13, 51814], "temperature": 0.0,
  "avg_logprob": -0.11077933060495478, "compression_ratio": 1.6923076923076923, "no_speech_prob":
  0.19690246880054474}, {"id": 91, "seek": 107200, "start": 1072.0, "end": 1076.0,
  "text": " And start thinking about it and making.", "tokens": [50364, 400, 722,
  1953, 466, 309, 293, 1455, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23016932203962998,
  "compression_ratio": 1.4010695187165776, "no_speech_prob": 0.04371524974703789},
  {"id": 92, "seek": 107200, "start": 1076.0, "end": 1078.0, "text": " Leaving time
  to do.", "tokens": [50564, 41253, 565, 281, 360, 13, 50664], "temperature": 0.0,
  "avg_logprob": -0.23016932203962998, "compression_ratio": 1.4010695187165776, "no_speech_prob":
  0.04371524974703789}, {"id": 93, "seek": 107200, "start": 1078.0, "end": 1085.0,
  "text": " Yeah, absolutely. You don''t want to be caught by surprise in those, those
  items for sure.", "tokens": [50664, 865, 11, 3122, 13, 509, 500, 380, 528, 281,
  312, 5415, 538, 6365, 294, 729, 11, 729, 4754, 337, 988, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.23016932203962998, "compression_ratio": 1.4010695187165776,
  "no_speech_prob": 0.04371524974703789}, {"id": 94, "seek": 107200, "start": 1085.0,
  "end": 1093.0, "text": " Yeah, that''s awesome. By the way, I remember that you
  guys also made a bunch of blog posts on like FICE and LSH.", "tokens": [51014, 865,
  11, 300, 311, 3476, 13, 3146, 264, 636, 11, 286, 1604, 300, 291, 1074, 611, 1027,
  257, 3840, 295, 6968, 12300, 322, 411, 479, 13663, 293, 441, 17308, 13, 51414],
  "temperature": 0.0, "avg_logprob": -0.23016932203962998, "compression_ratio": 1.4010695187165776,
  "no_speech_prob": 0.04371524974703789}, {"id": 95, "seek": 109300, "start": 1093.0,
  "end": 1103.0, "text": " I mean, I really like the way you did it. You know, it''s
  almost look what looks like a comic book, you know, you know, get, get, get deep
  with, with these things.", "tokens": [50364, 286, 914, 11, 286, 534, 411, 264, 636,
  291, 630, 309, 13, 509, 458, 11, 309, 311, 1920, 574, 437, 1542, 411, 257, 13900,
  1446, 11, 291, 458, 11, 291, 458, 11, 483, 11, 483, 11, 483, 2452, 365, 11, 365,
  613, 721, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22663739832436167, "compression_ratio":
  1.5977011494252873, "no_speech_prob": 0.2388550490140915}, {"id": 96, "seek": 109300,
  "start": 1103.0, "end": 1110.0, "text": " And I think you also shared the source
  code, like some notebooks. Is that right? Is that.", "tokens": [50864, 400, 286,
  519, 291, 611, 5507, 264, 4009, 3089, 11, 411, 512, 43782, 13, 1119, 300, 558, 30,
  1119, 300, 13, 51214], "temperature": 0.0, "avg_logprob": -0.22663739832436167,
  "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.2388550490140915},
  {"id": 97, "seek": 109300, "start": 1110.0, "end": 1115.0, "text": " Yeah, we, we,
  we publish.", "tokens": [51214, 865, 11, 321, 11, 321, 11, 321, 11374, 13, 51464],
  "temperature": 0.0, "avg_logprob": -0.22663739832436167, "compression_ratio": 1.5977011494252873,
  "no_speech_prob": 0.2388550490140915}, {"id": 98, "seek": 111500, "start": 1115.0,
  "end": 1121.0, "text": " And articles on vector search on face on.", "tokens": [50364,
  400, 11290, 322, 8062, 3164, 322, 1851, 322, 13, 50664], "temperature": 0.0, "avg_logprob":
  -0.26717655694306786, "compression_ratio": 1.5027322404371584, "no_speech_prob":
  0.23333612084388733}, {"id": 99, "seek": 111500, "start": 1121.0, "end": 1128.0,
  "text": " Semantic search different techniques and things like that. A lot of them
  are done by the very talented.", "tokens": [50664, 14421, 7128, 3164, 819, 7512,
  293, 721, 411, 300, 13, 316, 688, 295, 552, 366, 1096, 538, 264, 588, 13467, 13,
  51014], "temperature": 0.0, "avg_logprob": -0.26717655694306786, "compression_ratio":
  1.5027322404371584, "no_speech_prob": 0.23333612084388733}, {"id": 100, "seek":
  111500, "start": 1128.0, "end": 1141.0, "text": " James breaks, I should give him
  a shout out. We have a new one today about the index composite indexes and index
  factory in face.", "tokens": [51014, 5678, 9857, 11, 286, 820, 976, 796, 257, 8043,
  484, 13, 492, 362, 257, 777, 472, 965, 466, 264, 8186, 25557, 8186, 279, 293, 8186,
  9265, 294, 1851, 13, 51664], "temperature": 0.0, "avg_logprob": -0.26717655694306786,
  "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.23333612084388733},
  {"id": 101, "seek": 114100, "start": 1141.0, "end": 1146.0, "text": " We share code
  snippets and we have example notebooks for all of them.", "tokens": [50364, 492,
  2073, 3089, 35623, 1385, 293, 321, 362, 1365, 43782, 337, 439, 295, 552, 13, 50614],
  "temperature": 0.0, "avg_logprob": -0.14504288543354382, "compression_ratio": 1.6088888888888888,
  "no_speech_prob": 0.05774102360010147}, {"id": 102, "seek": 114100, "start": 1146.0,
  "end": 1151.0, "text": " And yeah, we''re very happy to see people like them.",
  "tokens": [50614, 400, 1338, 11, 321, 434, 588, 2055, 281, 536, 561, 411, 552, 13,
  50864], "temperature": 0.0, "avg_logprob": -0.14504288543354382, "compression_ratio":
  1.6088888888888888, "no_speech_prob": 0.05774102360010147}, {"id": 103, "seek":
  114100, "start": 1151.0, "end": 1161.0, "text": " Even people who are not familiar
  with vector search will see it and it peaks their interest because engineers like
  to see how things work and learn new things.", "tokens": [50864, 2754, 561, 567,
  366, 406, 4963, 365, 8062, 3164, 486, 536, 309, 293, 309, 26897, 641, 1179, 570,
  11955, 411, 281, 536, 577, 721, 589, 293, 1466, 777, 721, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.14504288543354382, "compression_ratio": 1.6088888888888888,
  "no_speech_prob": 0.05774102360010147}, {"id": 104, "seek": 114100, "start": 1161.0,
  "end": 1167.0, "text": " And that''s our goal. It''s some of them have almost nothing
  to do with pine cone.", "tokens": [51364, 400, 300, 311, 527, 3387, 13, 467, 311,
  512, 295, 552, 362, 1920, 1825, 281, 360, 365, 15113, 19749, 13, 51664], "temperature":
  0.0, "avg_logprob": -0.14504288543354382, "compression_ratio": 1.6088888888888888,
  "no_speech_prob": 0.05774102360010147}, {"id": 105, "seek": 116700, "start": 1167.0,
  "end": 1172.0, "text": " And we have more people to learn about.", "tokens": [50364,
  400, 321, 362, 544, 561, 281, 1466, 466, 13, 50614], "temperature": 0.0, "avg_logprob":
  -0.245787732741412, "compression_ratio": 1.5753968253968254, "no_speech_prob": 0.020519956946372986},
  {"id": 106, "seek": 116700, "start": 1172.0, "end": 1175.0, "text": " Vector search
  to.", "tokens": [50614, 691, 20814, 3164, 281, 13, 50764], "temperature": 0.0, "avg_logprob":
  -0.245787732741412, "compression_ratio": 1.5753968253968254, "no_speech_prob": 0.020519956946372986},
  {"id": 107, "seek": 116700, "start": 1175.0, "end": 1182.0, "text": " Realize that
  they can use vector search to replace their to improve the current applications
  and.", "tokens": [50764, 8467, 1125, 300, 436, 393, 764, 8062, 3164, 281, 7406,
  641, 281, 3470, 264, 2190, 5821, 293, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.245787732741412, "compression_ratio": 1.5753968253968254, "no_speech_prob": 0.020519956946372986},
  {"id": 108, "seek": 116700, "start": 1182.0, "end": 1187.0, "text": " If we succeed
  in that, I think it''ll certainly help us, but really everyone in the.", "tokens":
  [51114, 759, 321, 7754, 294, 300, 11, 286, 519, 309, 603, 3297, 854, 505, 11, 457,
  534, 1518, 294, 264, 13, 51364], "temperature": 0.0, "avg_logprob": -0.245787732741412,
  "compression_ratio": 1.5753968253968254, "no_speech_prob": 0.020519956946372986},
  {"id": 109, "seek": 116700, "start": 1187.0, "end": 1188.0, "text": " In this space.",
  "tokens": [51364, 682, 341, 1901, 13, 51414], "temperature": 0.0, "avg_logprob":
  -0.245787732741412, "compression_ratio": 1.5753968253968254, "no_speech_prob": 0.020519956946372986},
  {"id": 110, "seek": 116700, "start": 1188.0, "end": 1195.0, "text": " Yeah, I mean,
  absolutely. Those looks like our jam, you know, people are reading, citing and kind
  of discussing on Slack and things like that.", "tokens": [51414, 865, 11, 286, 914,
  11, 3122, 13, 3950, 1542, 411, 527, 7872, 11, 291, 458, 11, 561, 366, 3760, 11,
  48749, 293, 733, 295, 10850, 322, 37211, 293, 721, 411, 300, 13, 51764], "temperature":
  0.0, "avg_logprob": -0.245787732741412, "compression_ratio": 1.5753968253968254,
  "no_speech_prob": 0.020519956946372986}, {"id": 111, "seek": 119500, "start": 1195.0,
  "end": 1207.0, "text": " And yeah, it sounds like you guys are also kind of willing
  to share your knowledge with the community, even like beyond kind of share, you
  know, customer interaction and so on. Right.", "tokens": [50364, 400, 1338, 11,
  309, 3263, 411, 291, 1074, 366, 611, 733, 295, 4950, 281, 2073, 428, 3601, 365,
  264, 1768, 11, 754, 411, 4399, 733, 295, 2073, 11, 291, 458, 11, 5474, 9285, 293,
  370, 322, 13, 1779, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15861816155283073,
  "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.01606069877743721},
  {"id": 112, "seek": 119500, "start": 1207.0, "end": 1209.0, "text": " So that''s
  that''s awesome.", "tokens": [50964, 407, 300, 311, 300, 311, 3476, 13, 51064],
  "temperature": 0.0, "avg_logprob": -0.15861816155283073, "compression_ratio": 1.5051020408163265,
  "no_speech_prob": 0.01606069877743721}, {"id": 113, "seek": 119500, "start": 1209.0,
  "end": 1210.0, "text": " Yeah.", "tokens": [51064, 865, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.15861816155283073, "compression_ratio": 1.5051020408163265,
  "no_speech_prob": 0.01606069877743721}, {"id": 114, "seek": 119500, "start": 1210.0,
  "end": 1216.0, "text": " I think we are moving slowly to the third section of our
  podcast, which is why.", "tokens": [51114, 286, 519, 321, 366, 2684, 5692, 281,
  264, 2636, 3541, 295, 527, 7367, 11, 597, 307, 983, 13, 51414], "temperature": 0.0,
  "avg_logprob": -0.15861816155283073, "compression_ratio": 1.5051020408163265, "no_speech_prob":
  0.01606069877743721}, {"id": 115, "seek": 121600, "start": 1216.0, "end": 1222.0,
  "text": " And I think I know it''s a little bit more philosophical kind of stance
  and what you do.", "tokens": [50364, 400, 286, 519, 286, 458, 309, 311, 257, 707,
  857, 544, 25066, 733, 295, 21033, 293, 437, 291, 360, 13, 50664], "temperature":
  0.0, "avg_logprob": -0.16848244565598508, "compression_ratio": 1.6017316017316017,
  "no_speech_prob": 0.11230132728815079}, {"id": 116, "seek": 121600, "start": 1222.0,
  "end": 1229.0, "text": " And kind of like how you do it. I don''t know if you''ve
  been reflecting on your journey. I know you said you joined last year.", "tokens":
  [50664, 400, 733, 295, 411, 577, 291, 360, 309, 13, 286, 500, 380, 458, 498, 291,
  600, 668, 23543, 322, 428, 4671, 13, 286, 458, 291, 848, 291, 6869, 1036, 1064,
  13, 51014], "temperature": 0.0, "avg_logprob": -0.16848244565598508, "compression_ratio":
  1.6017316017316017, "no_speech_prob": 0.11230132728815079}, {"id": 117, "seek":
  121600, "start": 1229.0, "end": 1231.0, "text": " Join bank on last year.", "tokens":
  [51014, 19642, 3765, 322, 1036, 1064, 13, 51114], "temperature": 0.0, "avg_logprob":
  -0.16848244565598508, "compression_ratio": 1.6017316017316017, "no_speech_prob":
  0.11230132728815079}, {"id": 118, "seek": 121600, "start": 1231.0, "end": 1239.0,
  "text": " But I guess I''ll start off by just asking you what motivates you to be
  part of vector search development and this community as much.", "tokens": [51114,
  583, 286, 2041, 286, 603, 722, 766, 538, 445, 3365, 291, 437, 42569, 291, 281, 312,
  644, 295, 8062, 3164, 3250, 293, 341, 1768, 382, 709, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.16848244565598508, "compression_ratio": 1.6017316017316017,
  "no_speech_prob": 0.11230132728815079}, {"id": 119, "seek": 123900, "start": 1239.0,
  "end": 1256.0, "text": " Me personally, I''ve worked with 40, 40 startups when I
  was consulting over 40 startups. And when I met, you know, the founder of pine cone.",
  "tokens": [50364, 1923, 5665, 11, 286, 600, 2732, 365, 3356, 11, 3356, 28041, 562,
  286, 390, 23682, 670, 3356, 28041, 13, 400, 562, 286, 1131, 11, 291, 458, 11, 264,
  14917, 295, 15113, 19749, 13, 51214], "temperature": 0.0, "avg_logprob": -0.18929634094238282,
  "compression_ratio": 1.463855421686747, "no_speech_prob": 0.005013223737478256},
  {"id": 120, "seek": 123900, "start": 1256.0, "end": 1265.0, "text": " And learned
  about the product and about the space. I saw a familiar pattern, which caught my
  attention.", "tokens": [51214, 400, 3264, 466, 264, 1674, 293, 466, 264, 1901, 13,
  286, 1866, 257, 4963, 5102, 11, 597, 5415, 452, 3202, 13, 51664], "temperature":
  0.0, "avg_logprob": -0.18929634094238282, "compression_ratio": 1.463855421686747,
  "no_speech_prob": 0.005013223737478256}, {"id": 121, "seek": 126500, "start": 1265.0,
  "end": 1270.0, "text": " And the familiar pattern was from 2015.", "tokens": [50364,
  400, 264, 4963, 5102, 390, 490, 7546, 13, 50614], "temperature": 0.0, "avg_logprob":
  -0.3358294343295163, "compression_ratio": 1.4228855721393034, "no_speech_prob":
  0.042271923273801804}, {"id": 122, "seek": 126500, "start": 1270.0, "end": 1282.0,
  "text": " Six years ago now, almost seven when I started working with the time,
  very small company called Domino Data Lab, which.", "tokens": [50614, 11678, 924,
  2057, 586, 11, 1920, 3407, 562, 286, 1409, 1364, 365, 264, 565, 11, 588, 1359, 2237,
  1219, 16674, 2982, 11888, 10137, 11, 597, 13, 51214], "temperature": 0.0, "avg_logprob":
  -0.3358294343295163, "compression_ratio": 1.4228855721393034, "no_speech_prob":
  0.042271923273801804}, {"id": 123, "seek": 126500, "start": 1282.0, "end": 1290.0,
  "text": " It''s an ML ops platform at the time, we call that a data science platform.
  It''s used by over 20% or the fortune 500 companies.", "tokens": [51214, 467, 311,
  364, 21601, 44663, 3663, 412, 264, 565, 11, 321, 818, 300, 257, 1412, 3497, 3663,
  13, 467, 311, 1143, 538, 670, 945, 4, 420, 264, 16531, 5923, 3431, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.3358294343295163, "compression_ratio": 1.4228855721393034,
  "no_speech_prob": 0.042271923273801804}, {"id": 124, "seek": 129000, "start": 1290.0,
  "end": 1296.0, "text": " And the time was a small team and it was a product for
  data scientists, but like nobody knew exactly what is a data scientist.", "tokens":
  [50364, 400, 264, 565, 390, 257, 1359, 1469, 293, 309, 390, 257, 1674, 337, 1412,
  7708, 11, 457, 411, 5079, 2586, 2293, 437, 307, 257, 1412, 12662, 13, 50664], "temperature":
  0.0, "avg_logprob": -0.2033338184598126, "compression_ratio": 1.6329787234042554,
  "no_speech_prob": 0.04448205605149269}, {"id": 125, "seek": 129000, "start": 1296.0,
  "end": 1302.0, "text": " Few people called themselves that even if they were doing
  data science work.", "tokens": [50664, 33468, 561, 1219, 2969, 300, 754, 498, 436,
  645, 884, 1412, 3497, 589, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2033338184598126,
  "compression_ratio": 1.6329787234042554, "no_speech_prob": 0.04448205605149269},
  {"id": 126, "seek": 129000, "start": 1302.0, "end": 1307.0, "text": " A lot of work
  data science work was done on just people''s laptops.", "tokens": [50964, 316, 688,
  295, 589, 1412, 3497, 589, 390, 1096, 322, 445, 561, 311, 27642, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.2033338184598126, "compression_ratio": 1.6329787234042554,
  "no_speech_prob": 0.04448205605149269}, {"id": 127, "seek": 129000, "start": 1307.0,
  "end": 1310.0, "text": " And there''s no.", "tokens": [51214, 400, 456, 311, 572,
  13, 51364], "temperature": 0.0, "avg_logprob": -0.2033338184598126, "compression_ratio":
  1.6329787234042554, "no_speech_prob": 0.04448205605149269}, {"id": 128, "seek":
  129000, "start": 1310.0, "end": 1314.0, "text": " It was a very young.", "tokens":
  [51364, 467, 390, 257, 588, 2037, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.2033338184598126, "compression_ratio": 1.6329787234042554, "no_speech_prob":
  0.04448205605149269}, {"id": 129, "seek": 131400, "start": 1314.0, "end": 1317.0,
  "text": " Area, let''s say.", "tokens": [50364, 19405, 11, 718, 311, 584, 13, 50514],
  "temperature": 0.0, "avg_logprob": -0.19811121155233943, "compression_ratio": 1.4736842105263157,
  "no_speech_prob": 0.005171893164515495}, {"id": 130, "seek": 131400, "start": 1317.0,
  "end": 1321.0, "text": " Not not quite mature. There''s not a tooling for it and
  so on.", "tokens": [50514, 1726, 406, 1596, 14442, 13, 821, 311, 406, 257, 46593,
  337, 309, 293, 370, 322, 13, 50714], "temperature": 0.0, "avg_logprob": -0.19811121155233943,
  "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.005171893164515495},
  {"id": 131, "seek": 131400, "start": 1321.0, "end": 1329.0, "text": " And over time,
  over a few years, it became, of course, data science became.", "tokens": [50714,
  400, 670, 565, 11, 670, 257, 1326, 924, 11, 309, 3062, 11, 295, 1164, 11, 1412,
  3497, 3062, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19811121155233943,
  "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.005171893164515495},
  {"id": 132, "seek": 131400, "start": 1329.0, "end": 1338.0, "text": " A core function
  in many companies, like just like engineering and marketing and customer support.",
  "tokens": [51114, 316, 4965, 2445, 294, 867, 3431, 11, 411, 445, 411, 7043, 293,
  6370, 293, 5474, 1406, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19811121155233943,
  "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.005171893164515495},
  {"id": 133, "seek": 133800, "start": 1338.0, "end": 1346.0, "text": " And as that
  happened, like having the right tooling for that function.", "tokens": [50364, 400,
  382, 300, 2011, 11, 411, 1419, 264, 558, 46593, 337, 300, 2445, 13, 50764], "temperature":
  0.0, "avg_logprob": -0.17683476209640503, "compression_ratio": 1.5135135135135136,
  "no_speech_prob": 0.018351173028349876}, {"id": 134, "seek": 133800, "start": 1346.0,
  "end": 1357.0, "text": " And kind of maturing the capabilities and making sure it''s
  everything data sciences run can run in production securely and reliably and things
  like that.", "tokens": [50764, 400, 733, 295, 3803, 1345, 264, 10862, 293, 1455,
  988, 309, 311, 1203, 1412, 17677, 1190, 393, 1190, 294, 4265, 38348, 293, 49927,
  293, 721, 411, 300, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17683476209640503,
  "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.018351173028349876},
  {"id": 135, "seek": 135700, "start": 1357.0, "end": 1363.0, "text": " And so it
  became more important. Of course, the companies that were.", "tokens": [50364, 400,
  370, 309, 3062, 544, 1021, 13, 2720, 1164, 11, 264, 3431, 300, 645, 13, 50664],
  "temperature": 0.0, "avg_logprob": -0.2544973190516642, "compression_ratio": 1.5454545454545454,
  "no_speech_prob": 0.3018932342529297}, {"id": 136, "seek": 135700, "start": 1363.0,
  "end": 1369.0, "text": " Solving those things were growing with that demand.", "tokens":
  [50664, 7026, 798, 729, 721, 645, 4194, 365, 300, 4733, 13, 50964], "temperature":
  0.0, "avg_logprob": -0.2544973190516642, "compression_ratio": 1.5454545454545454,
  "no_speech_prob": 0.3018932342529297}, {"id": 137, "seek": 135700, "start": 1369.0,
  "end": 1375.0, "text": " And so I wanted to be a part of that journey, that kind
  of journey again.", "tokens": [50964, 400, 370, 286, 1415, 281, 312, 257, 644, 295,
  300, 4671, 11, 300, 733, 295, 4671, 797, 13, 51264], "temperature": 0.0, "avg_logprob":
  -0.2544973190516642, "compression_ratio": 1.5454545454545454, "no_speech_prob":
  0.3018932342529297}, {"id": 138, "seek": 135700, "start": 1375.0, "end": 1382.0,
  "text": " And again, I saw in Pinecon, I saw product that is pretty early in the
  space.", "tokens": [51264, 400, 797, 11, 286, 1866, 294, 33531, 1671, 11, 286, 1866,
  1674, 300, 307, 1238, 2440, 294, 264, 1901, 13, 51614], "temperature": 0.0, "avg_logprob":
  -0.2544973190516642, "compression_ratio": 1.5454545454545454, "no_speech_prob":
  0.3018932342529297}, {"id": 139, "seek": 138200, "start": 1382.0, "end": 1386.0,
  "text": " And I saw a lot of data based concept and.", "tokens": [50364, 400, 286,
  1866, 257, 688, 295, 1412, 2361, 3410, 293, 13, 50564], "temperature": 0.0, "avg_logprob":
  -0.2833099365234375, "compression_ratio": 1.6440677966101696, "no_speech_prob":
  0.0330592580139637}, {"id": 140, "seek": 138200, "start": 1386.0, "end": 1390.0,
  "text": " We had to spend a lot of time explaining to people what that means they
  weren''t getting it.", "tokens": [50564, 492, 632, 281, 3496, 257, 688, 295, 565,
  13468, 281, 561, 437, 300, 1355, 436, 4999, 380, 1242, 309, 13, 50764], "temperature":
  0.0, "avg_logprob": -0.2833099365234375, "compression_ratio": 1.6440677966101696,
  "no_speech_prob": 0.0330592580139637}, {"id": 141, "seek": 138200, "start": 1390.0,
  "end": 1395.0, "text": " On the user side, you see many, many engineers doing ML
  engineering work.", "tokens": [50764, 1282, 264, 4195, 1252, 11, 291, 536, 867,
  11, 867, 11955, 884, 21601, 7043, 589, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.2833099365234375, "compression_ratio": 1.6440677966101696, "no_speech_prob":
  0.0330592580139637}, {"id": 142, "seek": 138200, "start": 1395.0, "end": 1398.0,
  "text": " We don''t yet call themselves ML engineers.", "tokens": [51014, 492, 500,
  380, 1939, 818, 2969, 21601, 11955, 13, 51164], "temperature": 0.0, "avg_logprob":
  -0.2833099365234375, "compression_ratio": 1.6440677966101696, "no_speech_prob":
  0.0330592580139637}, {"id": 143, "seek": 138200, "start": 1398.0, "end": 1400.0,
  "text": " They''re still titled the software engineers.", "tokens": [51164, 814,
  434, 920, 19841, 264, 4722, 11955, 13, 51264], "temperature": 0.0, "avg_logprob":
  -0.2833099365234375, "compression_ratio": 1.6440677966101696, "no_speech_prob":
  0.0330592580139637}, {"id": 144, "seek": 138200, "start": 1400.0, "end": 1406.0,
  "text": " Or they might get data scientists, but they''re now working on like production
  applications.", "tokens": [51264, 1610, 436, 1062, 483, 1412, 7708, 11, 457, 436,
  434, 586, 1364, 322, 411, 4265, 5821, 13, 51564], "temperature": 0.0, "avg_logprob":
  -0.2833099365234375, "compression_ratio": 1.6440677966101696, "no_speech_prob":
  0.0330592580139637}, {"id": 145, "seek": 140600, "start": 1406.0, "end": 1416.0,
  "text": " And also we see that companies are struggling as they as they want to
  take vector search out of the lab and into production production applications.",
  "tokens": [50364, 400, 611, 321, 536, 300, 3431, 366, 9314, 382, 436, 382, 436,
  528, 281, 747, 8062, 3164, 484, 295, 264, 2715, 293, 666, 4265, 4265, 5821, 13,
  50864], "temperature": 0.0, "avg_logprob": -0.16826950537191854, "compression_ratio":
  1.5728155339805825, "no_speech_prob": 0.0004191641346551478}, {"id": 146, "seek":
  140600, "start": 1416.0, "end": 1420.0, "text": " They''re running up against the
  same challenges like the technology they have.", "tokens": [50864, 814, 434, 2614,
  493, 1970, 264, 912, 4759, 411, 264, 2899, 436, 362, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.16826950537191854, "compression_ratio": 1.5728155339805825,
  "no_speech_prob": 0.0004191641346551478}, {"id": 147, "seek": 140600, "start": 1420.0,
  "end": 1424.0, "text": " They had available wasn''t quite.", "tokens": [51064, 814,
  632, 2435, 2067, 380, 1596, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16826950537191854,
  "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.0004191641346551478},
  {"id": 148, "seek": 140600, "start": 1424.0, "end": 1426.0, "text": " Built for
  that.", "tokens": [51264, 49822, 337, 300, 13, 51364], "temperature": 0.0, "avg_logprob":
  -0.16826950537191854, "compression_ratio": 1.5728155339805825, "no_speech_prob":
  0.0004191641346551478}, {"id": 149, "seek": 140600, "start": 1426.0, "end": 1432.0,
  "text": " For huge scale and for like secure and reliable.", "tokens": [51364, 1171,
  2603, 4373, 293, 337, 411, 7144, 293, 12924, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.16826950537191854, "compression_ratio": 1.5728155339805825, "no_speech_prob":
  0.0004191641346551478}, {"id": 150, "seek": 143200, "start": 1432.0, "end": 1435.0,
  "text": " And so that''s the environment.", "tokens": [50364, 400, 370, 300, 311,
  264, 2823, 13, 50514], "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio":
  1.6029411764705883, "no_speech_prob": 0.0345943458378315}, {"id": 151, "seek": 143200,
  "start": 1435.0, "end": 1436.0, "text": " And.", "tokens": [50514, 400, 13, 50564],
  "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio": 1.6029411764705883,
  "no_speech_prob": 0.0345943458378315}, {"id": 152, "seek": 143200, "start": 1436.0,
  "end": 1438.0, "text": " Yeah, that''s exciting to be.", "tokens": [50564, 865,
  11, 300, 311, 4670, 281, 312, 13, 50664], "temperature": 0.0, "avg_logprob": -0.3239966062741859,
  "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0345943458378315},
  {"id": 153, "seek": 143200, "start": 1438.0, "end": 1440.0, "text": " To be in an
  emerging category like that.", "tokens": [50664, 1407, 312, 294, 364, 14989, 7719,
  411, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio":
  1.6029411764705883, "no_speech_prob": 0.0345943458378315}, {"id": 154, "seek": 143200,
  "start": 1440.0, "end": 1444.0, "text": " And solve a real need and see watch the
  need.", "tokens": [50764, 400, 5039, 257, 957, 643, 293, 536, 1159, 264, 643, 13,
  50964], "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio":
  1.6029411764705883, "no_speech_prob": 0.0345943458378315}, {"id": 155, "seek": 143200,
  "start": 1444.0, "end": 1446.0, "text": " Grow.", "tokens": [50964, 18476, 13, 51064],
  "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio": 1.6029411764705883,
  "no_speech_prob": 0.0345943458378315}, {"id": 156, "seek": 143200, "start": 1446.0,
  "end": 1447.0, "text": " Yeah.", "tokens": [51064, 865, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.3239966062741859, "compression_ratio": 1.6029411764705883,
  "no_speech_prob": 0.0345943458378315}, {"id": 157, "seek": 143200, "start": 1447.0,
  "end": 1450.0, "text": " That''s my personal, you know, that''s what motivates me.",
  "tokens": [51114, 663, 311, 452, 2973, 11, 291, 458, 11, 300, 311, 437, 42569, 385,
  13, 51264], "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio":
  1.6029411764705883, "no_speech_prob": 0.0345943458378315}, {"id": 158, "seek": 143200,
  "start": 1450.0, "end": 1451.0, "text": " And that''s why.", "tokens": [51264, 400,
  300, 311, 983, 13, 51314], "temperature": 0.0, "avg_logprob": -0.3239966062741859,
  "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0345943458378315},
  {"id": 159, "seek": 143200, "start": 1451.0, "end": 1452.0, "text": " So I''m excited
  to be here.", "tokens": [51314, 407, 286, 478, 2919, 281, 312, 510, 13, 51364],
  "temperature": 0.0, "avg_logprob": -0.3239966062741859, "compression_ratio": 1.6029411764705883,
  "no_speech_prob": 0.0345943458378315}, {"id": 160, "seek": 143200, "start": 1452.0,
  "end": 1459.0, "text": " If you want to go even even on a more philosophical level,
  like.", "tokens": [51364, 759, 291, 528, 281, 352, 754, 754, 322, 257, 544, 25066,
  1496, 11, 411, 13, 51714], "temperature": 0.0, "avg_logprob": -0.3239966062741859,
  "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.0345943458378315},
  {"id": 161, "seek": 145900, "start": 1459.0, "end": 1467.0, "text": " It''s really
  rewarding to me to.", "tokens": [50364, 467, 311, 534, 20063, 281, 385, 281, 13,
  50764], "temperature": 0.0, "avg_logprob": -0.24377586364746093, "compression_ratio":
  1.3823529411764706, "no_speech_prob": 0.005706429481506348}, {"id": 162, "seek":
  145900, "start": 1467.0, "end": 1470.0, "text": " Help grow.", "tokens": [50764,
  10773, 1852, 13, 50914], "temperature": 0.0, "avg_logprob": -0.24377586364746093,
  "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.005706429481506348},
  {"id": 163, "seek": 145900, "start": 1470.0, "end": 1476.0, "text": " The kinds
  of technologies that are powering.", "tokens": [50914, 440, 3685, 295, 7943, 300,
  366, 1347, 278, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24377586364746093,
  "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.005706429481506348},
  {"id": 164, "seek": 145900, "start": 1476.0, "end": 1483.0, "text": " Our like software
  infrastructure, which, which, which, which everything in this world runs on today.",
  "tokens": [51214, 2621, 411, 4722, 6896, 11, 597, 11, 597, 11, 597, 11, 597, 1203,
  294, 341, 1002, 6676, 322, 965, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24377586364746093,
  "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.005706429481506348},
  {"id": 165, "seek": 148300, "start": 1483.0, "end": 1491.0, "text": " So it''s really
  a big thing to do.", "tokens": [50364, 407, 309, 311, 534, 257, 955, 551, 281, 360,
  13, 50764], "temperature": 0.4, "avg_logprob": -0.5697867575656163, "compression_ratio":
  1.663594470046083, "no_speech_prob": 0.12653446197509766}, {"id": 166, "seek": 148300,
  "start": 1491.0, "end": 1495.0, "text": " It''s a fact that it''s kind of behind
  the scenes and under the hood that you know most consumers and most people don''t
  know that.", "tokens": [50764, 467, 311, 257, 1186, 300, 309, 311, 733, 295, 2261,
  264, 8026, 293, 833, 264, 13376, 300, 291, 458, 881, 11883, 293, 881, 561, 500,
  380, 458, 300, 13, 50964], "temperature": 0.4, "avg_logprob": -0.5697867575656163,
  "compression_ratio": 1.663594470046083, "no_speech_prob": 0.12653446197509766},
  {"id": 167, "seek": 148300, "start": 1495.0, "end": 1502.0, "text": " Their Facebook
  feed is powered by similarity search, or that their Google search is powered by
  similar research.", "tokens": [50964, 6710, 4384, 3154, 307, 17786, 538, 32194,
  3164, 11, 420, 300, 641, 3329, 3164, 307, 17786, 538, 2531, 2132, 13, 51314], "temperature":
  0.4, "avg_logprob": -0.5697867575656163, "compression_ratio": 1.663594470046083,
  "no_speech_prob": 0.12653446197509766}, {"id": 168, "seek": 148300, "start": 1502.0,
  "end": 1505.0, "text": " But it even without them knowing it affects them tremendously.",
  "tokens": [51314, 583, 309, 754, 1553, 552, 5276, 309, 11807, 552, 27985, 13, 51464],
  "temperature": 0.4, "avg_logprob": -0.5697867575656163, "compression_ratio": 1.663594470046083,
  "no_speech_prob": 0.12653446197509766}, {"id": 169, "seek": 148300, "start": 1505.0,
  "end": 1509.0, "text": " I feel like we have a.", "tokens": [51464, 286, 841, 411,
  321, 362, 257, 13, 51664], "temperature": 0.4, "avg_logprob": -0.5697867575656163,
  "compression_ratio": 1.663594470046083, "no_speech_prob": 0.12653446197509766},
  {"id": 170, "seek": 150900, "start": 1509.0, "end": 1512.0, "text": " And I think
  that''s really.", "tokens": [50364, 400, 286, 519, 300, 311, 534, 13, 50514], "temperature":
  0.0, "avg_logprob": -0.4781525223343461, "compression_ratio": 1.9637305699481866,
  "no_speech_prob": 0.02768482081592083}, {"id": 171, "seek": 150900, "start": 1512.0,
  "end": 1513.0, "text": " I think that''s really.", "tokens": [50514, 286, 519, 300,
  311, 534, 13, 50564], "temperature": 0.0, "avg_logprob": -0.4781525223343461, "compression_ratio":
  1.9637305699481866, "no_speech_prob": 0.02768482081592083}, {"id": 172, "seek":
  150900, "start": 1513.0, "end": 1515.0, "text": " I think that''s really.", "tokens":
  [50564, 286, 519, 300, 311, 534, 13, 50664], "temperature": 0.0, "avg_logprob":
  -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 173, "seek": 150900, "start": 1515.0, "end": 1517.0,
  "text": " I think that''s really.", "tokens": [50664, 286, 519, 300, 311, 534, 13,
  50764], "temperature": 0.0, "avg_logprob": -0.4781525223343461, "compression_ratio":
  1.9637305699481866, "no_speech_prob": 0.02768482081592083}, {"id": 174, "seek":
  150900, "start": 1517.0, "end": 1518.0, "text": " I think that''s really.", "tokens":
  [50764, 286, 519, 300, 311, 534, 13, 50814], "temperature": 0.0, "avg_logprob":
  -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 175, "seek": 150900, "start": 1518.0, "end": 1519.0,
  "text": " Yeah.", "tokens": [50814, 865, 13, 50864], "temperature": 0.0, "avg_logprob":
  -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 176, "seek": 150900, "start": 1519.0, "end": 1520.0,
  "text": " Yeah.", "tokens": [50864, 865, 13, 50914], "temperature": 0.0, "avg_logprob":
  -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 177, "seek": 150900, "start": 1520.0, "end": 1521.0,
  "text": " Yeah.", "tokens": [50914, 865, 13, 50964], "temperature": 0.0, "avg_logprob":
  -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 178, "seek": 150900, "start": 1521.0, "end": 1522.0,
  "text": " Sounds.", "tokens": [50964, 14576, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 179, "seek": 150900, "start": 1522.0, "end": 1523.0,
  "text": " So deep.", "tokens": [51014, 407, 2452, 13, 51064], "temperature": 0.0,
  "avg_logprob": -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 180, "seek": 150900, "start": 1523.0, "end": 1524.0,
  "text": " I mean, your connection to it.", "tokens": [51064, 286, 914, 11, 428,
  4984, 281, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.4781525223343461,
  "compression_ratio": 1.9637305699481866, "no_speech_prob": 0.02768482081592083},
  {"id": 181, "seek": 150900, "start": 1524.0, "end": 1528.0, "text": " And in general,
  like it sounds like you''re excited to be at the bleeding edge of stack, right?",
  "tokens": [51114, 400, 294, 2674, 11, 411, 309, 3263, 411, 291, 434, 2919, 281,
  312, 412, 264, 19312, 4691, 295, 8630, 11, 558, 30, 51314], "temperature": 0.0,
  "avg_logprob": -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 182, "seek": 150900, "start": 1528.0, "end": 1529.0,
  "text": " So kind of like.", "tokens": [51314, 407, 733, 295, 411, 13, 51364], "temperature":
  0.0, "avg_logprob": -0.4781525223343461, "compression_ratio": 1.9637305699481866,
  "no_speech_prob": 0.02768482081592083}, {"id": 183, "seek": 150900, "start": 1529.0,
  "end": 1531.0, "text": " Building the next thing.", "tokens": [51364, 18974, 264,
  958, 551, 13, 51464], "temperature": 0.0, "avg_logprob": -0.4781525223343461, "compression_ratio":
  1.9637305699481866, "no_speech_prob": 0.02768482081592083}, {"id": 184, "seek":
  150900, "start": 1531.0, "end": 1532.0, "text": " It''s.", "tokens": [51464, 467,
  311, 13, 51514], "temperature": 0.0, "avg_logprob": -0.4781525223343461, "compression_ratio":
  1.9637305699481866, "no_speech_prob": 0.02768482081592083}, {"id": 185, "seek":
  150900, "start": 1532.0, "end": 1534.0, "text": " I think it''s always exciting.",
  "tokens": [51514, 286, 519, 309, 311, 1009, 4670, 13, 51614], "temperature": 0.0,
  "avg_logprob": -0.4781525223343461, "compression_ratio": 1.9637305699481866, "no_speech_prob":
  0.02768482081592083}, {"id": 186, "seek": 150900, "start": 1534.0, "end": 1535.0,
  "text": " Of course, it''s also.", "tokens": [51614, 2720, 1164, 11, 309, 311, 611,
  13, 51664], "temperature": 0.0, "avg_logprob": -0.4781525223343461, "compression_ratio":
  1.9637305699481866, "no_speech_prob": 0.02768482081592083}, {"id": 187, "seek":
  153500, "start": 1535.0, "end": 1538.0, "text": " And in many ways.", "tokens":
  [50364, 400, 294, 867, 2098, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 188, "seek": 153500, "start": 1538.0, "end": 1539.0, "text": " Kind of.",
  "tokens": [50514, 9242, 295, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 189, "seek": 153500, "start": 1539.0, "end": 1541.0, "text": " Well, I don''t
  want to use the word dangerous.", "tokens": [50564, 1042, 11, 286, 500, 380, 528,
  281, 764, 264, 1349, 5795, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 190, "seek": 153500, "start": 1541.0, "end": 1542.0, "text": " I want to
  use the word.", "tokens": [50664, 286, 528, 281, 764, 264, 1349, 13, 50714], "temperature":
  0.0, "avg_logprob": -0.23426016445817618, "compression_ratio": 1.6167400881057268,
  "no_speech_prob": 0.02419867180287838}, {"id": 191, "seek": 153500, "start": 1542.0,
  "end": 1543.0, "text": " Kind of like intense.", "tokens": [50714, 9242, 295, 411,
  9447, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23426016445817618, "compression_ratio":
  1.6167400881057268, "no_speech_prob": 0.02419867180287838}, {"id": 192, "seek":
  153500, "start": 1543.0, "end": 1545.0, "text": " And you know, like.", "tokens":
  [50764, 400, 291, 458, 11, 411, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 193, "seek": 153500, "start": 1545.0, "end": 1546.0, "text": " It''s nice
  and bold.", "tokens": [50864, 467, 311, 1481, 293, 11928, 13, 50914], "temperature":
  0.0, "avg_logprob": -0.23426016445817618, "compression_ratio": 1.6167400881057268,
  "no_speech_prob": 0.02419867180287838}, {"id": 194, "seek": 153500, "start": 1546.0,
  "end": 1548.0, "text": " That was saying, right?", "tokens": [50914, 663, 390, 1566,
  11, 558, 30, 51014], "temperature": 0.0, "avg_logprob": -0.23426016445817618, "compression_ratio":
  1.6167400881057268, "no_speech_prob": 0.02419867180287838}, {"id": 195, "seek":
  153500, "start": 1548.0, "end": 1549.0, "text": " Yeah.", "tokens": [51014, 865,
  13, 51064], "temperature": 0.0, "avg_logprob": -0.23426016445817618, "compression_ratio":
  1.6167400881057268, "no_speech_prob": 0.02419867180287838}, {"id": 196, "seek":
  153500, "start": 1549.0, "end": 1550.0, "text": " Yeah.", "tokens": [51064, 865,
  13, 51114], "temperature": 0.0, "avg_logprob": -0.23426016445817618, "compression_ratio":
  1.6167400881057268, "no_speech_prob": 0.02419867180287838}, {"id": 197, "seek":
  153500, "start": 1550.0, "end": 1551.0, "text": " It''s.", "tokens": [51114, 467,
  311, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23426016445817618, "compression_ratio":
  1.6167400881057268, "no_speech_prob": 0.02419867180287838}, {"id": 198, "seek":
  153500, "start": 1551.0, "end": 1552.0, "text": " For sure.", "tokens": [51164,
  1171, 988, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 199, "seek": 153500, "start": 1552.0, "end": 1553.0, "text": " We don''t
  know how the future will play out.", "tokens": [51214, 492, 500, 380, 458, 577,
  264, 2027, 486, 862, 484, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 200, "seek": 153500, "start": 1553.0, "end": 1554.0, "text": " We have our
  hopes and.", "tokens": [51264, 492, 362, 527, 13681, 293, 13, 51314], "temperature":
  0.0, "avg_logprob": -0.23426016445817618, "compression_ratio": 1.6167400881057268,
  "no_speech_prob": 0.02419867180287838}, {"id": 201, "seek": 153500, "start": 1554.0,
  "end": 1556.0, "text": " And we''re making our bets.", "tokens": [51314, 400, 321,
  434, 1455, 527, 39922, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 202, "seek": 153500, "start": 1556.0, "end": 1559.0, "text": " But.", "tokens":
  [51414, 583, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23426016445817618,
  "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.02419867180287838},
  {"id": 203, "seek": 153500, "start": 1559.0, "end": 1560.0, "text": " It''s exciting
  to try it.", "tokens": [51564, 467, 311, 4670, 281, 853, 309, 13, 51614], "temperature":
  0.0, "avg_logprob": -0.23426016445817618, "compression_ratio": 1.6167400881057268,
  "no_speech_prob": 0.02419867180287838}, {"id": 204, "seek": 153500, "start": 1560.0,
  "end": 1561.0, "text": " And it.", "tokens": [51614, 400, 309, 13, 51664], "temperature":
  0.0, "avg_logprob": -0.23426016445817618, "compression_ratio": 1.6167400881057268,
  "no_speech_prob": 0.02419867180287838}, {"id": 205, "seek": 153500, "start": 1561.0,
  "end": 1562.0, "text": " That''s.", "tokens": [51664, 663, 311, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.23426016445817618, "compression_ratio": 1.6167400881057268,
  "no_speech_prob": 0.02419867180287838}, {"id": 206, "seek": 153500, "start": 1562.0,
  "end": 1563.0, "text": " It motivates us.", "tokens": [51714, 467, 42569, 505, 13,
  51764], "temperature": 0.0, "avg_logprob": -0.23426016445817618, "compression_ratio":
  1.6167400881057268, "no_speech_prob": 0.02419867180287838}, {"id": 207, "seek":
  156300, "start": 1563.0, "end": 1564.0, "text": " And it''s.", "tokens": [50364,
  400, 309, 311, 13, 50414], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 208, "seek": 156300, "start": 1564.0, "end": 1565.0, "text": " It''s.", "tokens":
  [50414, 467, 311, 13, 50464], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 209, "seek": 156300, "start": 1565.0, "end": 1567.0, "text": " Yeah, we''re
  not looking for safe.", "tokens": [50464, 865, 11, 321, 434, 406, 1237, 337, 3273,
  13, 50564], "temperature": 0.0, "avg_logprob": -0.25297793404000707, "compression_ratio":
  1.568888888888889, "no_speech_prob": 0.009742332622408867}, {"id": 210, "seek":
  156300, "start": 1567.0, "end": 1568.0, "text": " For safety here.", "tokens": [50564,
  1171, 4514, 510, 13, 50614], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 211, "seek": 156300, "start": 1568.0, "end": 1569.0, "text": " Yeah.", "tokens":
  [50614, 865, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 212, "seek": 156300, "start": 1569.0, "end": 1570.0, "text": " Yeah.", "tokens":
  [50664, 865, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 213, "seek": 156300, "start": 1570.0, "end": 1571.0, "text": " Absolutely.",
  "tokens": [50714, 7021, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 214, "seek": 156300, "start": 1571.0, "end": 1573.0, "text": " But on that
  front, like on the future,", "tokens": [50764, 583, 322, 300, 1868, 11, 411, 322,
  264, 2027, 11, 50864], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 215, "seek": 156300, "start": 1573.0, "end": 1574.0, "text": " a little bit.",
  "tokens": [50864, 257, 707, 857, 13, 50914], "temperature": 0.0, "avg_logprob":
  -0.25297793404000707, "compression_ratio": 1.568888888888889, "no_speech_prob":
  0.009742332622408867}, {"id": 216, "seek": 156300, "start": 1574.0, "end": 1578.0,
  "text": " Touching on the future of this market, even though it''s emerging.", "tokens":
  [50914, 20029, 278, 322, 264, 2027, 295, 341, 2142, 11, 754, 1673, 309, 311, 14989,
  13, 51114], "temperature": 0.0, "avg_logprob": -0.25297793404000707, "compression_ratio":
  1.568888888888889, "no_speech_prob": 0.009742332622408867}, {"id": 217, "seek":
  156300, "start": 1578.0, "end": 1581.0, "text": " You know, and it''s still unfolding
  in many ways.", "tokens": [51114, 509, 458, 11, 293, 309, 311, 920, 44586, 294,
  867, 2098, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25297793404000707,
  "compression_ratio": 1.568888888888889, "no_speech_prob": 0.009742332622408867},
  {"id": 218, "seek": 156300, "start": 1581.0, "end": 1585.0, "text": " And there
  are so many players already.", "tokens": [51264, 400, 456, 366, 370, 867, 4150,
  1217, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25297793404000707, "compression_ratio":
  1.568888888888889, "no_speech_prob": 0.009742332622408867}, {"id": 219, "seek":
  156300, "start": 1585.0, "end": 1587.0, "text": " But I''m just thinking like.",
  "tokens": [51464, 583, 286, 478, 445, 1953, 411, 13, 51564], "temperature": 0.0,
  "avg_logprob": -0.25297793404000707, "compression_ratio": 1.568888888888889, "no_speech_prob":
  0.009742332622408867}, {"id": 220, "seek": 156300, "start": 1587.0, "end": 1589.0,
  "text": " What do you think.", "tokens": [51564, 708, 360, 291, 519, 13, 51664],
  "temperature": 0.0, "avg_logprob": -0.25297793404000707, "compression_ratio": 1.568888888888889,
  "no_speech_prob": 0.009742332622408867}, {"id": 221, "seek": 156300, "start": 1589.0,
  "end": 1590.0, "text": " Kind of.", "tokens": [51664, 9242, 295, 13, 51714], "temperature":
  0.0, "avg_logprob": -0.25297793404000707, "compression_ratio": 1.568888888888889,
  "no_speech_prob": 0.009742332622408867}, {"id": 222, "seek": 159000, "start": 1590.0,
  "end": 1593.0, "text": " What strategic items and missing on the market right now?",
  "tokens": [50364, 708, 10924, 4754, 293, 5361, 322, 264, 2142, 558, 586, 30, 50514],
  "temperature": 0.0, "avg_logprob": -0.17039137620192307, "compression_ratio": 1.7142857142857142,
  "no_speech_prob": 0.018524089828133583}, {"id": 223, "seek": 159000, "start": 1593.0,
  "end": 1596.0, "text": " You know, when you think about not the data science part,",
  "tokens": [50514, 509, 458, 11, 562, 291, 519, 466, 406, 264, 1412, 3497, 644, 11,
  50664], "temperature": 0.0, "avg_logprob": -0.17039137620192307, "compression_ratio":
  1.7142857142857142, "no_speech_prob": 0.018524089828133583}, {"id": 224, "seek":
  159000, "start": 1596.0, "end": 1599.0, "text": " I think that data science is developed
  quite well.", "tokens": [50664, 286, 519, 300, 1412, 3497, 307, 4743, 1596, 731,
  13, 50814], "temperature": 0.0, "avg_logprob": -0.17039137620192307, "compression_ratio":
  1.7142857142857142, "no_speech_prob": 0.018524089828133583}, {"id": 225, "seek":
  159000, "start": 1599.0, "end": 1604.0, "text": " We have a lot of competing, you
  know, algorithms and frameworks.", "tokens": [50814, 492, 362, 257, 688, 295, 15439,
  11, 291, 458, 11, 14642, 293, 29834, 13, 51064], "temperature": 0.0, "avg_logprob":
  -0.17039137620192307, "compression_ratio": 1.7142857142857142, "no_speech_prob":
  0.018524089828133583}, {"id": 226, "seek": 159000, "start": 1604.0, "end": 1607.0,
  "text": " But like more like on the business side, right?", "tokens": [51064, 583,
  411, 544, 411, 322, 264, 1606, 1252, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob":
  -0.17039137620192307, "compression_ratio": 1.7142857142857142, "no_speech_prob":
  0.018524089828133583}, {"id": 227, "seek": 159000, "start": 1607.0, "end": 1612.0,
  "text": " And maybe that''s in line with like how users understand the systems.",
  "tokens": [51214, 400, 1310, 300, 311, 294, 1622, 365, 411, 577, 5022, 1223, 264,
  3652, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17039137620192307, "compression_ratio":
  1.7142857142857142, "no_speech_prob": 0.018524089828133583}, {"id": 228, "seek":
  159000, "start": 1612.0, "end": 1614.0, "text": " Maybe they don''t understand enough.",
  "tokens": [51464, 2704, 436, 500, 380, 1223, 1547, 13, 51564], "temperature": 0.0,
  "avg_logprob": -0.17039137620192307, "compression_ratio": 1.7142857142857142, "no_speech_prob":
  0.018524089828133583}, {"id": 229, "seek": 159000, "start": 1614.0, "end": 1617.0,
  "text": " Like, or like what items and missing?", "tokens": [51564, 1743, 11, 420,
  411, 437, 4754, 293, 5361, 30, 51714], "temperature": 0.0, "avg_logprob": -0.17039137620192307,
  "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.018524089828133583},
  {"id": 230, "seek": 159000, "start": 1617.0, "end": 1619.0, "text": " And maybe
  you''re working on that.", "tokens": [51714, 400, 1310, 291, 434, 1364, 322, 300,
  13, 51814], "temperature": 0.0, "avg_logprob": -0.17039137620192307, "compression_ratio":
  1.7142857142857142, "no_speech_prob": 0.018524089828133583}, {"id": 231, "seek":
  161900, "start": 1619.0, "end": 1625.0, "text": " Maybe you''re willing to share
  maybe not, but maybe something along those lines that we can discuss.", "tokens":
  [50364, 2704, 291, 434, 4950, 281, 2073, 1310, 406, 11, 457, 1310, 746, 2051, 729,
  3876, 300, 321, 393, 2248, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1670883066513959,
  "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.009171971119940281},
  {"id": 232, "seek": 161900, "start": 1625.0, "end": 1629.0, "text": " Yeah, I think
  you actually.", "tokens": [50664, 865, 11, 286, 519, 291, 767, 13, 50864], "temperature":
  0.0, "avg_logprob": -0.1670883066513959, "compression_ratio": 1.5555555555555556,
  "no_speech_prob": 0.009171971119940281}, {"id": 233, "seek": 161900, "start": 1629.0,
  "end": 1632.0, "text": " You made the right point, which is.", "tokens": [50864,
  509, 1027, 264, 558, 935, 11, 597, 307, 13, 51014], "temperature": 0.0, "avg_logprob":
  -0.1670883066513959, "compression_ratio": 1.5555555555555556, "no_speech_prob":
  0.009171971119940281}, {"id": 234, "seek": 161900, "start": 1632.0, "end": 1637.0,
  "text": " For a certain for a certain audience.", "tokens": [51014, 1171, 257, 1629,
  337, 257, 1629, 4034, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1670883066513959,
  "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.009171971119940281},
  {"id": 235, "seek": 161900, "start": 1637.0, "end": 1639.0, "text": " There''s not.",
  "tokens": [51264, 821, 311, 406, 13, 51364], "temperature": 0.0, "avg_logprob":
  -0.1670883066513959, "compression_ratio": 1.5555555555555556, "no_speech_prob":
  0.009171971119940281}, {"id": 236, "seek": 161900, "start": 1639.0, "end": 1647.0,
  "text": " I mean, there''s still more to be done for a very technical audience that''s
  familiar with the vector search.", "tokens": [51364, 286, 914, 11, 456, 311, 920,
  544, 281, 312, 1096, 337, 257, 588, 6191, 4034, 300, 311, 4963, 365, 264, 8062,
  3164, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1670883066513959, "compression_ratio":
  1.5555555555555556, "no_speech_prob": 0.009171971119940281}, {"id": 237, "seek":
  164700, "start": 1647.0, "end": 1651.0, "text": " They have a lot of tools in front
  of them and.", "tokens": [50364, 814, 362, 257, 688, 295, 3873, 294, 1868, 295,
  552, 293, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1628240229009272, "compression_ratio":
  1.5576036866359446, "no_speech_prob": 0.006784122437238693}, {"id": 238, "seek":
  164700, "start": 1651.0, "end": 1655.0, "text": " And right now, whatever extra
  features they needed, they''ve.", "tokens": [50564, 400, 558, 586, 11, 2035, 2857,
  4122, 436, 2978, 11, 436, 600, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1628240229009272,
  "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.006784122437238693},
  {"id": 239, "seek": 164700, "start": 1655.0, "end": 1658.0, "text": " They''ve hopefully
  figured out.", "tokens": [50764, 814, 600, 4696, 8932, 484, 13, 50914], "temperature":
  0.0, "avg_logprob": -0.1628240229009272, "compression_ratio": 1.5576036866359446,
  "no_speech_prob": 0.006784122437238693}, {"id": 240, "seek": 164700, "start": 1658.0,
  "end": 1664.0, "text": " It''s everyone else who doesn''t yet understand this and
  doesn''t quite see.", "tokens": [50914, 467, 311, 1518, 1646, 567, 1177, 380, 1939,
  1223, 341, 293, 1177, 380, 1596, 536, 13, 51214], "temperature": 0.0, "avg_logprob":
  -0.1628240229009272, "compression_ratio": 1.5576036866359446, "no_speech_prob":
  0.006784122437238693}, {"id": 241, "seek": 164700, "start": 1664.0, "end": 1668.0,
  "text": " How it applies to their applications.", "tokens": [51214, 1012, 309, 13165,
  281, 641, 5821, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1628240229009272,
  "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.006784122437238693},
  {"id": 242, "seek": 164700, "start": 1668.0, "end": 1676.0, "text": " And for whom
  it''s not clear what, you know, how to choose an algorithm, how to tune it.", "tokens":
  [51414, 400, 337, 7101, 309, 311, 406, 1850, 437, 11, 291, 458, 11, 577, 281, 2826,
  364, 9284, 11, 577, 281, 10864, 309, 13, 51814], "temperature": 0.0, "avg_logprob":
  -0.1628240229009272, "compression_ratio": 1.5576036866359446, "no_speech_prob":
  0.006784122437238693}, {"id": 243, "seek": 167600, "start": 1676.0, "end": 1680.0,
  "text": " That''s, I think the future isn''t educating.", "tokens": [50364, 663,
  311, 11, 286, 519, 264, 2027, 1943, 380, 28835, 13, 50564], "temperature": 0.0,
  "avg_logprob": -0.1755827780692808, "compression_ratio": 1.4759036144578312, "no_speech_prob":
  0.0002443080593366176}, {"id": 244, "seek": 167600, "start": 1680.0, "end": 1685.0,
  "text": " Those people and those companies and then bringing this capability to
  them.", "tokens": [50564, 3950, 561, 293, 729, 3431, 293, 550, 5062, 341, 13759,
  281, 552, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1755827780692808, "compression_ratio":
  1.4759036144578312, "no_speech_prob": 0.0002443080593366176}, {"id": 245, "seek":
  167600, "start": 1685.0, "end": 1692.0, "text": " And that means just helping them
  understand what it is, but it also means making the.", "tokens": [50814, 400, 300,
  1355, 445, 4315, 552, 1223, 437, 309, 307, 11, 457, 309, 611, 1355, 1455, 264, 13,
  51164], "temperature": 0.0, "avg_logprob": -0.1755827780692808, "compression_ratio":
  1.4759036144578312, "no_speech_prob": 0.0002443080593366176}, {"id": 246, "seek":
  167600, "start": 1692.0, "end": 1696.0, "text": " Products more accessible to them.",
  "tokens": [51164, 47699, 544, 9515, 281, 552, 13, 51364], "temperature": 0.0, "avg_logprob":
  -0.1755827780692808, "compression_ratio": 1.4759036144578312, "no_speech_prob":
  0.0002443080593366176}, {"id": 247, "seek": 167600, "start": 1696.0, "end": 1699.0,
  "text": " Like.", "tokens": [51364, 1743, 13, 51514], "temperature": 0.0, "avg_logprob":
  -0.1755827780692808, "compression_ratio": 1.4759036144578312, "no_speech_prob":
  0.0002443080593366176}, {"id": 248, "seek": 169900, "start": 1699.0, "end": 1706.0,
  "text": " And they can care of some of the technical details so that they can just
  focus on.", "tokens": [50364, 400, 436, 393, 1127, 295, 512, 295, 264, 6191, 4365,
  370, 300, 436, 393, 445, 1879, 322, 13, 50714], "temperature": 0.0, "avg_logprob":
  -0.1766753083183652, "compression_ratio": 1.58, "no_speech_prob": 0.002294097328558564},
  {"id": 249, "seek": 169900, "start": 1706.0, "end": 1710.0, "text": " Yeah, they''re
  business side of things in their application.", "tokens": [50714, 865, 11, 436,
  434, 1606, 1252, 295, 721, 294, 641, 3861, 13, 50914], "temperature": 0.0, "avg_logprob":
  -0.1766753083183652, "compression_ratio": 1.58, "no_speech_prob": 0.002294097328558564},
  {"id": 250, "seek": 169900, "start": 1710.0, "end": 1716.0, "text": " And there
  are many, many companies out there that can use vector search, but just haven''t
  heard of it.", "tokens": [50914, 400, 456, 366, 867, 11, 867, 3431, 484, 456, 300,
  393, 764, 8062, 3164, 11, 457, 445, 2378, 380, 2198, 295, 309, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.1766753083183652, "compression_ratio": 1.58, "no_speech_prob":
  0.002294097328558564}, {"id": 251, "seek": 169900, "start": 1716.0, "end": 1718.0,
  "text": " Don''t realize it.", "tokens": [51214, 1468, 380, 4325, 309, 13, 51314],
  "temperature": 0.0, "avg_logprob": -0.1766753083183652, "compression_ratio": 1.58,
  "no_speech_prob": 0.002294097328558564}, {"id": 252, "seek": 169900, "start": 1718.0,
  "end": 1720.0, "text": " And.", "tokens": [51314, 400, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.1766753083183652, "compression_ratio": 1.58, "no_speech_prob":
  0.002294097328558564}, {"id": 253, "seek": 169900, "start": 1720.0, "end": 1725.0,
  "text": " I think the future is in reaching those people.", "tokens": [51414, 286,
  519, 264, 2027, 307, 294, 9906, 729, 561, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.1766753083183652, "compression_ratio": 1.58, "no_speech_prob": 0.002294097328558564},
  {"id": 254, "seek": 172500, "start": 1725.0, "end": 1728.0, "text": " And I think
  even looking.", "tokens": [50364, 400, 286, 519, 754, 1237, 13, 50514], "temperature":
  0.0, "avg_logprob": -0.2399420464175871, "compression_ratio": 1.5980392156862746,
  "no_speech_prob": 0.0008687314111739397}, {"id": 255, "seek": 172500, "start": 1728.0,
  "end": 1730.0, "text": " Beyond vector search and just.", "tokens": [50514, 19707,
  8062, 3164, 293, 445, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2399420464175871,
  "compression_ratio": 1.5980392156862746, "no_speech_prob": 0.0008687314111739397},
  {"id": 256, "seek": 172500, "start": 1730.0, "end": 1736.0, "text": " Vector embeddings
  in general, I think as more, as more and more companies adopt.", "tokens": [50614,
  691, 20814, 12240, 29432, 294, 2674, 11, 286, 519, 382, 544, 11, 382, 544, 293,
  544, 3431, 6878, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2399420464175871,
  "compression_ratio": 1.5980392156862746, "no_speech_prob": 0.0008687314111739397},
  {"id": 257, "seek": 172500, "start": 1736.0, "end": 1738.0, "text": " Machine learning
  and learn about.", "tokens": [50914, 22155, 2539, 293, 1466, 466, 13, 51014], "temperature":
  0.0, "avg_logprob": -0.2399420464175871, "compression_ratio": 1.5980392156862746,
  "no_speech_prob": 0.0008687314111739397}, {"id": 258, "seek": 172500, "start": 1738.0,
  "end": 1739.0, "text": " And LP.", "tokens": [51014, 400, 38095, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.2399420464175871, "compression_ratio": 1.5980392156862746,
  "no_speech_prob": 0.0008687314111739397}, {"id": 259, "seek": 172500, "start": 1739.0,
  "end": 1744.0, "text": " And continue hiring for data scientists and now machine
  learning engineers, which.", "tokens": [51064, 400, 2354, 15335, 337, 1412, 7708,
  293, 586, 3479, 2539, 11955, 11, 597, 13, 51314], "temperature": 0.0, "avg_logprob":
  -0.2399420464175871, "compression_ratio": 1.5980392156862746, "no_speech_prob":
  0.0008687314111739397}, {"id": 260, "seek": 172500, "start": 1744.0, "end": 1748.0,
  "text": " By the way, are growing at a faster pace than.", "tokens": [51314, 3146,
  264, 636, 11, 366, 4194, 412, 257, 4663, 11638, 813, 13, 51514], "temperature":
  0.0, "avg_logprob": -0.2399420464175871, "compression_ratio": 1.5980392156862746,
  "no_speech_prob": 0.0008687314111739397}, {"id": 261, "seek": 172500, "start": 1748.0,
  "end": 1750.0, "text": " Data scientists.", "tokens": [51514, 11888, 7708, 13, 51614],
  "temperature": 0.0, "avg_logprob": -0.2399420464175871, "compression_ratio": 1.5980392156862746,
  "no_speech_prob": 0.0008687314111739397}, {"id": 262, "seek": 175000, "start": 1750.0,
  "end": 1756.0, "text": " The number of people with machine learning engineer titles
  on LinkedIn.", "tokens": [50364, 440, 1230, 295, 561, 365, 3479, 2539, 11403, 12992,
  322, 20657, 13, 50664], "temperature": 0.0, "avg_logprob": -0.27157571315765383,
  "compression_ratio": 1.4136363636363636, "no_speech_prob": 0.0008564196759834886},
  {"id": 263, "seek": 175000, "start": 1756.0, "end": 1759.0, "text": " Group by something
  like 16%.", "tokens": [50664, 10500, 538, 746, 411, 3165, 4, 13, 50814], "temperature":
  0.0, "avg_logprob": -0.27157571315765383, "compression_ratio": 1.4136363636363636,
  "no_speech_prob": 0.0008564196759834886}, {"id": 264, "seek": 175000, "start": 1759.0,
  "end": 1764.0, "text": " In Q2 of this year, which is when I last.", "tokens": [50814,
  682, 1249, 17, 295, 341, 1064, 11, 597, 307, 562, 286, 1036, 13, 51064], "temperature":
  0.0, "avg_logprob": -0.27157571315765383, "compression_ratio": 1.4136363636363636,
  "no_speech_prob": 0.0008564196759834886}, {"id": 265, "seek": 175000, "start": 1764.0,
  "end": 1767.0, "text": " Check this, where is data scientists grew by.", "tokens":
  [51064, 6881, 341, 11, 689, 307, 1412, 7708, 6109, 538, 13, 51214], "temperature":
  0.0, "avg_logprob": -0.27157571315765383, "compression_ratio": 1.4136363636363636,
  "no_speech_prob": 0.0008564196759834886}, {"id": 266, "seek": 175000, "start": 1767.0,
  "end": 1771.0, "text": " I don''t remember exactly, but single digits.", "tokens":
  [51214, 286, 500, 380, 1604, 2293, 11, 457, 2167, 27011, 13, 51414], "temperature":
  0.0, "avg_logprob": -0.27157571315765383, "compression_ratio": 1.4136363636363636,
  "no_speech_prob": 0.0008564196759834886}, {"id": 267, "seek": 175000, "start": 1771.0,
  "end": 1777.0, "text": " So and obviously not all those mental engineers are working
  on vector search.", "tokens": [51414, 407, 293, 2745, 406, 439, 729, 4973, 11955,
  366, 1364, 322, 8062, 3164, 13, 51714], "temperature": 0.0, "avg_logprob": -0.27157571315765383,
  "compression_ratio": 1.4136363636363636, "no_speech_prob": 0.0008564196759834886},
  {"id": 268, "seek": 177700, "start": 1777.0, "end": 1779.0, "text": " But.", "tokens":
  [50364, 583, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21351921979118796,
  "compression_ratio": 1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 269,
  "seek": 177700, "start": 1779.0, "end": 1781.0, "text": " They will have more and
  more.", "tokens": [50464, 814, 486, 362, 544, 293, 544, 13, 50564], "temperature":
  0.0, "avg_logprob": -0.21351921979118796, "compression_ratio": 1.4375, "no_speech_prob":
  0.002354922704398632}, {"id": 270, "seek": 177700, "start": 1781.0, "end": 1783.0,
  "text": " Vector embedding data.", "tokens": [50564, 691, 20814, 12240, 3584, 1412,
  13, 50664], "temperature": 0.0, "avg_logprob": -0.21351921979118796, "compression_ratio":
  1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 271, "seek": 177700, "start":
  1783.0, "end": 1786.0, "text": " But they''re trying to wrangle.", "tokens": [50664,
  583, 436, 434, 1382, 281, 928, 7846, 13, 50814], "temperature": 0.0, "avg_logprob":
  -0.21351921979118796, "compression_ratio": 1.4375, "no_speech_prob": 0.002354922704398632},
  {"id": 272, "seek": 177700, "start": 1786.0, "end": 1790.0, "text": " They want
  to maintain and analyze.", "tokens": [50814, 814, 528, 281, 6909, 293, 12477, 13,
  51014], "temperature": 0.0, "avg_logprob": -0.21351921979118796, "compression_ratio":
  1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 273, "seek": 177700, "start":
  1790.0, "end": 1794.0, "text": " And in some cases search through, but also maybe
  just.", "tokens": [51014, 400, 294, 512, 3331, 3164, 807, 11, 457, 611, 1310, 445,
  13, 51214], "temperature": 0.0, "avg_logprob": -0.21351921979118796, "compression_ratio":
  1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 274, "seek": 177700, "start":
  1794.0, "end": 1796.0, "text": " Feed into other models.", "tokens": [51214, 33720,
  666, 661, 5245, 13, 51314], "temperature": 0.0, "avg_logprob": -0.21351921979118796,
  "compression_ratio": 1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 275,
  "seek": 177700, "start": 1796.0, "end": 1797.0, "text": " And so on.", "tokens":
  [51314, 400, 370, 322, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21351921979118796,
  "compression_ratio": 1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 276,
  "seek": 177700, "start": 1797.0, "end": 1799.0, "text": " And so.", "tokens": [51364,
  400, 370, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21351921979118796, "compression_ratio":
  1.4375, "no_speech_prob": 0.002354922704398632}, {"id": 277, "seek": 177700, "start":
  1799.0, "end": 1806.0, "text": " In the past five years, we saw.", "tokens": [51464,
  682, 264, 1791, 1732, 924, 11, 321, 1866, 13, 51814], "temperature": 0.0, "avg_logprob":
  -0.21351921979118796, "compression_ratio": 1.4375, "no_speech_prob": 0.002354922704398632},
  {"id": 278, "seek": 180600, "start": 1806.0, "end": 1807.0, "text": " That''s.",
  "tokens": [50364, 663, 311, 13, 50414], "temperature": 0.6, "avg_logprob": -0.7825347900390625,
  "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.003963829018175602},
  {"id": 279, "seek": 180600, "start": 1807.0, "end": 1808.0, "text": " That''s why
  we want to work with data.", "tokens": [50414, 663, 311, 983, 321, 528, 281, 589,
  365, 1412, 13, 50464], "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio":
  1.7559055118110236, "no_speech_prob": 0.003963829018175602}, {"id": 280, "seek":
  180600, "start": 1808.0, "end": 1810.0, "text": " And a lot of questions have been
  asked.", "tokens": [50464, 400, 257, 688, 295, 1651, 362, 668, 2351, 13, 50564],
  "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio": 1.7559055118110236,
  "no_speech_prob": 0.003963829018175602}, {"id": 281, "seek": 180600, "start": 1810.0,
  "end": 1811.0, "text": " And so there are.", "tokens": [50564, 400, 370, 456, 366,
  13, 50614], "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio":
  1.7559055118110236, "no_speech_prob": 0.003963829018175602}, {"id": 282, "seek":
  180600, "start": 1811.0, "end": 1814.0, "text": " And so they need to think about
  the question of data warehouses and data lakes,", "tokens": [50614, 400, 370, 436,
  643, 281, 519, 466, 264, 1168, 295, 1412, 17464, 29578, 293, 1412, 25595, 11, 50764],
  "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio": 1.7559055118110236,
  "no_speech_prob": 0.003963829018175602}, {"id": 283, "seek": 180600, "start": 1814.0,
  "end": 1816.0, "text": " and really like.", "tokens": [50764, 293, 534, 411, 13,
  50864], "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio":
  1.7559055118110236, "no_speech_prob": 0.003963829018175602}, {"id": 284, "seek":
  180600, "start": 1816.0, "end": 1817.0, "text": " Companies.", "tokens": [50864,
  44031, 13, 50914], "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio":
  1.7559055118110236, "no_speech_prob": 0.003963829018175602}, {"id": 285, "seek":
  180600, "start": 1817.0, "end": 1819.0, "text": " Realizing they need to centralize
  their all their data.", "tokens": [50914, 8467, 3319, 436, 643, 281, 5777, 1125,
  641, 439, 641, 1412, 13, 51014], "temperature": 0.6, "avg_logprob": -0.7825347900390625,
  "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.003963829018175602},
  {"id": 286, "seek": 180600, "start": 1819.0, "end": 1822.0, "text": " For their
  data science teams and analysts and so on.", "tokens": [51014, 1171, 641, 1412,
  3497, 5491, 293, 31388, 293, 370, 322, 13, 51164], "temperature": 0.6, "avg_logprob":
  -0.7825347900390625, "compression_ratio": 1.7559055118110236, "no_speech_prob":
  0.003963829018175602}, {"id": 287, "seek": 180600, "start": 1822.0, "end": 1823.0,
  "text": " We.", "tokens": [51164, 492, 13, 51214], "temperature": 0.6, "avg_logprob":
  -0.7825347900390625, "compression_ratio": 1.7559055118110236, "no_speech_prob":
  0.003963829018175602}, {"id": 288, "seek": 180600, "start": 1823.0, "end": 1824.0,
  "text": " We believe.", "tokens": [51214, 492, 1697, 13, 51264], "temperature":
  0.6, "avg_logprob": -0.7825347900390625, "compression_ratio": 1.7559055118110236,
  "no_speech_prob": 0.003963829018175602}, {"id": 289, "seek": 180600, "start": 1824.0,
  "end": 1825.0, "text": " The same will.", "tokens": [51264, 440, 912, 486, 13, 51314],
  "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio": 1.7559055118110236,
  "no_speech_prob": 0.003963829018175602}, {"id": 290, "seek": 180600, "start": 1825.0,
  "end": 1829.0, "text": " Companies will need the same thing for vector embeddings.",
  "tokens": [51314, 44031, 486, 643, 264, 912, 551, 337, 8062, 12240, 29432, 13, 51514],
  "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio": 1.7559055118110236,
  "no_speech_prob": 0.003963829018175602}, {"id": 291, "seek": 180600, "start": 1829.0,
  "end": 1832.0, "text": " So the, they have.", "tokens": [51514, 407, 264, 11, 436,
  362, 13, 51664], "temperature": 0.6, "avg_logprob": -0.7825347900390625, "compression_ratio":
  1.7559055118110236, "no_speech_prob": 0.003963829018175602}, {"id": 292, "seek":
  180600, "start": 1832.0, "end": 1834.0, "text": " One database for.", "tokens":
  [51664, 1485, 8149, 337, 13, 51764], "temperature": 0.6, "avg_logprob": -0.7825347900390625,
  "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.003963829018175602},
  {"id": 293, "seek": 183400, "start": 1834.0, "end": 1842.88, "text": " all the can
  feed applications, feed training and analysis and so on. So yeah, that might", "tokens":
  [50364, 439, 264, 393, 3154, 5821, 11, 3154, 3097, 293, 5215, 293, 370, 322, 13,
  407, 1338, 11, 300, 1062, 50808], "temperature": 0.0, "avg_logprob": -0.2512951708854513,
  "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.08715543895959854},
  {"id": 294, "seek": 183400, "start": 1842.88, "end": 1849.12, "text": " be a few
  years out and we''ll see if that ever happens. But those are the kinds of things",
  "tokens": [50808, 312, 257, 1326, 924, 484, 293, 321, 603, 536, 498, 300, 1562,
  2314, 13, 583, 729, 366, 264, 3685, 295, 721, 51120], "temperature": 0.0, "avg_logprob":
  -0.2512951708854513, "compression_ratio": 1.6088888888888888, "no_speech_prob":
  0.08715543895959854}, {"id": 295, "seek": 183400, "start": 1849.12, "end": 1854.16,
  "text": " we''re thinking about often. Beyond research, how do we get, how do we
  help people get more", "tokens": [51120, 321, 434, 1953, 466, 2049, 13, 19707, 2132,
  11, 577, 360, 321, 483, 11, 577, 360, 321, 854, 561, 483, 544, 51372], "temperature":
  0.0, "avg_logprob": -0.2512951708854513, "compression_ratio": 1.6088888888888888,
  "no_speech_prob": 0.08715543895959854}, {"id": 296, "seek": 183400, "start": 1854.16,
  "end": 1859.68, "text": " use out of there? Yeah, I mean, so I guess it goes along
  the lines also of producing docs and", "tokens": [51372, 764, 484, 295, 456, 30,
  865, 11, 286, 914, 11, 370, 286, 2041, 309, 1709, 2051, 264, 3876, 611, 295, 10501,
  45623, 293, 51648], "temperature": 0.0, "avg_logprob": -0.2512951708854513, "compression_ratio":
  1.6088888888888888, "no_speech_prob": 0.08715543895959854}, {"id": 297, "seek":
  185968, "start": 1859.68, "end": 1865.6000000000001, "text": " the kind of documentation,
  kind of explaining and source code explaining things, right? How can I,", "tokens":
  [50364, 264, 733, 295, 14333, 11, 733, 295, 13468, 293, 4009, 3089, 13468, 721,
  11, 558, 30, 1012, 393, 286, 11, 50660], "temperature": 0.0, "avg_logprob": -0.258727970123291,
  "compression_ratio": 1.7767857142857142, "no_speech_prob": 0.016809910535812378},
  {"id": 298, "seek": 185968, "start": 1865.6000000000001, "end": 1871.8400000000001,
  "text": " you know, keep the road running and kind of doing things with my, because
  I don''t want to focus on", "tokens": [50660, 291, 458, 11, 1066, 264, 3060, 2614,
  293, 733, 295, 884, 721, 365, 452, 11, 570, 286, 500, 380, 528, 281, 1879, 322,
  50972], "temperature": 0.0, "avg_logprob": -0.258727970123291, "compression_ratio":
  1.7767857142857142, "no_speech_prob": 0.016809910535812378}, {"id": 299, "seek":
  185968, "start": 1871.8400000000001, "end": 1876.88, "text": " like, you know, need
  to create the of the vector of search itself maybe, but actually what I really",
  "tokens": [50972, 411, 11, 291, 458, 11, 643, 281, 1884, 264, 295, 264, 8062, 295,
  3164, 2564, 1310, 11, 457, 767, 437, 286, 534, 51224], "temperature": 0.0, "avg_logprob":
  -0.258727970123291, "compression_ratio": 1.7767857142857142, "no_speech_prob": 0.016809910535812378},
  {"id": 300, "seek": 185968, "start": 1876.88, "end": 1883.44, "text": " want is
  to achieve like, you know, my goal, right? You know, let''s say create a music search
  service", "tokens": [51224, 528, 307, 281, 4584, 411, 11, 291, 458, 11, 452, 3387,
  11, 558, 30, 509, 458, 11, 718, 311, 584, 1884, 257, 1318, 3164, 2643, 51552], "temperature":
  0.0, "avg_logprob": -0.258727970123291, "compression_ratio": 1.7767857142857142,
  "no_speech_prob": 0.016809910535812378}, {"id": 301, "seek": 188344, "start": 1883.44,
  "end": 1891.2, "text": " or something like that, right? Yeah, exactly. Yeah, it''s,
  that''s a trap. A lot of people and", "tokens": [50364, 420, 746, 411, 300, 11,
  558, 30, 865, 11, 2293, 13, 865, 11, 309, 311, 11, 300, 311, 257, 11487, 13, 316,
  688, 295, 561, 293, 50752], "temperature": 0.0, "avg_logprob": -0.20912809686346367,
  "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.003218613797798753},
  {"id": 302, "seek": 188344, "start": 1891.2, "end": 1898.8, "text": " companies
  fall into the, they love the technology, they love, you know, they''re very proud
  of,", "tokens": [50752, 3431, 2100, 666, 264, 11, 436, 959, 264, 2899, 11, 436,
  959, 11, 291, 458, 11, 436, 434, 588, 4570, 295, 11, 51132], "temperature": 0.0,
  "avg_logprob": -0.20912809686346367, "compression_ratio": 1.6267281105990783, "no_speech_prob":
  0.003218613797798753}, {"id": 303, "seek": 188344, "start": 1898.8, "end": 1904.88,
  "text": " yeah, building something unique. And as you should be, but you have to
  remember that that", "tokens": [51132, 1338, 11, 2390, 746, 3845, 13, 400, 382,
  291, 820, 312, 11, 457, 291, 362, 281, 1604, 300, 300, 51436], "temperature": 0.0,
  "avg_logprob": -0.20912809686346367, "compression_ratio": 1.6267281105990783, "no_speech_prob":
  0.003218613797798753}, {"id": 304, "seek": 188344, "start": 1906.24, "end": 1911.52,
  "text": " people you''re serving are just trying to solve some, some business problem.",
  "tokens": [51504, 561, 291, 434, 8148, 366, 445, 1382, 281, 5039, 512, 11, 512,
  1606, 1154, 13, 51768], "temperature": 0.0, "avg_logprob": -0.20912809686346367,
  "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.003218613797798753},
  {"id": 305, "seek": 191344, "start": 1913.44, "end": 1919.8400000000001, "text":
  " Some of them, the early adopters, they''ll, they might be very curious about how,
  how it works under", "tokens": [50364, 2188, 295, 552, 11, 264, 2440, 22486, 1559,
  11, 436, 603, 11, 436, 1062, 312, 588, 6369, 466, 577, 11, 577, 309, 1985, 833,
  50684], "temperature": 0.0, "avg_logprob": -0.12072736284007198, "compression_ratio":
  1.6736401673640167, "no_speech_prob": 7.660697883693501e-05}, {"id": 306, "seek":
  191344, "start": 1919.8400000000001, "end": 1926.16, "text": " the hood and they
  might want to have the ability to pull some levers and turn some knobs, but the
  vast", "tokens": [50684, 264, 13376, 293, 436, 1062, 528, 281, 362, 264, 3485, 281,
  2235, 512, 45571, 293, 1261, 512, 46999, 11, 457, 264, 8369, 51000], "temperature":
  0.0, "avg_logprob": -0.12072736284007198, "compression_ratio": 1.6736401673640167,
  "no_speech_prob": 7.660697883693501e-05}, {"id": 307, "seek": 191344, "start": 1926.16,
  "end": 1934.56, "text": " majority of people just want to implement machine learning
  into the applications to create a smarter", "tokens": [51000, 6286, 295, 561, 445,
  528, 281, 4445, 3479, 2539, 666, 264, 5821, 281, 1884, 257, 20294, 51420], "temperature":
  0.0, "avg_logprob": -0.12072736284007198, "compression_ratio": 1.6736401673640167,
  "no_speech_prob": 7.660697883693501e-05}, {"id": 308, "seek": 191344, "start": 1934.56,
  "end": 1943.3600000000001, "text": " search function to increase user engagement,
  things like that. Yeah, yeah, I think that was also", "tokens": [51420, 3164, 2445,
  281, 3488, 4195, 8742, 11, 721, 411, 300, 13, 865, 11, 1338, 11, 286, 519, 300,
  390, 611, 51860], "temperature": 0.0, "avg_logprob": -0.12072736284007198, "compression_ratio":
  1.6736401673640167, "no_speech_prob": 7.660697883693501e-05}, {"id": 309, "seek":
  194336, "start": 1943.6, "end": 1950.32, "text": " one recent article. I will also
  link it in the, in the notes, explaining that you can apply", "tokens": [50376,
  472, 5162, 7222, 13, 286, 486, 611, 2113, 309, 294, 264, 11, 294, 264, 5570, 11,
  13468, 300, 291, 393, 3079, 50712], "temperature": 0.0, "avg_logprob": -0.17104810597945233,
  "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.0004022227949462831},
  {"id": 310, "seek": 194336, "start": 1950.32, "end": 1956.7199999999998, "text":
  " a vector search to solve the zero heat problem in e-commerce. And, and that''s
  how you can save,", "tokens": [50712, 257, 8062, 3164, 281, 5039, 264, 4018, 3738,
  1154, 294, 308, 12, 26926, 13, 400, 11, 293, 300, 311, 577, 291, 393, 3155, 11,
  51032], "temperature": 0.0, "avg_logprob": -0.17104810597945233, "compression_ratio":
  1.5809128630705394, "no_speech_prob": 0.0004022227949462831}, {"id": 311, "seek":
  194336, "start": 1956.7199999999998, "end": 1963.76, "text": " well, actually earn
  money, right? So save the user experience in that sense. Yeah, so it sounds", "tokens":
  [51032, 731, 11, 767, 6012, 1460, 11, 558, 30, 407, 3155, 264, 4195, 1752, 294,
  300, 2020, 13, 865, 11, 370, 309, 3263, 51384], "temperature": 0.0, "avg_logprob":
  -0.17104810597945233, "compression_ratio": 1.5809128630705394, "no_speech_prob":
  0.0004022227949462831}, {"id": 312, "seek": 194336, "start": 1963.76, "end": 1968.8799999999999,
  "text": " like more and more use cases are coming up. I mean, you guys at the forefront
  of actually hearing", "tokens": [51384, 411, 544, 293, 544, 764, 3331, 366, 1348,
  493, 13, 286, 914, 11, 291, 1074, 412, 264, 27287, 295, 767, 4763, 51640], "temperature":
  0.0, "avg_logprob": -0.17104810597945233, "compression_ratio": 1.5809128630705394,
  "no_speech_prob": 0.0004022227949462831}, {"id": 313, "seek": 196888, "start": 1968.88,
  "end": 1975.7600000000002, "text": " what are the use cases, right? And kind of
  hopefully you''ll be sharing some of those with the", "tokens": [50364, 437, 366,
  264, 764, 3331, 11, 558, 30, 400, 733, 295, 4696, 291, 603, 312, 5414, 512, 295,
  729, 365, 264, 50708], "temperature": 0.0, "avg_logprob": -0.1363173256749692, "compression_ratio":
  1.6157205240174672, "no_speech_prob": 0.0023115132935345173}, {"id": 314, "seek":
  196888, "start": 1975.7600000000002, "end": 1983.2, "text": " audience at large
  and something we''ll learn from you guys. Yeah, I''ve, we''re still, we''re still",
  "tokens": [50708, 4034, 412, 2416, 293, 746, 321, 603, 1466, 490, 291, 1074, 13,
  865, 11, 286, 600, 11, 321, 434, 920, 11, 321, 434, 920, 51080], "temperature":
  0.0, "avg_logprob": -0.1363173256749692, "compression_ratio": 1.6157205240174672,
  "no_speech_prob": 0.0023115132935345173}, {"id": 315, "seek": 196888, "start": 1983.2,
  "end": 1991.1200000000001, "text": " constantly surprised by what people want to
  do with the vector search. And, yeah, we want to make", "tokens": [51080, 6460,
  6100, 538, 437, 561, 528, 281, 360, 365, 264, 8062, 3164, 13, 400, 11, 1338, 11,
  321, 528, 281, 652, 51476], "temperature": 0.0, "avg_logprob": -0.1363173256749692,
  "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0023115132935345173},
  {"id": 316, "seek": 196888, "start": 1991.1200000000001, "end": 1998.16, "text":
  " the product available to as many people as possible to see what they come up with.",
  "tokens": [51476, 264, 1674, 2435, 281, 382, 867, 561, 382, 1944, 281, 536, 437,
  436, 808, 493, 365, 13, 51828], "temperature": 0.0, "avg_logprob": -0.1363173256749692,
  "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0023115132935345173},
  {"id": 317, "seek": 199888, "start": 1999.68, "end": 2009.7600000000002, "text":
  " I will say though, we also surprised in a way by how many people want to just
  do vector search", "tokens": [50404, 286, 486, 584, 1673, 11, 321, 611, 6100, 294,
  257, 636, 538, 577, 867, 561, 528, 281, 445, 360, 8062, 3164, 50908], "temperature":
  0.0, "avg_logprob": -0.1249434719346974, "compression_ratio": 1.5297297297297296,
  "no_speech_prob": 0.0010734334355220199}, {"id": 318, "seek": 199888, "start": 2009.7600000000002,
  "end": 2019.2800000000002, "text": " on text data, which seems like such a simple
  thing to us, maybe. But it gets back to this point", "tokens": [50908, 322, 2487,
  1412, 11, 597, 2544, 411, 1270, 257, 2199, 551, 281, 505, 11, 1310, 13, 583, 309,
  2170, 646, 281, 341, 935, 51384], "temperature": 0.0, "avg_logprob": -0.1249434719346974,
  "compression_ratio": 1.5297297297297296, "no_speech_prob": 0.0010734334355220199},
  {"id": 319, "seek": 199888, "start": 2019.2800000000002, "end": 2025.1200000000001,
  "text": " that not everyone is, you know, this far along as, as people in the vector
  search community.", "tokens": [51384, 300, 406, 1518, 307, 11, 291, 458, 11, 341,
  1400, 2051, 382, 11, 382, 561, 294, 264, 8062, 3164, 1768, 13, 51676], "temperature":
  0.0, "avg_logprob": -0.1249434719346974, "compression_ratio": 1.5297297297297296,
  "no_speech_prob": 0.0010734334355220199}, {"id": 320, "seek": 202512, "start": 2026.08,
  "end": 2033.04, "text": " So we got to bring, we got to bring more people with us
  and help them see that once they''re done", "tokens": [50412, 407, 321, 658, 281,
  1565, 11, 321, 658, 281, 1565, 544, 561, 365, 505, 293, 854, 552, 536, 300, 1564,
  436, 434, 1096, 50760], "temperature": 0.0, "avg_logprob": -0.18708024422327676,
  "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.01758735068142414},
  {"id": 321, "seek": 202512, "start": 2033.04, "end": 2037.28, "text": " with a semantic
  search use case, there''s actually a lot more they can do with it. Yeah,", "tokens":
  [50760, 365, 257, 47982, 3164, 764, 1389, 11, 456, 311, 767, 257, 688, 544, 436,
  393, 360, 365, 309, 13, 865, 11, 50972], "temperature": 0.0, "avg_logprob": -0.18708024422327676,
  "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.01758735068142414},
  {"id": 322, "seek": 202512, "start": 2037.28, "end": 2046.0, "text": " I think it''s
  something that probably needs a bit of kind of discovery for everyone, but also
  sort", "tokens": [50972, 286, 519, 309, 311, 746, 300, 1391, 2203, 257, 857, 295,
  733, 295, 12114, 337, 1518, 11, 457, 611, 1333, 51408], "temperature": 0.0, "avg_logprob":
  -0.18708024422327676, "compression_ratio": 1.6877828054298643, "no_speech_prob":
  0.01758735068142414}, {"id": 323, "seek": 202512, "start": 2046.0, "end": 2051.2,
  "text": " of like blogging more about that and sharing more about that that, no,
  it''s not only text,", "tokens": [51408, 295, 411, 6968, 3249, 544, 466, 300, 293,
  5414, 544, 466, 300, 300, 11, 572, 11, 309, 311, 406, 787, 2487, 11, 51668], "temperature":
  0.0, "avg_logprob": -0.18708024422327676, "compression_ratio": 1.6877828054298643,
  "no_speech_prob": 0.01758735068142414}, {"id": 324, "seek": 205120, "start": 2051.2,
  "end": 2056.96, "text": " it''s actually everything that is inculcable as a vector,
  right? And could be dense, it could be", "tokens": [50364, 309, 311, 767, 1203,
  300, 307, 834, 425, 66, 712, 382, 257, 8062, 11, 558, 30, 400, 727, 312, 18011,
  11, 309, 727, 312, 50652], "temperature": 0.0, "avg_logprob": -0.18632020950317382,
  "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.0022406429052352905},
  {"id": 325, "seek": 205120, "start": 2056.96, "end": 2062.72, "text": " sparse,
  it could be whatever you have there as long as it''s a vector. Then you can send
  it in", "tokens": [50652, 637, 11668, 11, 309, 727, 312, 2035, 291, 362, 456, 382,
  938, 382, 309, 311, 257, 8062, 13, 1396, 291, 393, 2845, 309, 294, 50940], "temperature":
  0.0, "avg_logprob": -0.18632020950317382, "compression_ratio": 1.6297872340425532,
  "no_speech_prob": 0.0022406429052352905}, {"id": 326, "seek": 205120, "start": 2062.72,
  "end": 2067.2799999999997, "text": " index and search and then you need tools to
  choose the metric function, right? We didn''t talk about", "tokens": [50940, 8186,
  293, 3164, 293, 550, 291, 643, 3873, 281, 2826, 264, 20678, 2445, 11, 558, 30, 492,
  994, 380, 751, 466, 51168], "temperature": 0.0, "avg_logprob": -0.18632020950317382,
  "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.0022406429052352905},
  {"id": 327, "seek": 205120, "start": 2067.2799999999997, "end": 2075.52, "text":
  " it, but I know you guys support like three major distances like Euclidean and
  dot product and", "tokens": [51168, 309, 11, 457, 286, 458, 291, 1074, 1406, 411,
  1045, 2563, 22182, 411, 462, 1311, 31264, 282, 293, 5893, 1674, 293, 51580], "temperature":
  0.0, "avg_logprob": -0.18632020950317382, "compression_ratio": 1.6297872340425532,
  "no_speech_prob": 0.0022406429052352905}, {"id": 328, "seek": 207552, "start": 2075.52,
  "end": 2081.68, "text": " to sign. Yeah, so I mean, these are like more or less
  this standards across many, you know,", "tokens": [50364, 281, 1465, 13, 865, 11,
  370, 286, 914, 11, 613, 366, 411, 544, 420, 1570, 341, 7787, 2108, 867, 11, 291,
  458, 11, 50672], "temperature": 0.0, "avg_logprob": -0.25909970788394704, "compression_ratio":
  1.4816753926701571, "no_speech_prob": 0.0017748078098520637}, {"id": 329, "seek":
  207552, "start": 2081.68, "end": 2086.72, "text": " data science applications, but
  I''m sure there is somebody somewhere sitting in the garage and", "tokens": [50672,
  1412, 3497, 5821, 11, 457, 286, 478, 988, 456, 307, 2618, 4079, 3798, 294, 264,
  14400, 293, 50924], "temperature": 0.0, "avg_logprob": -0.25909970788394704, "compression_ratio":
  1.4816753926701571, "no_speech_prob": 0.0017748078098520637}, {"id": 330, "seek":
  207552, "start": 2086.72, "end": 2092.24, "text": " venting in new metric and probably
  you will want to kind of provide plug-in architecture for that", "tokens": [50924,
  6931, 278, 294, 777, 20678, 293, 1391, 291, 486, 528, 281, 733, 295, 2893, 5452,
  12, 259, 9482, 337, 300, 51200], "temperature": 0.0, "avg_logprob": -0.25909970788394704,
  "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.0017748078098520637},
  {"id": 331, "seek": 209224, "start": 2092.3199999999997, "end": 2101.2, "text":
  " case as well, right? Yeah, well, we have our own people in this figurative garages",
  "tokens": [50368, 1389, 382, 731, 11, 558, 30, 865, 11, 731, 11, 321, 362, 527,
  1065, 561, 294, 341, 31094, 1166, 3691, 1660, 50812], "temperature": 0.0, "avg_logprob":
  -0.17815639078617096, "compression_ratio": 1.5227272727272727, "no_speech_prob":
  0.005211774259805679}, {"id": 332, "seek": 209224, "start": 2102.72, "end": 2112.4799999999996,
  "text": " working on stuff as well. But also to go back to the previous thing, the
  vector database that", "tokens": [50888, 1364, 322, 1507, 382, 731, 13, 583, 611,
  281, 352, 646, 281, 264, 3894, 551, 11, 264, 8062, 8149, 300, 51376], "temperature":
  0.0, "avg_logprob": -0.17815639078617096, "compression_ratio": 1.5227272727272727,
  "no_speech_prob": 0.005211774259805679}, {"id": 333, "seek": 209224, "start": 2112.4799999999996,
  "end": 2119.8399999999997, "text": " surrounds the engine as well, which might just
  look like more traditional database features", "tokens": [51376, 44576, 264, 2848,
  382, 731, 11, 597, 1062, 445, 574, 411, 544, 5164, 8149, 4122, 51744], "temperature":
  0.0, "avg_logprob": -0.17815639078617096, "compression_ratio": 1.5227272727272727,
  "no_speech_prob": 0.005211774259805679}, {"id": 334, "seek": 211984, "start": 2120.32,
  "end": 2127.52, "text": " rather than and simply applied to vector search rather
  than some breakthrough algorithms or", "tokens": [50388, 2831, 813, 293, 2935, 6456,
  281, 8062, 3164, 2831, 813, 512, 22397, 14642, 420, 50748], "temperature": 0.0,
  "avg_logprob": -0.2619583716759315, "compression_ratio": 1.5568181818181819, "no_speech_prob":
  0.0030265129171311855}, {"id": 335, "seek": 211984, "start": 2128.7200000000003,
  "end": 2133.04, "text": " things like that. Although, yeah, you know, the filtering
  that we introduced with point", "tokens": [50808, 721, 411, 300, 13, 5780, 11, 1338,
  11, 291, 458, 11, 264, 30822, 300, 321, 7268, 365, 935, 51024], "temperature": 0.0,
  "avg_logprob": -0.2619583716759315, "compression_ratio": 1.5568181818181819, "no_speech_prob":
  0.0030265129171311855}, {"id": 336, "seek": 211984, "start": 2133.04, "end": 2143.92,
  "text": " on 2.0 is doing single stage filtering on vector index was, let''s say,
  let''s not say that it''s", "tokens": [51024, 322, 568, 13, 15, 307, 884, 2167,
  3233, 30822, 322, 8062, 8186, 390, 11, 718, 311, 584, 11, 718, 311, 406, 584, 300,
  309, 311, 51568], "temperature": 0.0, "avg_logprob": -0.2619583716759315, "compression_ratio":
  1.5568181818181819, "no_speech_prob": 0.0030265129171311855}, {"id": 337, "seek":
  214392, "start": 2144.0, "end": 2149.92, "text": " a collot of late nights in the
  garage. Yeah, yeah, sounds exciting and sounds like what your", "tokens": [50368,
  257, 1263, 310, 295, 3469, 13249, 294, 264, 14400, 13, 865, 11, 1338, 11, 3263,
  4670, 293, 3263, 411, 437, 428, 50664], "temperature": 0.0, "avg_logprob": -0.19278801144577387,
  "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.007601321674883366},
  {"id": 338, "seek": 214392, "start": 2149.92, "end": 2157.84, "text": " customers
  will benefit from, right? Almost immediately. Yeah, that''s fantastic. Yeah, I was
  thinking,", "tokens": [50664, 4581, 486, 5121, 490, 11, 558, 30, 12627, 4258, 13,
  865, 11, 300, 311, 5456, 13, 865, 11, 286, 390, 1953, 11, 51060], "temperature":
  0.0, "avg_logprob": -0.19278801144577387, "compression_ratio": 1.7153024911032029,
  "no_speech_prob": 0.007601321674883366}, {"id": 339, "seek": 214392, "start": 2157.84,
  "end": 2163.6800000000003, "text": " like, do you want to add anything more on Vinegon
  or like, for instance, if somebody wants to try it", "tokens": [51060, 411, 11,
  360, 291, 528, 281, 909, 1340, 544, 322, 40569, 10660, 420, 411, 11, 337, 5197,
  11, 498, 2618, 2738, 281, 853, 309, 51352], "temperature": 0.0, "avg_logprob": -0.19278801144577387,
  "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.007601321674883366},
  {"id": 340, "seek": 214392, "start": 2163.6800000000003, "end": 2169.28, "text":
  " out today, what''s the process looks like or should they just shoot you at the
  email? Yeah, well,", "tokens": [51352, 484, 965, 11, 437, 311, 264, 1399, 1542,
  411, 420, 820, 436, 445, 3076, 291, 412, 264, 3796, 30, 865, 11, 731, 11, 51632],
  "temperature": 0.0, "avg_logprob": -0.19278801144577387, "compression_ratio": 1.7153024911032029,
  "no_speech_prob": 0.007601321674883366}, {"id": 341, "seek": 214392, "start": 2169.28,
  "end": 2173.2000000000003, "text": " if they want to shoot me an email, they''re
  welcome to do that. If they want to a t-shirt,", "tokens": [51632, 498, 436, 528,
  281, 3076, 385, 364, 3796, 11, 436, 434, 2928, 281, 360, 300, 13, 759, 436, 528,
  281, 257, 256, 12, 15313, 11, 51828], "temperature": 0.0, "avg_logprob": -0.19278801144577387,
  "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.007601321674883366},
  {"id": 342, "seek": 217320, "start": 2173.2, "end": 2181.2, "text": " send me an
  email, grabgetpanko.io. But actually, we want to make it very easy for people to
  start", "tokens": [50364, 2845, 385, 364, 3796, 11, 4444, 847, 79, 657, 78, 13,
  1004, 13, 583, 767, 11, 321, 528, 281, 652, 309, 588, 1858, 337, 561, 281, 722,
  50764], "temperature": 0.0, "avg_logprob": -0.15735796585823725, "compression_ratio":
  1.7180616740088106, "no_speech_prob": 0.0009715275373309851}, {"id": 343, "seek":
  217320, "start": 2181.2, "end": 2187.8399999999997, "text": " and experiment with.
  And so you can go to panko.io slash start and create a free account. And for", "tokens":
  [50764, 293, 5120, 365, 13, 400, 370, 291, 393, 352, 281, 280, 657, 78, 13, 1004,
  17330, 722, 293, 1884, 257, 1737, 2696, 13, 400, 337, 51096], "temperature": 0.0,
  "avg_logprob": -0.15735796585823725, "compression_ratio": 1.7180616740088106, "no_speech_prob":
  0.0009715275373309851}, {"id": 344, "seek": 217320, "start": 2187.8399999999997,
  "end": 2197.04, "text": " small workloads, it''s actually free to use. You get one
  pod, which is enough for, definitely enough", "tokens": [51096, 1359, 32452, 11,
  309, 311, 767, 1737, 281, 764, 13, 509, 483, 472, 2497, 11, 597, 307, 1547, 337,
  11, 2138, 1547, 51556], "temperature": 0.0, "avg_logprob": -0.15735796585823725,
  "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.0009715275373309851},
  {"id": 345, "seek": 217320, "start": 2197.04, "end": 2201.7599999999998, "text":
  " for experimenting. And if you have a small workload, it''s enough for your production
  use case.", "tokens": [51556, 337, 29070, 13, 400, 498, 291, 362, 257, 1359, 20139,
  11, 309, 311, 1547, 337, 428, 4265, 764, 1389, 13, 51792], "temperature": 0.0, "avg_logprob":
  -0.15735796585823725, "compression_ratio": 1.7180616740088106, "no_speech_prob":
  0.0009715275373309851}, {"id": 346, "seek": 220320, "start": 2203.2, "end": 2207.12,
  "text": " That''s the easiest and fastest way to sign up. You don''t have to talk
  to anyone.", "tokens": [50364, 663, 311, 264, 12889, 293, 14573, 636, 281, 1465,
  493, 13, 509, 500, 380, 362, 281, 751, 281, 2878, 13, 50560], "temperature": 0.0,
  "avg_logprob": -0.12020600788177006, "compression_ratio": 1.4514285714285715, "no_speech_prob":
  0.0009048613719642162}, {"id": 347, "seek": 220320, "start": 2209.3599999999997,
  "end": 2218.08, "text": " If you need custom deployment configurations, like certain
  availability zones, or", "tokens": [50672, 759, 291, 643, 2375, 19317, 31493, 11,
  411, 1629, 17945, 16025, 11, 420, 51108], "temperature": 0.0, "avg_logprob": -0.12020600788177006,
  "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.0009048613719642162},
  {"id": 348, "seek": 220320, "start": 2220.16, "end": 2225.6, "text": " anything
  else, you can send me an email or you can use a contact form on our site and we''ll",
  "tokens": [51212, 1340, 1646, 11, 291, 393, 2845, 385, 364, 3796, 420, 291, 393,
  764, 257, 3385, 1254, 322, 527, 3621, 293, 321, 603, 51484], "temperature": 0.0,
  "avg_logprob": -0.12020600788177006, "compression_ratio": 1.4514285714285715, "no_speech_prob":
  0.0009048613719642162}, {"id": 349, "seek": 222560, "start": 2226.3199999999997,
  "end": 2229.52, "text": " get you set up. And it''s almost as quick. We just have
  to", "tokens": [50400, 483, 291, 992, 493, 13, 400, 309, 311, 1920, 382, 1702, 13,
  492, 445, 362, 281, 50560], "temperature": 0.0, "avg_logprob": -0.13275982471222572,
  "compression_ratio": 1.555023923444976, "no_speech_prob": 0.008896099403500557},
  {"id": 350, "seek": 222560, "start": 2232.24, "end": 2238.56, "text": " set up some
  configurations. But we want to help you get to production. And that means", "tokens":
  [50696, 992, 493, 512, 31493, 13, 583, 321, 528, 281, 854, 291, 483, 281, 4265,
  13, 400, 300, 1355, 51012], "temperature": 0.0, "avg_logprob": -0.13275982471222572,
  "compression_ratio": 1.555023923444976, "no_speech_prob": 0.008896099403500557},
  {"id": 351, "seek": 222560, "start": 2239.04, "end": 2243.36, "text": " not standing
  in your way. So that''s the best way to do it. Go to panko.io slash start.", "tokens":
  [51036, 406, 4877, 294, 428, 636, 13, 407, 300, 311, 264, 1151, 636, 281, 360, 309,
  13, 1037, 281, 280, 657, 78, 13, 1004, 17330, 722, 13, 51252], "temperature": 0.0,
  "avg_logprob": -0.13275982471222572, "compression_ratio": 1.555023923444976, "no_speech_prob":
  0.008896099403500557}, {"id": 352, "seek": 222560, "start": 2244.4, "end": 2249.36,
  "text": " Awesome. And we''ll make sure to link that in the notes as well. And you
  said, what do you mean", "tokens": [51304, 10391, 13, 400, 321, 603, 652, 988, 281,
  2113, 300, 294, 264, 5570, 382, 731, 13, 400, 291, 848, 11, 437, 360, 291, 914,
  51552], "temperature": 0.0, "avg_logprob": -0.13275982471222572, "compression_ratio":
  1.555023923444976, "no_speech_prob": 0.008896099403500557}, {"id": 353, "seek":
  224936, "start": 2249.44, "end": 2256.0, "text": " Kubernetes, right? Kubernetes
  pod. Oh yeah. I mean, we didn''t touch on this in this", "tokens": [50368, 23145,
  11, 558, 30, 23145, 2497, 13, 876, 1338, 13, 286, 914, 11, 321, 994, 380, 2557,
  322, 341, 294, 341, 50696], "temperature": 0.0, "avg_logprob": -0.2332640730816385,
  "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.02308342233300209},
  {"id": 354, "seek": 224936, "start": 2256.7200000000003, "end": 2262.6400000000003,
  "text": " in this episode, but obviously you guys are scaling with Kubernetes. So
  you''re also modern on", "tokens": [50732, 294, 341, 3500, 11, 457, 2745, 291, 1074,
  366, 21589, 365, 23145, 13, 407, 291, 434, 611, 4363, 322, 51028], "temperature":
  0.0, "avg_logprob": -0.2332640730816385, "compression_ratio": 1.6150442477876106,
  "no_speech_prob": 0.02308342233300209}, {"id": 355, "seek": 224936, "start": 2262.6400000000003,
  "end": 2270.08, "text": " that site as well. Oh yeah, we, we, you know, I should
  have mentioned this when you asked about", "tokens": [51028, 300, 3621, 382, 731,
  13, 876, 1338, 11, 321, 11, 321, 11, 291, 458, 11, 286, 820, 362, 2835, 341, 562,
  291, 2351, 466, 51400], "temperature": 0.0, "avg_logprob": -0.2332640730816385,
  "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.02308342233300209},
  {"id": 356, "seek": 224936, "start": 2270.08, "end": 2278.08, "text": " the inner
  workings. But yeah, we''re using Kubernetes to make the whole service horizontally",
  "tokens": [51400, 264, 7284, 589, 1109, 13, 583, 1338, 11, 321, 434, 1228, 23145,
  281, 652, 264, 1379, 2643, 33796, 51800], "temperature": 0.0, "avg_logprob": -0.2332640730816385,
  "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.02308342233300209},
  {"id": 357, "seek": 227808, "start": 2278.08, "end": 2283.04, "text": " scalable.
  And of course, the total managed on our side. So you don''t have to know anything
  about", "tokens": [50364, 38481, 13, 400, 295, 1164, 11, 264, 3217, 6453, 322, 527,
  1252, 13, 407, 291, 500, 380, 362, 281, 458, 1340, 466, 50612], "temperature": 0.0,
  "avg_logprob": -0.2074084886362855, "compression_ratio": 1.4795918367346939, "no_speech_prob":
  0.0007838575402274728}, {"id": 358, "seek": 227808, "start": 2283.04, "end": 2293.52,
  "text": " containers or Kubernetes or, or worry about any of it. But I mean, Kafka
  for streaming to support", "tokens": [50612, 17089, 420, 23145, 420, 11, 420, 3292,
  466, 604, 295, 309, 13, 583, 286, 914, 11, 47064, 337, 11791, 281, 1406, 51136],
  "temperature": 0.0, "avg_logprob": -0.2074084886362855, "compression_ratio": 1.4795918367346939,
  "no_speech_prob": 0.0007838575402274728}, {"id": 359, "seek": 227808, "start": 2293.52,
  "end": 2304.16, "text": " streaming index updates or batch, batch updates. There
  are load balancers that are API gateways", "tokens": [51136, 11791, 8186, 9205,
  420, 15245, 11, 15245, 9205, 13, 821, 366, 3677, 3119, 4463, 433, 300, 366, 9362,
  8539, 942, 51668], "temperature": 0.0, "avg_logprob": -0.2074084886362855, "compression_ratio":
  1.4795918367346939, "no_speech_prob": 0.0007838575402274728}, {"id": 360, "seek":
  230416, "start": 2304.24, "end": 2308.16, "text": " that are just a bunch of different.
  There''s a key value store under the hood.", "tokens": [50368, 300, 366, 445, 257,
  3840, 295, 819, 13, 821, 311, 257, 2141, 2158, 3531, 833, 264, 13376, 13, 50564],
  "temperature": 0.0, "avg_logprob": -0.16671541574839, "compression_ratio": 1.603846153846154,
  "no_speech_prob": 0.011620491743087769}, {"id": 361, "seek": 230416, "start": 2310.48,
  "end": 2314.48, "text": " If you want to see the architecture, you can cut our docs
  and learn a bit more about it. But again,", "tokens": [50680, 759, 291, 528, 281,
  536, 264, 9482, 11, 291, 393, 1723, 527, 45623, 293, 1466, 257, 857, 544, 466, 309,
  13, 583, 797, 11, 50880], "temperature": 0.0, "avg_logprob": -0.16671541574839,
  "compression_ratio": 1.603846153846154, "no_speech_prob": 0.011620491743087769},
  {"id": 362, "seek": 230416, "start": 2314.48, "end": 2318.3199999999997, "text":
  " you don''t have to know anything about it. And that''s the point. We make it a,",
  "tokens": [50880, 291, 500, 380, 362, 281, 458, 1340, 466, 309, 13, 400, 300, 311,
  264, 935, 13, 492, 652, 309, 257, 11, 51072], "temperature": 0.0, "avg_logprob":
  -0.16671541574839, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.011620491743087769},
  {"id": 363, "seek": 230416, "start": 2320.24, "end": 2326.8799999999997, "text":
  " you just make your API calls and, and get your results and do something with those
  results.", "tokens": [51168, 291, 445, 652, 428, 9362, 5498, 293, 11, 293, 483,
  428, 3542, 293, 360, 746, 365, 729, 3542, 13, 51500], "temperature": 0.0, "avg_logprob":
  -0.16671541574839, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.011620491743087769},
  {"id": 364, "seek": 230416, "start": 2326.8799999999997, "end": 2331.52, "text":
  " Yeah, exactly. Fantastic. And by the way, are you planning to kind of", "tokens":
  [51500, 865, 11, 2293, 13, 21320, 13, 400, 538, 264, 636, 11, 366, 291, 5038, 281,
  733, 295, 51732], "temperature": 0.0, "avg_logprob": -0.16671541574839, "compression_ratio":
  1.603846153846154, "no_speech_prob": 0.011620491743087769}, {"id": 365, "seek":
  233152, "start": 2332.48, "end": 2338.0, "text": " at some point, maybe open source,
  or actually implement some things for the public to send the", "tokens": [50412,
  412, 512, 935, 11, 1310, 1269, 4009, 11, 420, 767, 4445, 512, 721, 337, 264, 1908,
  281, 2845, 264, 50688], "temperature": 0.0, "avg_logprob": -0.1901295848728455,
  "compression_ratio": 1.6260504201680672, "no_speech_prob": 0.003159665036946535},
  {"id": 366, "seek": 233152, "start": 2338.0, "end": 2342.32, "text": " data in?
  Well, do you think it''s not a problem at all? You know, kind of some kind of connector",
  "tokens": [50688, 1412, 294, 30, 1042, 11, 360, 291, 519, 309, 311, 406, 257, 1154,
  412, 439, 30, 509, 458, 11, 733, 295, 512, 733, 295, 19127, 50904], "temperature":
  0.0, "avg_logprob": -0.1901295848728455, "compression_ratio": 1.6260504201680672,
  "no_speech_prob": 0.003159665036946535}, {"id": 367, "seek": 233152, "start": 2342.32,
  "end": 2348.8, "text": " called some kind of gluing code to the pinecon on the side
  of integration, right? So I guess", "tokens": [50904, 1219, 512, 733, 295, 1563,
  9635, 3089, 281, 264, 15113, 1671, 322, 264, 1252, 295, 10980, 11, 558, 30, 407,
  286, 2041, 51228], "temperature": 0.0, "avg_logprob": -0.1901295848728455, "compression_ratio":
  1.6260504201680672, "no_speech_prob": 0.003159665036946535}, {"id": 368, "seek":
  233152, "start": 2348.8, "end": 2353.52, "text": " obviously clients will still
  look at how do they plug in pinecon in the right part of the architecture.", "tokens":
  [51228, 2745, 6982, 486, 920, 574, 412, 577, 360, 436, 5452, 294, 15113, 1671, 294,
  264, 558, 644, 295, 264, 9482, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1901295848728455,
  "compression_ratio": 1.6260504201680672, "no_speech_prob": 0.003159665036946535},
  {"id": 369, "seek": 235352, "start": 2354.4, "end": 2364.96, "text": " Yeah, we''re
  thinking a lot about that. We''re looking at what are the most common data sources.",
  "tokens": [50408, 865, 11, 321, 434, 1953, 257, 688, 466, 300, 13, 492, 434, 1237,
  412, 437, 366, 264, 881, 2689, 1412, 7139, 13, 50936], "temperature": 0.0, "avg_logprob":
  -0.2683268422665803, "compression_ratio": 1.373015873015873, "no_speech_prob": 0.0046066101640462875},
  {"id": 370, "seek": 235352, "start": 2366.72, "end": 2376.4, "text": " What is typical
  usage look like? And what''s the trickiest part for people? And", "tokens": [51024,
  708, 307, 7476, 14924, 574, 411, 30, 400, 437, 311, 264, 4282, 6495, 644, 337, 561,
  30, 400, 51508], "temperature": 0.0, "avg_logprob": -0.2683268422665803, "compression_ratio":
  1.373015873015873, "no_speech_prob": 0.0046066101640462875}, {"id": 371, "seek":
  237640, "start": 2376.64, "end": 2385.92, "text": " we are thinking about how to
  make the trickiest part, parts easiest, as many people as possible.", "tokens":
  [50376, 321, 366, 1953, 466, 577, 281, 652, 264, 4282, 6495, 644, 11, 3166, 12889,
  11, 382, 867, 561, 382, 1944, 13, 50840], "temperature": 0.0, "avg_logprob": -0.16395123799641928,
  "compression_ratio": 1.583673469387755, "no_speech_prob": 0.0027856784872710705},
  {"id": 372, "seek": 237640, "start": 2386.8, "end": 2394.0, "text": " So can''t
  say much more than that, but certainly we''ll have some common use cases covered
  soon.", "tokens": [50884, 407, 393, 380, 584, 709, 544, 813, 300, 11, 457, 3297,
  321, 603, 362, 512, 2689, 764, 3331, 5343, 2321, 13, 51244], "temperature": 0.0,
  "avg_logprob": -0.16395123799641928, "compression_ratio": 1.583673469387755, "no_speech_prob":
  0.0027856784872710705}, {"id": 373, "seek": 237640, "start": 2394.8, "end": 2400.2400000000002,
  "text": " Yeah, yeah, sure. I mean, that''s so important. I mean, a lot of things
  like in machine learning,", "tokens": [51284, 865, 11, 1338, 11, 988, 13, 286, 914,
  11, 300, 311, 370, 1021, 13, 286, 914, 11, 257, 688, 295, 721, 411, 294, 3479, 2539,
  11, 51556], "temperature": 0.0, "avg_logprob": -0.16395123799641928, "compression_ratio":
  1.583673469387755, "no_speech_prob": 0.0027856784872710705}, {"id": 374, "seek":
  237640, "start": 2400.2400000000002, "end": 2405.6, "text": " you know, that like
  80% goes to data collection and cleaning. And then in the end, you plug in some",
  "tokens": [51556, 291, 458, 11, 300, 411, 4688, 4, 1709, 281, 1412, 5765, 293, 8924,
  13, 400, 550, 294, 264, 917, 11, 291, 5452, 294, 512, 51824], "temperature": 0.0,
  "avg_logprob": -0.16395123799641928, "compression_ratio": 1.583673469387755, "no_speech_prob":
  0.0027856784872710705}, {"id": 375, "seek": 240560, "start": 2405.6, "end": 2411.2799999999997,
  "text": " water, like, ooh, I sold the task, right? And the same kind of goes to
  the trying databases or,", "tokens": [50364, 1281, 11, 411, 11, 17024, 11, 286,
  3718, 264, 5633, 11, 558, 30, 400, 264, 912, 733, 295, 1709, 281, 264, 1382, 22380,
  420, 11, 50648], "temperature": 0.0, "avg_logprob": -0.23021762742908722, "compression_ratio":
  1.6470588235294117, "no_speech_prob": 0.0008808431448414922}, {"id": 376, "seek":
  240560, "start": 2411.2799999999997, "end": 2416.7999999999997, "text": " you know,
  software like, okay, how do I plug this in? And days go by and you''re still figuring
  things", "tokens": [50648, 291, 458, 11, 4722, 411, 11, 1392, 11, 577, 360, 286,
  5452, 341, 294, 30, 400, 1708, 352, 538, 293, 291, 434, 920, 15213, 721, 50924],
  "temperature": 0.0, "avg_logprob": -0.23021762742908722, "compression_ratio": 1.6470588235294117,
  "no_speech_prob": 0.0008808431448414922}, {"id": 377, "seek": 240560, "start": 2416.7999999999997,
  "end": 2422.88, "text": " out. So I think that''s the, that''s something to address.
  And I guess you guys are doing that, right?", "tokens": [50924, 484, 13, 407, 286,
  519, 300, 311, 264, 11, 300, 311, 746, 281, 2985, 13, 400, 286, 2041, 291, 1074,
  366, 884, 300, 11, 558, 30, 51228], "temperature": 0.0, "avg_logprob": -0.23021762742908722,
  "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0008808431448414922},
  {"id": 378, "seek": 240560, "start": 2424.24, "end": 2431.04, "text": " Yeah, yeah,
  we definitely, and also a lot of people, you know, we expect people to keep their",
  "tokens": [51296, 865, 11, 1338, 11, 321, 2138, 11, 293, 611, 257, 688, 295, 561,
  11, 291, 458, 11, 321, 2066, 561, 281, 1066, 641, 51636], "temperature": 0.0, "avg_logprob":
  -0.23021762742908722, "compression_ratio": 1.6470588235294117, "no_speech_prob":
  0.0008808431448414922}, {"id": 379, "seek": 243104, "start": 2431.04, "end": 2437.52,
  "text": " data warehouse and their document store, you know, because we are, we
  are your infected database. We''re", "tokens": [50364, 1412, 22244, 293, 641, 4166,
  3531, 11, 291, 458, 11, 570, 321, 366, 11, 321, 366, 428, 15414, 8149, 13, 492,
  434, 50688], "temperature": 0.0, "avg_logprob": -0.22446534253548886, "compression_ratio":
  1.5935828877005347, "no_speech_prob": 0.0006363232969306409}, {"id": 380, "seek":
  243104, "start": 2437.52, "end": 2447.44, "text": " not your blob storage or document
  storage. So a lot of people use PINCO and alongside the data warehouse", "tokens":
  [50688, 406, 428, 46115, 6725, 420, 4166, 6725, 13, 407, 257, 688, 295, 561, 764,
  430, 1464, 12322, 293, 12385, 264, 1412, 22244, 51184], "temperature": 0.0, "avg_logprob":
  -0.22446534253548886, "compression_ratio": 1.5935828877005347, "no_speech_prob":
  0.0006363232969306409}, {"id": 381, "seek": 243104, "start": 2448.96, "end": 2456.08,
  "text": " or some other database. And the easier and more seamless connections are
  between the two,", "tokens": [51260, 420, 512, 661, 8149, 13, 400, 264, 3571, 293,
  544, 28677, 9271, 366, 1296, 264, 732, 11, 51616], "temperature": 0.0, "avg_logprob":
  -0.22446534253548886, "compression_ratio": 1.5935828877005347, "no_speech_prob":
  0.0006363232969306409}, {"id": 382, "seek": 245608, "start": 2456.56, "end": 2461.36,
  "text": " the easier it is to get factory search into production. So that''s what
  we''re thinking about.", "tokens": [50388, 264, 3571, 309, 307, 281, 483, 9265,
  3164, 666, 4265, 13, 407, 300, 311, 437, 321, 434, 1953, 466, 13, 50628], "temperature":
  0.0, "avg_logprob": -0.25223926197398794, "compression_ratio": 1.5737051792828685,
  "no_speech_prob": 0.00350744160823524}, {"id": 383, "seek": 245608, "start": 2462.0,
  "end": 2468.4, "text": " Yeah, sounds great. Thanks. And yeah, I think we can wrap
  up like I really enjoyed talking to you, Greg.", "tokens": [50660, 865, 11, 3263,
  869, 13, 2561, 13, 400, 1338, 11, 286, 519, 321, 393, 7019, 493, 411, 286, 534,
  4626, 1417, 281, 291, 11, 11490, 13, 50980], "temperature": 0.0, "avg_logprob":
  -0.25223926197398794, "compression_ratio": 1.5737051792828685, "no_speech_prob":
  0.00350744160823524}, {"id": 384, "seek": 245608, "start": 2468.4, "end": 2474.96,
  "text": " I mean, your, your T-shirt is the best. I, once I get it, I will wear
  it as well. And I''ll be", "tokens": [50980, 286, 914, 11, 428, 11, 428, 314, 12,
  15313, 307, 264, 1151, 13, 286, 11, 1564, 286, 483, 309, 11, 286, 486, 3728, 309,
  382, 731, 13, 400, 286, 603, 312, 51308], "temperature": 0.0, "avg_logprob": -0.25223926197398794,
  "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.00350744160823524},
  {"id": 385, "seek": 245608, "start": 2474.96, "end": 2481.6, "text": " compatible
  with the researcher. So thanks so much for your thoughts. I mean, this was super
  deep. But I", "tokens": [51308, 18218, 365, 264, 21751, 13, 407, 3231, 370, 709,
  337, 428, 4598, 13, 286, 914, 11, 341, 390, 1687, 2452, 13, 583, 286, 51640], "temperature":
  0.0, "avg_logprob": -0.25223926197398794, "compression_ratio": 1.5737051792828685,
  "no_speech_prob": 0.00350744160823524}, {"id": 386, "seek": 248160, "start": 2481.6,
  "end": 2488.08, "text": " mean, also you shared some of your personal kind of, you
  know, attitude and aspirations in this area.", "tokens": [50364, 914, 11, 611, 291,
  5507, 512, 295, 428, 2973, 733, 295, 11, 291, 458, 11, 10157, 293, 32458, 294, 341,
  1859, 13, 50688], "temperature": 0.0, "avg_logprob": -0.16516026910745873, "compression_ratio":
  1.5680933852140078, "no_speech_prob": 0.006213393993675709}, {"id": 387, "seek":
  248160, "start": 2488.08, "end": 2494.7999999999997, "text": " It''s still emerging,
  but I mean, it''s great to see you guys at the forefront of it. And I hope to",
  "tokens": [50688, 467, 311, 920, 14989, 11, 457, 286, 914, 11, 309, 311, 869, 281,
  536, 291, 1074, 412, 264, 27287, 295, 309, 13, 400, 286, 1454, 281, 51024], "temperature":
  0.0, "avg_logprob": -0.16516026910745873, "compression_ratio": 1.5680933852140078,
  "no_speech_prob": 0.006213393993675709}, {"id": 388, "seek": 248160, "start": 2494.7999999999997,
  "end": 2500.64, "text": " hear more. And just last question, where our listeners
  can follow you or maybe like Twitter or LinkedIn,", "tokens": [51024, 1568, 544,
  13, 400, 445, 1036, 1168, 11, 689, 527, 23274, 393, 1524, 291, 420, 1310, 411, 5794,
  420, 20657, 11, 51316], "temperature": 0.0, "avg_logprob": -0.16516026910745873,
  "compression_ratio": 1.5680933852140078, "no_speech_prob": 0.006213393993675709},
  {"id": 389, "seek": 248160, "start": 2500.64, "end": 2508.88, "text": " where are
  you kind of publicly available? So for PINCO, you, on, on, we publish a lot of things
  on", "tokens": [51316, 689, 366, 291, 733, 295, 14843, 2435, 30, 407, 337, 430,
  1464, 12322, 11, 291, 11, 322, 11, 322, 11, 321, 11374, 257, 688, 295, 721, 322,
  51728], "temperature": 0.0, "avg_logprob": -0.16516026910745873, "compression_ratio":
  1.5680933852140078, "no_speech_prob": 0.006213393993675709}, {"id": 390, "seek":
  250888, "start": 2508.88, "end": 2515.84, "text": " our website. So you can go to
  PINCO.io and at the bottom, you can subscribe for email updates. And", "tokens":
  [50364, 527, 3144, 13, 407, 291, 393, 352, 281, 430, 1464, 12322, 13, 1004, 293,
  412, 264, 2767, 11, 291, 393, 3022, 337, 3796, 9205, 13, 400, 50712], "temperature":
  0.0, "avg_logprob": -0.15501789930390147, "compression_ratio": 1.4326923076923077,
  "no_speech_prob": 0.03184689208865166}, {"id": 391, "seek": 250888, "start": 2515.84,
  "end": 2520.1600000000003, "text": " you get, you know, all these face articles
  and things like that. You heard about, you''ll get them", "tokens": [50712, 291,
  483, 11, 291, 458, 11, 439, 613, 1851, 11290, 293, 721, 411, 300, 13, 509, 2198,
  466, 11, 291, 603, 483, 552, 50928], "temperature": 0.0, "avg_logprob": -0.15501789930390147,
  "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.03184689208865166},
  {"id": 392, "seek": 250888, "start": 2520.1600000000003, "end": 2527.36, "text":
  " in your inbox on Twitter. We''re at PINCO and underscore IO. On LinkedIn, we also
  have a big following", "tokens": [50928, 294, 428, 35067, 322, 5794, 13, 492, 434,
  412, 430, 1464, 12322, 293, 37556, 39839, 13, 1282, 20657, 11, 321, 611, 362, 257,
  955, 3480, 51288], "temperature": 0.0, "avg_logprob": -0.15501789930390147, "compression_ratio":
  1.4326923076923077, "no_speech_prob": 0.03184689208865166}, {"id": 393, "seek":
  252736, "start": 2528.32, "end": 2539.36, "text": " there. Me personally, I''m at
  Gregory underscore Kogen. Gregory is GRI, GOR, IY underscore K-O-G-A-N.", "tokens":
  [50412, 456, 13, 1923, 5665, 11, 286, 478, 412, 11490, 827, 37556, 591, 8799, 13,
  11490, 827, 307, 460, 5577, 11, 460, 2483, 11, 286, 56, 37556, 591, 12, 46, 12,
  38, 12, 32, 12, 45, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3060902815598708,
  "compression_ratio": 1.3175675675675675, "no_speech_prob": 0.02356462925672531},
  {"id": 394, "seek": 252736, "start": 2542.48, "end": 2547.6, "text": " But a lot
  of things I post there are PINCO and related because that''s what I think about
  a lot", "tokens": [51120, 583, 257, 688, 295, 721, 286, 2183, 456, 366, 430, 1464,
  12322, 293, 4077, 570, 300, 311, 437, 286, 519, 466, 257, 688, 51376], "temperature":
  0.0, "avg_logprob": -0.3060902815598708, "compression_ratio": 1.3175675675675675,
  "no_speech_prob": 0.02356462925672531}, {"id": 395, "seek": 254760, "start": 2547.68,
  "end": 2558.88, "text": " these days. And I''ll also add that big credit to you
  for also leading the way with, with doing a", "tokens": [50368, 613, 1708, 13, 400,
  286, 603, 611, 909, 300, 955, 5397, 281, 291, 337, 611, 5775, 264, 636, 365, 11,
  365, 884, 257, 50928], "temperature": 0.0, "avg_logprob": -0.17860854012625557,
  "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.007292834110558033},
  {"id": 396, "seek": 254760, "start": 2558.88, "end": 2568.48, "text": " podcast
  like this. Yeah, it''s exciting to see more people learn about this, about Factor
  Search,", "tokens": [50928, 7367, 411, 341, 13, 865, 11, 309, 311, 4670, 281, 536,
  544, 561, 1466, 466, 341, 11, 466, 479, 15104, 17180, 11, 51408], "temperature":
  0.0, "avg_logprob": -0.17860854012625557, "compression_ratio": 1.5139664804469273,
  "no_speech_prob": 0.007292834110558033}, {"id": 397, "seek": 254760, "start": 2568.48,
  "end": 2574.3199999999997, "text": " and start thinking about it and implementing
  it. And a lot of it is thanks to", "tokens": [51408, 293, 722, 1953, 466, 309, 293,
  18114, 309, 13, 400, 257, 688, 295, 309, 307, 3231, 281, 51700], "temperature":
  0.0, "avg_logprob": -0.17860854012625557, "compression_ratio": 1.5139664804469273,
  "no_speech_prob": 0.007292834110558033}, {"id": 398, "seek": 257432, "start": 2574.8,
  "end": 2582.2400000000002, "text": " evangelists like you who put in the work to
  do that. So thanks to you. Glad to hear that,", "tokens": [50388, 24546, 1751, 411,
  291, 567, 829, 294, 264, 589, 281, 360, 300, 13, 407, 3231, 281, 291, 13, 28301,
  281, 1568, 300, 11, 50760], "temperature": 0.0, "avg_logprob": -0.21562442582907135,
  "compression_ratio": 1.6311111111111112, "no_speech_prob": 0.018412329256534576},
  {"id": 399, "seek": 257432, "start": 2582.2400000000002, "end": 2587.1200000000003,
  "text": " right? Thanks so much. And actually, I must say that I''m educating myself
  equally on this journey.", "tokens": [50760, 558, 30, 2561, 370, 709, 13, 400, 767,
  11, 286, 1633, 584, 300, 286, 478, 28835, 2059, 12309, 322, 341, 4671, 13, 51004],
  "temperature": 0.0, "avg_logprob": -0.21562442582907135, "compression_ratio": 1.6311111111111112,
  "no_speech_prob": 0.018412329256534576}, {"id": 400, "seek": 257432, "start": 2587.1200000000003,
  "end": 2594.0, "text": " So hopefully as part of this journey, you know, the listeners
  and the readers can, can", "tokens": [51004, 407, 4696, 382, 644, 295, 341, 4671,
  11, 291, 458, 11, 264, 23274, 293, 264, 17147, 393, 11, 393, 51348], "temperature":
  0.0, "avg_logprob": -0.21562442582907135, "compression_ratio": 1.6311111111111112,
  "no_speech_prob": 0.018412329256534576}, {"id": 401, "seek": 257432, "start": 2594.0,
  "end": 2601.6000000000004, "text": " educate as well. So in the end, you know, value
  increases by doing these things. So that''s,", "tokens": [51348, 16092, 382, 731,
  13, 407, 294, 264, 917, 11, 291, 458, 11, 2158, 8637, 538, 884, 613, 721, 13, 407,
  300, 311, 11, 51728], "temperature": 0.0, "avg_logprob": -0.21562442582907135, "compression_ratio":
  1.6311111111111112, "no_speech_prob": 0.018412329256534576}, {"id": 402, "seek":
  260160, "start": 2601.6, "end": 2608.7999999999997, "text": " that''s what drives
  me here. So thanks so much for joining this show. Yeah, I hope we can record", "tokens":
  [50364, 300, 311, 437, 11754, 385, 510, 13, 407, 3231, 370, 709, 337, 5549, 341,
  855, 13, 865, 11, 286, 1454, 321, 393, 2136, 50724], "temperature": 0.0, "avg_logprob":
  -0.2604670891394982, "compression_ratio": 1.3541666666666667, "no_speech_prob":
  0.009526950307190418}, {"id": 403, "seek": 260160, "start": 2608.7999999999997,
  "end": 2617.52, "text": " another one at some time down the road. Yeah, that would
  be awesome. Awesome. Thanks Greg. Bye bye.", "tokens": [50724, 1071, 472, 412, 512,
  565, 760, 264, 3060, 13, 865, 11, 300, 576, 312, 3476, 13, 10391, 13, 2561, 11490,
  13, 4621, 6543, 13, 51160], "temperature": 0.0, "avg_logprob": -0.2604670891394982,
  "compression_ratio": 1.3541666666666667, "no_speech_prob": 0.009526950307190418}]'
---

Hello everyone, so, Dr. Podcast here. Today I have Greg Coggen with the charter of marketing. He works for Pinecon. So today we will dive into Pinecon and maybe Greg will give us some highlights as well. Hi Greg. It's me, Tree. Thanks for having me. Yeah, awesome. Thanks for joining.
So I was thinking maybe you can introduce yourself to our audience because actually I personally was quite impressed that you're so technical and even though you're in charge of marketing, you're like your lingo is so technical.
So technical, so can you do have some technical background? Yeah, I actually have a degree in naval architecture. It's an engineering degree and that was my career for three years. And I did systems engineering and mechanical engineering electrical and so on.
While I was doing that, I also was moonlighting as a web developer and taught myself PHP and things like that and reading about startups and eventually became clear that I should make my day jobs related to startups.
And so I left my engineering career and went to work with startups with marketing and I fell in love with it. That was about nine years ago. And I've been working with for the past eight years. I was consulting and advising technical startups on marketing.
And I loved it because I was able to use my engineering thinking and get along well with technical founders and the like the coding foundation I had allowed me to get a grasp for what it is the products do.
 And last year I joined pineconous the VP of marketing and the engineering background certainly helps we have a technical product technical users and really everyone at the company has a very technical background, even our director of product has a PhD in electrical engineering just to give you a sense.
And I was like, wow, that's impressive. Yeah, that's like you mentioned to the H.P. actually this was one of the first languages I called learned to code and decide Pearl, but yeah, this days.
I'm almost I slowed down before before I told people I learned PHP because I know there's a bit of stigma with it. It was like messy and it's like, you know, not as pristine or.
Yeah, as fancy as something else, but they got the job job done like with with that foundation, a lot of other things made a lot more sense. Yeah, absolutely. Yeah, I mean, I also enjoyed actually like it was one of the first jobs I got was in PHP.
So I built like a forum and every class in the code was starting with oops and I was asking the new engineer doesn't mean all OP like object oriented programming. And he said, no, it just means oops, I'm not technical. So he wasn't technical enough to know what is all P.
But anyway, that was kind of funny. Yeah, that's cool. So basically like you have the technical background. You also know how to explain things.
I think it's very important in our profession at large and sounds like you've been you've been advancing into this topic more and more to the level of becoming, you know, symbol or like BPO marketing actually to be precise, right. Yeah, that's awesome.
So tell me more a bit more about fine code like what what are you guys building and yeah, I know that you've recently had a major upgrade of fine code. Maybe if you wish you could highlight some of the improvements you guys made. Sure.
So we're building a vector database that makes it very easy to deploy to build and deploy the vector search into production applications. This is especially useful for semantic search and recommendation systems.
There are, we saw, I should say the founders saw that there's several ways of doing this to try and emulate the big companies like Facebook, Google, Microsoft and Spotify.
 They all involved a lot of engineering work and a lot of infrastructure work and maintenance to actually make it run in production, whether you're a small startup and have better things to focus on or a big tech company and also have better things to focus on, especially when supporting your search and recommender systems would involve like a big team of engineers.
So we recently announced pine cone 2.0 and that's that's a major release that gets us closer to helping companies deploy this in production.
So one of the biggest things we've heard from users is that to get this in production, they need to emulate some of their traditional search features they had before, but they're trying to replace. And that was specifically filtering.
They wanted to have some control over the nearest neighbor search results that they were getting through pine cone.
Another thing was cost since typically vector search nearest neighbor searches are done in memory companies with millions and billions of items, which are the types of companies that benefit most from pine cone.
We're finding it prohibitively expensive to do vector search not just on pine cone, but anywhere. And so for them, the barrier to getting into production wasn't lack of engineering teams. It was like just astronomical cost projections.
And so for that, we are releasing hybrid storage, which stores part of the, which basically stores some data on disk and a smaller amount of data in memory, which reduces costs up to 10x, reduces infrastructure costs. And we're passing that along to users.
So it's going to reduce it or manage the infrastructure, but their costs are going to go down as well. And there's some other things like sock to compliance. They're totally new rest API and Python client. And console. And a bunch of other things as well.
So, yeah, and there's even more I can't announce just yet, but we're our engineering team is growing in our development velocities picking up as well. So we're going to have lots of new things to share very soon. Yeah, that's fantastic. Can't wait. And then compress on the on the 2.0 release.
But I just noticed your t-shirt says love the nearest neighbor. Wow. This is so relevant to this discussion. We have lots more of these. Anyone can send me an email. I got pine cone that I know and I'll get your form to fill out to get one. Oh, thanks. Thanks, Greg. I'll gladly wear it.
So yeah, I mean that that covers the value prop behind your product. So I mean the key element for me is also that as you said, you're reducing cost and you know, like you provide fully managed, you know, solution to better search.
So teams don't have to kind of like run around, figure out some low level things and just get to business. That's great. So the next thing I wanted to ask you like more like on the lines of how you know there are different ways of implementing vector search right and there are different algorithms.
There is an end bench marks that will be big and then benchmarks soon as well. That competition is going for listeners outshare the link as well. But what ways did you kind of consider to implement your tech. I know some parts of it are proprietary.
So maybe you cannot share too much detail, but maybe you can share some things give us a clue how you do things on kind of like algorithmic side and also like kind of like speak to the product that large like, you know, you mentioned, so see two compliance.
So it was very important for your customers, right. So that also is kind of included in the how part.
Yeah, I'll be a little lighter on the technical side because I would rather, I'd rather point you to our docs and point people to our docs and some of the articles and examples we have, then say something that's imprecise from a technical standpoint.
Generally that there are sort of three layers, we see three layers in the inside of vector search solution or vector database. The lowest layer is the near neighbor search algorithm like annoy or hnsw. Then there's an index library, which contains those algorithms and that's like face.
And then there's a shell around that, which we're calling vector database that provides things like live index updates and crowd operations on vectors and filtering and metadata storage and things like that. So for the index, we, Pankoan does use face for exact search.
You can choose if what sort of engine you're running and a proprietary index for approximate search, which is obviously the bulk of use cases for us.
And we thought a lot about performance comparisons, maybe even open sourcing that proprietary index so we can, so we can be included in an end benchmark.
While we were thinking about that, we learned from users that actually like eaking out slightly more slightly lower latencies or slightly higher recall from the index was not really what they were after. That's not where they were stuck.
They were stuck on downstream things like horizontal scaling and adding features to an index. Setting up the infrastructure and managing it. And so since learning that and valid data that we focus much more on those things. And stayed with a proprietary index for the for approximate search.
And sure enough, we find that even people who ask a lot about this after they sign up and start using it, they really, you know, the solve their use case and they don't ask us about it again after that from some other search or recommendation system to vector search.
And you're just looking for an easy way to run it in production. So that's the use case just implement vector search and production.
 Or a lot of people come to us from from like an application side, which is they don't even know they want to use vector search, but they know they want to replace their semantic their keyword search with semantic search or they want to implement image similarity search that will work on fuzzy matches or they want to do anomaly detection.
So and or classification and things like that. It really is it has as many applications as search information retrieval general. A lot of people come to us for vectors, excuse me for semantic search. So they have their embedding models like bird or something like that.
And they got it working in the lab, the data science team got semantic search working using embeddings. Now they're like, okay, engineering team or ML engineering team.
How do we get this in our product? How do we make this? How do we keep latency below 200 milliseconds? How do we add filtering to this to give users control. And the ML engineering team is then goes out and finds like, oh, we can do this with something like bank home.
So those are those are the typical use cases, I would say semantic search, the most common or somebody just coming because they're looking for vector search and regardless of what it's for. Yeah, yeah, from from our from our perspective for pine cone.
We don't care what your data is like if it's in an embedding format, you can index it and then you search through it. Any it works with any model, any any, you know, initial data and because we have a rest API, you can call it from anywhere.
So you can use it in a notebook, you can use it in the backend application. Yeah, we're seeing a lot of interesting use cases. Yeah, sounds great. Sounds like a lot actually of use case that you mentioned.
I mean, obviously it's search, but then the answer to could also be like data science that they want to run.
If you take five, for instance, you know, metadata science teams, they run like large scale experiments using the library, but like obviously when that's the data science part, that's the exploration part.
But the moment you want to put this out to prod, you'll face a bunch of kind of like low level engineering concerns, like, oh, how do I do this? How do you do that? Reinventing the wheel isn't ever fun.
Well, sometimes it's fun if it's kind of like they'd work, but if you don't have time, you kind of like when I'm both faster than obviously you will want to use an existing solution for that. Yeah, we find that, you know, for the data science team, they don't, it's not their issue.
They need to develop the model and and prove that the method works. It becomes an engineering teams issue or the ML engineering teams issue. And yeah, they're often not exactly lacking things to do.
So, some organizations are all about like focusing on the core product and trying to use managed services wherever possible. Others like to develop things in house and prefer to take open source as much as possible.
So I think it depends on your, you know, how you prioritize your focus and what kind of, you know, what's your engineering culture at the company? Yeah, absolutely.
And sounds like you also address the elements of like, so see to and I believe you also will have GPR covered at some point already covered.
So we say we're GDPR friendly, which means there's no, there's no official certification you can get for being GDPR, you can just be following the regulations and able to make the proper disclosures and able to act on requests for deletion and things like that.
These are the types of things like the security aspects. It's another thing that a data science team might not force to when they're developing like a factor search solutions to some application. But when it goes engineering when you start talking about getting it into production.
And depending on the company, you're, yeah, you start, you know, all these things come up.
Does it meet our security, does it pass our security review? Does it pass our reliability requirements? Who's going to be on call if this thing goes down like all these things come up and we worry about those things so that the users don't have to.
Yeah, that's a big benefit like to the users again to focus on what matters to them. And by the way, I don't want to just so this doesn't come off as like promotional.
Anyone listening to this can treat this as just heads up about what you should think about if you want to get vector search in your production, even if you're using some other solution, like these are things you should plan for. And start thinking about it and making. Leaving time to do.
Yeah, absolutely. You don't want to be caught by surprise in those, those items for sure. Yeah, that's awesome. By the way, I remember that you guys also made a bunch of blog posts on like FICE and LSH. I mean, I really like the way you did it.
You know, it's almost look what looks like a comic book, you know, you know, get, get, get deep with, with these things. And I think you also shared the source code, like some notebooks. Is that right? Is that. Yeah, we, we, we publish. And articles on vector search on face on.
Semantic search different techniques and things like that. A lot of them are done by the very talented. James breaks, I should give him a shout out. We have a new one today about the index composite indexes and index factory in face.
We share code snippets and we have example notebooks for all of them. And yeah, we're very happy to see people like them. Even people who are not familiar with vector search will see it and it peaks their interest because engineers like to see how things work and learn new things.
And that's our goal. It's some of them have almost nothing to do with pine cone. And we have more people to learn about. Vector search to. Realize that they can use vector search to replace their to improve the current applications and.
If we succeed in that, I think it'll certainly help us, but really everyone in the. In this space. Yeah, I mean, absolutely. Those looks like our jam, you know, people are reading, citing and kind of discussing on Slack and things like that.
And yeah, it sounds like you guys are also kind of willing to share your knowledge with the community, even like beyond kind of share, you know, customer interaction and so on. Right. So that's that's awesome. Yeah. I think we are moving slowly to the third section of our podcast, which is why.
And I think I know it's a little bit more philosophical kind of stance and what you do. And kind of like how you do it. I don't know if you've been reflecting on your journey. I know you said you joined last year. Join bank on last year.
But I guess I'll start off by just asking you what motivates you to be part of vector search development and this community as much. Me personally, I've worked with 40, 40 startups when I was consulting over 40 startups. And when I met, you know, the founder of pine cone.
And learned about the product and about the space. I saw a familiar pattern, which caught my attention. And the familiar pattern was from 2015. Six years ago now, almost seven when I started working with the time, very small company called Domino Data Lab, which.
It's an ML ops platform at the time, we call that a data science platform. It's used by over 20% or the fortune 500 companies. And the time was a small team and it was a product for data scientists, but like nobody knew exactly what is a data scientist.
Few people called themselves that even if they were doing data science work. A lot of work data science work was done on just people's laptops. And there's no. It was a very young. Area, let's say. Not not quite mature. There's not a tooling for it and so on.
And over time, over a few years, it became, of course, data science became. A core function in many companies, like just like engineering and marketing and customer support. And as that happened, like having the right tooling for that function.
And kind of maturing the capabilities and making sure it's everything data sciences run can run in production securely and reliably and things like that. And so it became more important. Of course, the companies that were. Solving those things were growing with that demand.
And so I wanted to be a part of that journey, that kind of journey again. And again, I saw in Pinecon, I saw product that is pretty early in the space. And I saw a lot of data based concept and. We had to spend a lot of time explaining to people what that means they weren't getting it.
On the user side, you see many, many engineers doing ML engineering work. We don't yet call themselves ML engineers. They're still titled the software engineers. Or they might get data scientists, but they're now working on like production applications.
And also we see that companies are struggling as they as they want to take vector search out of the lab and into production production applications. They're running up against the same challenges like the technology they have. They had available wasn't quite. Built for that.
For huge scale and for like secure and reliable. And so that's the environment. And. Yeah, that's exciting to be. To be in an emerging category like that. And solve a real need and see watch the need. Grow. Yeah. That's my personal, you know, that's what motivates me. And that's why.
So I'm excited to be here. If you want to go even even on a more philosophical level, like. It's really rewarding to me to. Help grow. The kinds of technologies that are powering. Our like software infrastructure, which, which, which, which everything in this world runs on today.
So it's really a big thing to do. It's a fact that it's kind of behind the scenes and under the hood that you know most consumers and most people don't know that. Their Facebook feed is powered by similarity search, or that their Google search is powered by similar research.
But it even without them knowing it affects them tremendously. I feel like we have a. And I think that's really. I think that's really. I think that's really. I think that's really. I think that's really. Yeah. Yeah. Yeah. Sounds. So deep. I mean, your connection to it.
And in general, like it sounds like you're excited to be at the bleeding edge of stack, right? So kind of like. Building the next thing. It's. I think it's always exciting. Of course, it's also. And in many ways. Kind of. Well, I don't want to use the word dangerous. I want to use the word.
Kind of like intense. And you know, like. It's nice and bold. That was saying, right? Yeah. Yeah. It's. For sure. We don't know how the future will play out. We have our hopes and. And we're making our bets. But. It's exciting to try it. And it. That's. It motivates us. And it's. It's.
Yeah, we're not looking for safe. For safety here. Yeah. Yeah. Absolutely. But on that front, like on the future, a little bit. Touching on the future of this market, even though it's emerging. You know, and it's still unfolding in many ways. And there are so many players already.
But I'm just thinking like. What do you think. Kind of. What strategic items and missing on the market right now? You know, when you think about not the data science part, I think that data science is developed quite well. We have a lot of competing, you know, algorithms and frameworks.
But like more like on the business side, right? And maybe that's in line with like how users understand the systems. Maybe they don't understand enough. Like, or like what items and missing? And maybe you're working on that.
Maybe you're willing to share maybe not, but maybe something along those lines that we can discuss. Yeah, I think you actually. You made the right point, which is. For a certain for a certain audience. There's not.
I mean, there's still more to be done for a very technical audience that's familiar with the vector search. They have a lot of tools in front of them and. And right now, whatever extra features they needed, they've. They've hopefully figured out.
It's everyone else who doesn't yet understand this and doesn't quite see. How it applies to their applications. And for whom it's not clear what, you know, how to choose an algorithm, how to tune it. That's, I think the future isn't educating.
Those people and those companies and then bringing this capability to them. And that means just helping them understand what it is, but it also means making the. Products more accessible to them. Like. And they can care of some of the technical details so that they can just focus on.
Yeah, they're business side of things in their application. And there are many, many companies out there that can use vector search, but just haven't heard of it. Don't realize it. And. I think the future is in reaching those people. And I think even looking. Beyond vector search and just.
Vector embeddings in general, I think as more, as more and more companies adopt. Machine learning and learn about. And LP. And continue hiring for data scientists and now machine learning engineers, which. By the way, are growing at a faster pace than. Data scientists.
The number of people with machine learning engineer titles on LinkedIn. Group by something like 16%. In Q2 of this year, which is when I last. Check this, where is data scientists grew by. I don't remember exactly, but single digits.
So and obviously not all those mental engineers are working on vector search. But. They will have more and more. Vector embedding data. But they're trying to wrangle. They want to maintain and analyze. And in some cases search through, but also maybe just. Feed into other models. And so on. And so.
In the past five years, we saw. That's. That's why we want to work with data. And a lot of questions have been asked. And so there are. And so they need to think about the question of data warehouses and data lakes, and really like. Companies. Realizing they need to centralize their all their data.
For their data science teams and analysts and so on. We. We believe. The same will. Companies will need the same thing for vector embeddings. So the, they have. One database for. all the can feed applications, feed training and analysis and so on.
So yeah, that might be a few years out and we'll see if that ever happens. But those are the kinds of things we're thinking about often.
Beyond research, how do we get, how do we help people get more use out of there? Yeah, I mean, so I guess it goes along the lines also of producing docs and the kind of documentation, kind of explaining and source code explaining things, right?
How can I, you know, keep the road running and kind of doing things with my, because I don't want to focus on like, you know, need to create the of the vector of search itself maybe, but actually what I really want is to achieve like, you know, my goal, right?
You know, let's say create a music search service or something like that, right? Yeah, exactly.
Yeah, it's, that's a trap. A lot of people and companies fall into the, they love the technology, they love, you know, they're very proud of, yeah, building something unique.
And as you should be, but you have to remember that that people you're serving are just trying to solve some, some business problem.
 Some of them, the early adopters, they'll, they might be very curious about how, how it works under the hood and they might want to have the ability to pull some levers and turn some knobs, but the vast majority of people just want to implement machine learning into the applications to create a smarter search function to increase user engagement, things like that.
Yeah, yeah, I think that was also one recent article. I will also link it in the, in the notes, explaining that you can apply a vector search to solve the zero heat problem in e-commerce. And, and that's how you can save, well, actually earn money, right? So save the user experience in that sense.
Yeah, so it sounds like more and more use cases are coming up. I mean, you guys at the forefront of actually hearing what are the use cases, right? And kind of hopefully you'll be sharing some of those with the audience at large and something we'll learn from you guys.
Yeah, I've, we're still, we're still constantly surprised by what people want to do with the vector search. And, yeah, we want to make the product available to as many people as possible to see what they come up with.
I will say though, we also surprised in a way by how many people want to just do vector search on text data, which seems like such a simple thing to us, maybe. But it gets back to this point that not everyone is, you know, this far along as, as people in the vector search community.
So we got to bring, we got to bring more people with us and help them see that once they're done with a semantic search use case, there's actually a lot more they can do with it.
Yeah, I think it's something that probably needs a bit of kind of discovery for everyone, but also sort of like blogging more about that and sharing more about that that, no, it's not only text, it's actually everything that is inculcable as a vector, right?
And could be dense, it could be sparse, it could be whatever you have there as long as it's a vector.
Then you can send it in index and search and then you need tools to choose the metric function, right? We didn't talk about it, but I know you guys support like three major distances like Euclidean and dot product and to sign.
Yeah, so I mean, these are like more or less this standards across many, you know, data science applications, but I'm sure there is somebody somewhere sitting in the garage and venting in new metric and probably you will want to kind of provide plug-in architecture for that case as well, right?
Yeah, well, we have our own people in this figurative garages working on stuff as well.
But also to go back to the previous thing, the vector database that surrounds the engine as well, which might just look like more traditional database features rather than and simply applied to vector search rather than some breakthrough algorithms or things like that.
Although, yeah, you know, the filtering that we introduced with point on 2.0 is doing single stage filtering on vector index was, let's say, let's not say that it's a collot of late nights in the garage.
Yeah, yeah, sounds exciting and sounds like what your customers will benefit from, right? Almost immediately. Yeah, that's fantastic.
Yeah, I was thinking, like, do you want to add anything more on Vinegon or like, for instance, if somebody wants to try it out today, what's the process looks like or should they just shoot you at the email? Yeah, well, if they want to shoot me an email, they're welcome to do that.
If they want to a t-shirt, send me an email, grabgetpanko.io. But actually, we want to make it very easy for people to start and experiment with. And so you can go to panko.io slash start and create a free account. And for small workloads, it's actually free to use.
You get one pod, which is enough for, definitely enough for experimenting. And if you have a small workload, it's enough for your production use case. That's the easiest and fastest way to sign up. You don't have to talk to anyone.
If you need custom deployment configurations, like certain availability zones, or anything else, you can send me an email or you can use a contact form on our site and we'll get you set up. And it's almost as quick. We just have to set up some configurations.
But we want to help you get to production. And that means not standing in your way. So that's the best way to do it. Go to panko.io slash start. Awesome. And we'll make sure to link that in the notes as well. And you said, what do you mean Kubernetes, right? Kubernetes pod. Oh yeah.
I mean, we didn't touch on this in this in this episode, but obviously you guys are scaling with Kubernetes. So you're also modern on that site as well. Oh yeah, we, we, you know, I should have mentioned this when you asked about the inner workings.
But yeah, we're using Kubernetes to make the whole service horizontally scalable. And of course, the total managed on our side. So you don't have to know anything about containers or Kubernetes or, or worry about any of it.
But I mean, Kafka for streaming to support streaming index updates or batch, batch updates. There are load balancers that are API gateways that are just a bunch of different. There's a key value store under the hood.
If you want to see the architecture, you can cut our docs and learn a bit more about it. But again, you don't have to know anything about it. And that's the point. We make it a, you just make your API calls and, and get your results and do something with those results. Yeah, exactly. Fantastic.
And by the way, are you planning to kind of at some point, maybe open source, or actually implement some things for the public to send the data in? Well, do you think it's not a problem at all?
You know, kind of some kind of connector called some kind of gluing code to the pinecon on the side of integration, right? So I guess obviously clients will still look at how do they plug in pinecon in the right part of the architecture.
Yeah, we're thinking a lot about that. We're looking at what are the most common data sources. What is typical usage look like? And what's the trickiest part for people? And we are thinking about how to make the trickiest part, parts easiest, as many people as possible.
So can't say much more than that, but certainly we'll have some common use cases covered soon. Yeah, yeah, sure. I mean, that's so important. I mean, a lot of things like in machine learning, you know, that like 80% goes to data collection and cleaning.
And then in the end, you plug in some water, like, ooh, I sold the task, right? And the same kind of goes to the trying databases or, you know, software like, okay, how do I plug this in? And days go by and you're still figuring things out. So I think that's the, that's something to address.
And I guess you guys are doing that, right? Yeah, yeah, we definitely, and also a lot of people, you know, we expect people to keep their data warehouse and their document store, you know, because we are, we are your infected database. We're not your blob storage or document storage.
So a lot of people use PINCO and alongside the data warehouse or some other database. And the easier and more seamless connections are between the two, the easier it is to get factory search into production. So that's what we're thinking about. Yeah, sounds great. Thanks.
And yeah, I think we can wrap up like I really enjoyed talking to you, Greg. I mean, your, your T-shirt is the best. I, once I get it, I will wear it as well. And I'll be compatible with the researcher. So thanks so much for your thoughts. I mean, this was super deep.
But I mean, also you shared some of your personal kind of, you know, attitude and aspirations in this area. It's still emerging, but I mean, it's great to see you guys at the forefront of it. And I hope to hear more.
And just last question, where our listeners can follow you or maybe like Twitter or LinkedIn, where are you kind of publicly available? So for PINCO, you, on, on, we publish a lot of things on our website. So you can go to PINCO.io and at the bottom, you can subscribe for email updates.
And you get, you know, all these face articles and things like that. You heard about, you'll get them in your inbox on Twitter. We're at PINCO and underscore IO. On LinkedIn, we also have a big following there. Me personally, I'm at Gregory underscore Kogen.
Gregory is GRI, GOR, IY underscore K-O-G-A-N. But a lot of things I post there are PINCO and related because that's what I think about a lot these days. And I'll also add that big credit to you for also leading the way with, with doing a podcast like this.
Yeah, it's exciting to see more people learn about this, about Factor Search, and start thinking about it and implementing it. And a lot of it is thanks to evangelists like you who put in the work to do that. So thanks to you. Glad to hear that, right? Thanks so much.
And actually, I must say that I'm educating myself equally on this journey. So hopefully as part of this journey, you know, the listeners and the readers can, can educate as well. So in the end, you know, value increases by doing these things. So that's, that's what drives me here.
So thanks so much for joining this show. Yeah, I hope we can record another one at some time down the road. Yeah, that would be awesome. Awesome. Thanks Greg. Bye bye.