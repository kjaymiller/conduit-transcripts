---
description: '<p>YouTube: <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=FQAT6E3EX6g">https://www.youtube.com/watch?v=FQAT6E3EX6g</a></p><p>Show
  notes:</p><p>- On the Measure of Intelligence by François Chollet - Part 1: Foundations
  (Paper Explained) [YouTube](<a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=3_qGr...">https://www.youtube.com/watch?v=3_qGr...</a>)</p><p>-
  [2108.07258 On the Opportunities and Risks of Foundation Models](<a target="_blank"
  rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2108.07258">https://arxiv.org/abs/2108.07258</a>)</p><p>-
  [2005.11401 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](<a
  target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2005.11401">https://arxiv.org/abs/2005.11401</a>)</p><p></p><p>-
  Negative Data Augmentation: <a target="_blank" rel="noopener noreferrer nofollow"
  href="https://arxiv.org/abs/2102.05113">https://arxiv.org/abs/2102.05113</a></p><p></p><p>-
  Beyond Accuracy: Behavioral Testing of NLP models with CheckList: [2005.04118 Beyond
  Accuracy: Behavioral Testing of NLP models with CheckList](<a target="_blank" rel="noopener
  noreferrer nofollow" href="https://arxiv.org/abs/2005.04118">https://arxiv.org/abs/2005.04118</a>)</p><p></p><p>-
  Symbolic AI vs Deep Learning battle <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.technologyreview.com/2020...">https://www.technologyreview.com/2020...</a></p><p></p><p>-
  Dense Passage Retrieval for Open-Domain Question Answering <a target="_blank" rel="noopener
  noreferrer nofollow" href="https://arxiv.org/abs/2004.04906">https://arxiv.org/abs/2004.04906</a></p><p></p><p>-
  Data Augmentation Can Improve Robustness <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://arxiv.org/abs/2111.05328">https://arxiv.org/abs/2111.05328</a></p><p></p><p>-
  Contrastive Loss Explained. Contrastive loss has been used recently… | by Brian
  Williams | Towards Data Science <a target="_blank" rel="noopener noreferrer nofollow"
  href="https://towardsdatascience.com/contra...">https://towardsdatascience.com/contra...</a></p><p></p><p>-
  Keras Code examples <a target="_blank" rel="noopener noreferrer nofollow" href="https://keras.io/examples/">https://keras.io/examples/</a></p><p></p><p>-
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://you.com/">https://you.com/</a>
  -- new web search engine by Richard Socher</p><p></p><p>- The Book of Why: The New
  Science of Cause and Effect: Pearl, Judea, Mackenzie, Dana: 9780465097609: Amazon.com:
  Books <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.amazon.com/Book-Why-Scien...">https://www.amazon.com/Book-Why-Scien...</a></p><p></p><p>-
  Chelsea Finn: <a target="_blank" rel="noopener noreferrer nofollow" href="https://twitter.com/chelseabfinn">https://twitter.com/chelseabfinn</a></p><p></p><p>-
  Jeff Clune: <a target="_blank" rel="noopener noreferrer nofollow" href="https://twitter.com/jeffclune">https://twitter.com/jeffclune</a></p><p></p><p>-
  Michael Bronstein (Geometric Deep Learning): <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://twitter.com/mmbronstein">https://twitter.com/mmbronstein</a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2104.13478">https://arxiv.org/abs/2104.13478</a></p><p></p><p>-
  Connor''s Twitter: <a target="_blank" rel="noopener noreferrer nofollow" href="https://twitter.com/CShorten30">https://twitter.com/CShorten30</a></p><p></p><p>-
  Dmitry''s Twitter: <a target="_blank" rel="noopener noreferrer nofollow" href="https://twitter.com/DmitryKan">https://twitter.com/DmitryKan</a></p>'
image_url: https://media.rss.com/vector-podcast/20211223_011252_c0a8e84bf74cac993f87600e13f3d942.jpg
pub_date: Thu, 23 Dec 2021 13:32:52 GMT
title: Connor Shorten - PhD Researcher - Florida Atlantic University & Founder at
  Henry AI Labs
url: https://rss.com/podcasts/vector-podcast/347472
whisper_segments: '[{"id": 0, "seek": 0, "start": 0.0, "end": 13.84, "text": " Hey
  everyone, Dr. Podgas here.", "tokens": [50364, 1911, 1518, 11, 2491, 13, 12646,
  10549, 510, 13, 51056], "temperature": 0.0, "avg_logprob": -0.35951926909297344,
  "compression_ratio": 1.425233644859813, "no_speech_prob": 0.18691717088222504},
  {"id": 1, "seek": 0, "start": 13.84, "end": 20.16, "text": " And today we have Connor
  Shorten with me who will talk a bit about his research about", "tokens": [51056,
  400, 965, 321, 362, 33133, 16881, 268, 365, 385, 567, 486, 751, 257, 857, 466, 702,
  2132, 466, 51372], "temperature": 0.0, "avg_logprob": -0.35951926909297344, "compression_ratio":
  1.425233644859813, "no_speech_prob": 0.18691717088222504}, {"id": 2, "seek": 0,
  "start": 20.16, "end": 23.28, "text": " lecture databases, about YouTube hopefully
  as well.", "tokens": [51372, 7991, 22380, 11, 466, 3088, 4696, 382, 731, 13, 51528],
  "temperature": 0.0, "avg_logprob": -0.35951926909297344, "compression_ratio": 1.425233644859813,
  "no_speech_prob": 0.18691717088222504}, {"id": 3, "seek": 0, "start": 23.28, "end":
  25.48, "text": " So I''m expecting a really nice discussion today.", "tokens": [51528,
  407, 286, 478, 9650, 257, 534, 1481, 5017, 965, 13, 51638], "temperature": 0.0,
  "avg_logprob": -0.35951926909297344, "compression_ratio": 1.425233644859813, "no_speech_prob":
  0.18691717088222504}, {"id": 4, "seek": 0, "start": 25.48, "end": 27.080000000000002,
  "text": " Hey Connor, how are you doing?", "tokens": [51638, 1911, 33133, 11, 577,
  366, 291, 884, 30, 51718], "temperature": 0.0, "avg_logprob": -0.35951926909297344,
  "compression_ratio": 1.425233644859813, "no_speech_prob": 0.18691717088222504},
  {"id": 5, "seek": 0, "start": 27.080000000000002, "end": 29.96, "text": " Hey Dmitra,
  thanks so much for having me on the podcast.", "tokens": [51718, 1911, 413, 3508,
  424, 11, 3231, 370, 709, 337, 1419, 385, 322, 264, 7367, 13, 51862], "temperature":
  0.0, "avg_logprob": -0.35951926909297344, "compression_ratio": 1.425233644859813,
  "no_speech_prob": 0.18691717088222504}, {"id": 6, "seek": 2996, "start": 29.96,
  "end": 34.68, "text": " I''m really excited to continue our episode and maybe dive
  more into the deep learning research", "tokens": [50364, 286, 478, 534, 2919, 281,
  2354, 527, 3500, 293, 1310, 9192, 544, 666, 264, 2452, 2539, 2132, 50600], "temperature":
  0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 7, "seek": 2996, "start": 34.68,
  "end": 35.68, "text": " side.", "tokens": [50600, 1252, 13, 50650], "temperature":
  0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 8, "seek": 2996, "start": 35.68,
  "end": 40.2, "text": " I think our first podcast on Henry AI labs went really into
  the detail and the practical", "tokens": [50650, 286, 519, 527, 700, 7367, 322,
  11085, 7318, 20339, 1437, 534, 666, 264, 2607, 293, 264, 8496, 50876], "temperature":
  0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 9, "seek": 2996, "start": 40.2, "end":
  44.72, "text": " implementation and the history of Burton Elasticsearch and then
  all the different vector databases", "tokens": [50876, 11420, 293, 264, 2503, 295,
  46011, 2699, 2750, 405, 1178, 293, 550, 439, 264, 819, 8062, 22380, 51102], "temperature":
  0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 10, "seek": 2996, "start": 44.72,
  "end": 49.84, "text": " and I think so now we can kind of maybe look more in the
  research side of things and sort", "tokens": [51102, 293, 286, 519, 370, 586, 321,
  393, 733, 295, 1310, 574, 544, 294, 264, 2132, 1252, 295, 721, 293, 1333, 51358],
  "temperature": 0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 11, "seek": 2996, "start": 49.84,
  "end": 53.64, "text": " of discuss together about where we think all this vector
  search engine stuff is headed.", "tokens": [51358, 295, 2248, 1214, 466, 689, 321,
  519, 439, 341, 8062, 3164, 2848, 1507, 307, 12798, 13, 51548], "temperature": 0.0,
  "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792, "no_speech_prob":
  0.07932904362678528}, {"id": 12, "seek": 2996, "start": 53.64, "end": 54.64, "text":
  " Oh yeah, absolutely.", "tokens": [51548, 876, 1338, 11, 3122, 13, 51598], "temperature":
  0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 13, "seek": 2996, "start": 54.64,
  "end": 59.88, "text": " And it''s exciting to be recording based on the day when
  you actually released that video.", "tokens": [51598, 400, 309, 311, 4670, 281,
  312, 6613, 2361, 322, 264, 786, 562, 291, 767, 4736, 300, 960, 13, 51860], "temperature":
  0.0, "avg_logprob": -0.20426280681903547, "compression_ratio": 1.764525993883792,
  "no_speech_prob": 0.07932904362678528}, {"id": 14, "seek": 5988, "start": 59.88,
  "end": 65.92, "text": " So obviously we will link it so for our listeners and our
  audiences.", "tokens": [50364, 407, 2745, 321, 486, 2113, 309, 370, 337, 527, 23274,
  293, 527, 15479, 13, 50666], "temperature": 0.0, "avg_logprob": -0.21021656195322672,
  "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.00705825025215745},
  {"id": 15, "seek": 5988, "start": 65.92, "end": 69.36, "text": " And hey, could
  you please introduce yourself?", "tokens": [50666, 400, 4177, 11, 727, 291, 1767,
  5366, 1803, 30, 50838], "temperature": 0.0, "avg_logprob": -0.21021656195322672,
  "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.00705825025215745},
  {"id": 16, "seek": 5988, "start": 69.36, "end": 71.12, "text": " Yeah, great.",
  "tokens": [50838, 865, 11, 869, 13, 50926], "temperature": 0.0, "avg_logprob": -0.21021656195322672,
  "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.00705825025215745},
  {"id": 17, "seek": 5988, "start": 71.12, "end": 76.32000000000001, "text": " So
  to say to introduce myself, I guess I would like to kind of like be reintroducing",
  "tokens": [50926, 407, 281, 584, 281, 5366, 2059, 11, 286, 2041, 286, 576, 411,
  281, 733, 295, 411, 312, 319, 38132, 2175, 51186], "temperature": 0.0, "avg_logprob":
  -0.21021656195322672, "compression_ratio": 1.7123893805309736, "no_speech_prob":
  0.00705825025215745}, {"id": 18, "seek": 5988, "start": 76.32000000000001, "end":
  78.32000000000001, "text": " myself almost every like year.", "tokens": [51186,
  2059, 1920, 633, 411, 1064, 13, 51286], "temperature": 0.0, "avg_logprob": -0.21021656195322672,
  "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.00705825025215745},
  {"id": 19, "seek": 5988, "start": 78.32000000000001, "end": 82.96000000000001, "text":
  " So as obviously I make these YouTube videos and I''m kind of like still discovering
  my", "tokens": [51286, 407, 382, 2745, 286, 652, 613, 3088, 2145, 293, 286, 478,
  733, 295, 411, 920, 24773, 452, 51518], "temperature": 0.0, "avg_logprob": -0.21021656195322672,
  "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.00705825025215745},
  {"id": 20, "seek": 5988, "start": 82.96000000000001, "end": 85.88, "text": " role
  in deep learning research and still learning myself.", "tokens": [51518, 3090, 294,
  2452, 2539, 2132, 293, 920, 2539, 2059, 13, 51664], "temperature": 0.0, "avg_logprob":
  -0.21021656195322672, "compression_ratio": 1.7123893805309736, "no_speech_prob":
  0.00705825025215745}, {"id": 21, "seek": 8588, "start": 86.88, "end": 90.36, "text":
  " In my journey, I''m in my second year of my PhD.", "tokens": [50414, 682, 452,
  4671, 11, 286, 478, 294, 452, 1150, 1064, 295, 452, 14476, 13, 50588], "temperature":
  0.0, "avg_logprob": -0.21294747458563912, "compression_ratio": 1.692883895131086,
  "no_speech_prob": 0.00791763886809349}, {"id": 22, "seek": 8588, "start": 90.36,
  "end": 94.24, "text": " I finished my master''s degree where I got started with
  research on generative adversarial", "tokens": [50588, 286, 4335, 452, 4505, 311,
  4314, 689, 286, 658, 1409, 365, 2132, 322, 1337, 1166, 17641, 44745, 50782], "temperature":
  0.0, "avg_logprob": -0.21294747458563912, "compression_ratio": 1.692883895131086,
  "no_speech_prob": 0.00791763886809349}, {"id": 23, "seek": 8588, "start": 94.24,
  "end": 99.16, "text": " networks and data augmentation, published literature reviews
  on data augmentation for", "tokens": [50782, 9590, 293, 1412, 14501, 19631, 11,
  6572, 10394, 10229, 322, 1412, 14501, 19631, 337, 51028], "temperature": 0.0, "avg_logprob":
  -0.21294747458563912, "compression_ratio": 1.692883895131086, "no_speech_prob":
  0.00791763886809349}, {"id": 24, "seek": 8588, "start": 99.16, "end": 100.44, "text":
  " images and text.", "tokens": [51028, 5267, 293, 2487, 13, 51092], "temperature":
  0.0, "avg_logprob": -0.21294747458563912, "compression_ratio": 1.692883895131086,
  "no_speech_prob": 0.00791763886809349}, {"id": 25, "seek": 8588, "start": 100.44,
  "end": 105.03999999999999, "text": " And this has really been my research focus
  is data augmentation, the idea.", "tokens": [51092, 400, 341, 575, 534, 668, 452,
  2132, 1879, 307, 1412, 14501, 19631, 11, 264, 1558, 13, 51322], "temperature": 0.0,
  "avg_logprob": -0.21294747458563912, "compression_ratio": 1.692883895131086, "no_speech_prob":
  0.00791763886809349}, {"id": 26, "seek": 8588, "start": 105.03999999999999, "end":
  109.84, "text": " Primarily my interest was I started out with when I first learned
  about deep learning right", "tokens": [51322, 19671, 3289, 452, 1179, 390, 286,
  1409, 484, 365, 562, 286, 700, 3264, 466, 2452, 2539, 558, 51562], "temperature":
  0.0, "avg_logprob": -0.21294747458563912, "compression_ratio": 1.692883895131086,
  "no_speech_prob": 0.00791763886809349}, {"id": 27, "seek": 8588, "start": 109.84,
  "end": 112.28, "text": " away, I come from being a basketball player.", "tokens":
  [51562, 1314, 11, 286, 808, 490, 885, 257, 11767, 4256, 13, 51684], "temperature":
  0.0, "avg_logprob": -0.21294747458563912, "compression_ratio": 1.692883895131086,
  "no_speech_prob": 0.00791763886809349}, {"id": 28, "seek": 11228, "start": 112.28,
  "end": 116.88, "text": " I played basketball in college and I was ready to go deep
  learning for basketball.", "tokens": [50364, 286, 3737, 11767, 294, 3859, 293, 286,
  390, 1919, 281, 352, 2452, 2539, 337, 11767, 13, 50594], "temperature": 0.0, "avg_logprob":
  -0.1899503019989514, "compression_ratio": 1.7751677852348993, "no_speech_prob":
  0.017529329285025597}, {"id": 29, "seek": 11228, "start": 116.88, "end": 119.04,
  "text": " How can this improve basketball?", "tokens": [50594, 1012, 393, 341, 3470,
  11767, 30, 50702], "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio":
  1.7751677852348993, "no_speech_prob": 0.017529329285025597}, {"id": 30, "seek":
  11228, "start": 119.04, "end": 123.12, "text": " So one thing about basketball is
  when you''re playing, you want to have a highlight mix", "tokens": [50702, 407,
  472, 551, 466, 11767, 307, 562, 291, 434, 2433, 11, 291, 528, 281, 362, 257, 5078,
  2890, 50906], "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio":
  1.7751677852348993, "no_speech_prob": 0.017529329285025597}, {"id": 31, "seek":
  11228, "start": 123.12, "end": 127.12, "text": " tape where you have all your best
  moves and helps you get the college scholarship.", "tokens": [50906, 7314, 689,
  291, 362, 439, 428, 1151, 6067, 293, 3665, 291, 483, 264, 3859, 16178, 13, 51106],
  "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio": 1.7751677852348993,
  "no_speech_prob": 0.017529329285025597}, {"id": 32, "seek": 11228, "start": 127.12,
  "end": 130.96, "text": " And so I was really familiar with that process of what
  it takes to be recruited to play college", "tokens": [51106, 400, 370, 286, 390,
  534, 4963, 365, 300, 1399, 295, 437, 309, 2516, 281, 312, 33004, 281, 862, 3859,
  51298], "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio":
  1.7751677852348993, "no_speech_prob": 0.017529329285025597}, {"id": 33, "seek":
  11228, "start": 130.96, "end": 132.16, "text": " basketball.", "tokens": [51298,
  11767, 13, 51358], "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio":
  1.7751677852348993, "no_speech_prob": 0.017529329285025597}, {"id": 34, "seek":
  11228, "start": 132.16, "end": 136.56, "text": " So I wanted to build this computer
  vision system that would crop out, you know, you''re", "tokens": [51358, 407, 286,
  1415, 281, 1322, 341, 3820, 5201, 1185, 300, 576, 9086, 484, 11, 291, 458, 11, 291,
  434, 51578], "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio":
  1.7751677852348993, "no_speech_prob": 0.017529329285025597}, {"id": 35, "seek":
  11228, "start": 136.56, "end": 139.84, "text": " made baskets from full game tapes
  automatically.", "tokens": [51578, 1027, 42853, 490, 1577, 1216, 31349, 6772, 13,
  51742], "temperature": 0.0, "avg_logprob": -0.1899503019989514, "compression_ratio":
  1.7751677852348993, "no_speech_prob": 0.017529329285025597}, {"id": 36, "seek":
  13984, "start": 139.84, "end": 143.72, "text": " And so I came into this problem
  that everyone has seen where if you try to do supervised", "tokens": [50364, 400,
  370, 286, 1361, 666, 341, 1154, 300, 1518, 575, 1612, 689, 498, 291, 853, 281, 360,
  46533, 50558], "temperature": 0.0, "avg_logprob": -0.21070571567701257, "compression_ratio":
  1.7722772277227723, "no_speech_prob": 0.004523335490375757}, {"id": 37, "seek":
  13984, "start": 143.72, "end": 147.12, "text": " learning with small data sets,
  it does not work.", "tokens": [50558, 2539, 365, 1359, 1412, 6352, 11, 309, 775,
  406, 589, 13, 50728], "temperature": 0.0, "avg_logprob": -0.21070571567701257, "compression_ratio":
  1.7722772277227723, "no_speech_prob": 0.004523335490375757}, {"id": 38, "seek":
  13984, "start": 147.12, "end": 151.16, "text": " So like annotating data is extremely
  difficult.", "tokens": [50728, 407, 411, 25339, 990, 1412, 307, 4664, 2252, 13,
  50930], "temperature": 0.0, "avg_logprob": -0.21070571567701257, "compression_ratio":
  1.7722772277227723, "no_speech_prob": 0.004523335490375757}, {"id": 39, "seek":
  13984, "start": 151.16, "end": 155.08, "text": " Like you can, if you''re doing
  it yourself, you can probably get yourself like, you know,", "tokens": [50930, 1743,
  291, 393, 11, 498, 291, 434, 884, 309, 1803, 11, 291, 393, 1391, 483, 1803, 411,
  11, 291, 458, 11, 51126], "temperature": 0.0, "avg_logprob": -0.21070571567701257,
  "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.004523335490375757},
  {"id": 40, "seek": 13984, "start": 155.08, "end": 158.96, "text": " in my case,
  I was annotating made baskets and video clips, which is already high dimensional",
  "tokens": [51126, 294, 452, 1389, 11, 286, 390, 25339, 990, 1027, 42853, 293, 960,
  13117, 11, 597, 307, 1217, 1090, 18795, 51320], "temperature": 0.0, "avg_logprob":
  -0.21070571567701257, "compression_ratio": 1.7722772277227723, "no_speech_prob":
  0.004523335490375757}, {"id": 41, "seek": 13984, "start": 158.96, "end": 162.64000000000001,
  "text": " data already, you know, paying to store all that data.", "tokens": [51320,
  1412, 1217, 11, 291, 458, 11, 6229, 281, 3531, 439, 300, 1412, 13, 51504], "temperature":
  0.0, "avg_logprob": -0.21070571567701257, "compression_ratio": 1.7722772277227723,
  "no_speech_prob": 0.004523335490375757}, {"id": 42, "seek": 13984, "start": 162.64000000000001,
  "end": 165.04, "text": " So, you know, and labeling it was a problem.", "tokens":
  [51504, 407, 11, 291, 458, 11, 293, 40244, 309, 390, 257, 1154, 13, 51624], "temperature":
  0.0, "avg_logprob": -0.21070571567701257, "compression_ratio": 1.7722772277227723,
  "no_speech_prob": 0.004523335490375757}, {"id": 43, "seek": 13984, "start": 165.04,
  "end": 169.16, "text": " So I said, maybe data augmentation because I''m overfitting
  this data.", "tokens": [51624, 407, 286, 848, 11, 1310, 1412, 14501, 19631, 570,
  286, 478, 670, 69, 2414, 341, 1412, 13, 51830], "temperature": 0.0, "avg_logprob":
  -0.21070571567701257, "compression_ratio": 1.7722772277227723, "no_speech_prob":
  0.004523335490375757}, {"id": 44, "seek": 16916, "start": 169.16, "end": 173.44,
  "text": " So I can try to rotate it, crop it horizontally, flip it, increase the
  brightness, this whole", "tokens": [50364, 407, 286, 393, 853, 281, 13121, 309,
  11, 9086, 309, 33796, 11, 7929, 309, 11, 3488, 264, 21367, 11, 341, 1379, 50578],
  "temperature": 0.0, "avg_logprob": -0.27823940543241277, "compression_ratio": 1.7331081081081081,
  "no_speech_prob": 0.0008667344227433205}, {"id": 45, "seek": 16916, "start": 173.44,
  "end": 175.44, "text": " package of things you can do.", "tokens": [50578, 7372,
  295, 721, 291, 393, 360, 13, 50678], "temperature": 0.0, "avg_logprob": -0.27823940543241277,
  "compression_ratio": 1.7331081081081081, "no_speech_prob": 0.0008667344227433205},
  {"id": 46, "seek": 16916, "start": 175.44, "end": 176.44, "text": " Yeah, and orientation.",
  "tokens": [50678, 865, 11, 293, 14764, 13, 50728], "temperature": 0.0, "avg_logprob":
  -0.27823940543241277, "compression_ratio": 1.7331081081081081, "no_speech_prob":
  0.0008667344227433205}, {"id": 47, "seek": 16916, "start": 176.44, "end": 177.44,
  "text": " Yeah.", "tokens": [50728, 865, 13, 50778], "temperature": 0.0, "avg_logprob":
  -0.27823940543241277, "compression_ratio": 1.7331081081081081, "no_speech_prob":
  0.0008667344227433205}, {"id": 48, "seek": 16916, "start": 177.44, "end": 178.44,
  "text": " Right.", "tokens": [50778, 1779, 13, 50828], "temperature": 0.0, "avg_logprob":
  -0.27823940543241277, "compression_ratio": 1.7331081081081081, "no_speech_prob":
  0.0008667344227433205}, {"id": 49, "seek": 16916, "start": 178.44, "end": 179.44,
  "text": " And so it worked pretty well.", "tokens": [50828, 400, 370, 309, 2732,
  1238, 731, 13, 50878], "temperature": 0.0, "avg_logprob": -0.27823940543241277,
  "compression_ratio": 1.7331081081081081, "no_speech_prob": 0.0008667344227433205},
  {"id": 50, "seek": 16916, "start": 179.44, "end": 182.28, "text": " So I was pretty
  inspired by this idea of data augmentation.", "tokens": [50878, 407, 286, 390, 1238,
  7547, 538, 341, 1558, 295, 1412, 14501, 19631, 13, 51020], "temperature": 0.0, "avg_logprob":
  -0.27823940543241277, "compression_ratio": 1.7331081081081081, "no_speech_prob":
  0.0008667344227433205}, {"id": 51, "seek": 16916, "start": 182.28, "end": 187.51999999999998,
  "text": " I really like papers like Francois Chalets on the measure of intelligence
  where discussing", "tokens": [51020, 286, 534, 411, 10577, 411, 34695, 271, 761,
  304, 1385, 322, 264, 3481, 295, 7599, 689, 10850, 51282], "temperature": 0.0, "avg_logprob":
  -0.27823940543241277, "compression_ratio": 1.7331081081081081, "no_speech_prob":
  0.0008667344227433205}, {"id": 52, "seek": 16916, "start": 187.51999999999998, "end":
  193.56, "text": " the ideas of like system centric generalization developer, where
  generalization known unknowns", "tokens": [51282, 264, 3487, 295, 411, 1185, 1489,
  1341, 2674, 2144, 10754, 11, 689, 2674, 2144, 2570, 46048, 51584], "temperature":
  0.0, "avg_logprob": -0.27823940543241277, "compression_ratio": 1.7331081081081081,
  "no_speech_prob": 0.0008667344227433205}, {"id": 53, "seek": 16916, "start": 193.56,
  "end": 198.56, "text": " is kind of, you know, matrix of known and unknowns with
  generalization cases.", "tokens": [51584, 307, 733, 295, 11, 291, 458, 11, 8141,
  295, 2570, 293, 46048, 365, 2674, 2144, 3331, 13, 51834], "temperature": 0.0, "avg_logprob":
  -0.27823940543241277, "compression_ratio": 1.7331081081081081, "no_speech_prob":
  0.0008667344227433205}, {"id": 54, "seek": 19856, "start": 198.56, "end": 203.12,
  "text": " So I hold the belief that we can kind of steer the data in the direction
  that enables", "tokens": [50364, 407, 286, 1797, 264, 7107, 300, 321, 393, 733,
  295, 30814, 264, 1412, 294, 264, 3513, 300, 17077, 50592], "temperature": 0.0, "avg_logprob":
  -0.1719206907810309, "compression_ratio": 1.773371104815864, "no_speech_prob": 0.0006448252242989838},
  {"id": 55, "seek": 19856, "start": 203.12, "end": 204.12, "text": " more generalization.",
  "tokens": [50592, 544, 2674, 2144, 13, 50642], "temperature": 0.0, "avg_logprob":
  -0.1719206907810309, "compression_ratio": 1.773371104815864, "no_speech_prob": 0.0006448252242989838},
  {"id": 56, "seek": 19856, "start": 204.12, "end": 207.32, "text": " And the key
  to mocking more generalization is mostly going to be in the data space.", "tokens":
  [50642, 400, 264, 2141, 281, 17362, 278, 544, 2674, 2144, 307, 5240, 516, 281, 312,
  294, 264, 1412, 1901, 13, 50802], "temperature": 0.0, "avg_logprob": -0.1719206907810309,
  "compression_ratio": 1.773371104815864, "no_speech_prob": 0.0006448252242989838},
  {"id": 57, "seek": 19856, "start": 207.32, "end": 211.36, "text": " So I''d say
  I''m in this data centric AI category, which is, you know, lately become one", "tokens":
  [50802, 407, 286, 1116, 584, 286, 478, 294, 341, 1412, 1489, 1341, 7318, 7719, 11,
  597, 307, 11, 291, 458, 11, 12881, 1813, 472, 51004], "temperature": 0.0, "avg_logprob":
  -0.1719206907810309, "compression_ratio": 1.773371104815864, "no_speech_prob": 0.0006448252242989838},
  {"id": 58, "seek": 19856, "start": 211.36, "end": 213.52, "text": " of the buzzwords
  of where your camp is.", "tokens": [51004, 295, 264, 13036, 13832, 295, 689, 428,
  2255, 307, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1719206907810309, "compression_ratio":
  1.773371104815864, "no_speech_prob": 0.0006448252242989838}, {"id": 59, "seek":
  19856, "start": 213.52, "end": 217.12, "text": " I love things like neural architecture
  search and different learning strategies and all", "tokens": [51112, 286, 959, 721,
  411, 18161, 9482, 3164, 293, 819, 2539, 9029, 293, 439, 51292], "temperature": 0.0,
  "avg_logprob": -0.1719206907810309, "compression_ratio": 1.773371104815864, "no_speech_prob":
  0.0006448252242989838}, {"id": 60, "seek": 19856, "start": 217.12, "end": 218.96,
  "text": " that, but I really love the data augmentation.", "tokens": [51292, 300,
  11, 457, 286, 534, 959, 264, 1412, 14501, 19631, 13, 51384], "temperature": 0.0,
  "avg_logprob": -0.1719206907810309, "compression_ratio": 1.773371104815864, "no_speech_prob":
  0.0006448252242989838}, {"id": 61, "seek": 19856, "start": 218.96, "end": 222.68,
  "text": " I think there''s so much opportunity and research to explore this further.",
  "tokens": [51384, 286, 519, 456, 311, 370, 709, 2650, 293, 2132, 281, 6839, 341,
  3052, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1719206907810309, "compression_ratio":
  1.773371104815864, "no_speech_prob": 0.0006448252242989838}, {"id": 62, "seek":
  19856, "start": 222.68, "end": 224.0, "text": " And then.", "tokens": [51570, 400,
  550, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1719206907810309, "compression_ratio":
  1.773371104815864, "no_speech_prob": 0.0006448252242989838}, {"id": 63, "seek":
  19856, "start": 224.0, "end": 227.44, "text": " And so yeah, so I have a few ideas
  of how this could intersect with vector search engines", "tokens": [51636, 400,
  370, 1338, 11, 370, 286, 362, 257, 1326, 3487, 295, 577, 341, 727, 27815, 365, 8062,
  3164, 12982, 51808], "temperature": 0.0, "avg_logprob": -0.1719206907810309, "compression_ratio":
  1.773371104815864, "no_speech_prob": 0.0006448252242989838}, {"id": 64, "seek":
  22744, "start": 227.44, "end": 229.68, "text": " and vector representation learning.",
  "tokens": [50364, 293, 8062, 10290, 2539, 13, 50476], "temperature": 0.0, "avg_logprob":
  -0.15516703658633763, "compression_ratio": 1.8631921824104234, "no_speech_prob":
  0.0009783224668353796}, {"id": 65, "seek": 22744, "start": 229.68, "end": 230.68,
  "text": " So that''s on one end.", "tokens": [50476, 407, 300, 311, 322, 472, 917,
  13, 50526], "temperature": 0.0, "avg_logprob": -0.15516703658633763, "compression_ratio":
  1.8631921824104234, "no_speech_prob": 0.0009783224668353796}, {"id": 66, "seek":
  22744, "start": 230.68, "end": 234.2, "text": " So that''s kind of, you know, my
  research interest is in data augmentation and a bit of a background", "tokens":
  [50526, 407, 300, 311, 733, 295, 11, 291, 458, 11, 452, 2132, 1179, 307, 294, 1412,
  14501, 19631, 293, 257, 857, 295, 257, 3678, 50702], "temperature": 0.0, "avg_logprob":
  -0.15516703658633763, "compression_ratio": 1.8631921824104234, "no_speech_prob":
  0.0009783224668353796}, {"id": 67, "seek": 22744, "start": 234.2, "end": 237.48,
  "text": " about how I became so inspired in data augmentation.", "tokens": [50702,
  466, 577, 286, 3062, 370, 7547, 294, 1412, 14501, 19631, 13, 50866], "temperature":
  0.0, "avg_logprob": -0.15516703658633763, "compression_ratio": 1.8631921824104234,
  "no_speech_prob": 0.0009783224668353796}, {"id": 68, "seek": 22744, "start": 237.48,
  "end": 242.2, "text": " So then to say kind of what I''m doing right now is, you
  know, I''ve, so I''ve started doing", "tokens": [50866, 407, 550, 281, 584, 733,
  295, 437, 286, 478, 884, 558, 586, 307, 11, 291, 458, 11, 286, 600, 11, 370, 286,
  600, 1409, 884, 51102], "temperature": 0.0, "avg_logprob": -0.15516703658633763,
  "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.0009783224668353796},
  {"id": 69, "seek": 22744, "start": 242.2, "end": 243.72, "text": " some experiment
  papers.", "tokens": [51102, 512, 5120, 10577, 13, 51178], "temperature": 0.0, "avg_logprob":
  -0.15516703658633763, "compression_ratio": 1.8631921824104234, "no_speech_prob":
  0.0009783224668353796}, {"id": 70, "seek": 22744, "start": 243.72, "end": 247.48,
  "text": " Most of my computing is managed with Google collab, which is pretty nice.",
  "tokens": [51178, 4534, 295, 452, 15866, 307, 6453, 365, 3329, 44228, 11, 597, 307,
  1238, 1481, 13, 51366], "temperature": 0.0, "avg_logprob": -0.15516703658633763,
  "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.0009783224668353796},
  {"id": 71, "seek": 22744, "start": 247.48, "end": 251.52, "text": " You know, like,
  you have the Google collab notebooks and then you have the Google Drive", "tokens":
  [51366, 509, 458, 11, 411, 11, 291, 362, 264, 3329, 44228, 43782, 293, 550, 291,
  362, 264, 3329, 15622, 51568], "temperature": 0.0, "avg_logprob": -0.15516703658633763,
  "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.0009783224668353796},
  {"id": 72, "seek": 22744, "start": 251.52, "end": 255.72, "text": " integration
  for persistence and, you know, you can make it pretty far without putting", "tokens":
  [51568, 10980, 337, 37617, 293, 11, 291, 458, 11, 291, 393, 652, 309, 1238, 1400,
  1553, 3372, 51778], "temperature": 0.0, "avg_logprob": -0.15516703658633763, "compression_ratio":
  1.8631921824104234, "no_speech_prob": 0.0009783224668353796}, {"id": 73, "seek":
  25572, "start": 255.72, "end": 260.44, "text": " a dent in your wallet by doing
  it by getting too carried away.", "tokens": [50364, 257, 7059, 294, 428, 16599,
  538, 884, 309, 538, 1242, 886, 9094, 1314, 13, 50600], "temperature": 0.0, "avg_logprob":
  -0.19090166546049572, "compression_ratio": 1.6236933797909407, "no_speech_prob":
  0.0007440527551807463}, {"id": 74, "seek": 25572, "start": 260.44, "end": 263.64,
  "text": " And so that''s kind of how I''m setting that up.", "tokens": [50600, 400,
  370, 300, 311, 733, 295, 577, 286, 478, 3287, 300, 493, 13, 50760], "temperature":
  0.0, "avg_logprob": -0.19090166546049572, "compression_ratio": 1.6236933797909407,
  "no_speech_prob": 0.0007440527551807463}, {"id": 75, "seek": 25572, "start": 263.64,
  "end": 267.4, "text": " And, you know, I have, you know, I can tell people about
  like, as I mentioned, beginning", "tokens": [50760, 400, 11, 291, 458, 11, 286,
  362, 11, 291, 458, 11, 286, 393, 980, 561, 466, 411, 11, 382, 286, 2835, 11, 2863,
  50948], "temperature": 0.0, "avg_logprob": -0.19090166546049572, "compression_ratio":
  1.6236933797909407, "no_speech_prob": 0.0007440527551807463}, {"id": 76, "seek":
  25572, "start": 267.4, "end": 270.12, "text": " trying to reintroduce myself and
  figure out my role.", "tokens": [50948, 1382, 281, 319, 38132, 384, 2059, 293, 2573,
  484, 452, 3090, 13, 51084], "temperature": 0.0, "avg_logprob": -0.19090166546049572,
  "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.0007440527551807463},
  {"id": 77, "seek": 25572, "start": 270.12, "end": 273.96, "text": " So I had kind
  of like recently, like a high of achieving the best student paper at this", "tokens":
  [51084, 407, 286, 632, 733, 295, 411, 3938, 11, 411, 257, 1090, 295, 19626, 264,
  1151, 3107, 3035, 412, 341, 51276], "temperature": 0.0, "avg_logprob": -0.19090166546049572,
  "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.0007440527551807463},
  {"id": 78, "seek": 25572, "start": 273.96, "end": 278.16, "text": " ICT AI conference
  on something about inductive biases.", "tokens": [51276, 286, 10259, 7318, 7586,
  322, 746, 466, 31612, 488, 32152, 13, 51486], "temperature": 0.0, "avg_logprob":
  -0.19090166546049572, "compression_ratio": 1.6236933797909407, "no_speech_prob":
  0.0007440527551807463}, {"id": 79, "seek": 25572, "start": 278.16, "end": 282.96,
  "text": " And then the next day I get my ICLR reviews back, which were not great.",
  "tokens": [51486, 400, 550, 264, 958, 786, 286, 483, 452, 14360, 31722, 10229, 646,
  11, 597, 645, 406, 869, 13, 51726], "temperature": 0.0, "avg_logprob": -0.19090166546049572,
  "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.0007440527551807463},
  {"id": 80, "seek": 28296, "start": 282.96, "end": 288.12, "text": " So, you know,
  and that''s kind of the journey of this, you know, I''m just setting, setting",
  "tokens": [50364, 407, 11, 291, 458, 11, 293, 300, 311, 733, 295, 264, 4671, 295,
  341, 11, 291, 458, 11, 286, 478, 445, 3287, 11, 3287, 50622], "temperature": 0.0,
  "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876, "no_speech_prob":
  0.1636214703321457}, {"id": 81, "seek": 28296, "start": 288.12, "end": 293.35999999999996,
  "text": " forward to ICML and trying to just bounce back and stay on this journey
  of figuring out", "tokens": [50622, 2128, 281, 14360, 12683, 293, 1382, 281, 445,
  15894, 646, 293, 1754, 322, 341, 4671, 295, 15213, 484, 50884], "temperature": 0.0,
  "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876, "no_speech_prob":
  0.1636214703321457}, {"id": 82, "seek": 28296, "start": 293.35999999999996, "end":
  294.68, "text": " how to do deep learning research.", "tokens": [50884, 577, 281,
  360, 2452, 2539, 2132, 13, 50950], "temperature": 0.0, "avg_logprob": -0.22737705524151142,
  "compression_ratio": 1.7876447876447876, "no_speech_prob": 0.1636214703321457},
  {"id": 83, "seek": 28296, "start": 294.68, "end": 296.88, "text": " So it''s definitely
  a high.", "tokens": [50950, 407, 309, 311, 2138, 257, 1090, 13, 51060], "temperature":
  0.0, "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876,
  "no_speech_prob": 0.1636214703321457}, {"id": 84, "seek": 28296, "start": 296.88,
  "end": 297.88, "text": " Isn''t it?", "tokens": [51060, 6998, 380, 309, 30, 51110],
  "temperature": 0.0, "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876,
  "no_speech_prob": 0.1636214703321457}, {"id": 85, "seek": 28296, "start": 297.88,
  "end": 301.76, "text": " It''s like almost always like that, you know, like in machine
  learning, nothing is predictable", "tokens": [51110, 467, 311, 411, 1920, 1009,
  411, 300, 11, 291, 458, 11, 411, 294, 3479, 2539, 11, 1825, 307, 27737, 51304],
  "temperature": 0.0, "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876,
  "no_speech_prob": 0.1636214703321457}, {"id": 86, "seek": 28296, "start": 301.76,
  "end": 306.4, "text": " and nothing is given, you know, like, and you need to be
  kind of averse to that.", "tokens": [51304, 293, 1825, 307, 2212, 11, 291, 458,
  11, 411, 11, 293, 291, 643, 281, 312, 733, 295, 257, 4308, 281, 300, 13, 51536],
  "temperature": 0.0, "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876,
  "no_speech_prob": 0.1636214703321457}, {"id": 87, "seek": 28296, "start": 306.4,
  "end": 308.44, "text": " Well, not averse, but resistant, right?", "tokens": [51536,
  1042, 11, 406, 257, 4308, 11, 457, 20383, 11, 558, 30, 51638], "temperature": 0.0,
  "avg_logprob": -0.22737705524151142, "compression_ratio": 1.7876447876447876, "no_speech_prob":
  0.1636214703321457}, {"id": 88, "seek": 30844, "start": 308.44, "end": 309.56, "text":
  " Like, okay, I''m fine.", "tokens": [50364, 1743, 11, 1392, 11, 286, 478, 2489,
  13, 50420], "temperature": 0.0, "avg_logprob": -0.24192097981770833, "compression_ratio":
  1.7090301003344481, "no_speech_prob": 0.19697165489196777}, {"id": 89, "seek": 30844,
  "start": 309.56, "end": 313.32, "text": " I can take risks, but it''s like a marathon.",
  "tokens": [50420, 286, 393, 747, 10888, 11, 457, 309, 311, 411, 257, 27601, 13,
  50608], "temperature": 0.0, "avg_logprob": -0.24192097981770833, "compression_ratio":
  1.7090301003344481, "no_speech_prob": 0.19697165489196777}, {"id": 90, "seek": 30844,
  "start": 313.32, "end": 314.32, "text": " It''s not a sprint.", "tokens": [50608,
  467, 311, 406, 257, 25075, 13, 50658], "temperature": 0.0, "avg_logprob": -0.24192097981770833,
  "compression_ratio": 1.7090301003344481, "no_speech_prob": 0.19697165489196777},
  {"id": 91, "seek": 30844, "start": 314.32, "end": 316.52, "text": " Oh, yeah, definitely.",
  "tokens": [50658, 876, 11, 1338, 11, 2138, 13, 50768], "temperature": 0.0, "avg_logprob":
  -0.24192097981770833, "compression_ratio": 1.7090301003344481, "no_speech_prob":
  0.19697165489196777}, {"id": 92, "seek": 30844, "start": 316.52, "end": 321.72,
  "text": " And just the disappointment of investing a month or two into a research
  project and then", "tokens": [50768, 400, 445, 264, 28175, 295, 10978, 257, 1618,
  420, 732, 666, 257, 2132, 1716, 293, 550, 51028], "temperature": 0.0, "avg_logprob":
  -0.24192097981770833, "compression_ratio": 1.7090301003344481, "no_speech_prob":
  0.19697165489196777}, {"id": 93, "seek": 30844, "start": 321.72, "end": 323.24,
  "text": " you just start running the experiments.", "tokens": [51028, 291, 445,
  722, 2614, 264, 12050, 13, 51104], "temperature": 0.0, "avg_logprob": -0.24192097981770833,
  "compression_ratio": 1.7090301003344481, "no_speech_prob": 0.19697165489196777},
  {"id": 94, "seek": 30844, "start": 323.24, "end": 325.76, "text": " And you''re
  like, oh, this is not working.", "tokens": [51104, 400, 291, 434, 411, 11, 1954,
  11, 341, 307, 406, 1364, 13, 51230], "temperature": 0.0, "avg_logprob": -0.24192097981770833,
  "compression_ratio": 1.7090301003344481, "no_speech_prob": 0.19697165489196777},
  {"id": 95, "seek": 30844, "start": 325.76, "end": 329.28, "text": " And your advisor''s
  on the phone twice a week and saying, how''s it going?", "tokens": [51230, 400,
  428, 19161, 311, 322, 264, 2593, 6091, 257, 1243, 293, 1566, 11, 577, 311, 309,
  516, 30, 51406], "temperature": 0.0, "avg_logprob": -0.24192097981770833, "compression_ratio":
  1.7090301003344481, "no_speech_prob": 0.19697165489196777}, {"id": 96, "seek": 30844,
  "start": 329.28, "end": 330.72, "text": " And you''re like, not good.", "tokens":
  [51406, 400, 291, 434, 411, 11, 406, 665, 13, 51478], "temperature": 0.0, "avg_logprob":
  -0.24192097981770833, "compression_ratio": 1.7090301003344481, "no_speech_prob":
  0.19697165489196777}, {"id": 97, "seek": 30844, "start": 330.72, "end": 332.64,
  "text": " You know, like, so that''s stressful.", "tokens": [51478, 509, 458, 11,
  411, 11, 370, 300, 311, 19108, 13, 51574], "temperature": 0.0, "avg_logprob": -0.24192097981770833,
  "compression_ratio": 1.7090301003344481, "no_speech_prob": 0.19697165489196777},
  {"id": 98, "seek": 30844, "start": 332.64, "end": 335.88, "text": " And, you know,
  anyone else going through that, I can definitely relate to that kind of", "tokens":
  [51574, 400, 11, 291, 458, 11, 2878, 1646, 516, 807, 300, 11, 286, 393, 2138, 10961,
  281, 300, 733, 295, 51736], "temperature": 0.0, "avg_logprob": -0.24192097981770833,
  "compression_ratio": 1.7090301003344481, "no_speech_prob": 0.19697165489196777},
  {"id": 99, "seek": 30844, "start": 335.88, "end": 336.88, "text": " struggle.",
  "tokens": [51736, 7799, 13, 51786], "temperature": 0.0, "avg_logprob": -0.24192097981770833,
  "compression_ratio": 1.7090301003344481, "no_speech_prob": 0.19697165489196777},
  {"id": 100, "seek": 33688, "start": 336.88, "end": 340.68, "text": " Is this by
  the way, why you do YouTube show Henry A. L.A.", "tokens": [50364, 1119, 341, 538,
  264, 636, 11, 983, 291, 360, 3088, 855, 11085, 316, 13, 441, 13, 32, 13, 50554],
  "temperature": 0.0, "avg_logprob": -0.24558462816126206, "compression_ratio": 1.628930817610063,
  "no_speech_prob": 0.007410705089569092}, {"id": 101, "seek": 33688, "start": 340.68,
  "end": 341.68, "text": " Labs?", "tokens": [50554, 40047, 30, 50604], "temperature":
  0.0, "avg_logprob": -0.24558462816126206, "compression_ratio": 1.628930817610063,
  "no_speech_prob": 0.007410705089569092}, {"id": 102, "seek": 33688, "start": 341.68,
  "end": 342.68, "text": " Is this why you do it?", "tokens": [50604, 1119, 341, 983,
  291, 360, 309, 30, 50654], "temperature": 0.0, "avg_logprob": -0.24558462816126206,
  "compression_ratio": 1.628930817610063, "no_speech_prob": 0.007410705089569092},
  {"id": 103, "seek": 33688, "start": 342.68, "end": 343.68, "text": " Or is there
  something else as well?", "tokens": [50654, 1610, 307, 456, 746, 1646, 382, 731,
  30, 50704], "temperature": 0.0, "avg_logprob": -0.24558462816126206, "compression_ratio":
  1.628930817610063, "no_speech_prob": 0.007410705089569092}, {"id": 104, "seek":
  33688, "start": 343.68, "end": 348.08, "text": " I just wanted to kind of tap into
  the psychological element of it if you thought about it.", "tokens": [50704, 286,
  445, 1415, 281, 733, 295, 5119, 666, 264, 14346, 4478, 295, 309, 498, 291, 1194,
  466, 309, 13, 50924], "temperature": 0.0, "avg_logprob": -0.24558462816126206, "compression_ratio":
  1.628930817610063, "no_speech_prob": 0.007410705089569092}, {"id": 105, "seek":
  33688, "start": 348.08, "end": 350.08, "text": " Yeah, yeah, I love to talk about
  it.", "tokens": [50924, 865, 11, 1338, 11, 286, 959, 281, 751, 466, 309, 13, 51024],
  "temperature": 0.0, "avg_logprob": -0.24558462816126206, "compression_ratio": 1.628930817610063,
  "no_speech_prob": 0.007410705089569092}, {"id": 106, "seek": 33688, "start": 350.08,
  "end": 355.48, "text": " I mean, my inspiration for YouTube came from, I guess I
  was just like one of these people", "tokens": [51024, 286, 914, 11, 452, 10249,
  337, 3088, 1361, 490, 11, 286, 2041, 286, 390, 445, 411, 472, 295, 613, 561, 51294],
  "temperature": 0.0, "avg_logprob": -0.24558462816126206, "compression_ratio": 1.628930817610063,
  "no_speech_prob": 0.007410705089569092}, {"id": 107, "seek": 33688, "start": 355.48,
  "end": 361.48, "text": " who really enjoyed like we would have guest lectures come
  to Florida Atlantic University.", "tokens": [51294, 567, 534, 4626, 411, 321, 576,
  362, 8341, 16564, 808, 281, 9117, 20233, 3535, 13, 51594], "temperature": 0.0, "avg_logprob":
  -0.24558462816126206, "compression_ratio": 1.628930817610063, "no_speech_prob":
  0.007410705089569092}, {"id": 108, "seek": 33688, "start": 361.48, "end": 365.08,
  "text": " One that stood out to me more than anything else is researchers from Johns
  Hopkins came", "tokens": [51594, 1485, 300, 9371, 484, 281, 385, 544, 813, 1340,
  1646, 307, 10309, 490, 37016, 29999, 1361, 51774], "temperature": 0.0, "avg_logprob":
  -0.24558462816126206, "compression_ratio": 1.628930817610063, "no_speech_prob":
  0.007410705089569092}, {"id": 109, "seek": 36508, "start": 365.08, "end": 370.47999999999996,
  "text": " to, they had built a prosthetic limb that connects to a brain computer
  interface.", "tokens": [50364, 281, 11, 436, 632, 3094, 257, 39976, 3532, 30390,
  300, 16967, 281, 257, 3567, 3820, 9226, 13, 50634], "temperature": 0.0, "avg_logprob":
  -0.21546588766163793, "compression_ratio": 1.821917808219178, "no_speech_prob":
  0.015819894149899483}, {"id": 110, "seek": 36508, "start": 370.47999999999996, "end":
  374.8, "text": " And they have people who have lost their limbs and they can, you
  know, blindfolded touch", "tokens": [50634, 400, 436, 362, 561, 567, 362, 2731,
  641, 29315, 293, 436, 393, 11, 291, 458, 11, 44846, 292, 2557, 50850], "temperature":
  0.0, "avg_logprob": -0.21546588766163793, "compression_ratio": 1.821917808219178,
  "no_speech_prob": 0.015819894149899483}, {"id": 111, "seek": 36508, "start": 374.8,
  "end": 378.52, "text": " an orange and say, this is an orange, this is an apple,
  this is a banana.", "tokens": [50850, 364, 7671, 293, 584, 11, 341, 307, 364, 7671,
  11, 341, 307, 364, 10606, 11, 341, 307, 257, 14194, 13, 51036], "temperature": 0.0,
  "avg_logprob": -0.21546588766163793, "compression_ratio": 1.821917808219178, "no_speech_prob":
  0.015819894149899483}, {"id": 112, "seek": 36508, "start": 378.52, "end": 380.56,
  "text": " And they came to talk to us at Florida Atlantic.", "tokens": [51036, 400,
  436, 1361, 281, 751, 281, 505, 412, 9117, 20233, 13, 51138], "temperature": 0.0,
  "avg_logprob": -0.21546588766163793, "compression_ratio": 1.821917808219178, "no_speech_prob":
  0.015819894149899483}, {"id": 113, "seek": 36508, "start": 380.56, "end": 382.56,
  "text": " And I mean, it was, it was inspiring.", "tokens": [51138, 400, 286, 914,
  11, 309, 390, 11, 309, 390, 15883, 13, 51238], "temperature": 0.0, "avg_logprob":
  -0.21546588766163793, "compression_ratio": 1.821917808219178, "no_speech_prob":
  0.015819894149899483}, {"id": 114, "seek": 36508, "start": 382.56, "end": 386.32,
  "text": " I like, I love these kind of seminars and just, I guess like falling in
  love with this", "tokens": [51238, 286, 411, 11, 286, 959, 613, 733, 295, 43112,
  293, 445, 11, 286, 2041, 411, 7440, 294, 959, 365, 341, 51426], "temperature": 0.0,
  "avg_logprob": -0.21546588766163793, "compression_ratio": 1.821917808219178, "no_speech_prob":
  0.015819894149899483}, {"id": 115, "seek": 36508, "start": 386.32, "end": 388.32,
  "text": " kind of presentation.", "tokens": [51426, 733, 295, 5860, 13, 51526],
  "temperature": 0.0, "avg_logprob": -0.21546588766163793, "compression_ratio": 1.821917808219178,
  "no_speech_prob": 0.015819894149899483}, {"id": 116, "seek": 36508, "start": 388.32,
  "end": 391.52, "text": " It''s almost like, say like to me, it''s kind of like an
  allegace to like maybe like stand-up", "tokens": [51526, 467, 311, 1920, 411, 11,
  584, 411, 281, 385, 11, 309, 311, 733, 295, 411, 364, 10364, 617, 281, 411, 1310,
  411, 1463, 12, 1010, 51686], "temperature": 0.0, "avg_logprob": -0.21546588766163793,
  "compression_ratio": 1.821917808219178, "no_speech_prob": 0.015819894149899483},
  {"id": 117, "seek": 39152, "start": 391.52, "end": 396.32, "text": " comedy, how
  you have someone who gets up on stage and puts the show on, you know, the", "tokens":
  [50364, 13394, 11, 577, 291, 362, 1580, 567, 2170, 493, 322, 3233, 293, 8137, 264,
  855, 322, 11, 291, 458, 11, 264, 50604], "temperature": 0.0, "avg_logprob": -0.17862069189965307,
  "compression_ratio": 1.916083916083916, "no_speech_prob": 0.030704699456691742},
  {"id": 118, "seek": 39152, "start": 396.32, "end": 398.0, "text": " benefit of the
  slides behind them.", "tokens": [50604, 5121, 295, 264, 9788, 2261, 552, 13, 50688],
  "temperature": 0.0, "avg_logprob": -0.17862069189965307, "compression_ratio": 1.916083916083916,
  "no_speech_prob": 0.030704699456691742}, {"id": 119, "seek": 39152, "start": 398.0,
  "end": 401.24, "text": " And, you know, I really like these, these kind of talks.",
  "tokens": [50688, 400, 11, 291, 458, 11, 286, 534, 411, 613, 11, 613, 733, 295,
  6686, 13, 50850], "temperature": 0.0, "avg_logprob": -0.17862069189965307, "compression_ratio":
  1.916083916083916, "no_speech_prob": 0.030704699456691742}, {"id": 120, "seek":
  39152, "start": 401.24, "end": 404.91999999999996, "text": " And that''s kind of,
  so that''s kind of like the art of it is what I really like about YouTube.", "tokens":
  [50850, 400, 300, 311, 733, 295, 11, 370, 300, 311, 733, 295, 411, 264, 1523, 295,
  309, 307, 437, 286, 534, 411, 466, 3088, 13, 51034], "temperature": 0.0, "avg_logprob":
  -0.17862069189965307, "compression_ratio": 1.916083916083916, "no_speech_prob":
  0.030704699456691742}, {"id": 121, "seek": 39152, "start": 404.91999999999996, "end":
  409.4, "text": " I mean, I definitely believe in YouTube as the medium for communicating
  these ideas", "tokens": [51034, 286, 914, 11, 286, 2138, 1697, 294, 3088, 382, 264,
  6399, 337, 17559, 613, 3487, 51258], "temperature": 0.0, "avg_logprob": -0.17862069189965307,
  "compression_ratio": 1.916083916083916, "no_speech_prob": 0.030704699456691742},
  {"id": 122, "seek": 39152, "start": 409.4, "end": 410.4, "text": " right now.",
  "tokens": [51258, 558, 586, 13, 51308], "temperature": 0.0, "avg_logprob": -0.17862069189965307,
  "compression_ratio": 1.916083916083916, "no_speech_prob": 0.030704699456691742},
  {"id": 123, "seek": 39152, "start": 410.4, "end": 416.52, "text": " You know, like,
  and we''ll get into talking about writing on medium and like, yeah, like", "tokens":
  [51308, 509, 458, 11, 411, 11, 293, 321, 603, 483, 666, 1417, 466, 3579, 322, 6399,
  293, 411, 11, 1338, 11, 411, 51614], "temperature": 0.0, "avg_logprob": -0.17862069189965307,
  "compression_ratio": 1.916083916083916, "no_speech_prob": 0.030704699456691742},
  {"id": 124, "seek": 39152, "start": 416.52, "end": 420.24, "text": " the different
  ways you can write on Twitter, you can write on medium, you can record podcasts",
  "tokens": [51614, 264, 819, 2098, 291, 393, 2464, 322, 5794, 11, 291, 393, 2464,
  322, 6399, 11, 291, 393, 2136, 24045, 51800], "temperature": 0.0, "avg_logprob":
  -0.17862069189965307, "compression_ratio": 1.916083916083916, "no_speech_prob":
  0.030704699456691742}, {"id": 125, "seek": 42024, "start": 420.24, "end": 425.0,
  "text": " and put it on Spotify, Apple, and you can write these research papers
  obviously just,", "tokens": [50364, 293, 829, 309, 322, 29036, 11, 6373, 11, 293,
  291, 393, 2464, 613, 2132, 10577, 2745, 445, 11, 50602], "temperature": 0.0, "avg_logprob":
  -0.32970752716064455, "compression_ratio": 1.6150943396226416, "no_speech_prob":
  0.008928782306611538}, {"id": 126, "seek": 42024, "start": 425.0, "end": 431.96000000000004,
  "text": " you know, upload it to archive, treat it like a medium of the number of
  user on archive", "tokens": [50602, 291, 458, 11, 6580, 309, 281, 23507, 11, 2387,
  309, 411, 257, 6399, 295, 264, 1230, 295, 4195, 322, 23507, 50950], "temperature":
  0.0, "avg_logprob": -0.32970752716064455, "compression_ratio": 1.6150943396226416,
  "no_speech_prob": 0.008928782306611538}, {"id": 127, "seek": 42024, "start": 431.96000000000004,
  "end": 434.56, "text": " is probably less than what you get on YouTube.", "tokens":
  [50950, 307, 1391, 1570, 813, 437, 291, 483, 322, 3088, 13, 51080], "temperature":
  0.0, "avg_logprob": -0.32970752716064455, "compression_ratio": 1.6150943396226416,
  "no_speech_prob": 0.008928782306611538}, {"id": 128, "seek": 42024, "start": 434.56,
  "end": 436.04, "text": " The content is different too.", "tokens": [51080, 440,
  2701, 307, 819, 886, 13, 51154], "temperature": 0.0, "avg_logprob": -0.32970752716064455,
  "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.008928782306611538},
  {"id": 129, "seek": 42024, "start": 436.04, "end": 437.04, "text": " So, yeah.",
  "tokens": [51154, 407, 11, 1338, 13, 51204], "temperature": 0.0, "avg_logprob":
  -0.32970752716064455, "compression_ratio": 1.6150943396226416, "no_speech_prob":
  0.008928782306611538}, {"id": 130, "seek": 42024, "start": 437.04, "end": 438.04,
  "text": " Yeah.", "tokens": [51204, 865, 13, 51254], "temperature": 0.0, "avg_logprob":
  -0.32970752716064455, "compression_ratio": 1.6150943396226416, "no_speech_prob":
  0.008928782306611538}, {"id": 131, "seek": 42024, "start": 438.04, "end": 443.24,
  "text": " So, yeah, I really believe in the medium and then I just want to see the
  art form develop", "tokens": [51254, 407, 11, 1338, 11, 286, 534, 1697, 294, 264,
  6399, 293, 550, 286, 445, 528, 281, 536, 264, 1523, 1254, 1499, 51514], "temperature":
  0.0, "avg_logprob": -0.32970752716064455, "compression_ratio": 1.6150943396226416,
  "no_speech_prob": 0.008928782306611538}, {"id": 132, "seek": 42024, "start": 443.24,
  "end": 444.24, "text": " further.", "tokens": [51514, 3052, 13, 51564], "temperature":
  0.0, "avg_logprob": -0.32970752716064455, "compression_ratio": 1.6150943396226416,
  "no_speech_prob": 0.008928782306611538}, {"id": 133, "seek": 42024, "start": 444.24,
  "end": 446.08, "text": " Like, I''m really impressed with what Yannick Kiltch was
  doing.", "tokens": [51564, 1743, 11, 286, 478, 534, 11679, 365, 437, 398, 969, 618,
  591, 2352, 339, 390, 884, 13, 51656], "temperature": 0.0, "avg_logprob": -0.32970752716064455,
  "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.008928782306611538},
  {"id": 134, "seek": 44608, "start": 446.08, "end": 450.71999999999997, "text": "
  Like, right now he''s just released auto regressive diffusion models and, you know,
  I''m excited", "tokens": [50364, 1743, 11, 558, 586, 415, 311, 445, 4736, 8399,
  1121, 22733, 25242, 5245, 293, 11, 291, 458, 11, 286, 478, 2919, 50596], "temperature":
  0.0, "avg_logprob": -0.22870539275693222, "compression_ratio": 1.6795774647887325,
  "no_speech_prob": 0.4000794291496277}, {"id": 135, "seek": 44608, "start": 450.71999999999997,
  "end": 454.96, "text": " to watch it and that''s, and that''s the fun about it is,
  is you have this excitement about", "tokens": [50596, 281, 1159, 309, 293, 300,
  311, 11, 293, 300, 311, 264, 1019, 466, 309, 307, 11, 307, 291, 362, 341, 14755,
  466, 50808], "temperature": 0.0, "avg_logprob": -0.22870539275693222, "compression_ratio":
  1.6795774647887325, "no_speech_prob": 0.4000794291496277}, {"id": 136, "seek": 44608,
  "start": 454.96, "end": 455.96, "text": " it.", "tokens": [50808, 309, 13, 50858],
  "temperature": 0.0, "avg_logprob": -0.22870539275693222, "compression_ratio": 1.6795774647887325,
  "no_speech_prob": 0.4000794291496277}, {"id": 137, "seek": 44608, "start": 455.96,
  "end": 456.96, "text": " Let''s link that as well.", "tokens": [50858, 961, 311,
  2113, 300, 382, 731, 13, 50908], "temperature": 0.0, "avg_logprob": -0.22870539275693222,
  "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.4000794291496277},
  {"id": 138, "seek": 44608, "start": 456.96, "end": 460.56, "text": " It''s a YouTube
  as well or like another show you mentioned.", "tokens": [50908, 467, 311, 257, 3088,
  382, 731, 420, 411, 1071, 855, 291, 2835, 13, 51088], "temperature": 0.0, "avg_logprob":
  -0.22870539275693222, "compression_ratio": 1.6795774647887325, "no_speech_prob":
  0.4000794291496277}, {"id": 139, "seek": 44608, "start": 460.56, "end": 461.56,
  "text": " Yeah, yeah.", "tokens": [51088, 865, 11, 1338, 13, 51138], "temperature":
  0.0, "avg_logprob": -0.22870539275693222, "compression_ratio": 1.6795774647887325,
  "no_speech_prob": 0.4000794291496277}, {"id": 140, "seek": 44608, "start": 461.56,
  "end": 466.79999999999995, "text": " I think just YouTube, Yannick Kiltch, I think
  most of our viewers will know what we''re talking", "tokens": [51138, 286, 519,
  445, 3088, 11, 398, 969, 618, 591, 2352, 339, 11, 286, 519, 881, 295, 527, 8499,
  486, 458, 437, 321, 434, 1417, 51400], "temperature": 0.0, "avg_logprob": -0.22870539275693222,
  "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.4000794291496277},
  {"id": 141, "seek": 44608, "start": 466.79999999999995, "end": 467.79999999999995,
  "text": " about.", "tokens": [51400, 466, 13, 51450], "temperature": 0.0, "avg_logprob":
  -0.22870539275693222, "compression_ratio": 1.6795774647887325, "no_speech_prob":
  0.4000794291496277}, {"id": 142, "seek": 44608, "start": 467.79999999999995, "end":
  470.28, "text": " I just want to make sure that I will also educate myself.", "tokens":
  [51450, 286, 445, 528, 281, 652, 988, 300, 286, 486, 611, 16092, 2059, 13, 51574],
  "temperature": 0.0, "avg_logprob": -0.22870539275693222, "compression_ratio": 1.6795774647887325,
  "no_speech_prob": 0.4000794291496277}, {"id": 143, "seek": 44608, "start": 470.28,
  "end": 472.36, "text": " So, so let''s link that.", "tokens": [51574, 407, 11, 370,
  718, 311, 2113, 300, 13, 51678], "temperature": 0.0, "avg_logprob": -0.22870539275693222,
  "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.4000794291496277},
  {"id": 144, "seek": 44608, "start": 472.36, "end": 473.36, "text": " Awesome.",
  "tokens": [51678, 10391, 13, 51728], "temperature": 0.0, "avg_logprob": -0.22870539275693222,
  "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.4000794291496277},
  {"id": 145, "seek": 47336, "start": 473.36, "end": 478.28000000000003, "text": "
  Yeah, I mean, and so yeah, you said that data augmentation is one thing you worked
  on and", "tokens": [50364, 865, 11, 286, 914, 11, 293, 370, 1338, 11, 291, 848,
  300, 1412, 14501, 19631, 307, 472, 551, 291, 2732, 322, 293, 50610], "temperature":
  0.0, "avg_logprob": -0.21103688596769143, "compression_ratio": 1.6895306859205776,
  "no_speech_prob": 0.10372499376535416}, {"id": 146, "seek": 47336, "start": 478.28000000000003,
  "end": 480.2, "text": " I guess continue working on.", "tokens": [50610, 286, 2041,
  2354, 1364, 322, 13, 50706], "temperature": 0.0, "avg_logprob": -0.21103688596769143,
  "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.10372499376535416},
  {"id": 147, "seek": 47336, "start": 480.2, "end": 485.28000000000003, "text": "
  It''s actually interesting that you did that in CV space, but there is also somehow
  connection", "tokens": [50706, 467, 311, 767, 1880, 300, 291, 630, 300, 294, 22995,
  1901, 11, 457, 456, 307, 611, 6063, 4984, 50960], "temperature": 0.0, "avg_logprob":
  -0.21103688596769143, "compression_ratio": 1.6895306859205776, "no_speech_prob":
  0.10372499376535416}, {"id": 148, "seek": 47336, "start": 485.28000000000003, "end":
  486.28000000000003, "text": " in text, right?", "tokens": [50960, 294, 2487, 11,
  558, 30, 51010], "temperature": 0.0, "avg_logprob": -0.21103688596769143, "compression_ratio":
  1.6895306859205776, "no_speech_prob": 0.10372499376535416}, {"id": 149, "seek":
  47336, "start": 486.28000000000003, "end": 488.68, "text": " Can you tell a bit
  more about that?", "tokens": [51010, 1664, 291, 980, 257, 857, 544, 466, 300, 30,
  51130], "temperature": 0.0, "avg_logprob": -0.21103688596769143, "compression_ratio":
  1.6895306859205776, "no_speech_prob": 0.10372499376535416}, {"id": 150, "seek":
  47336, "start": 488.68, "end": 494.76, "text": " Yeah, so I, so I spent the, I think
  it was this, sorry, I''m getting my dates wrong.", "tokens": [51130, 865, 11, 370,
  286, 11, 370, 286, 4418, 264, 11, 286, 519, 309, 390, 341, 11, 2597, 11, 286, 478,
  1242, 452, 11691, 2085, 13, 51434], "temperature": 0.0, "avg_logprob": -0.21103688596769143,
  "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.10372499376535416},
  {"id": 151, "seek": 47336, "start": 494.76, "end": 495.76, "text": " It''s currently
  the fall.", "tokens": [51434, 467, 311, 4362, 264, 2100, 13, 51484], "temperature":
  0.0, "avg_logprob": -0.21103688596769143, "compression_ratio": 1.6895306859205776,
  "no_speech_prob": 0.10372499376535416}, {"id": 152, "seek": 47336, "start": 495.76,
  "end": 499.96000000000004, "text": " So, I think I spent the summer spring of last
  year trying to transition these ideas into", "tokens": [51484, 407, 11, 286, 519,
  286, 4418, 264, 4266, 5587, 295, 1036, 1064, 1382, 281, 6034, 613, 3487, 666, 51694],
  "temperature": 0.0, "avg_logprob": -0.21103688596769143, "compression_ratio": 1.6895306859205776,
  "no_speech_prob": 0.10372499376535416}, {"id": 153, "seek": 47336, "start": 499.96000000000004,
  "end": 500.96000000000004, "text": " text.", "tokens": [51694, 2487, 13, 51744],
  "temperature": 0.0, "avg_logprob": -0.21103688596769143, "compression_ratio": 1.6895306859205776,
  "no_speech_prob": 0.10372499376535416}, {"id": 154, "seek": 50096, "start": 500.96,
  "end": 505.71999999999997, "text": " I did the image data augmentation survey in
  2019 where the sentiment was still extremely", "tokens": [50364, 286, 630, 264,
  3256, 1412, 14501, 19631, 8984, 294, 6071, 689, 264, 16149, 390, 920, 4664, 50602],
  "temperature": 0.0, "avg_logprob": -0.22838417912872744, "compression_ratio": 1.655688622754491,
  "no_speech_prob": 0.025469627231359482}, {"id": 155, "seek": 50096, "start": 505.71999999999997,
  "end": 508.08, "text": " hot around GANs, gender, vatricero networks.", "tokens":
  [50602, 2368, 926, 460, 1770, 82, 11, 7898, 11, 371, 267, 1341, 2032, 9590, 13,
  50720], "temperature": 0.0, "avg_logprob": -0.22838417912872744, "compression_ratio":
  1.655688622754491, "no_speech_prob": 0.025469627231359482}, {"id": 156, "seek":
  50096, "start": 508.08, "end": 510.96, "text": " Everyone was really excited about
  this real fake loss.", "tokens": [50720, 5198, 390, 534, 2919, 466, 341, 957, 7592,
  4470, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22838417912872744, "compression_ratio":
  1.655688622754491, "no_speech_prob": 0.025469627231359482}, {"id": 157, "seek":
  50096, "start": 510.96, "end": 514.52, "text": " We can generate data and then add
  that to the data set and then, you know, suddenly we", "tokens": [50864, 492, 393,
  8460, 1412, 293, 550, 909, 300, 281, 264, 1412, 992, 293, 550, 11, 291, 458, 11,
  5800, 321, 51042], "temperature": 0.0, "avg_logprob": -0.22838417912872744, "compression_ratio":
  1.655688622754491, "no_speech_prob": 0.025469627231359482}, {"id": 158, "seek":
  50096, "start": 514.52, "end": 519.4, "text": " have this very broad coverage for
  interpolation in our data space.", "tokens": [51042, 362, 341, 588, 4152, 9645,
  337, 44902, 399, 294, 527, 1412, 1901, 13, 51286], "temperature": 0.0, "avg_logprob":
  -0.22838417912872744, "compression_ratio": 1.655688622754491, "no_speech_prob":
  0.025469627231359482}, {"id": 159, "seek": 50096, "start": 519.4, "end": 521.64,
  "text": " So then I was trying to look into text.", "tokens": [51286, 407, 550,
  286, 390, 1382, 281, 574, 666, 2487, 13, 51398], "temperature": 0.0, "avg_logprob":
  -0.22838417912872744, "compression_ratio": 1.655688622754491, "no_speech_prob":
  0.025469627231359482}, {"id": 160, "seek": 50096, "start": 521.64, "end": 525.92,
  "text": " Text is, I say the key lesson I learned is that it''s harder to be labeled
  preserving.", "tokens": [51398, 18643, 307, 11, 286, 584, 264, 2141, 6898, 286,
  3264, 307, 300, 309, 311, 6081, 281, 312, 21335, 33173, 13, 51612], "temperature":
  0.0, "avg_logprob": -0.22838417912872744, "compression_ratio": 1.655688622754491,
  "no_speech_prob": 0.025469627231359482}, {"id": 161, "seek": 50096, "start": 525.92,
  "end": 530.04, "text": " When you''re forming the X prime Y, it''s less likely that
  the Y is going to have that", "tokens": [51612, 1133, 291, 434, 15745, 264, 1783,
  5835, 398, 11, 309, 311, 1570, 3700, 300, 264, 398, 307, 516, 281, 362, 300, 51818],
  "temperature": 0.0, "avg_logprob": -0.22838417912872744, "compression_ratio": 1.655688622754491,
  "no_speech_prob": 0.025469627231359482}, {"id": 162, "seek": 53004, "start": 530.04,
  "end": 536.4399999999999, "text": " same high level class labels as you''re trying
  to do things like say, like the starter kit", "tokens": [50364, 912, 1090, 1496,
  1508, 16949, 382, 291, 434, 1382, 281, 360, 721, 411, 584, 11, 411, 264, 22465,
  8260, 50684], "temperature": 0.0, "avg_logprob": -0.20935244208214268, "compression_ratio":
  1.8543046357615893, "no_speech_prob": 0.0050623067654669285}, {"id": 163, "seek":
  53004, "start": 536.4399999999999, "end": 542.4399999999999, "text": " would be
  random swapping, random insertion, random deletion, those kind of things.", "tokens":
  [50684, 576, 312, 4974, 1693, 10534, 11, 4974, 8969, 313, 11, 4974, 1103, 302, 313,
  11, 729, 733, 295, 721, 13, 50984], "temperature": 0.0, "avg_logprob": -0.20935244208214268,
  "compression_ratio": 1.8543046357615893, "no_speech_prob": 0.0050623067654669285},
  {"id": 164, "seek": 53004, "start": 542.4399999999999, "end": 546.28, "text": "
  And then you kind of transition into maybe trying to use a knowledge graph to better
  guide", "tokens": [50984, 400, 550, 291, 733, 295, 6034, 666, 1310, 1382, 281, 764,
  257, 3601, 4295, 281, 1101, 5934, 51176], "temperature": 0.0, "avg_logprob": -0.20935244208214268,
  "compression_ratio": 1.8543046357615893, "no_speech_prob": 0.0050623067654669285},
  {"id": 165, "seek": 53004, "start": 546.28, "end": 548.68, "text": " the text you''re
  replacing.", "tokens": [51176, 264, 2487, 291, 434, 19139, 13, 51296], "temperature":
  0.0, "avg_logprob": -0.20935244208214268, "compression_ratio": 1.8543046357615893,
  "no_speech_prob": 0.0050623067654669285}, {"id": 166, "seek": 53004, "start": 548.68,
  "end": 552.28, "text": " And then ideas like say mix up where you cut and paste
  and glue sentences together.", "tokens": [51296, 400, 550, 3487, 411, 584, 2890,
  493, 689, 291, 1723, 293, 9163, 293, 8998, 16579, 1214, 13, 51476], "temperature":
  0.0, "avg_logprob": -0.20935244208214268, "compression_ratio": 1.8543046357615893,
  "no_speech_prob": 0.0050623067654669285}, {"id": 167, "seek": 53004, "start": 552.28,
  "end": 554.7199999999999, "text": " I''m not like a huge fan of that, but it''s
  kind of interesting.", "tokens": [51476, 286, 478, 406, 411, 257, 2603, 3429, 295,
  300, 11, 457, 309, 311, 733, 295, 1880, 13, 51598], "temperature": 0.0, "avg_logprob":
  -0.20935244208214268, "compression_ratio": 1.8543046357615893, "no_speech_prob":
  0.0050623067654669285}, {"id": 168, "seek": 53004, "start": 554.7199999999999, "end":
  555.7199999999999, "text": " Yes.", "tokens": [51598, 1079, 13, 51648], "temperature":
  0.0, "avg_logprob": -0.20935244208214268, "compression_ratio": 1.8543046357615893,
  "no_speech_prob": 0.0050623067654669285}, {"id": 169, "seek": 53004, "start": 555.7199999999999,
  "end": 556.7199999999999, "text": " Might as well have like drop out.", "tokens":
  [51648, 23964, 382, 731, 362, 411, 3270, 484, 13, 51698], "temperature": 0.0, "avg_logprob":
  -0.20935244208214268, "compression_ratio": 1.8543046357615893, "no_speech_prob":
  0.0050623067654669285}, {"id": 170, "seek": 53004, "start": 556.7199999999999, "end":
  559.7199999999999, "text": " It''s kind of like a, you know, like I don''t think
  there''s a lot of intuition in the", "tokens": [51698, 467, 311, 733, 295, 411,
  257, 11, 291, 458, 11, 411, 286, 500, 380, 519, 456, 311, 257, 688, 295, 24002,
  294, 264, 51848], "temperature": 0.0, "avg_logprob": -0.20935244208214268, "compression_ratio":
  1.8543046357615893, "no_speech_prob": 0.0050623067654669285}, {"id": 171, "seek":
  55972, "start": 559.72, "end": 563.44, "text": " data space of why just smashing
  them together would work so well.", "tokens": [50364, 1412, 1901, 295, 983, 445,
  43316, 552, 1214, 576, 589, 370, 731, 13, 50550], "temperature": 0.0, "avg_logprob":
  -0.18025071070744442, "compression_ratio": 1.8083067092651757, "no_speech_prob":
  0.00034681532997637987}, {"id": 172, "seek": 55972, "start": 563.44, "end": 565.0,
  "text": " But it does kind of work.", "tokens": [50550, 583, 309, 775, 733, 295,
  589, 13, 50628], "temperature": 0.0, "avg_logprob": -0.18025071070744442, "compression_ratio":
  1.8083067092651757, "no_speech_prob": 0.00034681532997637987}, {"id": 173, "seek":
  55972, "start": 565.0, "end": 570.0400000000001, "text": " And then, and then I
  really like this category of generative data augmentation is obviously", "tokens":
  [50628, 400, 550, 11, 293, 550, 286, 534, 411, 341, 7719, 295, 1337, 1166, 1412,
  14501, 19631, 307, 2745, 50880], "temperature": 0.0, "avg_logprob": -0.18025071070744442,
  "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.00034681532997637987},
  {"id": 174, "seek": 55972, "start": 570.0400000000001, "end": 571.96, "text": "
  mentioning my start in gendered adversarial networks.", "tokens": [50880, 18315,
  452, 722, 294, 7898, 292, 17641, 44745, 9590, 13, 50976], "temperature": 0.0, "avg_logprob":
  -0.18025071070744442, "compression_ratio": 1.8083067092651757, "no_speech_prob":
  0.00034681532997637987}, {"id": 175, "seek": 55972, "start": 571.96, "end": 574.36,
  "text": " And this idea that you learn the data distribution.", "tokens": [50976,
  400, 341, 1558, 300, 291, 1466, 264, 1412, 7316, 13, 51096], "temperature": 0.0,
  "avg_logprob": -0.18025071070744442, "compression_ratio": 1.8083067092651757, "no_speech_prob":
  0.00034681532997637987}, {"id": 176, "seek": 55972, "start": 574.36, "end": 578.88,
  "text": " So you sample from the data distribution to learn classifiers and kind
  of classifiers", "tokens": [51096, 407, 291, 6889, 490, 264, 1412, 7316, 281, 1466,
  1508, 23463, 293, 733, 295, 1508, 23463, 51322], "temperature": 0.0, "avg_logprob":
  -0.18025071070744442, "compression_ratio": 1.8083067092651757, "no_speech_prob":
  0.00034681532997637987}, {"id": 177, "seek": 55972, "start": 578.88, "end": 584.48,
  "text": " being almost like a appendage of the generative model, which is, which
  is like what we''re talking", "tokens": [51322, 885, 1920, 411, 257, 34116, 609,
  295, 264, 1337, 1166, 2316, 11, 597, 307, 11, 597, 307, 411, 437, 321, 434, 1417,
  51602], "temperature": 0.0, "avg_logprob": -0.18025071070744442, "compression_ratio":
  1.8083067092651757, "no_speech_prob": 0.00034681532997637987}, {"id": 178, "seek":
  55972, "start": 584.48, "end": 588.4, "text": " about with the modules, the supervised
  learning tasks that you append onto the vector search", "tokens": [51602, 466, 365,
  264, 16679, 11, 264, 46533, 2539, 9608, 300, 291, 34116, 3911, 264, 8062, 3164,
  51798], "temperature": 0.0, "avg_logprob": -0.18025071070744442, "compression_ratio":
  1.8083067092651757, "no_speech_prob": 0.00034681532997637987}, {"id": 179, "seek":
  58840, "start": 588.4, "end": 590.36, "text": " engine database.", "tokens": [50364,
  2848, 8149, 13, 50462], "temperature": 0.0, "avg_logprob": -0.21727121793306792,
  "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.012114069424569607},
  {"id": 180, "seek": 58840, "start": 590.36, "end": 595.8, "text": " It''s like this
  task of having a generative model or say a representative vector space is", "tokens":
  [50462, 467, 311, 411, 341, 5633, 295, 1419, 257, 1337, 1166, 2316, 420, 584, 257,
  12424, 8062, 1901, 307, 50734], "temperature": 0.0, "avg_logprob": -0.21727121793306792,
  "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.012114069424569607},
  {"id": 181, "seek": 58840, "start": 595.8, "end": 599.9599999999999, "text": " kind
  of like the real context that built into the supervised learning task.", "tokens":
  [50734, 733, 295, 411, 264, 957, 4319, 300, 3094, 666, 264, 46533, 2539, 5633, 13,
  50942], "temperature": 0.0, "avg_logprob": -0.21727121793306792, "compression_ratio":
  1.6805555555555556, "no_speech_prob": 0.012114069424569607}, {"id": 182, "seek":
  58840, "start": 599.9599999999999, "end": 601.4399999999999, "text": " Or at least
  that''s the way I see it.", "tokens": [50942, 1610, 412, 1935, 300, 311, 264, 636,
  286, 536, 309, 13, 51016], "temperature": 0.0, "avg_logprob": -0.21727121793306792,
  "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.012114069424569607},
  {"id": 183, "seek": 58840, "start": 601.4399999999999, "end": 604.8, "text": " And,
  you know, maybe anyone can leave a comment if they are have a different idea about",
  "tokens": [51016, 400, 11, 291, 458, 11, 1310, 2878, 393, 1856, 257, 2871, 498,
  436, 366, 362, 257, 819, 1558, 466, 51184], "temperature": 0.0, "avg_logprob": -0.21727121793306792,
  "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.012114069424569607},
  {"id": 184, "seek": 58840, "start": 604.8, "end": 605.8, "text": " that.", "tokens":
  [51184, 300, 13, 51234], "temperature": 0.0, "avg_logprob": -0.21727121793306792,
  "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.012114069424569607},
  {"id": 185, "seek": 58840, "start": 605.8, "end": 606.8, "text": " I think it''s
  ill aimed.", "tokens": [51234, 286, 519, 309, 311, 3171, 20540, 13, 51284], "temperature":
  0.0, "avg_logprob": -0.21727121793306792, "compression_ratio": 1.6805555555555556,
  "no_speech_prob": 0.012114069424569607}, {"id": 186, "seek": 58840, "start": 606.8,
  "end": 609.36, "text": " But so that''s kind of how I see those two things integrating.",
  "tokens": [51284, 583, 370, 300, 311, 733, 295, 577, 286, 536, 729, 732, 721, 26889,
  13, 51412], "temperature": 0.0, "avg_logprob": -0.21727121793306792, "compression_ratio":
  1.6805555555555556, "no_speech_prob": 0.012114069424569607}, {"id": 187, "seek":
  58840, "start": 609.36, "end": 614.16, "text": " So to connect this back to text,
  what we can do is text is we can use things like GPT", "tokens": [51412, 407, 281,
  1745, 341, 646, 281, 2487, 11, 437, 321, 393, 360, 307, 2487, 307, 321, 393, 764,
  721, 411, 26039, 51, 51652], "temperature": 0.0, "avg_logprob": -0.21727121793306792,
  "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.012114069424569607},
  {"id": 188, "seek": 61416, "start": 614.16, "end": 618.8, "text": " three or more
  so what they do is you would prompt GPT three.", "tokens": [50364, 1045, 420, 544,
  370, 437, 436, 360, 307, 291, 576, 12391, 26039, 51, 1045, 13, 50596], "temperature":
  0.0, "avg_logprob": -0.1784707886832101, "compression_ratio": 1.8108108108108107,
  "no_speech_prob": 0.097793348133564}, {"id": 189, "seek": 61416, "start": 618.8,
  "end": 623.6, "text": " So you''d say, you know, please finish this movie review
  with a positive sentiment as", "tokens": [50596, 407, 291, 1116, 584, 11, 291, 458,
  11, 1767, 2413, 341, 3169, 3131, 365, 257, 3353, 16149, 382, 50836], "temperature":
  0.0, "avg_logprob": -0.1784707886832101, "compression_ratio": 1.8108108108108107,
  "no_speech_prob": 0.097793348133564}, {"id": 190, "seek": 61416, "start": 623.6,
  "end": 624.76, "text": " the prompt.", "tokens": [50836, 264, 12391, 13, 50894],
  "temperature": 0.0, "avg_logprob": -0.1784707886832101, "compression_ratio": 1.8108108108108107,
  "no_speech_prob": 0.097793348133564}, {"id": 191, "seek": 61416, "start": 624.76,
  "end": 627.6, "text": " And then you can just remove whatever you want from the
  original data point.", "tokens": [50894, 400, 550, 291, 393, 445, 4159, 2035, 291,
  528, 490, 264, 3380, 1412, 935, 13, 51036], "temperature": 0.0, "avg_logprob": -0.1784707886832101,
  "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.097793348133564}, {"id":
  192, "seek": 61416, "start": 627.6, "end": 629.76, "text": " And GPT three can generate
  a new movie review.", "tokens": [51036, 400, 26039, 51, 1045, 393, 8460, 257, 777,
  3169, 3131, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1784707886832101,
  "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.097793348133564}, {"id":
  193, "seek": 61416, "start": 629.76, "end": 634.04, "text": " And then you can blow
  up your data set size, avoid the pitfalls of overfitting and that", "tokens": [51144,
  400, 550, 291, 393, 6327, 493, 428, 1412, 992, 2744, 11, 5042, 264, 10147, 18542,
  295, 670, 69, 2414, 293, 300, 51358], "temperature": 0.0, "avg_logprob": -0.1784707886832101,
  "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.097793348133564}, {"id":
  194, "seek": 61416, "start": 634.04, "end": 635.56, "text": " kind of promise of
  data augmentation.", "tokens": [51358, 733, 295, 6228, 295, 1412, 14501, 19631,
  13, 51434], "temperature": 0.0, "avg_logprob": -0.1784707886832101, "compression_ratio":
  1.8108108108108107, "no_speech_prob": 0.097793348133564}, {"id": 195, "seek": 61416,
  "start": 635.56, "end": 639.36, "text": " So hopefully that kind of answers the
  question of how I did this transition from image to", "tokens": [51434, 407, 4696,
  300, 733, 295, 6338, 264, 1168, 295, 577, 286, 630, 341, 6034, 490, 3256, 281, 51624],
  "temperature": 0.0, "avg_logprob": -0.1784707886832101, "compression_ratio": 1.8108108108108107,
  "no_speech_prob": 0.097793348133564}, {"id": 196, "seek": 61416, "start": 639.36,
  "end": 640.36, "text": " text data augmentation.", "tokens": [51624, 2487, 1412,
  14501, 19631, 13, 51674], "temperature": 0.0, "avg_logprob": -0.1784707886832101,
  "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.097793348133564}, {"id":
  197, "seek": 61416, "start": 640.36, "end": 641.36, "text": " Yeah, it does.", "tokens":
  [51674, 865, 11, 309, 775, 13, 51724], "temperature": 0.0, "avg_logprob": -0.1784707886832101,
  "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.097793348133564}, {"id":
  198, "seek": 64136, "start": 641.36, "end": 646.92, "text": " And I mean, why I''m
  asking also is because, you know, you can also treat these two sources", "tokens":
  [50364, 400, 286, 914, 11, 983, 286, 478, 3365, 611, 307, 570, 11, 291, 458, 11,
  291, 393, 611, 2387, 613, 732, 7139, 50642], "temperature": 0.0, "avg_logprob":
  -0.19987475430523907, "compression_ratio": 1.6778242677824269, "no_speech_prob":
  0.046540241688489914}, {"id": 199, "seek": 64136, "start": 646.92, "end": 651.4,
  "text": " of data in like kind of in a joint training task, right?", "tokens": [50642,
  295, 1412, 294, 411, 733, 295, 294, 257, 7225, 3097, 5633, 11, 558, 30, 50866],
  "temperature": 0.0, "avg_logprob": -0.19987475430523907, "compression_ratio": 1.6778242677824269,
  "no_speech_prob": 0.046540241688489914}, {"id": 200, "seek": 64136, "start": 651.4,
  "end": 654.48, "text": " So you can kind of train the joint neural network.", "tokens":
  [50866, 407, 291, 393, 733, 295, 3847, 264, 7225, 18161, 3209, 13, 51020], "temperature":
  0.0, "avg_logprob": -0.19987475430523907, "compression_ratio": 1.6778242677824269,
  "no_speech_prob": 0.046540241688489914}, {"id": 201, "seek": 64136, "start": 654.48,
  "end": 659.44, "text": " And for example, when you watch, let''s say watch using
  the algorithm, you watch the movie", "tokens": [51020, 400, 337, 1365, 11, 562,
  291, 1159, 11, 718, 311, 584, 1159, 1228, 264, 9284, 11, 291, 1159, 264, 3169, 51268],
  "temperature": 0.0, "avg_logprob": -0.19987475430523907, "compression_ratio": 1.6778242677824269,
  "no_speech_prob": 0.046540241688489914}, {"id": 202, "seek": 64136, "start": 659.44,
  "end": 666.12, "text": " or cartoon and you see some scene where, you know, one
  hero is kind of crying.", "tokens": [51268, 420, 18569, 293, 291, 536, 512, 4145,
  689, 11, 291, 458, 11, 472, 5316, 307, 733, 295, 8554, 13, 51602], "temperature":
  0.0, "avg_logprob": -0.19987475430523907, "compression_ratio": 1.6778242677824269,
  "no_speech_prob": 0.046540241688489914}, {"id": 203, "seek": 64136, "start": 666.12,
  "end": 668.32, "text": " The other one is cheering him up.", "tokens": [51602, 440,
  661, 472, 307, 11060, 796, 493, 13, 51712], "temperature": 0.0, "avg_logprob": -0.19987475430523907,
  "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.046540241688489914},
  {"id": 204, "seek": 66832, "start": 668.32, "end": 671.0400000000001, "text": "
  You know, now where do you pay attention to?", "tokens": [50364, 509, 458, 11, 586,
  689, 360, 291, 1689, 3202, 281, 30, 50500], "temperature": 0.0, "avg_logprob": -0.2420017791516853,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.12082384526729584},
  {"id": 205, "seek": 66832, "start": 671.0400000000001, "end": 672.36, "text": "
  It''s also important, right?", "tokens": [50500, 467, 311, 611, 1021, 11, 558, 30,
  50566], "temperature": 0.0, "avg_logprob": -0.2420017791516853, "compression_ratio":
  1.6666666666666667, "no_speech_prob": 0.12082384526729584}, {"id": 206, "seek":
  66832, "start": 672.36, "end": 673.7600000000001, "text": " Because it''s the whole
  scene.", "tokens": [50566, 1436, 309, 311, 264, 1379, 4145, 13, 50636], "temperature":
  0.0, "avg_logprob": -0.2420017791516853, "compression_ratio": 1.6666666666666667,
  "no_speech_prob": 0.12082384526729584}, {"id": 207, "seek": 66832, "start": 673.7600000000001,
  "end": 678.32, "text": " Now you need to pay attention, maybe just to that pin on
  his neck, you know, that he''s", "tokens": [50636, 823, 291, 643, 281, 1689, 3202,
  11, 1310, 445, 281, 300, 5447, 322, 702, 6189, 11, 291, 458, 11, 300, 415, 311,
  50864], "temperature": 0.0, "avg_logprob": -0.2420017791516853, "compression_ratio":
  1.6666666666666667, "no_speech_prob": 0.12082384526729584}, {"id": 208, "seek":
  66832, "start": 678.32, "end": 680.12, "text": " not happy about.", "tokens": [50864,
  406, 2055, 466, 13, 50954], "temperature": 0.0, "avg_logprob": -0.2420017791516853,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.12082384526729584},
  {"id": 209, "seek": 66832, "start": 680.12, "end": 681.48, "text": " And you know,
  things like that.", "tokens": [50954, 400, 291, 458, 11, 721, 411, 300, 13, 51022],
  "temperature": 0.0, "avg_logprob": -0.2420017791516853, "compression_ratio": 1.6666666666666667,
  "no_speech_prob": 0.12082384526729584}, {"id": 210, "seek": 66832, "start": 681.48,
  "end": 683.6400000000001, "text": " So have you thought about that as well?", "tokens":
  [51022, 407, 362, 291, 1194, 466, 300, 382, 731, 30, 51130], "temperature": 0.0,
  "avg_logprob": -0.2420017791516853, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.12082384526729584}, {"id": 211, "seek": 66832, "start": 683.6400000000001, "end":
  686.36, "text": " Or are you still considering them as independent?", "tokens":
  [51130, 1610, 366, 291, 920, 8079, 552, 382, 6695, 30, 51266], "temperature": 0.0,
  "avg_logprob": -0.2420017791516853, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.12082384526729584}, {"id": 212, "seek": 66832, "start": 686.36, "end": 687.96,
  "text": " Yeah, I know.", "tokens": [51266, 865, 11, 286, 458, 13, 51346], "temperature":
  0.0, "avg_logprob": -0.2420017791516853, "compression_ratio": 1.6666666666666667,
  "no_speech_prob": 0.12082384526729584}, {"id": 213, "seek": 66832, "start": 687.96,
  "end": 689.48, "text": " Yeah, I love that idea.", "tokens": [51346, 865, 11, 286,
  959, 300, 1558, 13, 51422], "temperature": 0.0, "avg_logprob": -0.2420017791516853,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.12082384526729584},
  {"id": 214, "seek": 66832, "start": 689.48, "end": 695.32, "text": " Like I think
  what we''re the word that most people are using is multimodal learning.", "tokens":
  [51422, 1743, 286, 519, 437, 321, 434, 264, 1349, 300, 881, 561, 366, 1228, 307,
  32972, 378, 304, 2539, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2420017791516853,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.12082384526729584},
  {"id": 215, "seek": 69532, "start": 695.32, "end": 698.2, "text": " And I''d call
  that paper multimodal data augmentation.", "tokens": [50364, 400, 286, 1116, 818,
  300, 3035, 32972, 378, 304, 1412, 14501, 19631, 13, 50508], "temperature": 0.0,
  "avg_logprob": -0.2481349686444816, "compression_ratio": 1.583629893238434, "no_speech_prob":
  0.052273061126470566}, {"id": 216, "seek": 69532, "start": 698.2, "end": 703.4000000000001,
  "text": " And you know, just last night Microsoft released a new 2.5 billion parameter
  image text", "tokens": [50508, 400, 291, 458, 11, 445, 1036, 1818, 8116, 4736, 257,
  777, 568, 13, 20, 5218, 13075, 3256, 2487, 50768], "temperature": 0.0, "avg_logprob":
  -0.2481349686444816, "compression_ratio": 1.583629893238434, "no_speech_prob": 0.052273061126470566},
  {"id": 217, "seek": 69532, "start": 703.4000000000001, "end": 704.4000000000001,
  "text": " embedding space.", "tokens": [50768, 12240, 3584, 1901, 13, 50818], "temperature":
  0.0, "avg_logprob": -0.2481349686444816, "compression_ratio": 1.583629893238434,
  "no_speech_prob": 0.052273061126470566}, {"id": 218, "seek": 69532, "start": 704.4000000000001,
  "end": 709.98, "text": " You know, everyone''s knows about OpenAI''s clip image
  text spaces and the dolly, the avocado", "tokens": [50818, 509, 458, 11, 1518, 311,
  3255, 466, 7238, 48698, 311, 7353, 3256, 2487, 7673, 293, 264, 2722, 88, 11, 264,
  27041, 51097], "temperature": 0.0, "avg_logprob": -0.2481349686444816, "compression_ratio":
  1.583629893238434, "no_speech_prob": 0.052273061126470566}, {"id": 219, "seek":
  69532, "start": 709.98, "end": 711.7600000000001, "text": " shaved armchair generation.",
  "tokens": [51097, 37980, 3726, 17892, 5125, 13, 51186], "temperature": 0.0, "avg_logprob":
  -0.2481349686444816, "compression_ratio": 1.583629893238434, "no_speech_prob": 0.052273061126470566},
  {"id": 220, "seek": 69532, "start": 711.7600000000001, "end": 713.8000000000001,
  "text": " Everyone likes that.", "tokens": [51186, 5198, 5902, 300, 13, 51288],
  "temperature": 0.0, "avg_logprob": -0.2481349686444816, "compression_ratio": 1.583629893238434,
  "no_speech_prob": 0.052273061126470566}, {"id": 221, "seek": 69532, "start": 713.8000000000001,
  "end": 717.8000000000001, "text": " So yeah, I mean, multimodal learning is so exciting.",
  "tokens": [51288, 407, 1338, 11, 286, 914, 11, 32972, 378, 304, 2539, 307, 370,
  4670, 13, 51488], "temperature": 0.0, "avg_logprob": -0.2481349686444816, "compression_ratio":
  1.583629893238434, "no_speech_prob": 0.052273061126470566}, {"id": 222, "seek":
  69532, "start": 717.8000000000001, "end": 723.7600000000001, "text": " Yeah, I''d
  say it''s going to be an interesting thing with the computation of it and what kind",
  "tokens": [51488, 865, 11, 286, 1116, 584, 309, 311, 516, 281, 312, 364, 1880, 551,
  365, 264, 24903, 295, 309, 293, 437, 733, 51786], "temperature": 0.0, "avg_logprob":
  -0.2481349686444816, "compression_ratio": 1.583629893238434, "no_speech_prob": 0.052273061126470566},
  {"id": 223, "seek": 72376, "start": 724.76, "end": 727.68, "text": " of in what
  the computation requires, we''re setting up these kind of tests.", "tokens": [50414,
  295, 294, 437, 264, 24903, 7029, 11, 321, 434, 3287, 493, 613, 733, 295, 6921, 13,
  50560], "temperature": 0.0, "avg_logprob": -0.22855460475867903, "compression_ratio":
  1.7085889570552146, "no_speech_prob": 0.009539502672851086}, {"id": 224, "seek":
  72376, "start": 727.68, "end": 731.3199999999999, "text": " I''d say, especially
  with video data, like you just mentioned, I, you know, I wouldn''t", "tokens": [50560,
  286, 1116, 584, 11, 2318, 365, 960, 1412, 11, 411, 291, 445, 2835, 11, 286, 11,
  291, 458, 11, 286, 2759, 380, 50742], "temperature": 0.0, "avg_logprob": -0.22855460475867903,
  "compression_ratio": 1.7085889570552146, "no_speech_prob": 0.009539502672851086},
  {"id": 225, "seek": 72376, "start": 731.3199999999999, "end": 735.4, "text": " really
  want to play around with video data with my collab Google Drive workflow that I
  mentioned", "tokens": [50742, 534, 528, 281, 862, 926, 365, 960, 1412, 365, 452,
  44228, 3329, 15622, 20993, 300, 286, 2835, 50946], "temperature": 0.0, "avg_logprob":
  -0.22855460475867903, "compression_ratio": 1.7085889570552146, "no_speech_prob":
  0.009539502672851086}, {"id": 226, "seek": 72376, "start": 735.4, "end": 736.4,
  "text": " earlier.", "tokens": [50946, 3071, 13, 50996], "temperature": 0.0, "avg_logprob":
  -0.22855460475867903, "compression_ratio": 1.7085889570552146, "no_speech_prob":
  0.009539502672851086}, {"id": 227, "seek": 72376, "start": 736.4, "end": 737.4,
  "text": " Yeah.", "tokens": [50996, 865, 13, 51046], "temperature": 0.0, "avg_logprob":
  -0.22855460475867903, "compression_ratio": 1.7085889570552146, "no_speech_prob":
  0.009539502672851086}, {"id": 228, "seek": 72376, "start": 737.4, "end": 738.4,
  "text": " Yeah.", "tokens": [51046, 865, 13, 51096], "temperature": 0.0, "avg_logprob":
  -0.22855460475867903, "compression_ratio": 1.7085889570552146, "no_speech_prob":
  0.009539502672851086}, {"id": 229, "seek": 72376, "start": 738.4, "end": 743.0,
  "text": " But it''s interesting also that big players, like you mentioned Microsoft
  and I mean, others,", "tokens": [51096, 583, 309, 311, 1880, 611, 300, 955, 4150,
  11, 411, 291, 2835, 8116, 293, 286, 914, 11, 2357, 11, 51326], "temperature": 0.0,
  "avg_logprob": -0.22855460475867903, "compression_ratio": 1.7085889570552146, "no_speech_prob":
  0.009539502672851086}, {"id": 230, "seek": 72376, "start": 743.0, "end": 746.92,
  "text": " they''re moving in direction of increasing number of parameters in the
  model.", "tokens": [51326, 436, 434, 2684, 294, 3513, 295, 5662, 1230, 295, 9834,
  294, 264, 2316, 13, 51522], "temperature": 0.0, "avg_logprob": -0.22855460475867903,
  "compression_ratio": 1.7085889570552146, "no_speech_prob": 0.009539502672851086},
  {"id": 231, "seek": 72376, "start": 746.92, "end": 751.16, "text": " But when you
  go to practice and you need to build a classifier, you know, you don''t have", "tokens":
  [51522, 583, 562, 291, 352, 281, 3124, 293, 291, 643, 281, 1322, 257, 1508, 9902,
  11, 291, 458, 11, 291, 500, 380, 362, 51734], "temperature": 0.0, "avg_logprob":
  -0.22855460475867903, "compression_ratio": 1.7085889570552146, "no_speech_prob":
  0.009539502672851086}, {"id": 232, "seek": 72376, "start": 751.16, "end": 752.68,
  "text": " that much capacity.", "tokens": [51734, 300, 709, 6042, 13, 51810], "temperature":
  0.0, "avg_logprob": -0.22855460475867903, "compression_ratio": 1.7085889570552146,
  "no_speech_prob": 0.009539502672851086}, {"id": 233, "seek": 75268, "start": 752.68,
  "end": 757.64, "text": " Like you don''t want to spend that much capacity really
  unless you''re building like a terminator", "tokens": [50364, 1743, 291, 500, 380,
  528, 281, 3496, 300, 709, 6042, 534, 5969, 291, 434, 2390, 411, 257, 10761, 1639,
  50612], "temperature": 0.0, "avg_logprob": -0.23132730141664162, "compression_ratio":
  1.6285714285714286, "no_speech_prob": 0.016156353056430817}, {"id": 234, "seek":
  75268, "start": 757.64, "end": 761.3199999999999, "text": " level AI, which will
  handle all tasks that you have.", "tokens": [50612, 1496, 7318, 11, 597, 486, 4813,
  439, 9608, 300, 291, 362, 13, 50796], "temperature": 0.0, "avg_logprob": -0.23132730141664162,
  "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.016156353056430817},
  {"id": 235, "seek": 75268, "start": 761.3199999999999, "end": 764.7199999999999,
  "text": " But probably you won''t do that because it''s still not there.", "tokens":
  [50796, 583, 1391, 291, 1582, 380, 360, 300, 570, 309, 311, 920, 406, 456, 13, 50966],
  "temperature": 0.0, "avg_logprob": -0.23132730141664162, "compression_ratio": 1.6285714285714286,
  "no_speech_prob": 0.016156353056430817}, {"id": 236, "seek": 75268, "start": 764.7199999999999,
  "end": 769.64, "text": " So do you also think about that kind of the practical element
  or are you still kind of", "tokens": [50966, 407, 360, 291, 611, 519, 466, 300,
  733, 295, 264, 8496, 4478, 420, 366, 291, 920, 733, 295, 51212], "temperature":
  0.0, "avg_logprob": -0.23132730141664162, "compression_ratio": 1.6285714285714286,
  "no_speech_prob": 0.016156353056430817}, {"id": 237, "seek": 75268, "start": 769.64,
  "end": 772.88, "text": " fencing the beauty of these complex models?", "tokens":
  [51212, 283, 13644, 264, 6643, 295, 613, 3997, 5245, 30, 51374], "temperature":
  0.0, "avg_logprob": -0.23132730141664162, "compression_ratio": 1.6285714285714286,
  "no_speech_prob": 0.016156353056430817}, {"id": 238, "seek": 75268, "start": 772.88,
  "end": 775.3599999999999, "text": " Well, wait, do you see that?", "tokens": [51374,
  1042, 11, 1699, 11, 360, 291, 536, 300, 30, 51498], "temperature": 0.0, "avg_logprob":
  -0.23132730141664162, "compression_ratio": 1.6285714285714286, "no_speech_prob":
  0.016156353056430817}, {"id": 239, "seek": 75268, "start": 775.3599999999999, "end":
  781.16, "text": " Yeah, well, I''ll stake my flag in the same campus, the foundation
  models, researchers,", "tokens": [51498, 865, 11, 731, 11, 286, 603, 10407, 452,
  7166, 294, 264, 912, 4828, 11, 264, 7030, 5245, 11, 10309, 11, 51788], "temperature":
  0.0, "avg_logprob": -0.23132730141664162, "compression_ratio": 1.6285714285714286,
  "no_speech_prob": 0.016156353056430817}, {"id": 240, "seek": 78116, "start": 781.16,
  "end": 783.1999999999999, "text": " and I think it was mostly Stanford.", "tokens":
  [50364, 293, 286, 519, 309, 390, 5240, 20374, 13, 50466], "temperature": 0.0, "avg_logprob":
  -0.2473928145779908, "compression_ratio": 1.6277602523659307, "no_speech_prob":
  0.015554750338196754}, {"id": 241, "seek": 78116, "start": 783.1999999999999, "end":
  787.76, "text": " They published this paper titled on the opportunities and risk
  of foundation models, some title like", "tokens": [50466, 814, 6572, 341, 3035,
  19841, 322, 264, 4786, 293, 3148, 295, 7030, 5245, 11, 512, 4876, 411, 50694], "temperature":
  0.0, "avg_logprob": -0.2473928145779908, "compression_ratio": 1.6277602523659307,
  "no_speech_prob": 0.015554750338196754}, {"id": 242, "seek": 78116, "start": 787.76,
  "end": 788.76, "text": " that.", "tokens": [50694, 300, 13, 50744], "temperature":
  0.0, "avg_logprob": -0.2473928145779908, "compression_ratio": 1.6277602523659307,
  "no_speech_prob": 0.015554750338196754}, {"id": 243, "seek": 78116, "start": 788.76,
  "end": 789.76, "text": " I''m sorry, it''s not exactly correct.", "tokens": [50744,
  286, 478, 2597, 11, 309, 311, 406, 2293, 3006, 13, 50794], "temperature": 0.0, "avg_logprob":
  -0.2473928145779908, "compression_ratio": 1.6277602523659307, "no_speech_prob":
  0.015554750338196754}, {"id": 244, "seek": 78116, "start": 789.76, "end": 794.4,
  "text": " But, you know, this kind of ideology that big companies like Microsoft
  and Vitya Google", "tokens": [50794, 583, 11, 291, 458, 11, 341, 733, 295, 23101,
  300, 955, 3431, 411, 8116, 293, 691, 507, 64, 3329, 51026], "temperature": 0.0,
  "avg_logprob": -0.2473928145779908, "compression_ratio": 1.6277602523659307, "no_speech_prob":
  0.015554750338196754}, {"id": 245, "seek": 78116, "start": 794.4, "end": 797.24,
  "text": " Facebook, they''ll build these big, big models.", "tokens": [51026, 4384,
  11, 436, 603, 1322, 613, 955, 11, 955, 5245, 13, 51168], "temperature": 0.0, "avg_logprob":
  -0.2473928145779908, "compression_ratio": 1.6277602523659307, "no_speech_prob":
  0.015554750338196754}, {"id": 246, "seek": 78116, "start": 797.24, "end": 800.0799999999999,
  "text": " And then what we''ll do is we''ll use this knowledge distillation interface
  to compress", "tokens": [51168, 400, 550, 437, 321, 603, 360, 307, 321, 603, 764,
  341, 3601, 42923, 399, 9226, 281, 14778, 51310], "temperature": 0.0, "avg_logprob":
  -0.2473928145779908, "compression_ratio": 1.6277602523659307, "no_speech_prob":
  0.015554750338196754}, {"id": 247, "seek": 78116, "start": 800.0799999999999, "end":
  802.16, "text": " it into practical use cases.", "tokens": [51310, 309, 666, 8496,
  764, 3331, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2473928145779908, "compression_ratio":
  1.6277602523659307, "no_speech_prob": 0.015554750338196754}, {"id": 248, "seek":
  78116, "start": 802.16, "end": 807.12, "text": " And so we''ve seen, I''d say this
  started with Colin Raffle and the people who worked on", "tokens": [51414, 400,
  370, 321, 600, 1612, 11, 286, 1116, 584, 341, 1409, 365, 29253, 497, 29264, 293,
  264, 561, 567, 2732, 322, 51662], "temperature": 0.0, "avg_logprob": -0.2473928145779908,
  "compression_ratio": 1.6277602523659307, "no_speech_prob": 0.015554750338196754},
  {"id": 249, "seek": 80712, "start": 807.12, "end": 811.88, "text": " my paper with
  the text to text transfer transform of the T5 model, not showed how you could",
  "tokens": [50364, 452, 3035, 365, 264, 2487, 281, 2487, 5003, 4088, 295, 264, 314,
  20, 2316, 11, 406, 4712, 577, 291, 727, 50602], "temperature": 0.0, "avg_logprob":
  -0.22747027079264323, "compression_ratio": 1.910344827586207, "no_speech_prob":
  0.005559222307056189}, {"id": 250, "seek": 80712, "start": 811.88, "end": 816.88,
  "text": " unify all text supervised learning tasks through the same kind of language
  modeling style", "tokens": [50602, 517, 2505, 439, 2487, 46533, 2539, 9608, 807,
  264, 912, 733, 295, 2856, 15983, 3758, 50852], "temperature": 0.0, "avg_logprob":
  -0.22747027079264323, "compression_ratio": 1.910344827586207, "no_speech_prob":
  0.005559222307056189}, {"id": 251, "seek": 80712, "start": 816.88, "end": 817.88,
  "text": " interface.", "tokens": [50852, 9226, 13, 50902], "temperature": 0.0, "avg_logprob":
  -0.22747027079264323, "compression_ratio": 1.910344827586207, "no_speech_prob":
  0.005559222307056189}, {"id": 252, "seek": 80712, "start": 817.88, "end": 821.08,
  "text": " You just prompt it with, you know, natural language inference and then
  you give it the", "tokens": [50902, 509, 445, 12391, 309, 365, 11, 291, 458, 11,
  3303, 2856, 38253, 293, 550, 291, 976, 309, 264, 51062], "temperature": 0.0, "avg_logprob":
  -0.22747027079264323, "compression_ratio": 1.910344827586207, "no_speech_prob":
  0.005559222307056189}, {"id": 253, "seek": 80712, "start": 821.08, "end": 825.36,
  "text": " input or you say, answer this question, give it the input or you say,
  re-rank these documents", "tokens": [51062, 4846, 420, 291, 584, 11, 1867, 341,
  1168, 11, 976, 309, 264, 4846, 420, 291, 584, 11, 319, 12, 20479, 613, 8512, 51276],
  "temperature": 0.0, "avg_logprob": -0.22747027079264323, "compression_ratio": 1.910344827586207,
  "no_speech_prob": 0.005559222307056189}, {"id": 254, "seek": 80712, "start": 825.36,
  "end": 826.36, "text": " and give them the document.", "tokens": [51276, 293, 976,
  552, 264, 4166, 13, 51326], "temperature": 0.0, "avg_logprob": -0.22747027079264323,
  "compression_ratio": 1.910344827586207, "no_speech_prob": 0.005559222307056189},
  {"id": 255, "seek": 80712, "start": 826.36, "end": 829.6, "text": " So it''s the
  same interface for every supervised learning task.", "tokens": [51326, 407, 309,
  311, 264, 912, 9226, 337, 633, 46533, 2539, 5633, 13, 51488], "temperature": 0.0,
  "avg_logprob": -0.22747027079264323, "compression_ratio": 1.910344827586207, "no_speech_prob":
  0.005559222307056189}, {"id": 256, "seek": 80712, "start": 829.6, "end": 835.44,
  "text": " So yeah, I''m, and then just one more thing to kind of put in the citation
  context is this", "tokens": [51488, 407, 1338, 11, 286, 478, 11, 293, 550, 445,
  472, 544, 551, 281, 733, 295, 829, 294, 264, 45590, 4319, 307, 341, 51780], "temperature":
  0.0, "avg_logprob": -0.22747027079264323, "compression_ratio": 1.910344827586207,
  "no_speech_prob": 0.005559222307056189}, {"id": 257, "seek": 83544, "start": 835.44,
  "end": 839.6, "text": " general purpose, like, opening iClip and it looks like Microsoft,
  I think they''re calling", "tokens": [50364, 2674, 4334, 11, 411, 11, 5193, 741,
  9966, 647, 293, 309, 1542, 411, 8116, 11, 286, 519, 436, 434, 5141, 50572], "temperature":
  0.0, "avg_logprob": -0.2112394650777181, "compression_ratio": 1.726384364820847,
  "no_speech_prob": 0.0013060539495199919}, {"id": 258, "seek": 83544, "start": 839.6,
  "end": 841.96, "text": " it bletchly or something like that.", "tokens": [50572,
  309, 888, 7858, 356, 420, 746, 411, 300, 13, 50690], "temperature": 0.0, "avg_logprob":
  -0.2112394650777181, "compression_ratio": 1.726384364820847, "no_speech_prob": 0.0013060539495199919},
  {"id": 259, "seek": 83544, "start": 841.96, "end": 848.08, "text": " But this idea
  of just having two vector embedding spaces and then using the contrast of alignment",
  "tokens": [50690, 583, 341, 1558, 295, 445, 1419, 732, 8062, 12240, 3584, 7673,
  293, 550, 1228, 264, 8712, 295, 18515, 50996], "temperature": 0.0, "avg_logprob":
  -0.2112394650777181, "compression_ratio": 1.726384364820847, "no_speech_prob": 0.0013060539495199919},
  {"id": 260, "seek": 83544, "start": 848.08, "end": 851.6400000000001, "text": "
  as the general interface for any kind of task, because as we mentioned, you can
  put any", "tokens": [50996, 382, 264, 2674, 9226, 337, 604, 733, 295, 5633, 11,
  570, 382, 321, 2835, 11, 291, 393, 829, 604, 51174], "temperature": 0.0, "avg_logprob":
  -0.2112394650777181, "compression_ratio": 1.726384364820847, "no_speech_prob": 0.0013060539495199919},
  {"id": 261, "seek": 83544, "start": 851.6400000000001, "end": 855.6, "text": " task
  into natural language, any task that you''re going to do with supervised learning
  could", "tokens": [51174, 5633, 666, 3303, 2856, 11, 604, 5633, 300, 291, 434, 516,
  281, 360, 365, 46533, 2539, 727, 51372], "temperature": 0.0, "avg_logprob": -0.2112394650777181,
  "compression_ratio": 1.726384364820847, "no_speech_prob": 0.0013060539495199919},
  {"id": 262, "seek": 83544, "start": 855.6, "end": 857.08, "text": " be described
  with natural language.", "tokens": [51372, 312, 7619, 365, 3303, 2856, 13, 51446],
  "temperature": 0.0, "avg_logprob": -0.2112394650777181, "compression_ratio": 1.726384364820847,
  "no_speech_prob": 0.0013060539495199919}, {"id": 263, "seek": 83544, "start": 857.08,
  "end": 861.32, "text": " So you have that kind of interface and the Allen Institute
  has another architecture called", "tokens": [51446, 407, 291, 362, 300, 733, 295,
  9226, 293, 264, 17160, 9446, 575, 1071, 9482, 1219, 51658], "temperature": 0.0,
  "avg_logprob": -0.2112394650777181, "compression_ratio": 1.726384364820847, "no_speech_prob":
  0.0013060539495199919}, {"id": 264, "seek": 86132, "start": 861.32, "end": 865.96,
  "text": " general purpose vision systems that, you know, unifies all these tasks,
  object detection,", "tokens": [50364, 2674, 4334, 5201, 3652, 300, 11, 291, 458,
  11, 517, 11221, 439, 613, 9608, 11, 2657, 17784, 11, 50596], "temperature": 0.0,
  "avg_logprob": -0.1865214226951062, "compression_ratio": 1.859375, "no_speech_prob":
  0.002084535313770175}, {"id": 265, "seek": 86132, "start": 865.96, "end": 870.4000000000001,
  "text": " semantic segmentation, service, normal estimation, all these kind of ideas
  are unifying one architecture", "tokens": [50596, 47982, 9469, 399, 11, 2643, 11,
  2710, 35701, 11, 439, 613, 733, 295, 3487, 366, 517, 5489, 472, 9482, 50818], "temperature":
  0.0, "avg_logprob": -0.1865214226951062, "compression_ratio": 1.859375, "no_speech_prob":
  0.002084535313770175}, {"id": 266, "seek": 86132, "start": 870.4000000000001, "end":
  871.4000000000001, "text": " interface.", "tokens": [50818, 9226, 13, 50868], "temperature":
  0.0, "avg_logprob": -0.1865214226951062, "compression_ratio": 1.859375, "no_speech_prob":
  0.002084535313770175}, {"id": 267, "seek": 86132, "start": 871.4000000000001, "end":
  875.24, "text": " So to kind of wrap up my answer to the question, I think it''s
  going to be Microsoft and", "tokens": [50868, 407, 281, 733, 295, 7019, 493, 452,
  1867, 281, 264, 1168, 11, 286, 519, 309, 311, 516, 281, 312, 8116, 293, 51060],
  "temperature": 0.0, "avg_logprob": -0.1865214226951062, "compression_ratio": 1.859375,
  "no_speech_prob": 0.002084535313770175}, {"id": 268, "seek": 86132, "start": 875.24,
  "end": 877.6, "text": " them scaling up like crazy.", "tokens": [51060, 552, 21589,
  493, 411, 3219, 13, 51178], "temperature": 0.0, "avg_logprob": -0.1865214226951062,
  "compression_ratio": 1.859375, "no_speech_prob": 0.002084535313770175}, {"id": 269,
  "seek": 86132, "start": 877.6, "end": 880.44, "text": " Maybe they''re going to
  run it out of internet scale data eventually.", "tokens": [51178, 2704, 436, 434,
  516, 281, 1190, 309, 484, 295, 4705, 4373, 1412, 4728, 13, 51320], "temperature":
  0.0, "avg_logprob": -0.1865214226951062, "compression_ratio": 1.859375, "no_speech_prob":
  0.002084535313770175}, {"id": 270, "seek": 86132, "start": 880.44, "end": 884.2800000000001,
  "text": " I think Microsoft has said that they can train like a 32 trillion parameter
  model if they", "tokens": [51320, 286, 519, 8116, 575, 848, 300, 436, 393, 3847,
  411, 257, 8858, 18723, 13075, 2316, 498, 436, 51512], "temperature": 0.0, "avg_logprob":
  -0.1865214226951062, "compression_ratio": 1.859375, "no_speech_prob": 0.002084535313770175},
  {"id": 271, "seek": 86132, "start": 884.2800000000001, "end": 886.08, "text": "
  were motivated to do so.", "tokens": [51512, 645, 14515, 281, 360, 370, 13, 51602],
  "temperature": 0.0, "avg_logprob": -0.1865214226951062, "compression_ratio": 1.859375,
  "no_speech_prob": 0.002084535313770175}, {"id": 272, "seek": 86132, "start": 886.08,
  "end": 890.2800000000001, "text": " So I think they''re going to run out of internet
  scale data and then the data augmentation", "tokens": [51602, 407, 286, 519, 436,
  434, 516, 281, 1190, 484, 295, 4705, 4373, 1412, 293, 550, 264, 1412, 14501, 19631,
  51812], "temperature": 0.0, "avg_logprob": -0.1865214226951062, "compression_ratio":
  1.859375, "no_speech_prob": 0.002084535313770175}, {"id": 273, "seek": 89028, "start":
  890.28, "end": 893.8399999999999, "text": " will be the next step from going from
  say like the 400 million image taxpayers that are", "tokens": [50364, 486, 312,
  264, 958, 1823, 490, 516, 490, 584, 411, 264, 8423, 2459, 3256, 38205, 300, 366,
  50542], "temperature": 0.0, "avg_logprob": -0.19603939545460236, "compression_ratio":
  1.6232394366197183, "no_speech_prob": 0.0009415590320713818}, {"id": 274, "seek":
  89028, "start": 893.8399999999999, "end": 899.8399999999999, "text": " now open
  sourced or Luther AI has the pile, which is like 800 gigabytes of raw text if you",
  "tokens": [50542, 586, 1269, 11006, 1232, 420, 20693, 7318, 575, 264, 14375, 11,
  597, 307, 411, 13083, 42741, 295, 8936, 2487, 498, 291, 50842], "temperature": 0.0,
  "avg_logprob": -0.19603939545460236, "compression_ratio": 1.6232394366197183, "no_speech_prob":
  0.0009415590320713818}, {"id": 275, "seek": 89028, "start": 899.8399999999999, "end":
  902.76, "text": " want to do something with that.", "tokens": [50842, 528, 281,
  360, 746, 365, 300, 13, 50988], "temperature": 0.0, "avg_logprob": -0.19603939545460236,
  "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.0009415590320713818},
  {"id": 276, "seek": 89028, "start": 902.76, "end": 907.1999999999999, "text": "
  So I think eventually as you go into the 32 trillion parameter and on, they''re
  going to", "tokens": [50988, 407, 286, 519, 4728, 382, 291, 352, 666, 264, 8858,
  18723, 13075, 293, 322, 11, 436, 434, 516, 281, 51210], "temperature": 0.0, "avg_logprob":
  -0.19603939545460236, "compression_ratio": 1.6232394366197183, "no_speech_prob":
  0.0009415590320713818}, {"id": 277, "seek": 89028, "start": 907.1999999999999, "end":
  912.12, "text": " use data augmentation to have these inductive biases about how
  we can keep scaling the", "tokens": [51210, 764, 1412, 14501, 19631, 281, 362, 613,
  31612, 488, 32152, 466, 577, 321, 393, 1066, 21589, 264, 51456], "temperature":
  0.0, "avg_logprob": -0.19603939545460236, "compression_ratio": 1.6232394366197183,
  "no_speech_prob": 0.0009415590320713818}, {"id": 278, "seek": 89028, "start": 912.12,
  "end": 913.52, "text": " data side of it.", "tokens": [51456, 1412, 1252, 295, 309,
  13, 51526], "temperature": 0.0, "avg_logprob": -0.19603939545460236, "compression_ratio":
  1.6232394366197183, "no_speech_prob": 0.0009415590320713818}, {"id": 279, "seek":
  89028, "start": 913.52, "end": 917.36, "text": " So yeah, so I think they can scale
  the models for a while.", "tokens": [51526, 407, 1338, 11, 370, 286, 519, 436, 393,
  4373, 264, 5245, 337, 257, 1339, 13, 51718], "temperature": 0.0, "avg_logprob":
  -0.19603939545460236, "compression_ratio": 1.6232394366197183, "no_speech_prob":
  0.0009415590320713818}, {"id": 280, "seek": 91736, "start": 917.48, "end": 921.5600000000001,
  "text": " Yeah, I guess they probably they are doing an amazing job, but like they
  are probably", "tokens": [50370, 865, 11, 286, 2041, 436, 1391, 436, 366, 884, 364,
  2243, 1691, 11, 457, 411, 436, 366, 1391, 50574], "temperature": 0.0, "avg_logprob":
  -0.22442102432250977, "compression_ratio": 1.6912280701754385, "no_speech_prob":
  0.031633563339710236}, {"id": 281, "seek": 91736, "start": 921.5600000000001, "end":
  926.36, "text": " still writing the horse of what Peter Norby called the unreasonable
  effectiveness of data,", "tokens": [50574, 920, 3579, 264, 6832, 295, 437, 6508,
  6966, 2322, 1219, 264, 41730, 21208, 295, 1412, 11, 50814], "temperature": 0.0,
  "avg_logprob": -0.22442102432250977, "compression_ratio": 1.6912280701754385, "no_speech_prob":
  0.031633563339710236}, {"id": 282, "seek": 91736, "start": 926.36, "end": 927.36,
  "text": " right?", "tokens": [50814, 558, 30, 50864], "temperature": 0.0, "avg_logprob":
  -0.22442102432250977, "compression_ratio": 1.6912280701754385, "no_speech_prob":
  0.031633563339710236}, {"id": 283, "seek": 91736, "start": 927.36, "end": 933.04,
  "text": " So like your algorithm might not be kind of as as nuanced as your data
  is and so just", "tokens": [50864, 407, 411, 428, 9284, 1062, 406, 312, 733, 295,
  382, 382, 45115, 382, 428, 1412, 307, 293, 370, 445, 51148], "temperature": 0.0,
  "avg_logprob": -0.22442102432250977, "compression_ratio": 1.6912280701754385, "no_speech_prob":
  0.031633563339710236}, {"id": 284, "seek": 91736, "start": 933.04, "end": 937.6800000000001,
  "text": " give it to the machine learning algorithm as much as possible and then
  kind of it will", "tokens": [51148, 976, 309, 281, 264, 3479, 2539, 9284, 382, 709,
  382, 1944, 293, 550, 733, 295, 309, 486, 51380], "temperature": 0.0, "avg_logprob":
  -0.22442102432250977, "compression_ratio": 1.6912280701754385, "no_speech_prob":
  0.031633563339710236}, {"id": 285, "seek": 91736, "start": 937.6800000000001, "end":
  938.92, "text": " learn, right?", "tokens": [51380, 1466, 11, 558, 30, 51442], "temperature":
  0.0, "avg_logprob": -0.22442102432250977, "compression_ratio": 1.6912280701754385,
  "no_speech_prob": 0.031633563339710236}, {"id": 286, "seek": 91736, "start": 938.92,
  "end": 941.88, "text": " But you know, like in practical situations, this is what
  I alluded to.", "tokens": [51442, 583, 291, 458, 11, 411, 294, 8496, 6851, 11, 341,
  307, 437, 286, 33919, 281, 13, 51590], "temperature": 0.0, "avg_logprob": -0.22442102432250977,
  "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.031633563339710236},
  {"id": 287, "seek": 91736, "start": 941.88, "end": 944.16, "text": " Like you just
  don''t have that much data.", "tokens": [51590, 1743, 291, 445, 500, 380, 362, 300,
  709, 1412, 13, 51704], "temperature": 0.0, "avg_logprob": -0.22442102432250977,
  "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.031633563339710236},
  {"id": 288, "seek": 94416, "start": 944.16, "end": 948.28, "text": " On the other
  hand, you don''t want you don''t have that much choice and you also mentioned",
  "tokens": [50364, 1282, 264, 661, 1011, 11, 291, 500, 380, 528, 291, 500, 380, 362,
  300, 709, 3922, 293, 291, 611, 2835, 50570], "temperature": 0.0, "avg_logprob":
  -0.21474220569317157, "compression_ratio": 1.7162162162162162, "no_speech_prob":
  0.041352272033691406}, {"id": 289, "seek": 94416, "start": 948.28, "end": 949.28,
  "text": " this.", "tokens": [50570, 341, 13, 50620], "temperature": 0.0, "avg_logprob":
  -0.21474220569317157, "compression_ratio": 1.7162162162162162, "no_speech_prob":
  0.041352272033691406}, {"id": 290, "seek": 94416, "start": 949.28, "end": 952.68,
  "text": " This is a very interesting topic of data augmentation in text because
  in images, you can do like", "tokens": [50620, 639, 307, 257, 588, 1880, 4829, 295,
  1412, 14501, 19631, 294, 2487, 570, 294, 5267, 11, 291, 393, 360, 411, 50790], "temperature":
  0.0, "avg_logprob": -0.21474220569317157, "compression_ratio": 1.7162162162162162,
  "no_speech_prob": 0.041352272033691406}, {"id": 291, "seek": 94416, "start": 952.68,
  "end": 955.48, "text": " cropping rotation and huge changes and whatnot.", "tokens":
  [50790, 4848, 3759, 12447, 293, 2603, 2962, 293, 25882, 13, 50930], "temperature":
  0.0, "avg_logprob": -0.21474220569317157, "compression_ratio": 1.7162162162162162,
  "no_speech_prob": 0.041352272033691406}, {"id": 292, "seek": 94416, "start": 955.48,
  "end": 958.28, "text": " In text, you can do that like so easily.", "tokens": [50930,
  682, 2487, 11, 291, 393, 360, 300, 411, 370, 3612, 13, 51070], "temperature": 0.0,
  "avg_logprob": -0.21474220569317157, "compression_ratio": 1.7162162162162162, "no_speech_prob":
  0.041352272033691406}, {"id": 293, "seek": 94416, "start": 958.28, "end": 962.16,
  "text": " For example, if you say you have a sentence London is the capital of Great
  Britain, you cannot", "tokens": [51070, 1171, 1365, 11, 498, 291, 584, 291, 362,
  257, 8174, 7042, 307, 264, 4238, 295, 3769, 12960, 11, 291, 2644, 51264], "temperature":
  0.0, "avg_logprob": -0.21474220569317157, "compression_ratio": 1.7162162162162162,
  "no_speech_prob": 0.041352272033691406}, {"id": 294, "seek": 94416, "start": 962.16,
  "end": 963.4, "text": " put Barcelona there.", "tokens": [51264, 829, 21247, 456,
  13, 51326], "temperature": 0.0, "avg_logprob": -0.21474220569317157, "compression_ratio":
  1.7162162162162162, "no_speech_prob": 0.041352272033691406}, {"id": 295, "seek":
  94416, "start": 963.4, "end": 965.36, "text": " It will not make sense.", "tokens":
  [51326, 467, 486, 406, 652, 2020, 13, 51424], "temperature": 0.0, "avg_logprob":
  -0.21474220569317157, "compression_ratio": 1.7162162162162162, "no_speech_prob":
  0.041352272033691406}, {"id": 296, "seek": 94416, "start": 965.36, "end": 970.12,
  "text": " So, you know, but like you can still find another example where you could
  probably swap", "tokens": [51424, 407, 11, 291, 458, 11, 457, 411, 291, 393, 920,
  915, 1071, 1365, 689, 291, 727, 1391, 18135, 51662], "temperature": 0.0, "avg_logprob":
  -0.21474220569317157, "compression_ratio": 1.7162162162162162, "no_speech_prob":
  0.041352272033691406}, {"id": 297, "seek": 97012, "start": 970.12, "end": 974.32,
  "text": " cities and that''s how you build, you know, the augmentation.", "tokens":
  [50364, 6486, 293, 300, 311, 577, 291, 1322, 11, 291, 458, 11, 264, 14501, 19631,
  13, 50574], "temperature": 0.0, "avg_logprob": -0.19449284293434838, "compression_ratio":
  1.7529411764705882, "no_speech_prob": 0.004695868119597435}, {"id": 298, "seek":
  97012, "start": 974.32, "end": 975.72, "text": " But then there are other things.",
  "tokens": [50574, 583, 550, 456, 366, 661, 721, 13, 50644], "temperature": 0.0,
  "avg_logprob": -0.19449284293434838, "compression_ratio": 1.7529411764705882, "no_speech_prob":
  0.004695868119597435}, {"id": 299, "seek": 97012, "start": 975.72, "end": 980.68,
  "text": " For example, if you take machine translation, you know, it suffers from
  hallucination problem.", "tokens": [50644, 1171, 1365, 11, 498, 291, 747, 3479,
  12853, 11, 291, 458, 11, 309, 33776, 490, 35212, 2486, 1154, 13, 50892], "temperature":
  0.0, "avg_logprob": -0.19449284293434838, "compression_ratio": 1.7529411764705882,
  "no_speech_prob": 0.004695868119597435}, {"id": 300, "seek": 97012, "start": 980.68,
  "end": 985.88, "text": " I don''t know if you heard about it, but like if you have
  certain like distortion in your", "tokens": [50892, 286, 500, 380, 458, 498, 291,
  2198, 466, 309, 11, 457, 411, 498, 291, 362, 1629, 411, 28426, 294, 428, 51152],
  "temperature": 0.0, "avg_logprob": -0.19449284293434838, "compression_ratio": 1.7529411764705882,
  "no_speech_prob": 0.004695868119597435}, {"id": 301, "seek": 97012, "start": 985.88,
  "end": 991.84, "text": " data, for example, you call the websites and you also called
  erroneously the advertisement.", "tokens": [51152, 1412, 11, 337, 1365, 11, 291,
  818, 264, 12891, 293, 291, 611, 1219, 1189, 26446, 5098, 264, 31370, 13, 51450],
  "temperature": 0.0, "avg_logprob": -0.19449284293434838, "compression_ratio": 1.7529411764705882,
  "no_speech_prob": 0.004695868119597435}, {"id": 302, "seek": 97012, "start": 991.84,
  "end": 998.64, "text": " So you glued the advertisement to the source pair, source
  target pair, right?", "tokens": [51450, 407, 291, 28008, 264, 31370, 281, 264, 4009,
  6119, 11, 4009, 3779, 6119, 11, 558, 30, 51790], "temperature": 0.0, "avg_logprob":
  -0.19449284293434838, "compression_ratio": 1.7529411764705882, "no_speech_prob":
  0.004695868119597435}, {"id": 303, "seek": 99864, "start": 998.64, "end": 1003.1999999999999,
  "text": " Now your model is hallucinating about that advertisement when the student
  has, right?", "tokens": [50364, 823, 428, 2316, 307, 35212, 8205, 466, 300, 31370,
  562, 264, 3107, 575, 11, 558, 30, 50592], "temperature": 0.0, "avg_logprob": -0.21392417535549257,
  "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.007361919619143009},
  {"id": 304, "seek": 99864, "start": 1003.1999999999999, "end": 1005.6, "text": "
  So, and it''s flipping facts.", "tokens": [50592, 407, 11, 293, 309, 311, 26886,
  9130, 13, 50712], "temperature": 0.0, "avg_logprob": -0.21392417535549257, "compression_ratio":
  1.6618181818181819, "no_speech_prob": 0.007361919619143009}, {"id": 305, "seek":
  99864, "start": 1005.6, "end": 1009.24, "text": " It''s also switching, you know,
  object and subject easily.", "tokens": [50712, 467, 311, 611, 16493, 11, 291, 458,
  11, 2657, 293, 3983, 3612, 13, 50894], "temperature": 0.0, "avg_logprob": -0.21392417535549257,
  "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.007361919619143009},
  {"id": 306, "seek": 99864, "start": 1009.24, "end": 1010.4, "text": " So it''s not
  something.", "tokens": [50894, 407, 309, 311, 406, 746, 13, 50952], "temperature":
  0.0, "avg_logprob": -0.21392417535549257, "compression_ratio": 1.6618181818181819,
  "no_speech_prob": 0.007361919619143009}, {"id": 307, "seek": 99864, "start": 1010.4,
  "end": 1014.08, "text": " And again, now I''m stepping on the territory of the model
  itself, right?", "tokens": [50952, 400, 797, 11, 586, 286, 478, 16821, 322, 264,
  11360, 295, 264, 2316, 2564, 11, 558, 30, 51136], "temperature": 0.0, "avg_logprob":
  -0.21392417535549257, "compression_ratio": 1.6618181818181819, "no_speech_prob":
  0.007361919619143009}, {"id": 308, "seek": 99864, "start": 1014.08, "end": 1017.04,
  "text": " But like, and model robustness.", "tokens": [51136, 583, 411, 11, 293,
  2316, 13956, 1287, 13, 51284], "temperature": 0.0, "avg_logprob": -0.21392417535549257,
  "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.007361919619143009},
  {"id": 309, "seek": 99864, "start": 1017.04, "end": 1021.76, "text": " But I think
  data augmentation plays a key role in actually making sure that your model", "tokens":
  [51284, 583, 286, 519, 1412, 14501, 19631, 5749, 257, 2141, 3090, 294, 767, 1455,
  988, 300, 428, 2316, 51520], "temperature": 0.0, "avg_logprob": -0.21392417535549257,
  "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.007361919619143009},
  {"id": 310, "seek": 99864, "start": 1021.76, "end": 1026.44, "text": " can kind
  of at least not hiccup on some very basic things, right?", "tokens": [51520, 393,
  733, 295, 412, 1935, 406, 23697, 16794, 322, 512, 588, 3875, 721, 11, 558, 30, 51754],
  "temperature": 0.0, "avg_logprob": -0.21392417535549257, "compression_ratio": 1.6618181818181819,
  "no_speech_prob": 0.007361919619143009}, {"id": 311, "seek": 99864, "start": 1026.44,
  "end": 1027.44, "text": " So.", "tokens": [51754, 407, 13, 51804], "temperature":
  0.0, "avg_logprob": -0.21392417535549257, "compression_ratio": 1.6618181818181819,
  "no_speech_prob": 0.007361919619143009}, {"id": 312, "seek": 102744, "start": 1028.04,
  "end": 1030.16, "text": " Yeah, and we''re completely in agreement with that.",
  "tokens": [50394, 865, 11, 293, 321, 434, 2584, 294, 8106, 365, 300, 13, 50500],
  "temperature": 0.0, "avg_logprob": -0.17013627688090008, "compression_ratio": 1.7615658362989324,
  "no_speech_prob": 0.011538082733750343}, {"id": 313, "seek": 102744, "start": 1030.16,
  "end": 1036.6000000000001, "text": " I think one other part to that story will be
  how, say, so Facebook has this model called", "tokens": [50500, 286, 519, 472, 661,
  644, 281, 300, 1657, 486, 312, 577, 11, 584, 11, 370, 4384, 575, 341, 2316, 1219,
  50822], "temperature": 0.0, "avg_logprob": -0.17013627688090008, "compression_ratio":
  1.7615658362989324, "no_speech_prob": 0.011538082733750343}, {"id": 314, "seek":
  102744, "start": 1036.6000000000001, "end": 1041.1200000000001, "text": " retrieval
  augmented generation, where the whole idea is to add more context to avoid this",
  "tokens": [50822, 19817, 3337, 36155, 5125, 11, 689, 264, 1379, 1558, 307, 281,
  909, 544, 4319, 281, 5042, 341, 51048], "temperature": 0.0, "avg_logprob": -0.17013627688090008,
  "compression_ratio": 1.7615658362989324, "no_speech_prob": 0.011538082733750343},
  {"id": 315, "seek": 102744, "start": 1041.1200000000001, "end": 1042.44, "text":
  " hallucination problem.", "tokens": [51048, 35212, 2486, 1154, 13, 51114], "temperature":
  0.0, "avg_logprob": -0.17013627688090008, "compression_ratio": 1.7615658362989324,
  "no_speech_prob": 0.011538082733750343}, {"id": 316, "seek": 102744, "start": 1042.44,
  "end": 1045.6000000000001, "text": " So to kind of break down three things, you
  just said, I want to start off with the, yeah,", "tokens": [51114, 407, 281, 733,
  295, 1821, 760, 1045, 721, 11, 291, 445, 848, 11, 286, 528, 281, 722, 766, 365,
  264, 11, 1338, 11, 51272], "temperature": 0.0, "avg_logprob": -0.17013627688090008,
  "compression_ratio": 1.7615658362989324, "no_speech_prob": 0.011538082733750343},
  {"id": 317, "seek": 102744, "start": 1045.6000000000001, "end": 1048.04, "text":
  " the hallucination thing and transitioning right into that.", "tokens": [51272,
  264, 35212, 2486, 551, 293, 33777, 558, 666, 300, 13, 51394], "temperature": 0.0,
  "avg_logprob": -0.17013627688090008, "compression_ratio": 1.7615658362989324, "no_speech_prob":
  0.011538082733750343}, {"id": 318, "seek": 102744, "start": 1048.04, "end": 1053.44,
  "text": " So, so I think the idea of adding more context is our best solution to
  stopping hallucination", "tokens": [51394, 407, 11, 370, 286, 519, 264, 1558, 295,
  5127, 544, 4319, 307, 527, 1151, 3827, 281, 12767, 35212, 2486, 51664], "temperature":
  0.0, "avg_logprob": -0.17013627688090008, "compression_ratio": 1.7615658362989324,
  "no_speech_prob": 0.011538082733750343}, {"id": 319, "seek": 105344, "start": 1053.52,
  "end": 1058.56, "text": " and maybe using consistency, contrastive loss, loss functions
  for the fine tuning to,", "tokens": [50368, 293, 1310, 1228, 14416, 11, 8712, 488,
  4470, 11, 4470, 6828, 337, 264, 2489, 15164, 281, 11, 50620], "temperature": 0.0,
  "avg_logprob": -0.27125413450476243, "compression_ratio": 1.771513353115727, "no_speech_prob":
  0.0026054223999381065}, {"id": 320, "seek": 105344, "start": 1058.56, "end": 1060.0800000000002,
  "text": " to make sure they''re attending on the context.", "tokens": [50620, 281,
  652, 988, 436, 434, 15862, 322, 264, 4319, 13, 50696], "temperature": 0.0, "avg_logprob":
  -0.27125413450476243, "compression_ratio": 1.771513353115727, "no_speech_prob":
  0.0026054223999381065}, {"id": 321, "seek": 105344, "start": 1060.0800000000002,
  "end": 1065.16, "text": " Because like I recently reviewed a paper on my channel
  titled open, open, open challenges", "tokens": [50696, 1436, 411, 286, 3938, 18429,
  257, 3035, 322, 452, 2269, 19841, 1269, 11, 1269, 11, 1269, 4759, 50950], "temperature":
  0.0, "avg_logprob": -0.27125413450476243, "compression_ratio": 1.771513353115727,
  "no_speech_prob": 0.0026054223999381065}, {"id": 322, "seek": 105344, "start": 1065.16,
  "end": 1069.64, "text": " in open domain generalization, some title like that, where,
  um, where yeah, these models,", "tokens": [50950, 294, 1269, 9274, 2674, 2144, 11,
  512, 4876, 411, 300, 11, 689, 11, 1105, 11, 689, 1338, 11, 613, 5245, 11, 51174],
  "temperature": 0.0, "avg_logprob": -0.27125413450476243, "compression_ratio": 1.771513353115727,
  "no_speech_prob": 0.0026054223999381065}, {"id": 323, "seek": 105344, "start": 1069.64,
  "end": 1070.8, "text": " you get them the context.", "tokens": [51174, 291, 483,
  552, 264, 4319, 13, 51232], "temperature": 0.0, "avg_logprob": -0.27125413450476243,
  "compression_ratio": 1.771513353115727, "no_speech_prob": 0.0026054223999381065},
  {"id": 324, "seek": 105344, "start": 1070.8, "end": 1073.48, "text": " So they have
  additional context in the input, but they just don''t read it.", "tokens": [51232,
  407, 436, 362, 4497, 4319, 294, 264, 4846, 11, 457, 436, 445, 500, 380, 1401, 309,
  13, 51366], "temperature": 0.0, "avg_logprob": -0.27125413450476243, "compression_ratio":
  1.771513353115727, "no_speech_prob": 0.0026054223999381065}, {"id": 325, "seek":
  105344, "start": 1073.48, "end": 1075.64, "text": " And they just generalize as
  if it''s not there.", "tokens": [51366, 400, 436, 445, 2674, 1125, 382, 498, 309,
  311, 406, 456, 13, 51474], "temperature": 0.0, "avg_logprob": -0.27125413450476243,
  "compression_ratio": 1.771513353115727, "no_speech_prob": 0.0026054223999381065},
  {"id": 326, "seek": 105344, "start": 1075.64, "end": 1078.3600000000001, "text":
  " So fixing that problem is definitely step one.", "tokens": [51474, 407, 19442,
  300, 1154, 307, 2138, 1823, 472, 13, 51610], "temperature": 0.0, "avg_logprob":
  -0.27125413450476243, "compression_ratio": 1.771513353115727, "no_speech_prob":
  0.0026054223999381065}, {"id": 327, "seek": 105344, "start": 1078.3600000000001,
  "end": 1083.04, "text": " And so then to go into the second thing that you mentioned
  where you replaced London with", "tokens": [51610, 400, 370, 550, 281, 352, 666,
  264, 1150, 551, 300, 291, 2835, 689, 291, 10772, 7042, 365, 51844], "temperature":
  0.0, "avg_logprob": -0.27125413450476243, "compression_ratio": 1.771513353115727,
  "no_speech_prob": 0.0026054223999381065}, {"id": 328, "seek": 108304, "start": 1083.04,
  "end": 1088.36, "text": " Barcelona and that''s the thing about tech data augmentation
  is, it''s, it''s not label", "tokens": [50364, 21247, 293, 300, 311, 264, 551, 466,
  7553, 1412, 14501, 19631, 307, 11, 309, 311, 11, 309, 311, 406, 7645, 50630], "temperature":
  0.0, "avg_logprob": -0.2060009258896557, "compression_ratio": 1.7373737373737375,
  "no_speech_prob": 0.0012733318144455552}, {"id": 329, "seek": 108304, "start": 1088.36,
  "end": 1089.36, "text": " preserving really.", "tokens": [50630, 33173, 534, 13,
  50680], "temperature": 0.0, "avg_logprob": -0.2060009258896557, "compression_ratio":
  1.7373737373737375, "no_speech_prob": 0.0012733318144455552}, {"id": 330, "seek":
  108304, "start": 1089.36, "end": 1091.24, "text": " It''s harder to find symmetries
  in the space.", "tokens": [50680, 467, 311, 6081, 281, 915, 14232, 302, 2244, 294,
  264, 1901, 13, 50774], "temperature": 0.0, "avg_logprob": -0.2060009258896557, "compression_ratio":
  1.7373737373737375, "no_speech_prob": 0.0012733318144455552}, {"id": 331, "seek":
  108304, "start": 1091.24, "end": 1092.84, "text": " It''s easier to find these differences.",
  "tokens": [50774, 467, 311, 3571, 281, 915, 613, 7300, 13, 50854], "temperature":
  0.0, "avg_logprob": -0.2060009258896557, "compression_ratio": 1.7373737373737375,
  "no_speech_prob": 0.0012733318144455552}, {"id": 332, "seek": 108304, "start": 1092.84,
  "end": 1094.32, "text": " So there''s one paper.", "tokens": [50854, 407, 456, 311,
  472, 3035, 13, 50928], "temperature": 0.0, "avg_logprob": -0.2060009258896557, "compression_ratio":
  1.7373737373737375, "no_speech_prob": 0.0012733318144455552}, {"id": 333, "seek":
  108304, "start": 1094.32, "end": 1098.1599999999999, "text": " Maybe I''d like to
  point readers to titled on negative data augmentation.", "tokens": [50928, 2704,
  286, 1116, 411, 281, 935, 17147, 281, 19841, 322, 3671, 1412, 14501, 19631, 13,
  51120], "temperature": 0.0, "avg_logprob": -0.2060009258896557, "compression_ratio":
  1.7373737373737375, "no_speech_prob": 0.0012733318144455552}, {"id": 334, "seek":
  108304, "start": 1098.1599999999999, "end": 1101.6399999999999, "text": " And so
  they''re kind of flipping the, so it''s like, how do we use augmented data?", "tokens":
  [51120, 400, 370, 436, 434, 733, 295, 26886, 264, 11, 370, 309, 311, 411, 11, 577,
  360, 321, 764, 36155, 1412, 30, 51294], "temperature": 0.0, "avg_logprob": -0.2060009258896557,
  "compression_ratio": 1.7373737373737375, "no_speech_prob": 0.0012733318144455552},
  {"id": 335, "seek": 108304, "start": 1101.6399999999999, "end": 1106.6399999999999,
  "text": " Should we just keep using this, you know, kale divergence between the
  one hot class", "tokens": [51294, 6454, 321, 445, 1066, 1228, 341, 11, 291, 458,
  11, 34699, 47387, 1296, 264, 472, 2368, 1508, 51544], "temperature": 0.0, "avg_logprob":
  -0.2060009258896557, "compression_ratio": 1.7373737373737375, "no_speech_prob":
  0.0012733318144455552}, {"id": 336, "seek": 108304, "start": 1106.6399999999999,
  "end": 1109.8799999999999, "text": " vectors or should we do something different
  with the augmented data?", "tokens": [51544, 18875, 420, 820, 321, 360, 746, 819,
  365, 264, 36155, 1412, 30, 51706], "temperature": 0.0, "avg_logprob": -0.2060009258896557,
  "compression_ratio": 1.7373737373737375, "no_speech_prob": 0.0012733318144455552},
  {"id": 337, "seek": 110988, "start": 1109.88, "end": 1113.7600000000002, "text":
  " I mentioned consistency losses where the loss would be, you know, the representations",
  "tokens": [50364, 286, 2835, 14416, 15352, 689, 264, 4470, 576, 312, 11, 291, 458,
  11, 264, 33358, 50558], "temperature": 0.0, "avg_logprob": -0.24675430520607608,
  "compression_ratio": 1.7665615141955835, "no_speech_prob": 0.2044392228126526},
  {"id": 338, "seek": 110988, "start": 1113.7600000000002, "end": 1118.92, "text":
  " of X and X prime ignoring whatever the Y label is and negative data augmentation
  is saying,", "tokens": [50558, 295, 1783, 293, 1783, 5835, 26258, 2035, 264, 398,
  7645, 307, 293, 3671, 1412, 14501, 19631, 307, 1566, 11, 50816], "temperature":
  0.0, "avg_logprob": -0.24675430520607608, "compression_ratio": 1.7665615141955835,
  "no_speech_prob": 0.2044392228126526}, {"id": 339, "seek": 110988, "start": 1118.92,
  "end": 1120.2, "text": " you know, push them apart.", "tokens": [50816, 291, 458,
  11, 2944, 552, 4936, 13, 50880], "temperature": 0.0, "avg_logprob": -0.24675430520607608,
  "compression_ratio": 1.7665615141955835, "no_speech_prob": 0.2044392228126526},
  {"id": 340, "seek": 110988, "start": 1120.2, "end": 1121.44, "text": " These are
  not the same label.", "tokens": [50880, 1981, 366, 406, 264, 912, 7645, 13, 50942],
  "temperature": 0.0, "avg_logprob": -0.24675430520607608, "compression_ratio": 1.7665615141955835,
  "no_speech_prob": 0.2044392228126526}, {"id": 341, "seek": 110988, "start": 1121.44,
  "end": 1123.2, "text": " We''ve switched London with Barcelona.", "tokens": [50942,
  492, 600, 16858, 7042, 365, 21247, 13, 51030], "temperature": 0.0, "avg_logprob":
  -0.24675430520607608, "compression_ratio": 1.7665615141955835, "no_speech_prob":
  0.2044392228126526}, {"id": 342, "seek": 110988, "start": 1123.2, "end": 1128.0800000000002,
  "text": " And so then I think the last thing, as we''re talking about, like the
  practical implementation,", "tokens": [51030, 400, 370, 550, 286, 519, 264, 1036,
  551, 11, 382, 321, 434, 1417, 466, 11, 411, 264, 8496, 11420, 11, 51274], "temperature":
  0.0, "avg_logprob": -0.24675430520607608, "compression_ratio": 1.7665615141955835,
  "no_speech_prob": 0.2044392228126526}, {"id": 343, "seek": 110988, "start": 1128.0800000000002,
  "end": 1131.4, "text": " I think you say two things, there''s like two directions
  that which are really interesting.", "tokens": [51274, 286, 519, 291, 584, 732,
  721, 11, 456, 311, 411, 732, 11095, 300, 597, 366, 534, 1880, 13, 51440], "temperature":
  0.0, "avg_logprob": -0.24675430520607608, "compression_ratio": 1.7665615141955835,
  "no_speech_prob": 0.2044392228126526}, {"id": 344, "seek": 110988, "start": 1131.4,
  "end": 1134.6000000000001, "text": " And I think what you''re getting to with the
  data augmentation is, is you want to prevent", "tokens": [51440, 400, 286, 519,
  437, 291, 434, 1242, 281, 365, 264, 1412, 14501, 19631, 307, 11, 307, 291, 528,
  281, 4871, 51600], "temperature": 0.0, "avg_logprob": -0.24675430520607608, "compression_ratio":
  1.7665615141955835, "no_speech_prob": 0.2044392228126526}, {"id": 345, "seek": 110988,
  "start": 1134.6000000000001, "end": 1135.6000000000001, "text": " overfitting.",
  "tokens": [51600, 670, 69, 2414, 13, 51650], "temperature": 0.0, "avg_logprob":
  -0.24675430520607608, "compression_ratio": 1.7665615141955835, "no_speech_prob":
  0.2044392228126526}, {"id": 346, "seek": 113560, "start": 1135.6, "end": 1140.24,
  "text": " And if you have, if you''re, you know, grabbing Microsoft''s 32 trillion
  parameter model,", "tokens": [50364, 400, 498, 291, 362, 11, 498, 291, 434, 11,
  291, 458, 11, 23771, 8116, 311, 8858, 18723, 13075, 2316, 11, 50596], "temperature":
  0.0, "avg_logprob": -0.19803947126361685, "compression_ratio": 1.6696428571428572,
  "no_speech_prob": 0.0108503932133317}, {"id": 347, "seek": 113560, "start": 1140.24,
  "end": 1144.52, "text": " and you''ve only got 100 labeled examples, there''s no
  way that''s going to work.", "tokens": [50596, 293, 291, 600, 787, 658, 2319, 21335,
  5110, 11, 456, 311, 572, 636, 300, 311, 516, 281, 589, 13, 50810], "temperature":
  0.0, "avg_logprob": -0.19803947126361685, "compression_ratio": 1.6696428571428572,
  "no_speech_prob": 0.0108503932133317}, {"id": 348, "seek": 113560, "start": 1144.52,
  "end": 1145.52, "text": " So you want to prevent overfitting.", "tokens": [50810,
  407, 291, 528, 281, 4871, 670, 69, 2414, 13, 50860], "temperature": 0.0, "avg_logprob":
  -0.19803947126361685, "compression_ratio": 1.6696428571428572, "no_speech_prob":
  0.0108503932133317}, {"id": 349, "seek": 113560, "start": 1145.52, "end": 1148.6799999999998,
  "text": " And then I think kind of the second part to that story when people talk
  about this kind", "tokens": [50860, 400, 550, 286, 519, 733, 295, 264, 1150, 644,
  281, 300, 1657, 562, 561, 751, 466, 341, 733, 51018], "temperature": 0.0, "avg_logprob":
  -0.19803947126361685, "compression_ratio": 1.6696428571428572, "no_speech_prob":
  0.0108503932133317}, {"id": 350, "seek": 113560, "start": 1148.6799999999998, "end":
  1152.9199999999998, "text": " of topic is, is like storage and inference cost and
  obviously training costs.", "tokens": [51018, 295, 4829, 307, 11, 307, 411, 6725,
  293, 38253, 2063, 293, 2745, 3097, 5497, 13, 51230], "temperature": 0.0, "avg_logprob":
  -0.19803947126361685, "compression_ratio": 1.6696428571428572, "no_speech_prob":
  0.0108503932133317}, {"id": 351, "seek": 113560, "start": 1152.9199999999998, "end":
  1154.08, "text": " You''re going to fine tune this.", "tokens": [51230, 509, 434,
  516, 281, 2489, 10864, 341, 13, 51288], "temperature": 0.0, "avg_logprob": -0.19803947126361685,
  "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0108503932133317},
  {"id": 352, "seek": 113560, "start": 1154.08, "end": 1157.04, "text": " So maybe
  training costs has been solved with prompting where you don''t actually need to",
  "tokens": [51288, 407, 1310, 3097, 5497, 575, 668, 13041, 365, 12391, 278, 689,
  291, 500, 380, 767, 643, 281, 51436], "temperature": 0.0, "avg_logprob": -0.19803947126361685,
  "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0108503932133317},
  {"id": 353, "seek": 113560, "start": 1157.04, "end": 1158.4399999999998, "text":
  " do any grading to send updates.", "tokens": [51436, 360, 604, 35540, 281, 2845,
  9205, 13, 51506], "temperature": 0.0, "avg_logprob": -0.19803947126361685, "compression_ratio":
  1.6696428571428572, "no_speech_prob": 0.0108503932133317}, {"id": 354, "seek": 113560,
  "start": 1158.4399999999998, "end": 1161.8799999999999, "text": " You just give
  more in the input context.", "tokens": [51506, 509, 445, 976, 544, 294, 264, 4846,
  4319, 13, 51678], "temperature": 0.0, "avg_logprob": -0.19803947126361685, "compression_ratio":
  1.6696428571428572, "no_speech_prob": 0.0108503932133317}, {"id": 355, "seek": 116188,
  "start": 1161.88, "end": 1165.92, "text": " But then I think inference cost is solved
  with this knowledge installation interface.", "tokens": [50364, 583, 550, 286, 519,
  38253, 2063, 307, 13041, 365, 341, 3601, 13260, 9226, 13, 50566], "temperature":
  0.0, "avg_logprob": -0.2702792718158505, "compression_ratio": 1.744360902255639,
  "no_speech_prob": 0.03740179166197777}, {"id": 356, "seek": 116188, "start": 1165.92,
  "end": 1172.8000000000002, "text": " And I think hugging face, man, I think the
  name of their product is lightning or something", "tokens": [50566, 400, 286, 519,
  41706, 1851, 11, 587, 11, 286, 519, 264, 1315, 295, 641, 1674, 307, 16589, 420,
  746, 50910], "temperature": 0.0, "avg_logprob": -0.2702792718158505, "compression_ratio":
  1.744360902255639, "no_speech_prob": 0.03740179166197777}, {"id": 357, "seek": 116188,
  "start": 1172.8000000000002, "end": 1175.48, "text": " like that where it''s about
  inference acceleration.", "tokens": [50910, 411, 300, 689, 309, 311, 466, 38253,
  17162, 13, 51044], "temperature": 0.0, "avg_logprob": -0.2702792718158505, "compression_ratio":
  1.744360902255639, "no_speech_prob": 0.03740179166197777}, {"id": 358, "seek": 116188,
  "start": 1175.48, "end": 1178.5600000000002, "text": " And it looks like they''re,
  you know, they''re doing it pretty well.", "tokens": [51044, 400, 309, 1542, 411,
  436, 434, 11, 291, 458, 11, 436, 434, 884, 309, 1238, 731, 13, 51198], "temperature":
  0.0, "avg_logprob": -0.2702792718158505, "compression_ratio": 1.744360902255639,
  "no_speech_prob": 0.03740179166197777}, {"id": 359, "seek": 116188, "start": 1178.5600000000002,
  "end": 1181.7600000000002, "text": " So I certainly bet on hugging face to solve
  that problem.", "tokens": [51198, 407, 286, 3297, 778, 322, 41706, 1851, 281, 5039,
  300, 1154, 13, 51358], "temperature": 0.0, "avg_logprob": -0.2702792718158505, "compression_ratio":
  1.744360902255639, "no_speech_prob": 0.03740179166197777}, {"id": 360, "seek": 116188,
  "start": 1181.7600000000002, "end": 1182.7600000000002, "text": " Oh, yeah, absolutely.",
  "tokens": [51358, 876, 11, 1338, 11, 3122, 13, 51408], "temperature": 0.0, "avg_logprob":
  -0.2702792718158505, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.03740179166197777},
  {"id": 361, "seek": 116188, "start": 1182.7600000000002, "end": 1185.16, "text":
  " I think they call it infinity, you know?", "tokens": [51408, 286, 519, 436, 818,
  309, 13202, 11, 291, 458, 30, 51528], "temperature": 0.0, "avg_logprob": -0.2702792718158505,
  "compression_ratio": 1.744360902255639, "no_speech_prob": 0.03740179166197777},
  {"id": 362, "seek": 116188, "start": 1185.16, "end": 1186.16, "text": " Infinity.",
  "tokens": [51528, 34762, 13, 51578], "temperature": 0.0, "avg_logprob": -0.2702792718158505,
  "compression_ratio": 1.744360902255639, "no_speech_prob": 0.03740179166197777},
  {"id": 363, "seek": 116188, "start": 1186.16, "end": 1187.96, "text": " Yeah, sorry
  about that.", "tokens": [51578, 865, 11, 2597, 466, 300, 13, 51668], "temperature":
  0.0, "avg_logprob": -0.2702792718158505, "compression_ratio": 1.744360902255639,
  "no_speech_prob": 0.03740179166197777}, {"id": 364, "seek": 116188, "start": 1187.96,
  "end": 1188.96, "text": " Oh, it''s okay.", "tokens": [51668, 876, 11, 309, 311,
  1392, 13, 51718], "temperature": 0.0, "avg_logprob": -0.2702792718158505, "compression_ratio":
  1.744360902255639, "no_speech_prob": 0.03740179166197777}, {"id": 365, "seek": 118896,
  "start": 1189.3600000000001, "end": 1193.52, "text": " It''s also like testing your
  memory, you know, like we remember.", "tokens": [50384, 467, 311, 611, 411, 4997,
  428, 4675, 11, 291, 458, 11, 411, 321, 1604, 13, 50592], "temperature": 0.0, "avg_logprob":
  -0.19283623788871018, "compression_ratio": 1.634703196347032, "no_speech_prob":
  0.07675180584192276}, {"id": 366, "seek": 118896, "start": 1193.52, "end": 1198.08,
  "text": " And I think it''s still also like at some point, and I think Elon Musk
  is afraid of it.", "tokens": [50592, 400, 286, 519, 309, 311, 920, 611, 411, 412,
  512, 935, 11, 293, 286, 519, 28498, 26019, 307, 4638, 295, 309, 13, 50820], "temperature":
  0.0, "avg_logprob": -0.19283623788871018, "compression_ratio": 1.634703196347032,
  "no_speech_prob": 0.07675180584192276}, {"id": 367, "seek": 118896, "start": 1198.08,
  "end": 1204.52, "text": " Hey, Elon, if you''re listening to this, hello, you know,
  like he''s afraid of that our", "tokens": [50820, 1911, 11, 28498, 11, 498, 291,
  434, 4764, 281, 341, 11, 7751, 11, 291, 458, 11, 411, 415, 311, 4638, 295, 300,
  527, 51142], "temperature": 0.0, "avg_logprob": -0.19283623788871018, "compression_ratio":
  1.634703196347032, "no_speech_prob": 0.07675180584192276}, {"id": 368, "seek": 118896,
  "start": 1204.52, "end": 1207.04, "text": " interface is way too slow, right?",
  "tokens": [51142, 9226, 307, 636, 886, 2964, 11, 558, 30, 51268], "temperature":
  0.0, "avg_logprob": -0.19283623788871018, "compression_ratio": 1.634703196347032,
  "no_speech_prob": 0.07675180584192276}, {"id": 369, "seek": 118896, "start": 1207.04,
  "end": 1214.3600000000001, "text": " And so eventually I will basically supersede
  us, which I don''t think so, but let''s see.", "tokens": [51268, 400, 370, 4728,
  286, 486, 1936, 37906, 4858, 505, 11, 597, 286, 500, 380, 519, 370, 11, 457, 718,
  311, 536, 13, 51634], "temperature": 0.0, "avg_logprob": -0.19283623788871018, "compression_ratio":
  1.634703196347032, "no_speech_prob": 0.07675180584192276}, {"id": 370, "seek": 121436,
  "start": 1214.36, "end": 1219.08, "text": " But also like what''s interesting, I
  was thinking that maybe a little bit like developing this", "tokens": [50364, 583,
  611, 411, 437, 311, 1880, 11, 286, 390, 1953, 300, 1310, 257, 707, 857, 411, 6416,
  341, 50600], "temperature": 0.0, "avg_logprob": -0.24631410890871341, "compression_ratio":
  1.676923076923077, "no_speech_prob": 0.006588254123926163}, {"id": 371, "seek":
  121436, "start": 1219.08, "end": 1225.1599999999999, "text": " topic further, but
  it sounds you have so much knowledge on this and it''s so packed, what", "tokens":
  [50600, 4829, 3052, 11, 457, 309, 3263, 291, 362, 370, 709, 3601, 322, 341, 293,
  309, 311, 370, 13265, 11, 437, 50904], "temperature": 0.0, "avg_logprob": -0.24631410890871341,
  "compression_ratio": 1.676923076923077, "no_speech_prob": 0.006588254123926163},
  {"id": 372, "seek": 121436, "start": 1225.1599999999999, "end": 1230.84, "text":
  " you said, you know, like, for example, if we could use the language model itself
  to help", "tokens": [50904, 291, 848, 11, 291, 458, 11, 411, 11, 337, 1365, 11,
  498, 321, 727, 764, 264, 2856, 2316, 2564, 281, 854, 51188], "temperature": 0.0,
  "avg_logprob": -0.24631410890871341, "compression_ratio": 1.676923076923077, "no_speech_prob":
  0.006588254123926163}, {"id": 373, "seek": 121436, "start": 1230.84, "end": 1233.36,
  "text": " us generate, you said GPT, right?", "tokens": [51188, 505, 8460, 11, 291,
  848, 26039, 51, 11, 558, 30, 51314], "temperature": 0.0, "avg_logprob": -0.24631410890871341,
  "compression_ratio": 1.676923076923077, "no_speech_prob": 0.006588254123926163},
  {"id": 374, "seek": 121436, "start": 1233.36, "end": 1238.12, "text": " It''s generative
  model, but there could be some others, which will kind of help us to generate",
  "tokens": [51314, 467, 311, 1337, 1166, 2316, 11, 457, 456, 727, 312, 512, 2357,
  11, 597, 486, 733, 295, 854, 505, 281, 8460, 51552], "temperature": 0.0, "avg_logprob":
  -0.24631410890871341, "compression_ratio": 1.676923076923077, "no_speech_prob":
  0.006588254123926163}, {"id": 375, "seek": 121436, "start": 1238.12, "end": 1240.8,
  "text": " things and then augment the dataset.", "tokens": [51552, 721, 293, 550,
  29919, 264, 28872, 13, 51686], "temperature": 0.0, "avg_logprob": -0.24631410890871341,
  "compression_ratio": 1.676923076923077, "no_speech_prob": 0.006588254123926163},
  {"id": 376, "seek": 124080, "start": 1241.2, "end": 1243.9199999999998, "text":
  " But there is one beautiful that I don''t know if you''ve read this paper.", "tokens":
  [50384, 583, 456, 307, 472, 2238, 300, 286, 500, 380, 458, 498, 291, 600, 1401,
  341, 3035, 13, 50520], "temperature": 0.0, "avg_logprob": -0.24566272774127998,
  "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.017959708347916603},
  {"id": 377, "seek": 124080, "start": 1243.9199999999998, "end": 1248.24, "text":
  " It''s called what bird is not lessons from a new suite of cycling,", "tokens":
  [50520, 467, 311, 1219, 437, 5255, 307, 406, 8820, 490, 257, 777, 14205, 295, 22425,
  11, 50736], "temperature": 0.0, "avg_logprob": -0.24566272774127998, "compression_ratio":
  1.6068702290076335, "no_speech_prob": 0.017959708347916603}, {"id": 378, "seek":
  124080, "start": 1248.24, "end": 1250.52, "text": " holistic diagnostics for language
  models.", "tokens": [50736, 30334, 43215, 1167, 337, 2856, 5245, 13, 50850], "temperature":
  0.0, "avg_logprob": -0.24566272774127998, "compression_ratio": 1.6068702290076335,
  "no_speech_prob": 0.017959708347916603}, {"id": 379, "seek": 124080, "start": 1250.52,
  "end": 1258.28, "text": " And so basically the paper essentially claims that bird
  does not distinguish the negations.", "tokens": [50850, 400, 370, 1936, 264, 3035,
  4476, 9441, 300, 5255, 775, 406, 20206, 264, 2485, 763, 13, 51238], "temperature":
  0.0, "avg_logprob": -0.24566272774127998, "compression_ratio": 1.6068702290076335,
  "no_speech_prob": 0.017959708347916603}, {"id": 380, "seek": 124080, "start": 1258.28,
  "end": 1262.8799999999999, "text": " And that can be super, super sensitive, like
  in sentiment analysis, right?", "tokens": [51238, 400, 300, 393, 312, 1687, 11,
  1687, 9477, 11, 411, 294, 16149, 5215, 11, 558, 30, 51468], "temperature": 0.0,
  "avg_logprob": -0.24566272774127998, "compression_ratio": 1.6068702290076335, "no_speech_prob":
  0.017959708347916603}, {"id": 381, "seek": 124080, "start": 1262.8799999999999,
  "end": 1267.1599999999999, "text": " At least, but also like in machine translation
  and other downstream tasks.", "tokens": [51468, 1711, 1935, 11, 457, 611, 411, 294,
  3479, 12853, 293, 661, 30621, 9608, 13, 51682], "temperature": 0.0, "avg_logprob":
  -0.24566272774127998, "compression_ratio": 1.6068702290076335, "no_speech_prob":
  0.017959708347916603}, {"id": 382, "seek": 126716, "start": 1267.16, "end": 1268.96,
  "text": " So have you thought about this?", "tokens": [50364, 407, 362, 291, 1194,
  466, 341, 30, 50454], "temperature": 0.0, "avg_logprob": -0.2627053774320162, "compression_ratio":
  1.7077922077922079, "no_speech_prob": 0.021291537210345268}, {"id": 383, "seek":
  126716, "start": 1268.96, "end": 1273.2, "text": " Like basically there is actually
  a now a development.", "tokens": [50454, 1743, 1936, 456, 307, 767, 257, 586, 257,
  3250, 13, 50666], "temperature": 0.0, "avg_logprob": -0.2627053774320162, "compression_ratio":
  1.7077922077922079, "no_speech_prob": 0.021291537210345268}, {"id": 384, "seek":
  126716, "start": 1273.2, "end": 1278.96, "text": " I think it''s also on Microsoft
  side to try to bring knowledge into the language model.", "tokens": [50666, 286,
  519, 309, 311, 611, 322, 8116, 1252, 281, 853, 281, 1565, 3601, 666, 264, 2856,
  2316, 13, 50954], "temperature": 0.0, "avg_logprob": -0.2627053774320162, "compression_ratio":
  1.7077922077922079, "no_speech_prob": 0.021291537210345268}, {"id": 385, "seek":
  126716, "start": 1278.96, "end": 1281.88, "text": " And you can do it in a variety
  of ways you mentioned knowledge graph, but there are other", "tokens": [50954, 400,
  291, 393, 360, 309, 294, 257, 5673, 295, 2098, 291, 2835, 3601, 4295, 11, 457, 456,
  366, 661, 51100], "temperature": 0.0, "avg_logprob": -0.2627053774320162, "compression_ratio":
  1.7077922077922079, "no_speech_prob": 0.021291537210345268}, {"id": 386, "seek":
  126716, "start": 1281.88, "end": 1284.4, "text": " ways kind of to bring in the
  structured knowledge.", "tokens": [51100, 2098, 733, 295, 281, 1565, 294, 264, 18519,
  3601, 13, 51226], "temperature": 0.0, "avg_logprob": -0.2627053774320162, "compression_ratio":
  1.7077922077922079, "no_speech_prob": 0.021291537210345268}, {"id": 387, "seek":
  126716, "start": 1284.4, "end": 1286.6000000000001, "text": " So any thoughts on
  that on that topic?", "tokens": [51226, 407, 604, 4598, 322, 300, 322, 300, 4829,
  30, 51336], "temperature": 0.0, "avg_logprob": -0.2627053774320162, "compression_ratio":
  1.7077922077922079, "no_speech_prob": 0.021291537210345268}, {"id": 388, "seek":
  126716, "start": 1286.6000000000001, "end": 1291.3600000000001, "text": " Yeah,
  and this is where I''m just starting getting back into we V8 because I think we",
  "tokens": [51336, 865, 11, 293, 341, 307, 689, 286, 478, 445, 2891, 1242, 646, 666,
  321, 691, 23, 570, 286, 519, 321, 51574], "temperature": 0.0, "avg_logprob": -0.2627053774320162,
  "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.021291537210345268},
  {"id": 389, "seek": 126716, "start": 1291.3600000000001, "end": 1295.4, "text":
  " V8 is going to be a huge part of solving that problem and adding the additional
  context.", "tokens": [51574, 691, 23, 307, 516, 281, 312, 257, 2603, 644, 295, 12606,
  300, 1154, 293, 5127, 264, 4497, 4319, 13, 51776], "temperature": 0.0, "avg_logprob":
  -0.2627053774320162, "compression_ratio": 1.7077922077922079, "no_speech_prob":
  0.021291537210345268}, {"id": 390, "seek": 129540, "start": 1295.4, "end": 1297.64,
  "text": " But first I want to raise you one paper.", "tokens": [50364, 583, 700,
  286, 528, 281, 5300, 291, 472, 3035, 13, 50476], "temperature": 0.0, "avg_logprob":
  -0.2511287689208984, "compression_ratio": 1.717607973421927, "no_speech_prob": 0.00789932906627655},
  {"id": 391, "seek": 129540, "start": 1297.64, "end": 1301.8400000000001, "text":
  " So from the psycholinguistic thing, I want to point readers in the direction of
  viewers", "tokens": [50476, 407, 490, 264, 4681, 401, 7050, 3142, 551, 11, 286,
  528, 281, 935, 17147, 294, 264, 3513, 295, 8499, 50686], "temperature": 0.0, "avg_logprob":
  -0.2511287689208984, "compression_ratio": 1.717607973421927, "no_speech_prob": 0.00789932906627655},
  {"id": 392, "seek": 129540, "start": 1301.8400000000001, "end": 1303.64, "text":
  " in the direction of checklist.", "tokens": [50686, 294, 264, 3513, 295, 30357,
  13, 50776], "temperature": 0.0, "avg_logprob": -0.2511287689208984, "compression_ratio":
  1.717607973421927, "no_speech_prob": 0.00789932906627655}, {"id": 393, "seek": 129540,
  "start": 1303.64, "end": 1307.0400000000002, "text": " It was one of the best paper
  awards at a recent ACL conference.", "tokens": [50776, 467, 390, 472, 295, 264,
  1151, 3035, 15193, 412, 257, 5162, 43873, 7586, 13, 50946], "temperature": 0.0,
  "avg_logprob": -0.2511287689208984, "compression_ratio": 1.717607973421927, "no_speech_prob":
  0.00789932906627655}, {"id": 394, "seek": 129540, "start": 1307.0400000000002, "end":
  1313.68, "text": " ACL is I think ACL EM and OP, like the top NLP conferences checklist
  is exactly what you", "tokens": [50946, 43873, 307, 286, 519, 43873, 16237, 293,
  23324, 11, 411, 264, 1192, 426, 45196, 22032, 30357, 307, 2293, 437, 291, 51278],
  "temperature": 0.0, "avg_logprob": -0.2511287689208984, "compression_ratio": 1.717607973421927,
  "no_speech_prob": 0.00789932906627655}, {"id": 395, "seek": 129540, "start": 1313.68,
  "end": 1314.68, "text": " say.", "tokens": [51278, 584, 13, 51328], "temperature":
  0.0, "avg_logprob": -0.2511287689208984, "compression_ratio": 1.717607973421927,
  "no_speech_prob": 0.00789932906627655}, {"id": 396, "seek": 129540, "start": 1314.68,
  "end": 1318.96, "text": " It''s a complete suite of tests for negations named entity
  swapping.", "tokens": [51328, 467, 311, 257, 3566, 14205, 295, 6921, 337, 2485,
  763, 4926, 13977, 1693, 10534, 13, 51542], "temperature": 0.0, "avg_logprob": -0.2511287689208984,
  "compression_ratio": 1.717607973421927, "no_speech_prob": 0.00789932906627655},
  {"id": 397, "seek": 129540, "start": 1318.96, "end": 1320.2, "text": " And it''s
  really nice to use.", "tokens": [51542, 400, 309, 311, 534, 1481, 281, 764, 13,
  51604], "temperature": 0.0, "avg_logprob": -0.2511287689208984, "compression_ratio":
  1.717607973421927, "no_speech_prob": 0.00789932906627655}, {"id": 398, "seek": 129540,
  "start": 1320.2, "end": 1321.2, "text": " It''s on GitHub.", "tokens": [51604, 467,
  311, 322, 23331, 13, 51654], "temperature": 0.0, "avg_logprob": -0.2511287689208984,
  "compression_ratio": 1.717607973421927, "no_speech_prob": 0.00789932906627655},
  {"id": 399, "seek": 129540, "start": 1321.2, "end": 1325.2, "text": " So yeah, so
  they have the interfaces for testing for that kind of thing, which I think", "tokens":
  [51654, 407, 1338, 11, 370, 436, 362, 264, 28416, 337, 4997, 337, 300, 733, 295,
  551, 11, 597, 286, 519, 51854], "temperature": 0.0, "avg_logprob": -0.2511287689208984,
  "compression_ratio": 1.717607973421927, "no_speech_prob": 0.00789932906627655},
  {"id": 400, "seek": 132520, "start": 1325.2, "end": 1328.8, "text": " once you have
  the test, you can start hacking away, it''s solving it.", "tokens": [50364, 1564,
  291, 362, 264, 1500, 11, 291, 393, 722, 31422, 1314, 11, 309, 311, 12606, 309, 13,
  50544], "temperature": 0.0, "avg_logprob": -0.28172068235253084, "compression_ratio":
  1.735408560311284, "no_speech_prob": 0.00039121831650845706}, {"id": 401, "seek":
  132520, "start": 1328.8, "end": 1330.76, "text": " It''s not theoretically grounded.",
  "tokens": [50544, 467, 311, 406, 29400, 23535, 13, 50642], "temperature": 0.0, "avg_logprob":
  -0.28172068235253084, "compression_ratio": 1.735408560311284, "no_speech_prob":
  0.00039121831650845706}, {"id": 402, "seek": 132520, "start": 1330.76, "end": 1334.56,
  "text": " If you have the right test, you could hack away until you pass the test.",
  "tokens": [50642, 759, 291, 362, 264, 558, 1500, 11, 291, 727, 10339, 1314, 1826,
  291, 1320, 264, 1500, 13, 50832], "temperature": 0.0, "avg_logprob": -0.28172068235253084,
  "compression_ratio": 1.735408560311284, "no_speech_prob": 0.00039121831650845706},
  {"id": 403, "seek": 132520, "start": 1334.56, "end": 1338.88, "text": " So checklist
  is the test for that.", "tokens": [50832, 407, 30357, 307, 264, 1500, 337, 300,
  13, 51048], "temperature": 0.0, "avg_logprob": -0.28172068235253084, "compression_ratio":
  1.735408560311284, "no_speech_prob": 0.00039121831650845706}, {"id": 404, "seek":
  132520, "start": 1338.88, "end": 1344.16, "text": " But then so yeah, so then the
  idea of context and and we V8.", "tokens": [51048, 583, 550, 370, 1338, 11, 370,
  550, 264, 1558, 295, 4319, 293, 293, 321, 691, 23, 13, 51312], "temperature": 0.0,
  "avg_logprob": -0.28172068235253084, "compression_ratio": 1.735408560311284, "no_speech_prob":
  0.00039121831650845706}, {"id": 405, "seek": 132520, "start": 1344.16, "end": 1349.72,
  "text": " So so V8 is so the vector search engine part and you know, Facebook paper
  dense passage", "tokens": [51312, 407, 370, 691, 23, 307, 370, 264, 8062, 3164,
  2848, 644, 293, 291, 458, 11, 4384, 3035, 18011, 11497, 51590], "temperature": 0.0,
  "avg_logprob": -0.28172068235253084, "compression_ratio": 1.735408560311284, "no_speech_prob":
  0.00039121831650845706}, {"id": 406, "seek": 132520, "start": 1349.72, "end": 1353.2,
  "text": " retrieval is their current approach where they have, you know, the text
  embeddings, the", "tokens": [51590, 19817, 3337, 307, 641, 2190, 3109, 689, 436,
  362, 11, 291, 458, 11, 264, 2487, 12240, 29432, 11, 264, 51764], "temperature":
  0.0, "avg_logprob": -0.28172068235253084, "compression_ratio": 1.735408560311284,
  "no_speech_prob": 0.00039121831650845706}, {"id": 407, "seek": 135320, "start":
  1353.2, "end": 1356.6000000000001, "text": " documents and they''re going to go
  retrieve the context so that you can avoid hallucination,", "tokens": [50364, 8512,
  293, 436, 434, 516, 281, 352, 30254, 264, 4319, 370, 300, 291, 393, 5042, 35212,
  2486, 11, 50534], "temperature": 0.0, "avg_logprob": -0.21401780169943105, "compression_ratio":
  1.6317567567567568, "no_speech_prob": 0.004736820701509714}, {"id": 408, "seek":
  135320, "start": 1356.6000000000001, "end": 1360.0800000000002, "text": " hopefully
  avoid these kind of vulnerabilities through robustness.", "tokens": [50534, 4696,
  5042, 613, 733, 295, 37633, 807, 13956, 1287, 13, 50708], "temperature": 0.0, "avg_logprob":
  -0.21401780169943105, "compression_ratio": 1.6317567567567568, "no_speech_prob":
  0.004736820701509714}, {"id": 409, "seek": 135320, "start": 1360.0800000000002,
  "end": 1365.0, "text": " But so vector search engines is what I see as being a huge
  player in solving that particular", "tokens": [50708, 583, 370, 8062, 3164, 12982,
  307, 437, 286, 536, 382, 885, 257, 2603, 4256, 294, 12606, 300, 1729, 50954], "temperature":
  0.0, "avg_logprob": -0.21401780169943105, "compression_ratio": 1.6317567567567568,
  "no_speech_prob": 0.004736820701509714}, {"id": 410, "seek": 135320, "start": 1365.0,
  "end": 1366.0, "text": " problem.", "tokens": [50954, 1154, 13, 51004], "temperature":
  0.0, "avg_logprob": -0.21401780169943105, "compression_ratio": 1.6317567567567568,
  "no_speech_prob": 0.004736820701509714}, {"id": 411, "seek": 135320, "start": 1366.0,
  "end": 1370.4, "text": " And I see that transitioning not just from text, but image
  text of video text like the idea", "tokens": [51004, 400, 286, 536, 300, 33777,
  406, 445, 490, 2487, 11, 457, 3256, 2487, 295, 960, 2487, 411, 264, 1558, 51224],
  "temperature": 0.0, "avg_logprob": -0.21401780169943105, "compression_ratio": 1.6317567567567568,
  "no_speech_prob": 0.004736820701509714}, {"id": 412, "seek": 135320, "start": 1370.4,
  "end": 1374.8400000000001, "text": " that you want to add some more context from
  your database to the current inference.", "tokens": [51224, 300, 291, 528, 281,
  909, 512, 544, 4319, 490, 428, 8149, 281, 264, 2190, 38253, 13, 51446], "temperature":
  0.0, "avg_logprob": -0.21401780169943105, "compression_ratio": 1.6317567567567568,
  "no_speech_prob": 0.004736820701509714}, {"id": 413, "seek": 135320, "start": 1374.8400000000001,
  "end": 1375.8400000000001, "text": " Yeah, yeah.", "tokens": [51446, 865, 11, 1338,
  13, 51496], "temperature": 0.0, "avg_logprob": -0.21401780169943105, "compression_ratio":
  1.6317567567567568, "no_speech_prob": 0.004736820701509714}, {"id": 414, "seek":
  135320, "start": 1375.8400000000001, "end": 1379.48, "text": " I mean, V8 is doing
  fantastic work.", "tokens": [51496, 286, 914, 11, 691, 23, 307, 884, 5456, 589,
  13, 51678], "temperature": 0.0, "avg_logprob": -0.21401780169943105, "compression_ratio":
  1.6317567567567568, "no_speech_prob": 0.004736820701509714}, {"id": 415, "seek":
  137948, "start": 1379.48, "end": 1384.8, "text": " Actually, we have a podcast recorded
  with mob and so, you know, my listener''s can actually", "tokens": [50364, 5135,
  11, 321, 362, 257, 7367, 8287, 365, 4298, 293, 370, 11, 291, 458, 11, 452, 31569,
  311, 393, 767, 50630], "temperature": 0.0, "avg_logprob": -0.23937352498372397,
  "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.03639225661754608},
  {"id": 416, "seek": 137948, "start": 1384.8, "end": 1388.88, "text": " watch it
  and then we also had an episode with you where we covered some of the things.",
  "tokens": [50630, 1159, 309, 293, 550, 321, 611, 632, 364, 3500, 365, 291, 689,
  321, 5343, 512, 295, 264, 721, 13, 50834], "temperature": 0.0, "avg_logprob": -0.23937352498372397,
  "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.03639225661754608},
  {"id": 417, "seek": 137948, "start": 1388.88, "end": 1393.8, "text": " And you also
  recorded a bunch of videos like walking through the feature set.", "tokens": [50834,
  400, 291, 611, 8287, 257, 3840, 295, 2145, 411, 4494, 807, 264, 4111, 992, 13, 51080],
  "temperature": 0.0, "avg_logprob": -0.23937352498372397, "compression_ratio": 1.6692607003891051,
  "no_speech_prob": 0.03639225661754608}, {"id": 418, "seek": 137948, "start": 1393.8,
  "end": 1400.56, "text": " What caught your attention in V8 when kind of if you can
  slightly compare to other database", "tokens": [51080, 708, 5415, 428, 3202, 294,
  691, 23, 562, 733, 295, 498, 291, 393, 4748, 6794, 281, 661, 8149, 51418], "temperature":
  0.0, "avg_logprob": -0.23937352498372397, "compression_ratio": 1.6692607003891051,
  "no_speech_prob": 0.03639225661754608}, {"id": 419, "seek": 137948, "start": 1400.56,
  "end": 1401.56, "text": " vendors?", "tokens": [51418, 22056, 30, 51468], "temperature":
  0.0, "avg_logprob": -0.23937352498372397, "compression_ratio": 1.6692607003891051,
  "no_speech_prob": 0.03639225661754608}, {"id": 420, "seek": 137948, "start": 1401.56,
  "end": 1408.52, "text": " Okay, well, I don''t have much of a comparison to other
  database vendors.", "tokens": [51468, 1033, 11, 731, 11, 286, 500, 380, 362, 709,
  295, 257, 9660, 281, 661, 8149, 22056, 13, 51816], "temperature": 0.0, "avg_logprob":
  -0.23937352498372397, "compression_ratio": 1.6692607003891051, "no_speech_prob":
  0.03639225661754608}, {"id": 421, "seek": 140852, "start": 1408.52, "end": 1412.76,
  "text": " And so I''m, you know, apologies to everyone out there working on this.",
  "tokens": [50364, 400, 370, 286, 478, 11, 291, 458, 11, 34929, 281, 1518, 484, 456,
  1364, 322, 341, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1736291940661444,
  "compression_ratio": 1.7226027397260273, "no_speech_prob": 0.0009971614927053452},
  {"id": 422, "seek": 140852, "start": 1412.76, "end": 1416.8799999999999, "text":
  " My experience with it doesn''t come from the practical software engineering side
  of it.", "tokens": [50576, 1222, 1752, 365, 309, 1177, 380, 808, 490, 264, 8496,
  4722, 7043, 1252, 295, 309, 13, 50782], "temperature": 0.0, "avg_logprob": -0.1736291940661444,
  "compression_ratio": 1.7226027397260273, "no_speech_prob": 0.0009971614927053452},
  {"id": 423, "seek": 140852, "start": 1416.8799999999999, "end": 1420.6399999999999,
  "text": " It comes from reading these research papers and then being familiar with
  these ideas.", "tokens": [50782, 467, 1487, 490, 3760, 613, 2132, 10577, 293, 550,
  885, 4963, 365, 613, 3487, 13, 50970], "temperature": 0.0, "avg_logprob": -0.1736291940661444,
  "compression_ratio": 1.7226027397260273, "no_speech_prob": 0.0009971614927053452},
  {"id": 424, "seek": 140852, "start": 1420.6399999999999, "end": 1424.6, "text":
  " And then, I mean, V8 is easy to use.", "tokens": [50970, 400, 550, 11, 286, 914,
  11, 691, 23, 307, 1858, 281, 764, 13, 51168], "temperature": 0.0, "avg_logprob":
  -0.1736291940661444, "compression_ratio": 1.7226027397260273, "no_speech_prob":
  0.0009971614927053452}, {"id": 425, "seek": 140852, "start": 1424.6, "end": 1427.56,
  "text": " It''s really well, the documentation is great.", "tokens": [51168, 467,
  311, 534, 731, 11, 264, 14333, 307, 869, 13, 51316], "temperature": 0.0, "avg_logprob":
  -0.1736291940661444, "compression_ratio": 1.7226027397260273, "no_speech_prob":
  0.0009971614927053452}, {"id": 426, "seek": 140852, "start": 1427.56, "end": 1428.84,
  "text": " It''s easy to get started with it.", "tokens": [51316, 467, 311, 1858,
  281, 483, 1409, 365, 309, 13, 51380], "temperature": 0.0, "avg_logprob": -0.1736291940661444,
  "compression_ratio": 1.7226027397260273, "no_speech_prob": 0.0009971614927053452},
  {"id": 427, "seek": 140852, "start": 1428.84, "end": 1433.04, "text": " So that
  was a huge thing for me is, you know, when I first met Bob, first of all, you",
  "tokens": [51380, 407, 300, 390, 257, 2603, 551, 337, 385, 307, 11, 291, 458, 11,
  562, 286, 700, 1131, 6085, 11, 700, 295, 439, 11, 291, 51590], "temperature": 0.0,
  "avg_logprob": -0.1736291940661444, "compression_ratio": 1.7226027397260273, "no_speech_prob":
  0.0009971614927053452}, {"id": 428, "seek": 140852, "start": 1433.04, "end": 1435.96,
  "text": " know, he''s a great guy and, you know, meeting this team.", "tokens":
  [51590, 458, 11, 415, 311, 257, 869, 2146, 293, 11, 291, 458, 11, 3440, 341, 1469,
  13, 51736], "temperature": 0.0, "avg_logprob": -0.1736291940661444, "compression_ratio":
  1.7226027397260273, "no_speech_prob": 0.0009971614927053452}, {"id": 429, "seek":
  143596, "start": 1435.96, "end": 1439.4, "text": " They''re all really on top of
  everything and their slack chat is really great.", "tokens": [50364, 814, 434, 439,
  534, 322, 1192, 295, 1203, 293, 641, 29767, 5081, 307, 534, 869, 13, 50536], "temperature":
  0.0, "avg_logprob": -0.22765669389204546, "compression_ratio": 1.7967479674796747,
  "no_speech_prob": 0.025702012702822685}, {"id": 430, "seek": 143596, "start": 1439.4,
  "end": 1442.52, "text": " People, you know, pitching in their problems and it''s
  just a great community.", "tokens": [50536, 3432, 11, 291, 458, 11, 37499, 294,
  641, 2740, 293, 309, 311, 445, 257, 869, 1768, 13, 50692], "temperature": 0.0, "avg_logprob":
  -0.22765669389204546, "compression_ratio": 1.7967479674796747, "no_speech_prob":
  0.025702012702822685}, {"id": 431, "seek": 143596, "start": 1442.52, "end": 1447.76,
  "text": " But, you know, what, what did it for me is, so I met Bob and then I spent
  about two weeks", "tokens": [50692, 583, 11, 291, 458, 11, 437, 11, 437, 630, 309,
  337, 385, 307, 11, 370, 286, 1131, 6085, 293, 550, 286, 4418, 466, 732, 3259, 50954],
  "temperature": 0.0, "avg_logprob": -0.22765669389204546, "compression_ratio": 1.7967479674796747,
  "no_speech_prob": 0.025702012702822685}, {"id": 432, "seek": 143596, "start": 1447.76,
  "end": 1450.8, "text": " going through their documentation, the quick start, the
  installation set up, you know,", "tokens": [50954, 516, 807, 641, 14333, 11, 264,
  1702, 722, 11, 264, 13260, 992, 493, 11, 291, 458, 11, 51106], "temperature": 0.0,
  "avg_logprob": -0.22765669389204546, "compression_ratio": 1.7967479674796747, "no_speech_prob":
  0.025702012702822685}, {"id": 433, "seek": 143596, "start": 1450.8, "end": 1452.32,
  "text": " get my data sets in there.", "tokens": [51106, 483, 452, 1412, 6352, 294,
  456, 13, 51182], "temperature": 0.0, "avg_logprob": -0.22765669389204546, "compression_ratio":
  1.7967479674796747, "no_speech_prob": 0.025702012702822685}, {"id": 434, "seek":
  143596, "start": 1452.32, "end": 1453.72, "text": " And it''s just really easy to
  use.", "tokens": [51182, 400, 309, 311, 445, 534, 1858, 281, 764, 13, 51252], "temperature":
  0.0, "avg_logprob": -0.22765669389204546, "compression_ratio": 1.7967479674796747,
  "no_speech_prob": 0.025702012702822685}, {"id": 435, "seek": 143596, "start": 1453.72,
  "end": 1456.88, "text": " So I, and then, and then learning about all these other
  things like the Python client.", "tokens": [51252, 407, 286, 11, 293, 550, 11, 293,
  550, 2539, 466, 439, 613, 661, 721, 411, 264, 15329, 6423, 13, 51410], "temperature":
  0.0, "avg_logprob": -0.22765669389204546, "compression_ratio": 1.7967479674796747,
  "no_speech_prob": 0.025702012702822685}, {"id": 436, "seek": 143596, "start": 1456.88,
  "end": 1460.76, "text": " Like as we talk about fetching the context, I mean, we
  want to ingrate that into a training", "tokens": [51410, 1743, 382, 321, 751, 466,
  23673, 278, 264, 4319, 11, 286, 914, 11, 321, 528, 281, 3957, 4404, 300, 666, 257,
  3097, 51604], "temperature": 0.0, "avg_logprob": -0.22765669389204546, "compression_ratio":
  1.7967479674796747, "no_speech_prob": 0.025702012702822685}, {"id": 437, "seek":
  143596, "start": 1460.76, "end": 1465.08, "text": " loop where say Facebook also
  recently released internet augmented generation where they''re", "tokens": [51604,
  6367, 689, 584, 4384, 611, 3938, 4736, 4705, 36155, 5125, 689, 436, 434, 51820],
  "temperature": 0.0, "avg_logprob": -0.22765669389204546, "compression_ratio": 1.7967479674796747,
  "no_speech_prob": 0.025702012702822685}, {"id": 438, "seek": 146508, "start": 1465.08,
  "end": 1469.8, "text": " using the Bing API to bring in the context and then learn
  with that extra training.", "tokens": [50364, 1228, 264, 30755, 9362, 281, 1565,
  294, 264, 4319, 293, 550, 1466, 365, 300, 2857, 3097, 13, 50600], "temperature":
  0.0, "avg_logprob": -0.16515919470017956, "compression_ratio": 1.7560975609756098,
  "no_speech_prob": 0.00039996570558287203}, {"id": 439, "seek": 146508, "start":
  1469.8, "end": 1474.24, "text": " So they have a Python client that lets you integrate
  that into your model workflows.", "tokens": [50600, 407, 436, 362, 257, 15329, 6423,
  300, 6653, 291, 13365, 300, 666, 428, 2316, 43461, 13, 50822], "temperature": 0.0,
  "avg_logprob": -0.16515919470017956, "compression_ratio": 1.7560975609756098, "no_speech_prob":
  0.00039996570558287203}, {"id": 440, "seek": 146508, "start": 1474.24, "end": 1478.28,
  "text": " And then something we talked about in our last podcast, I love the GraphQL
  interface.", "tokens": [50822, 400, 550, 746, 321, 2825, 466, 294, 527, 1036, 7367,
  11, 286, 959, 264, 21884, 13695, 9226, 13, 51024], "temperature": 0.0, "avg_logprob":
  -0.16515919470017956, "compression_ratio": 1.7560975609756098, "no_speech_prob":
  0.00039996570558287203}, {"id": 441, "seek": 146508, "start": 1478.28, "end": 1479.36,
  "text": " I think it''s really cool.", "tokens": [51024, 286, 519, 309, 311, 534,
  1627, 13, 51078], "temperature": 0.0, "avg_logprob": -0.16515919470017956, "compression_ratio":
  1.7560975609756098, "no_speech_prob": 0.00039996570558287203}, {"id": 442, "seek":
  146508, "start": 1479.36, "end": 1481.28, "text": " And I love the web demo.", "tokens":
  [51078, 400, 286, 959, 264, 3670, 10723, 13, 51174], "temperature": 0.0, "avg_logprob":
  -0.16515919470017956, "compression_ratio": 1.7560975609756098, "no_speech_prob":
  0.00039996570558287203}, {"id": 443, "seek": 146508, "start": 1481.28, "end": 1486.08,
  "text": " So you can, you know, get started with the GraphQL interface and you can
  practice your", "tokens": [51174, 407, 291, 393, 11, 291, 458, 11, 483, 1409, 365,
  264, 21884, 13695, 9226, 293, 291, 393, 3124, 428, 51414], "temperature": 0.0, "avg_logprob":
  -0.16515919470017956, "compression_ratio": 1.7560975609756098, "no_speech_prob":
  0.00039996570558287203}, {"id": 444, "seek": 146508, "start": 1486.08, "end": 1491.1599999999999,
  "text": " queries, you know, you know, learn it quickly before you make any commitment
  of installing", "tokens": [51414, 24109, 11, 291, 458, 11, 291, 458, 11, 1466, 309,
  2661, 949, 291, 652, 604, 8371, 295, 20762, 51668], "temperature": 0.0, "avg_logprob":
  -0.16515919470017956, "compression_ratio": 1.7560975609756098, "no_speech_prob":
  0.00039996570558287203}, {"id": 445, "seek": 146508, "start": 1491.1599999999999,
  "end": 1492.96, "text": " your mouse database.", "tokens": [51668, 428, 9719, 8149,
  13, 51758], "temperature": 0.0, "avg_logprob": -0.16515919470017956, "compression_ratio":
  1.7560975609756098, "no_speech_prob": 0.00039996570558287203}, {"id": 446, "seek":
  149296, "start": 1492.96, "end": 1498.8, "text": " So yeah, and I just think we
  be it is like a beautiful technology that''s making my, my", "tokens": [50364, 407,
  1338, 11, 293, 286, 445, 519, 321, 312, 309, 307, 411, 257, 2238, 2899, 300, 311,
  1455, 452, 11, 452, 50656], "temperature": 0.0, "avg_logprob": -0.24151722352896163,
  "compression_ratio": 1.674911660777385, "no_speech_prob": 0.015586864203214645},
  {"id": 447, "seek": 149296, "start": 1498.8, "end": 1501.64, "text": " life is trying
  to do deep learning research just a lot easier.", "tokens": [50656, 993, 307, 1382,
  281, 360, 2452, 2539, 2132, 445, 257, 688, 3571, 13, 50798], "temperature": 0.0,
  "avg_logprob": -0.24151722352896163, "compression_ratio": 1.674911660777385, "no_speech_prob":
  0.015586864203214645}, {"id": 448, "seek": 149296, "start": 1501.64, "end": 1506.1200000000001,
  "text": " So, you know, it''s awesome that they''re willing to support Henry AI
  labs and help me continue", "tokens": [50798, 407, 11, 291, 458, 11, 309, 311, 3476,
  300, 436, 434, 4950, 281, 1406, 11085, 7318, 20339, 293, 854, 385, 2354, 51022],
  "temperature": 0.0, "avg_logprob": -0.24151722352896163, "compression_ratio": 1.674911660777385,
  "no_speech_prob": 0.015586864203214645}, {"id": 449, "seek": 149296, "start": 1506.1200000000001,
  "end": 1507.44, "text": " making content on YouTube.", "tokens": [51022, 1455, 2701,
  322, 3088, 13, 51088], "temperature": 0.0, "avg_logprob": -0.24151722352896163,
  "compression_ratio": 1.674911660777385, "no_speech_prob": 0.015586864203214645},
  {"id": 450, "seek": 149296, "start": 1507.44, "end": 1512.24, "text": " Well, at
  the same time, it''s a, you know, it''s a tool that helps me do what I want to do",
  "tokens": [51088, 1042, 11, 412, 264, 912, 565, 11, 309, 311, 257, 11, 291, 458,
  11, 309, 311, 257, 2290, 300, 3665, 385, 360, 437, 286, 528, 281, 360, 51328], "temperature":
  0.0, "avg_logprob": -0.24151722352896163, "compression_ratio": 1.674911660777385,
  "no_speech_prob": 0.015586864203214645}, {"id": 451, "seek": 149296, "start": 1512.24,
  "end": 1513.8, "text": " with this kind of research.", "tokens": [51328, 365, 341,
  733, 295, 2132, 13, 51406], "temperature": 0.0, "avg_logprob": -0.24151722352896163,
  "compression_ratio": 1.674911660777385, "no_speech_prob": 0.015586864203214645},
  {"id": 452, "seek": 149296, "start": 1513.8, "end": 1514.8, "text": " Yeah.", "tokens":
  [51406, 865, 13, 51456], "temperature": 0.0, "avg_logprob": -0.24151722352896163,
  "compression_ratio": 1.674911660777385, "no_speech_prob": 0.015586864203214645},
  {"id": 453, "seek": 149296, "start": 1514.8, "end": 1519.04, "text": " And are you
  like already using via V8 in your research or planning to use?", "tokens": [51456,
  400, 366, 291, 411, 1217, 1228, 5766, 691, 23, 294, 428, 2132, 420, 5038, 281, 764,
  30, 51668], "temperature": 0.0, "avg_logprob": -0.24151722352896163, "compression_ratio":
  1.674911660777385, "no_speech_prob": 0.015586864203214645}, {"id": 454, "seek":
  149296, "start": 1519.04, "end": 1520.04, "text": " Yeah.", "tokens": [51668, 865,
  13, 51718], "temperature": 0.0, "avg_logprob": -0.24151722352896163, "compression_ratio":
  1.674911660777385, "no_speech_prob": 0.015586864203214645}, {"id": 455, "seek":
  152004, "start": 1520.6399999999999, "end": 1523.68, "text": " So I haven''t really
  made a Henry AI labs video on this yet, but it''s something I''m really", "tokens":
  [50394, 407, 286, 2378, 380, 534, 1027, 257, 11085, 7318, 20339, 960, 322, 341,
  1939, 11, 457, 309, 311, 746, 286, 478, 534, 50546], "temperature": 0.0, "avg_logprob":
  -0.3061877809721848, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.43473872542381287},
  {"id": 456, "seek": 152004, "start": 1523.68, "end": 1524.68, "text": " excited
  about.", "tokens": [50546, 2919, 466, 13, 50596], "temperature": 0.0, "avg_logprob":
  -0.3061877809721848, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.43473872542381287},
  {"id": 457, "seek": 152004, "start": 1524.68, "end": 1531.28, "text": " So one paper
  I recently had accepted in ICML A, not quite ICML, but ICML A, it''s application",
  "tokens": [50596, 407, 472, 3035, 286, 3938, 632, 9035, 294, 14360, 12683, 316,
  11, 406, 1596, 14360, 12683, 11, 457, 14360, 12683, 316, 11, 309, 311, 3861, 50926],
  "temperature": 0.0, "avg_logprob": -0.3061877809721848, "compression_ratio": 1.710344827586207,
  "no_speech_prob": 0.43473872542381287}, {"id": 458, "seek": 152004, "start": 1531.28,
  "end": 1532.28, "text": " to add it to it.", "tokens": [50926, 281, 909, 309, 281,
  309, 13, 50976], "temperature": 0.0, "avg_logprob": -0.3061877809721848, "compression_ratio":
  1.710344827586207, "no_speech_prob": 0.43473872542381287}, {"id": 459, "seek": 152004,
  "start": 1532.28, "end": 1537.12, "text": " But it''s a, it''s a caros, Bert is
  the title of the paper and it''s about, you know, language", "tokens": [50976, 583,
  309, 311, 257, 11, 309, 311, 257, 1032, 329, 11, 29594, 307, 264, 4876, 295, 264,
  3035, 293, 309, 311, 466, 11, 291, 458, 11, 2856, 51218], "temperature": 0.0, "avg_logprob":
  -0.3061877809721848, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.43473872542381287},
  {"id": 460, "seek": 152004, "start": 1537.12, "end": 1541.12, "text": " modeling
  with caros documentation and caros code examples and, you know, like Syek", "tokens":
  [51218, 15983, 365, 1032, 329, 14333, 293, 1032, 329, 3089, 5110, 293, 11, 291,
  458, 11, 411, 3902, 916, 51418], "temperature": 0.0, "avg_logprob": -0.3061877809721848,
  "compression_ratio": 1.710344827586207, "no_speech_prob": 0.43473872542381287},
  {"id": 461, "seek": 152004, "start": 1541.12, "end": 1544.8799999999999, "text":
  " Paul, Franceschal Leigh, they''re going crazy with these caros code examples.",
  "tokens": [51418, 4552, 11, 31441, 339, 304, 1456, 910, 11, 436, 434, 516, 3219,
  365, 613, 1032, 329, 3089, 5110, 13, 51606], "temperature": 0.0, "avg_logprob":
  -0.3061877809721848, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.43473872542381287},
  {"id": 462, "seek": 152004, "start": 1544.8799999999999, "end": 1546.3999999999999,
  "text": " And there''s so many examples.", "tokens": [51606, 400, 456, 311, 370,
  867, 5110, 13, 51682], "temperature": 0.0, "avg_logprob": -0.3061877809721848, "compression_ratio":
  1.710344827586207, "no_speech_prob": 0.43473872542381287}, {"id": 463, "seek": 154640,
  "start": 1546.4, "end": 1551.3600000000001, "text": " Like you could, you have like
  a PhD and more organized completely online on this caros", "tokens": [50364, 1743,
  291, 727, 11, 291, 362, 411, 257, 14476, 293, 544, 9983, 2584, 2950, 322, 341, 1032,
  329, 50612], "temperature": 0.0, "avg_logprob": -0.2208238425829732, "compression_ratio":
  1.863481228668942, "no_speech_prob": 0.024185435846447945}, {"id": 464, "seek":
  154640, "start": 1551.3600000000001, "end": 1552.3600000000001, "text": " code examples
  to me.", "tokens": [50612, 3089, 5110, 281, 385, 13, 50662], "temperature": 0.0,
  "avg_logprob": -0.2208238425829732, "compression_ratio": 1.863481228668942, "no_speech_prob":
  0.024185435846447945}, {"id": 465, "seek": 154640, "start": 1552.3600000000001,
  "end": 1555.96, "text": " It''s like the most interesting collection of deep learning
  information on the internet", "tokens": [50662, 467, 311, 411, 264, 881, 1880, 5765,
  295, 2452, 2539, 1589, 322, 264, 4705, 50842], "temperature": 0.0, "avg_logprob":
  -0.2208238425829732, "compression_ratio": 1.863481228668942, "no_speech_prob": 0.024185435846447945},
  {"id": 466, "seek": 154640, "start": 1555.96, "end": 1557.96, "text": " as the caros
  code examples.", "tokens": [50842, 382, 264, 1032, 329, 3089, 5110, 13, 50942],
  "temperature": 0.0, "avg_logprob": -0.2208238425829732, "compression_ratio": 1.863481228668942,
  "no_speech_prob": 0.024185435846447945}, {"id": 467, "seek": 154640, "start": 1557.96,
  "end": 1561.88, "text": " So from there, there''s like two ideas is like, can we
  build a language model that can", "tokens": [50942, 407, 490, 456, 11, 456, 311,
  411, 732, 3487, 307, 411, 11, 393, 321, 1322, 257, 2856, 2316, 300, 393, 51138],
  "temperature": 0.0, "avg_logprob": -0.2208238425829732, "compression_ratio": 1.863481228668942,
  "no_speech_prob": 0.024185435846447945}, {"id": 468, "seek": 154640, "start": 1561.88,
  "end": 1565.48, "text": " like debug your caros code for you and, you know, open
  AI code X. Everyone knows that", "tokens": [51138, 411, 24083, 428, 1032, 329, 3089,
  337, 291, 293, 11, 291, 458, 11, 1269, 7318, 3089, 1783, 13, 5198, 3255, 300, 51318],
  "temperature": 0.0, "avg_logprob": -0.2208238425829732, "compression_ratio": 1.863481228668942,
  "no_speech_prob": 0.024185435846447945}, {"id": 469, "seek": 154640, "start": 1565.48,
  "end": 1568.2, "text": " it looks like the answer to that is yes.", "tokens": [51318,
  309, 1542, 411, 264, 1867, 281, 300, 307, 2086, 13, 51454], "temperature": 0.0,
  "avg_logprob": -0.2208238425829732, "compression_ratio": 1.863481228668942, "no_speech_prob":
  0.024185435846447945}, {"id": 470, "seek": 154640, "start": 1568.2, "end": 1571.0800000000002,
  "text": " And you know, they have the lead code, they have data sets of like lead
  code.", "tokens": [51454, 400, 291, 458, 11, 436, 362, 264, 1477, 3089, 11, 436,
  362, 1412, 6352, 295, 411, 1477, 3089, 13, 51598], "temperature": 0.0, "avg_logprob":
  -0.2208238425829732, "compression_ratio": 1.863481228668942, "no_speech_prob": 0.024185435846447945},
  {"id": 471, "seek": 154640, "start": 1571.0800000000002, "end": 1573.0800000000002,
  "text": " I know everyone loves lead code.", "tokens": [51598, 286, 458, 1518, 6752,
  1477, 3089, 13, 51698], "temperature": 0.0, "avg_logprob": -0.2208238425829732,
  "compression_ratio": 1.863481228668942, "no_speech_prob": 0.024185435846447945},
  {"id": 472, "seek": 157308, "start": 1573.08, "end": 1576.32, "text": " And everyone
  is looking for a job.", "tokens": [50364, 400, 1518, 307, 1237, 337, 257, 1691,
  13, 50526], "temperature": 0.0, "avg_logprob": -0.2806231490964812, "compression_ratio":
  1.7338709677419355, "no_speech_prob": 0.029828401282429695}, {"id": 473, "seek":
  157308, "start": 1576.32, "end": 1582.12, "text": " Yeah, code X is, you know, able
  to pass these lead code tests.", "tokens": [50526, 865, 11, 3089, 1783, 307, 11,
  291, 458, 11, 1075, 281, 1320, 613, 1477, 3089, 6921, 13, 50816], "temperature":
  0.0, "avg_logprob": -0.2806231490964812, "compression_ratio": 1.7338709677419355,
  "no_speech_prob": 0.029828401282429695}, {"id": 474, "seek": 157308, "start": 1582.12,
  "end": 1585.8, "text": " So, you know, and I, you know, I''d say some lead code
  tests are harder than the deep learning", "tokens": [50816, 407, 11, 291, 458, 11,
  293, 286, 11, 291, 458, 11, 286, 1116, 584, 512, 1477, 3089, 6921, 366, 6081, 813,
  264, 2452, 2539, 51000], "temperature": 0.0, "avg_logprob": -0.2806231490964812,
  "compression_ratio": 1.7338709677419355, "no_speech_prob": 0.029828401282429695},
  {"id": 475, "seek": 157308, "start": 1585.8, "end": 1586.8, "text": " debugging.",
  "tokens": [51000, 45592, 13, 51050], "temperature": 0.0, "avg_logprob": -0.2806231490964812,
  "compression_ratio": 1.7338709677419355, "no_speech_prob": 0.029828401282429695},
  {"id": 476, "seek": 157308, "start": 1586.8, "end": 1591.4399999999998, "text":
  " So, you know, it looks like it looks like a pretty promising solution.", "tokens":
  [51050, 407, 11, 291, 458, 11, 309, 1542, 411, 309, 1542, 411, 257, 1238, 20257,
  3827, 13, 51282], "temperature": 0.0, "avg_logprob": -0.2806231490964812, "compression_ratio":
  1.7338709677419355, "no_speech_prob": 0.029828401282429695}, {"id": 477, "seek":
  157308, "start": 1591.4399999999998, "end": 1595.6, "text": " And so in the second
  project I have that I''m integrating WeeVeate, what to help me", "tokens": [51282,
  400, 370, 294, 264, 1150, 1716, 286, 362, 300, 286, 478, 26889, 492, 68, 53, 68,
  473, 11, 437, 281, 854, 385, 51490], "temperature": 0.0, "avg_logprob": -0.2806231490964812,
  "compression_ratio": 1.7338709677419355, "no_speech_prob": 0.029828401282429695},
  {"id": 478, "seek": 157308, "start": 1595.6, "end": 1600.56, "text": " do is, is,
  you know, Facebook is big on unsupervised machine translation.", "tokens": [51490,
  360, 307, 11, 307, 11, 291, 458, 11, 4384, 307, 955, 322, 2693, 12879, 24420, 3479,
  12853, 13, 51738], "temperature": 0.0, "avg_logprob": -0.2806231490964812, "compression_ratio":
  1.7338709677419355, "no_speech_prob": 0.029828401282429695}, {"id": 479, "seek":
  160056, "start": 1600.56, "end": 1605.76, "text": " They did a paper where they''re
  translating between Python and JavaScript without any annotation.", "tokens": [50364,
  814, 630, 257, 3035, 689, 436, 434, 35030, 1296, 15329, 293, 15778, 1553, 604, 48654,
  13, 50624], "temperature": 0.0, "avg_logprob": -0.21026254918453466, "compression_ratio":
  1.7725752508361203, "no_speech_prob": 0.03237887844443321}, {"id": 480, "seek":
  160056, "start": 1605.76, "end": 1611.6799999999998, "text": " So maybe we can translate
  between caros and PyTorch without needing to, or PyTorch and", "tokens": [50624,
  407, 1310, 321, 393, 13799, 1296, 1032, 329, 293, 9953, 51, 284, 339, 1553, 18006,
  281, 11, 420, 9953, 51, 284, 339, 293, 50920], "temperature": 0.0, "avg_logprob":
  -0.21026254918453466, "compression_ratio": 1.7725752508361203, "no_speech_prob":
  0.03237887844443321}, {"id": 481, "seek": 160056, "start": 1611.6799999999998, "end":
  1615.6399999999999, "text": " Jack''s even to, without, you know, somehow without
  much labeling.", "tokens": [50920, 4718, 311, 754, 281, 11, 1553, 11, 291, 458,
  11, 6063, 1553, 709, 40244, 13, 51118], "temperature": 0.0, "avg_logprob": -0.21026254918453466,
  "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.03237887844443321},
  {"id": 482, "seek": 160056, "start": 1615.6399999999999, "end": 1619.04, "text":
  " And this is very much an infant research project.", "tokens": [51118, 400, 341,
  307, 588, 709, 364, 16757, 2132, 1716, 13, 51288], "temperature": 0.0, "avg_logprob":
  -0.21026254918453466, "compression_ratio": 1.7725752508361203, "no_speech_prob":
  0.03237887844443321}, {"id": 483, "seek": 160056, "start": 1619.04, "end": 1623.1599999999999,
  "text": " But if you have that, if you could bring the caros code examples to PyTorch
  and Jack''s", "tokens": [51288, 583, 498, 291, 362, 300, 11, 498, 291, 727, 1565,
  264, 1032, 329, 3089, 5110, 281, 9953, 51, 284, 339, 293, 4718, 311, 51494], "temperature":
  0.0, "avg_logprob": -0.21026254918453466, "compression_ratio": 1.7725752508361203,
  "no_speech_prob": 0.03237887844443321}, {"id": 484, "seek": 160056, "start": 1623.1599999999999,
  "end": 1626.32, "text": " and just, you know, help people share this knowledge.",
  "tokens": [51494, 293, 445, 11, 291, 458, 11, 854, 561, 2073, 341, 3601, 13, 51652],
  "temperature": 0.0, "avg_logprob": -0.21026254918453466, "compression_ratio": 1.7725752508361203,
  "no_speech_prob": 0.03237887844443321}, {"id": 485, "seek": 160056, "start": 1626.32,
  "end": 1630.44, "text": " So, so this is like two of my personal projects that I''ve
  started integrating WeeVeate in", "tokens": [51652, 407, 11, 370, 341, 307, 411,
  732, 295, 452, 2973, 4455, 300, 286, 600, 1409, 26889, 492, 68, 53, 68, 473, 294,
  51858], "temperature": 0.0, "avg_logprob": -0.21026254918453466, "compression_ratio":
  1.7725752508361203, "no_speech_prob": 0.03237887844443321}, {"id": 486, "seek":
  163044, "start": 1630.44, "end": 1634.0800000000002, "text": " and then one of the
  project that I''m, you know, extremely passionate about and really", "tokens": [50364,
  293, 550, 472, 295, 264, 1716, 300, 286, 478, 11, 291, 458, 11, 4664, 11410, 466,
  293, 534, 50546], "temperature": 0.0, "avg_logprob": -0.21051079322551858, "compression_ratio":
  1.723127035830619, "no_speech_prob": 0.0003647717530839145}, {"id": 487, "seek":
  163044, "start": 1634.0800000000002, "end": 1637.0, "text": " into with my involvement
  with the university.", "tokens": [50546, 666, 365, 452, 17447, 365, 264, 5454, 13,
  50692], "temperature": 0.0, "avg_logprob": -0.21051079322551858, "compression_ratio":
  1.723127035830619, "no_speech_prob": 0.0003647717530839145}, {"id": 488, "seek":
  163044, "start": 1637.0, "end": 1641.4, "text": " And this is kind of a separate
  thing that I''m not too heavy on because I don''t want to", "tokens": [50692, 400,
  341, 307, 733, 295, 257, 4994, 551, 300, 286, 478, 406, 886, 4676, 322, 570, 286,
  500, 380, 528, 281, 50912], "temperature": 0.0, "avg_logprob": -0.21051079322551858,
  "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0003647717530839145},
  {"id": 489, "seek": 163044, "start": 1641.4, "end": 1643.6000000000001, "text":
  " like kind of push the commercial interest too much.", "tokens": [50912, 411, 733,
  295, 2944, 264, 6841, 1179, 886, 709, 13, 51022], "temperature": 0.0, "avg_logprob":
  -0.21051079322551858, "compression_ratio": 1.723127035830619, "no_speech_prob":
  0.0003647717530839145}, {"id": 490, "seek": 163044, "start": 1643.6000000000001,
  "end": 1645.76, "text": " It''s, you know, and WeeVeate is open source.", "tokens":
  [51022, 467, 311, 11, 291, 458, 11, 293, 492, 68, 53, 68, 473, 307, 1269, 4009,
  13, 51130], "temperature": 0.0, "avg_logprob": -0.21051079322551858, "compression_ratio":
  1.723127035830619, "no_speech_prob": 0.0003647717530839145}, {"id": 491, "seek":
  163044, "start": 1645.76, "end": 1647.3600000000001, "text": " So it''s an open
  source software.", "tokens": [51130, 407, 309, 311, 364, 1269, 4009, 4722, 13, 51210],
  "temperature": 0.0, "avg_logprob": -0.21051079322551858, "compression_ratio": 1.723127035830619,
  "no_speech_prob": 0.0003647717530839145}, {"id": 492, "seek": 163044, "start": 1647.3600000000001,
  "end": 1650.0800000000002, "text": " We have, we can download it from GitHub and
  we have it.", "tokens": [51210, 492, 362, 11, 321, 393, 5484, 309, 490, 23331, 293,
  321, 362, 309, 13, 51346], "temperature": 0.0, "avg_logprob": -0.21051079322551858,
  "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0003647717530839145},
  {"id": 493, "seek": 163044, "start": 1650.0800000000002, "end": 1652.4, "text":
  " So they can''t, you know, take it away.", "tokens": [51346, 407, 436, 393, 380,
  11, 291, 458, 11, 747, 309, 1314, 13, 51462], "temperature": 0.0, "avg_logprob":
  -0.21051079322551858, "compression_ratio": 1.723127035830619, "no_speech_prob":
  0.0003647717530839145}, {"id": 494, "seek": 163044, "start": 1652.4, "end": 1657.76,
  "text": " And so, so this other project is, we''re trying to build patient information
  retrieval", "tokens": [51462, 400, 370, 11, 370, 341, 661, 1716, 307, 11, 321, 434,
  1382, 281, 1322, 4537, 1589, 19817, 3337, 51730], "temperature": 0.0, "avg_logprob":
  -0.21051079322551858, "compression_ratio": 1.723127035830619, "no_speech_prob":
  0.0003647717530839145}, {"id": 495, "seek": 165776, "start": 1657.76, "end": 1663.08,
  "text": " systems where you, you know, you come to the hospital and they start to
  record your, you", "tokens": [50364, 3652, 689, 291, 11, 291, 458, 11, 291, 808,
  281, 264, 4530, 293, 436, 722, 281, 2136, 428, 11, 291, 50630], "temperature": 0.0,
  "avg_logprob": -0.32687178654457205, "compression_ratio": 1.7233333333333334, "no_speech_prob":
  0.07071597874164581}, {"id": 496, "seek": 165776, "start": 1663.08, "end": 1668.24,
  "text": " know, coagulation studies, they, all the physiological markers and the
  genetic history.", "tokens": [50630, 458, 11, 598, 559, 2776, 5313, 11, 436, 11,
  439, 264, 41234, 19175, 293, 264, 12462, 2503, 13, 50888], "temperature": 0.0, "avg_logprob":
  -0.32687178654457205, "compression_ratio": 1.7233333333333334, "no_speech_prob":
  0.07071597874164581}, {"id": 497, "seek": 165776, "start": 1668.24, "end": 1670.04,
  "text": " And we want to go query the literature maybe.", "tokens": [50888, 400,
  321, 528, 281, 352, 14581, 264, 10394, 1310, 13, 50978], "temperature": 0.0, "avg_logprob":
  -0.32687178654457205, "compression_ratio": 1.7233333333333334, "no_speech_prob":
  0.07071597874164581}, {"id": 498, "seek": 165776, "start": 1670.04, "end": 1674.84,
  "text": " So this is, you know, as a research project and the on Institute has been
  pioneering this", "tokens": [50978, 407, 341, 307, 11, 291, 458, 11, 382, 257, 2132,
  1716, 293, 264, 322, 9446, 575, 668, 19761, 1794, 341, 51218], "temperature": 0.0,
  "avg_logprob": -0.32687178654457205, "compression_ratio": 1.7233333333333334, "no_speech_prob":
  0.07071597874164581}, {"id": 499, "seek": 165776, "start": 1674.84, "end": 1679.28,
  "text": " with data sets like core 19 and their system called sub.ai.", "tokens":
  [51218, 365, 1412, 6352, 411, 4965, 1294, 293, 641, 1185, 1219, 1422, 13, 1301,
  13, 51440], "temperature": 0.0, "avg_logprob": -0.32687178654457205, "compression_ratio":
  1.7233333333333334, "no_speech_prob": 0.07071597874164581}, {"id": 500, "seek":
  165776, "start": 1679.28, "end": 1681.72, "text": " Salesforce research had a system
  called co-search.", "tokens": [51440, 40398, 2132, 632, 257, 1185, 1219, 598, 12,
  405, 1178, 13, 51562], "temperature": 0.0, "avg_logprob": -0.32687178654457205,
  "compression_ratio": 1.7233333333333334, "no_speech_prob": 0.07071597874164581},
  {"id": 501, "seek": 165776, "start": 1681.72, "end": 1683.32, "text": " I''m just
  kind of naming things for people.", "tokens": [51562, 286, 478, 445, 733, 295, 25290,
  721, 337, 561, 13, 51642], "temperature": 0.0, "avg_logprob": -0.32687178654457205,
  "compression_ratio": 1.7233333333333334, "no_speech_prob": 0.07071597874164581},
  {"id": 502, "seek": 165776, "start": 1683.32, "end": 1685.8, "text": " Oh my god,
  I''m not going to describe these things.", "tokens": [51642, 876, 452, 3044, 11,
  286, 478, 406, 516, 281, 6786, 613, 721, 13, 51766], "temperature": 0.0, "avg_logprob":
  -0.32687178654457205, "compression_ratio": 1.7233333333333334, "no_speech_prob":
  0.07071597874164581}, {"id": 503, "seek": 168580, "start": 1685.9199999999998, "end":
  1689.96, "text": " So these are like literature scientific literature mining systems
  where you, you know,", "tokens": [50370, 407, 613, 366, 411, 10394, 8134, 10394,
  15512, 3652, 689, 291, 11, 291, 458, 11, 50572], "temperature": 0.0, "avg_logprob":
  -0.24364545004708427, "compression_ratio": 1.797583081570997, "no_speech_prob":
  0.005606834311038256}, {"id": 504, "seek": 168580, "start": 1689.96, "end": 1694.76,
  "text": " you want information about say COVID-19 and or, you know, someone''s coming
  in there", "tokens": [50572, 291, 528, 1589, 466, 584, 4566, 12, 3405, 293, 420,
  11, 291, 458, 11, 1580, 311, 1348, 294, 456, 50812], "temperature": 0.0, "avg_logprob":
  -0.24364545004708427, "compression_ratio": 1.797583081570997, "no_speech_prob":
  0.005606834311038256}, {"id": 505, "seek": 168580, "start": 1694.76, "end": 1697.76,
  "text": " with some obscure disease, you want to be able to query the literature
  with particular", "tokens": [50812, 365, 512, 34443, 4752, 11, 291, 528, 281, 312,
  1075, 281, 14581, 264, 10394, 365, 1729, 50962], "temperature": 0.0, "avg_logprob":
  -0.24364545004708427, "compression_ratio": 1.797583081570997, "no_speech_prob":
  0.005606834311038256}, {"id": 506, "seek": 168580, "start": 1697.76, "end": 1699.0,
  "text": " information about this patient.", "tokens": [50962, 1589, 466, 341, 4537,
  13, 51024], "temperature": 0.0, "avg_logprob": -0.24364545004708427, "compression_ratio":
  1.797583081570997, "no_speech_prob": 0.005606834311038256}, {"id": 507, "seek":
  168580, "start": 1699.0, "end": 1702.1599999999999, "text": " And so this is the
  information retrieval problem that, you know, we''re super interested", "tokens":
  [51024, 400, 370, 341, 307, 264, 1589, 19817, 3337, 1154, 300, 11, 291, 458, 11,
  321, 434, 1687, 3102, 51182], "temperature": 0.0, "avg_logprob": -0.24364545004708427,
  "compression_ratio": 1.797583081570997, "no_speech_prob": 0.005606834311038256},
  {"id": 508, "seek": 168580, "start": 1702.1599999999999, "end": 1703.84, "text":
  " in as spectrature search engine people.", "tokens": [51182, 294, 382, 6177, 81,
  1503, 3164, 2848, 561, 13, 51266], "temperature": 0.0, "avg_logprob": -0.24364545004708427,
  "compression_ratio": 1.797583081570997, "no_speech_prob": 0.005606834311038256},
  {"id": 509, "seek": 168580, "start": 1703.84, "end": 1709.44, "text": " So we''re
  trying to turn these patients into, which is what I have is mostly tabular data.",
  "tokens": [51266, 407, 321, 434, 1382, 281, 1261, 613, 4209, 666, 11, 597, 307,
  437, 286, 362, 307, 5240, 4421, 1040, 1412, 13, 51546], "temperature": 0.0, "avg_logprob":
  -0.24364545004708427, "compression_ratio": 1.797583081570997, "no_speech_prob":
  0.005606834311038256}, {"id": 510, "seek": 168580, "start": 1709.44, "end": 1713.96,
  "text": " You might get a little bit of medical images, some clinical reports for
  some text, but,", "tokens": [51546, 509, 1062, 483, 257, 707, 857, 295, 4625, 5267,
  11, 512, 9115, 7122, 337, 512, 2487, 11, 457, 11, 51772], "temperature": 0.0, "avg_logprob":
  -0.24364545004708427, "compression_ratio": 1.797583081570997, "no_speech_prob":
  0.005606834311038256}, {"id": 511, "seek": 171396, "start": 1714.64, "end": 1715.76,
  "text": " yeah, mostly tabular data.", "tokens": [50398, 1338, 11, 5240, 4421, 1040,
  1412, 13, 50454], "temperature": 0.0, "avg_logprob": -0.21258800617162732, "compression_ratio":
  1.679245283018868, "no_speech_prob": 0.007347135804593563}, {"id": 512, "seek":
  171396, "start": 1715.76, "end": 1720.16, "text": " So we want to encode that into
  vectors, send those vectors into the scientific literature,", "tokens": [50454,
  407, 321, 528, 281, 2058, 1429, 300, 666, 18875, 11, 2845, 729, 18875, 666, 264,
  8134, 10394, 11, 50674], "temperature": 0.0, "avg_logprob": -0.21258800617162732,
  "compression_ratio": 1.679245283018868, "no_speech_prob": 0.007347135804593563},
  {"id": 513, "seek": 171396, "start": 1720.16, "end": 1724.8, "text": " and then
  maybe there''s some clinical trial, you know, because it''s so much data.", "tokens":
  [50674, 293, 550, 1310, 456, 311, 512, 9115, 7308, 11, 291, 458, 11, 570, 309, 311,
  370, 709, 1412, 13, 50906], "temperature": 0.0, "avg_logprob": -0.21258800617162732,
  "compression_ratio": 1.679245283018868, "no_speech_prob": 0.007347135804593563},
  {"id": 514, "seek": 171396, "start": 1724.8, "end": 1728.96, "text": " Once you
  really download, like say the core 19 data set from the on Institute,", "tokens":
  [50906, 3443, 291, 534, 5484, 11, 411, 584, 264, 4965, 1294, 1412, 992, 490, 264,
  322, 9446, 11, 51114], "temperature": 0.0, "avg_logprob": -0.21258800617162732,
  "compression_ratio": 1.679245283018868, "no_speech_prob": 0.007347135804593563},
  {"id": 515, "seek": 171396, "start": 1728.96, "end": 1734.48, "text": " you''ll
  realize that, you know, 500,000 papers about COVID is nothing anyone could read.",
  "tokens": [51114, 291, 603, 4325, 300, 11, 291, 458, 11, 5923, 11, 1360, 10577,
  466, 4566, 307, 1825, 2878, 727, 1401, 13, 51390], "temperature": 0.0, "avg_logprob":
  -0.21258800617162732, "compression_ratio": 1.679245283018868, "no_speech_prob":
  0.007347135804593563}, {"id": 516, "seek": 171396, "start": 1734.48, "end": 1737.52,
  "text": " You know, I already know this from reading deep learning papers.", "tokens":
  [51390, 509, 458, 11, 286, 1217, 458, 341, 490, 3760, 2452, 2539, 10577, 13, 51542],
  "temperature": 0.0, "avg_logprob": -0.21258800617162732, "compression_ratio": 1.679245283018868,
  "no_speech_prob": 0.007347135804593563}, {"id": 517, "seek": 171396, "start": 1737.52,
  "end": 1739.24, "text": " It''s like no one can read this.", "tokens": [51542, 467,
  311, 411, 572, 472, 393, 1401, 341, 13, 51628], "temperature": 0.0, "avg_logprob":
  -0.21258800617162732, "compression_ratio": 1.679245283018868, "no_speech_prob":
  0.007347135804593563}, {"id": 518, "seek": 171396, "start": 1739.24, "end": 1743.2,
  "text": " And even like, if you go traditional way, and I wanted those at the top",
  "tokens": [51628, 400, 754, 411, 11, 498, 291, 352, 5164, 636, 11, 293, 286, 1415,
  729, 412, 264, 1192, 51826], "temperature": 0.0, "avg_logprob": -0.21258800617162732,
  "compression_ratio": 1.679245283018868, "no_speech_prob": 0.007347135804593563},
  {"id": 519, "seek": 174320, "start": 1743.24, "end": 1748.1200000000001, "text":
  " in, in this area, you know, like if you go traditional way, let''s say you have
  a keyword look up,", "tokens": [50366, 294, 11, 294, 341, 1859, 11, 291, 458, 11,
  411, 498, 291, 352, 5164, 636, 11, 718, 311, 584, 291, 362, 257, 20428, 574, 493,
  11, 50610], "temperature": 0.0, "avg_logprob": -0.22133786538067987, "compression_ratio":
  1.775438596491228, "no_speech_prob": 0.003284771926701069}, {"id": 520, "seek":
  174320, "start": 1748.1200000000001, "end": 1752.68, "text": " right? So keyword
  search, you would have to build like some kind of synonym layer,", "tokens": [50610,
  558, 30, 407, 20428, 3164, 11, 291, 576, 362, 281, 1322, 411, 512, 733, 295, 5451,
  12732, 4583, 11, 50838], "temperature": 0.0, "avg_logprob": -0.22133786538067987,
  "compression_ratio": 1.775438596491228, "no_speech_prob": 0.003284771926701069},
  {"id": 521, "seek": 174320, "start": 1752.68, "end": 1757.76, "text": " which means
  you need to understand what you''re doing, or you will need to hire somebody to
  do that.", "tokens": [50838, 597, 1355, 291, 643, 281, 1223, 437, 291, 434, 884,
  11, 420, 291, 486, 643, 281, 11158, 2618, 281, 360, 300, 13, 51092], "temperature":
  0.0, "avg_logprob": -0.22133786538067987, "compression_ratio": 1.775438596491228,
  "no_speech_prob": 0.003284771926701069}, {"id": 522, "seek": 174320, "start": 1757.76,
  "end": 1762.92, "text": " And that''s like an additional step, which kind of like,
  you know, doesn''t reduce the journey", "tokens": [51092, 400, 300, 311, 411, 364,
  4497, 1823, 11, 597, 733, 295, 411, 11, 291, 458, 11, 1177, 380, 5407, 264, 4671,
  51350], "temperature": 0.0, "avg_logprob": -0.22133786538067987, "compression_ratio":
  1.775438596491228, "no_speech_prob": 0.003284771926701069}, {"id": 523, "seek":
  174320, "start": 1762.92, "end": 1768.4, "text": " for you. You have to do that
  and this is that you feel like you have more control, maybe,", "tokens": [51350,
  337, 291, 13, 509, 362, 281, 360, 300, 293, 341, 307, 300, 291, 841, 411, 291, 362,
  544, 1969, 11, 1310, 11, 51624], "temperature": 0.0, "avg_logprob": -0.22133786538067987,
  "compression_ratio": 1.775438596491228, "no_speech_prob": 0.003284771926701069},
  {"id": 524, "seek": 174320, "start": 1768.4, "end": 1770.8400000000001, "text":
  " but at the same time, it''s very laborious.", "tokens": [51624, 457, 412, 264,
  912, 565, 11, 309, 311, 588, 5938, 851, 13, 51746], "temperature": 0.0, "avg_logprob":
  -0.22133786538067987, "compression_ratio": 1.775438596491228, "no_speech_prob":
  0.003284771926701069}, {"id": 525, "seek": 177084, "start": 1770.9599999999998,
  "end": 1775.1599999999999, "text": " So at the same time, similarity search kind
  of doesn''t have that boundary, right?", "tokens": [50370, 407, 412, 264, 912, 565,
  11, 32194, 3164, 733, 295, 1177, 380, 362, 300, 12866, 11, 558, 30, 50580], "temperature":
  0.0, "avg_logprob": -0.20636556662765204, "compression_ratio": 1.78125, "no_speech_prob":
  0.00159863056614995}, {"id": 526, "seek": 177084, "start": 1775.1599999999999, "end":
  1780.32, "text": " So essentially you haven''t coded it and now you, you know, now
  that the challenge,", "tokens": [50580, 407, 4476, 291, 2378, 380, 34874, 309, 293,
  586, 291, 11, 291, 458, 11, 586, 300, 264, 3430, 11, 50838], "temperature": 0.0,
  "avg_logprob": -0.20636556662765204, "compression_ratio": 1.78125, "no_speech_prob":
  0.00159863056614995}, {"id": 527, "seek": 177084, "start": 1780.32, "end": 1784.3999999999999,
  "text": " the complexity moves more into the space of choosing the right neural
  network", "tokens": [50838, 264, 14024, 6067, 544, 666, 264, 1901, 295, 10875, 264,
  558, 18161, 3209, 51042], "temperature": 0.0, "avg_logprob": -0.20636556662765204,
  "compression_ratio": 1.78125, "no_speech_prob": 0.00159863056614995}, {"id": 528,
  "seek": 177084, "start": 1784.3999999999999, "end": 1787.04, "text": " and then
  choosing the right database.", "tokens": [51042, 293, 550, 10875, 264, 558, 8149,
  13, 51174], "temperature": 0.0, "avg_logprob": -0.20636556662765204, "compression_ratio":
  1.78125, "no_speech_prob": 0.00159863056614995}, {"id": 529, "seek": 177084, "start":
  1787.04, "end": 1790.08, "text": " Everyone knows which is the right database.",
  "tokens": [51174, 5198, 3255, 597, 307, 264, 558, 8149, 13, 51326], "temperature":
  0.0, "avg_logprob": -0.20636556662765204, "compression_ratio": 1.78125, "no_speech_prob":
  0.00159863056614995}, {"id": 530, "seek": 177084, "start": 1790.08, "end": 1795.08,
  "text": " So, but anyway, but I''m just saying, like, but, but I''m just saying,
  like,", "tokens": [51326, 407, 11, 457, 4033, 11, 457, 286, 478, 445, 1566, 11,
  411, 11, 457, 11, 457, 286, 478, 445, 1566, 11, 411, 11, 51576], "temperature":
  0.0, "avg_logprob": -0.20636556662765204, "compression_ratio": 1.78125, "no_speech_prob":
  0.00159863056614995}, {"id": 531, "seek": 179508, "start": 1795.12, "end": 1801.6799999999998,
  "text": " do you think that similarity search will completely supersede keyword",
  "tokens": [50366, 360, 291, 519, 300, 32194, 3164, 486, 2584, 37906, 4858, 20428,
  50694], "temperature": 0.0, "avg_logprob": -0.24039471274928043, "compression_ratio":
  1.5739910313901346, "no_speech_prob": 0.003325967350974679}, {"id": 532, "seek":
  179508, "start": 1801.6799999999998, "end": 1804.56, "text": " or you still see
  some synergy between them?", "tokens": [50694, 420, 291, 920, 536, 512, 50163, 1296,
  552, 30, 50838], "temperature": 0.0, "avg_logprob": -0.24039471274928043, "compression_ratio":
  1.5739910313901346, "no_speech_prob": 0.003325967350974679}, {"id": 533, "seek":
  179508, "start": 1807.12, "end": 1812.08, "text": " Yeah. And well, I like, before
  I get into saying my opinion on this,", "tokens": [50966, 865, 13, 400, 731, 11,
  286, 411, 11, 949, 286, 483, 666, 1566, 452, 4800, 322, 341, 11, 51214], "temperature":
  0.0, "avg_logprob": -0.24039471274928043, "compression_ratio": 1.5739910313901346,
  "no_speech_prob": 0.003325967350974679}, {"id": 534, "seek": 179508, "start": 1812.08,
  "end": 1814.24, "text": " I''d say that I''m not the expert on keyword search.",
  "tokens": [51214, 286, 1116, 584, 300, 286, 478, 406, 264, 5844, 322, 20428, 3164,
  13, 51322], "temperature": 0.0, "avg_logprob": -0.24039471274928043, "compression_ratio":
  1.5739910313901346, "no_speech_prob": 0.003325967350974679}, {"id": 535, "seek":
  179508, "start": 1814.24, "end": 1816.1999999999998, "text": " So, so here''s my
  opinion on it.", "tokens": [51322, 407, 11, 370, 510, 311, 452, 4800, 322, 309,
  13, 51420], "temperature": 0.0, "avg_logprob": -0.24039471274928043, "compression_ratio":
  1.5739910313901346, "no_speech_prob": 0.003325967350974679}, {"id": 536, "seek":
  179508, "start": 1816.1999999999998, "end": 1821.08, "text": " I, you know, we V8
  has a symbolic filtering where you can still do symbolic searches.", "tokens": [51420,
  286, 11, 291, 458, 11, 321, 691, 23, 575, 257, 25755, 30822, 689, 291, 393, 920,
  360, 25755, 26701, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24039471274928043,
  "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.003325967350974679},
  {"id": 537, "seek": 182108, "start": 1821.08, "end": 1822.6399999999999, "text":
  " You can still do the keyword filtering.", "tokens": [50364, 509, 393, 920, 360,
  264, 20428, 30822, 13, 50442], "temperature": 0.0, "avg_logprob": -0.19698003927866617,
  "compression_ratio": 1.7846153846153847, "no_speech_prob": 0.0011335811577737331},
  {"id": 538, "seek": 182108, "start": 1822.6399999999999, "end": 1825.6799999999998,
  "text": " You can still have these symbolic characteristics.", "tokens": [50442,
  509, 393, 920, 362, 613, 25755, 10891, 13, 50594], "temperature": 0.0, "avg_logprob":
  -0.19698003927866617, "compression_ratio": 1.7846153846153847, "no_speech_prob":
  0.0011335811577737331}, {"id": 539, "seek": 182108, "start": 1825.6799999999998,
  "end": 1829.4399999999998, "text": " And, you know, I''m in the same, I believe
  things like what Gary Marcus talks about,", "tokens": [50594, 400, 11, 291, 458,
  11, 286, 478, 294, 264, 912, 11, 286, 1697, 721, 411, 437, 13788, 26574, 6686, 466,
  11, 50782], "temperature": 0.0, "avg_logprob": -0.19698003927866617, "compression_ratio":
  1.7846153846153847, "no_speech_prob": 0.0011335811577737331}, {"id": 540, "seek":
  182108, "start": 1829.4399999999998, "end": 1832.1999999999998, "text": " about,
  you know, it''s not really robust to these symbolic queries.", "tokens": [50782,
  466, 11, 291, 458, 11, 309, 311, 406, 534, 13956, 281, 613, 25755, 24109, 13, 50920],
  "temperature": 0.0, "avg_logprob": -0.19698003927866617, "compression_ratio": 1.7846153846153847,
  "no_speech_prob": 0.0011335811577737331}, {"id": 541, "seek": 182108, "start": 1832.1999999999998,
  "end": 1836.32, "text": " What we mentioned earlier, where you insert negation and
  it might completely throw it off.", "tokens": [50920, 708, 321, 2835, 3071, 11,
  689, 291, 8969, 2485, 399, 293, 309, 1062, 2584, 3507, 309, 766, 13, 51126], "temperature":
  0.0, "avg_logprob": -0.19698003927866617, "compression_ratio": 1.7846153846153847,
  "no_speech_prob": 0.0011335811577737331}, {"id": 542, "seek": 182108, "start": 1836.32,
  "end": 1840.28, "text": " So robustness is like not completely solved that.", "tokens":
  [51126, 407, 13956, 1287, 307, 411, 406, 2584, 13041, 300, 13, 51324], "temperature":
  0.0, "avg_logprob": -0.19698003927866617, "compression_ratio": 1.7846153846153847,
  "no_speech_prob": 0.0011335811577737331}, {"id": 543, "seek": 182108, "start": 1840.28,
  "end": 1844.04, "text": " I was reading a paper this morning called from DeepMind
  Researcher''s data augmentation", "tokens": [51324, 286, 390, 3760, 257, 3035, 341,
  2446, 1219, 490, 14895, 44, 471, 10303, 260, 311, 1412, 14501, 19631, 51512], "temperature":
  0.0, "avg_logprob": -0.19698003927866617, "compression_ratio": 1.7846153846153847,
  "no_speech_prob": 0.0011335811577737331}, {"id": 544, "seek": 182108, "start": 1844.04,
  "end": 1845.08, "text": " can help robustness.", "tokens": [51512, 393, 854, 13956,
  1287, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19698003927866617, "compression_ratio":
  1.7846153846153847, "no_speech_prob": 0.0011335811577737331}, {"id": 545, "seek":
  182108, "start": 1845.08, "end": 1849.4399999999998, "text": " It was like such
  a on the nose title, like that, like data augmentation helps robustness.", "tokens":
  [51564, 467, 390, 411, 1270, 257, 322, 264, 6690, 4876, 11, 411, 300, 11, 411, 1412,
  14501, 19631, 3665, 13956, 1287, 13, 51782], "temperature": 0.0, "avg_logprob":
  -0.19698003927866617, "compression_ratio": 1.7846153846153847, "no_speech_prob":
  0.0011335811577737331}, {"id": 546, "seek": 184944, "start": 1849.44, "end": 1851.28,
  "text": " So, so yeah, solving robustness.", "tokens": [50364, 407, 11, 370, 1338,
  11, 12606, 13956, 1287, 13, 50456], "temperature": 0.0, "avg_logprob": -0.2322935042842742,
  "compression_ratio": 1.8410596026490067, "no_speech_prob": 0.0035861677024513483},
  {"id": 547, "seek": 184944, "start": 1851.28, "end": 1855.56, "text": " And I''m,
  you know, I saw a, I''m not like, I still think solving robustness is a huge issue
  for this.", "tokens": [50456, 400, 286, 478, 11, 291, 458, 11, 286, 1866, 257, 11,
  286, 478, 406, 411, 11, 286, 920, 519, 12606, 13956, 1287, 307, 257, 2603, 2734,
  337, 341, 13, 50670], "temperature": 0.0, "avg_logprob": -0.2322935042842742, "compression_ratio":
  1.8410596026490067, "no_speech_prob": 0.0035861677024513483}, {"id": 548, "seek":
  184944, "start": 1855.56, "end": 1858.6000000000001, "text": " It''s not completely
  put together yet.", "tokens": [50670, 467, 311, 406, 2584, 829, 1214, 1939, 13,
  50822], "temperature": 0.0, "avg_logprob": -0.2322935042842742, "compression_ratio":
  1.8410596026490067, "no_speech_prob": 0.0035861677024513483}, {"id": 549, "seek":
  184944, "start": 1858.6000000000001, "end": 1860.04, "text": " Yeah, absolutely.
  I agree. I agree.", "tokens": [50822, 865, 11, 3122, 13, 286, 3986, 13, 286, 3986,
  13, 50894], "temperature": 0.0, "avg_logprob": -0.2322935042842742, "compression_ratio":
  1.8410596026490067, "no_speech_prob": 0.0035861677024513483}, {"id": 550, "seek":
  184944, "start": 1860.04, "end": 1863.48, "text": " So, but like, yeah, you mentioned
  you are not an expert on keyword search,", "tokens": [50894, 407, 11, 457, 411,
  11, 1338, 11, 291, 2835, 291, 366, 406, 364, 5844, 322, 20428, 3164, 11, 51066],
  "temperature": 0.0, "avg_logprob": -0.2322935042842742, "compression_ratio": 1.8410596026490067,
  "no_speech_prob": 0.0035861677024513483}, {"id": 551, "seek": 184944, "start": 1863.48,
  "end": 1866.8, "text": " but at the same time, I think you were the expert of using
  like Google, right?", "tokens": [51066, 457, 412, 264, 912, 565, 11, 286, 519, 291,
  645, 264, 5844, 295, 1228, 411, 3329, 11, 558, 30, 51232], "temperature": 0.0, "avg_logprob":
  -0.2322935042842742, "compression_ratio": 1.8410596026490067, "no_speech_prob":
  0.0035861677024513483}, {"id": 552, "seek": 184944, "start": 1866.8, "end": 1868.64,
  "text": " So like you still type keywords.", "tokens": [51232, 407, 411, 291, 920,
  2010, 21009, 13, 51324], "temperature": 0.0, "avg_logprob": -0.2322935042842742,
  "compression_ratio": 1.8410596026490067, "no_speech_prob": 0.0035861677024513483},
  {"id": 553, "seek": 184944, "start": 1868.64, "end": 1871.64, "text": " And, and
  I think psychologically, you still expect, you know,", "tokens": [51324, 400, 11,
  293, 286, 519, 41387, 11, 291, 920, 2066, 11, 291, 458, 11, 51474], "temperature":
  0.0, "avg_logprob": -0.2322935042842742, "compression_ratio": 1.8410596026490067,
  "no_speech_prob": 0.0035861677024513483}, {"id": 554, "seek": 184944, "start": 1871.64,
  "end": 1877.8, "text": " the snippets to contain some of your keywords as a validation
  that the search engine got it, right?", "tokens": [51474, 264, 35623, 1385, 281,
  5304, 512, 295, 428, 21009, 382, 257, 24071, 300, 264, 3164, 2848, 658, 309, 11,
  558, 30, 51782], "temperature": 0.0, "avg_logprob": -0.2322935042842742, "compression_ratio":
  1.8410596026490067, "no_speech_prob": 0.0035861677024513483}, {"id": 555, "seek":
  187780, "start": 1877.8, "end": 1883.8, "text": " So like otherwise, search engine
  maybe that just, you know, returns you garbage in return to what you want.", "tokens":
  [50364, 407, 411, 5911, 11, 3164, 2848, 1310, 300, 445, 11, 291, 458, 11, 11247,
  291, 14150, 294, 2736, 281, 437, 291, 528, 13, 50664], "temperature": 0.0, "avg_logprob":
  -0.2674149685218686, "compression_ratio": 1.7534722222222223, "no_speech_prob":
  0.004555961582809687}, {"id": 556, "seek": 187780, "start": 1883.8, "end": 1889.0,
  "text": " Yeah, and that''s why I think like like the page rank, transition dynamic
  matrices,", "tokens": [50664, 865, 11, 293, 300, 311, 983, 286, 519, 411, 411, 264,
  3028, 6181, 11, 6034, 8546, 32284, 11, 50924], "temperature": 0.0, "avg_logprob":
  -0.2674149685218686, "compression_ratio": 1.7534722222222223, "no_speech_prob":
  0.004555961582809687}, {"id": 557, "seek": 187780, "start": 1889.0, "end": 1894.9199999999998,
  "text": " though, those kind of things that that''s like, it won''t be enough to
  just have the vector search engine probably.", "tokens": [50924, 1673, 11, 729,
  733, 295, 721, 300, 300, 311, 411, 11, 309, 1582, 380, 312, 1547, 281, 445, 362,
  264, 8062, 3164, 2848, 1391, 13, 51220], "temperature": 0.0, "avg_logprob": -0.2674149685218686,
  "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.004555961582809687},
  {"id": 558, "seek": 187780, "start": 1894.9199999999998, "end": 1898.2, "text":
  " You''ll probably need some kind of like tuning layer.", "tokens": [51220, 509,
  603, 1391, 643, 512, 733, 295, 411, 15164, 4583, 13, 51384], "temperature": 0.0,
  "avg_logprob": -0.2674149685218686, "compression_ratio": 1.7534722222222223, "no_speech_prob":
  0.004555961582809687}, {"id": 559, "seek": 187780, "start": 1898.2, "end": 1900.6,
  "text": " And that''s why, so we''ve got has the Python client.", "tokens": [51384,
  400, 300, 311, 983, 11, 370, 321, 600, 658, 575, 264, 15329, 6423, 13, 51504], "temperature":
  0.0, "avg_logprob": -0.2674149685218686, "compression_ratio": 1.7534722222222223,
  "no_speech_prob": 0.004555961582809687}, {"id": 560, "seek": 187780, "start": 1900.6,
  "end": 1905.32, "text": " As I mentioned previously, a research project for this
  would be to integrate that Python client", "tokens": [51504, 1018, 286, 2835, 8046,
  11, 257, 2132, 1716, 337, 341, 576, 312, 281, 13365, 300, 15329, 6423, 51740], "temperature":
  0.0, "avg_logprob": -0.2674149685218686, "compression_ratio": 1.7534722222222223,
  "no_speech_prob": 0.004555961582809687}, {"id": 561, "seek": 190532, "start": 1905.32,
  "end": 1909.32, "text": " into the training loop of the, you know, whatever is doing
  the supervised learning task.", "tokens": [50364, 666, 264, 3097, 6367, 295, 264,
  11, 291, 458, 11, 2035, 307, 884, 264, 46533, 2539, 5633, 13, 50564], "temperature":
  0.0, "avg_logprob": -0.18089821759392233, "compression_ratio": 1.8827361563517915,
  "no_speech_prob": 0.0028386542107909918}, {"id": 562, "seek": 190532, "start": 1909.32,
  "end": 1912.04, "text": " So it kind of isn''t just retrieving.", "tokens": [50564,
  407, 309, 733, 295, 1943, 380, 445, 19817, 798, 13, 50700], "temperature": 0.0,
  "avg_logprob": -0.18089821759392233, "compression_ratio": 1.8827361563517915, "no_speech_prob":
  0.0028386542107909918}, {"id": 563, "seek": 190532, "start": 1912.04, "end": 1916.2,
  "text": " It''s like when we talked about the difference in information retrieval
  and approximate nearest neighbor search,", "tokens": [50700, 467, 311, 411, 562,
  321, 2825, 466, 264, 2649, 294, 1589, 19817, 3337, 293, 30874, 23831, 5987, 3164,
  11, 50908], "temperature": 0.0, "avg_logprob": -0.18089821759392233, "compression_ratio":
  1.8827361563517915, "no_speech_prob": 0.0028386542107909918}, {"id": 564, "seek":
  190532, "start": 1916.2, "end": 1919.3999999999999, "text": " it''s kind of like
  the semantics differences between the things you''re encoding,", "tokens": [50908,
  309, 311, 733, 295, 411, 264, 4361, 45298, 7300, 1296, 264, 721, 291, 434, 43430,
  11, 51068], "temperature": 0.0, "avg_logprob": -0.18089821759392233, "compression_ratio":
  1.8827361563517915, "no_speech_prob": 0.0028386542107909918}, {"id": 565, "seek":
  190532, "start": 1919.3999999999999, "end": 1923.8799999999999, "text": " where
  you might be encoding a like the email title and then the email body.", "tokens":
  [51068, 689, 291, 1062, 312, 43430, 257, 411, 264, 3796, 4876, 293, 550, 264, 3796,
  1772, 13, 51292], "temperature": 0.0, "avg_logprob": -0.18089821759392233, "compression_ratio":
  1.8827361563517915, "no_speech_prob": 0.0028386542107909918}, {"id": 566, "seek":
  190532, "start": 1923.8799999999999, "end": 1928.6, "text": " And so you have these
  different kind of like transitions between the categories of objects you''re encoding.",
  "tokens": [51292, 400, 370, 291, 362, 613, 819, 733, 295, 411, 23767, 1296, 264,
  10479, 295, 6565, 291, 434, 43430, 13, 51528], "temperature": 0.0, "avg_logprob":
  -0.18089821759392233, "compression_ratio": 1.8827361563517915, "no_speech_prob":
  0.0028386542107909918}, {"id": 567, "seek": 190532, "start": 1928.6, "end": 1935.08,
  "text": " So, so yeah, like the, you know, I still think that there''s like a layer
  of,", "tokens": [51528, 407, 11, 370, 1338, 11, 411, 264, 11, 291, 458, 11, 286,
  920, 519, 300, 456, 311, 411, 257, 4583, 295, 11, 51852], "temperature": 0.0, "avg_logprob":
  -0.18089821759392233, "compression_ratio": 1.8827361563517915, "no_speech_prob":
  0.0028386542107909918}, {"id": 568, "seek": 193508, "start": 1935.1599999999999,
  "end": 1940.12, "text": " I don''t know how to describe it, maybe like that system
  one system two, I know people like that analogy,", "tokens": [50368, 286, 500, 380,
  458, 577, 281, 6786, 309, 11, 1310, 411, 300, 1185, 472, 1185, 732, 11, 286, 458,
  561, 411, 300, 21663, 11, 50616], "temperature": 0.0, "avg_logprob": -0.21974966094249815,
  "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0015949123771861196},
  {"id": 569, "seek": 193508, "start": 1940.12, "end": 1945.72, "text": " but there''s
  some kind of layer between keyword search and vector neural representations.", "tokens":
  [50616, 457, 456, 311, 512, 733, 295, 4583, 1296, 20428, 3164, 293, 8062, 18161,
  33358, 13, 50896], "temperature": 0.0, "avg_logprob": -0.21974966094249815, "compression_ratio":
  1.68259385665529, "no_speech_prob": 0.0015949123771861196}, {"id": 570, "seek":
  193508, "start": 1945.72, "end": 1947.24, "text": " There''s something in the middle
  of that.", "tokens": [50896, 821, 311, 746, 294, 264, 2808, 295, 300, 13, 50972],
  "temperature": 0.0, "avg_logprob": -0.21974966094249815, "compression_ratio": 1.68259385665529,
  "no_speech_prob": 0.0015949123771861196}, {"id": 571, "seek": 193508, "start": 1947.24,
  "end": 1950.36, "text": " And, you know, I don''t know what it is, but yeah, I guess
  page rank.", "tokens": [50972, 400, 11, 291, 458, 11, 286, 500, 380, 458, 437, 309,
  307, 11, 457, 1338, 11, 286, 2041, 3028, 6181, 13, 51128], "temperature": 0.0, "avg_logprob":
  -0.21974966094249815, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0015949123771861196},
  {"id": 572, "seek": 193508, "start": 1950.36, "end": 1951.24, "text": " Yeah.",
  "tokens": [51128, 865, 13, 51172], "temperature": 0.0, "avg_logprob": -0.21974966094249815,
  "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0015949123771861196},
  {"id": 573, "seek": 193508, "start": 1951.24, "end": 1957.8799999999999, "text":
  " Yeah, like basically you''re talking about sort of even, even after vector database
  has returned to the", "tokens": [51172, 865, 11, 411, 1936, 291, 434, 1417, 466,
  1333, 295, 754, 11, 754, 934, 8062, 8149, 575, 8752, 281, 264, 51504], "temperature":
  0.0, "avg_logprob": -0.21974966094249815, "compression_ratio": 1.68259385665529,
  "no_speech_prob": 0.0015949123771861196}, {"id": 574, "seek": 193508, "start": 1957.8799999999999,
  "end": 1964.4399999999998, "text": " nearest neighbors, you still have a sort of
  liberty to apply a re-runker, right?", "tokens": [51504, 23831, 12512, 11, 291,
  920, 362, 257, 1333, 295, 22849, 281, 3079, 257, 319, 12, 12997, 5767, 11, 558,
  30, 51832], "temperature": 0.0, "avg_logprob": -0.21974966094249815, "compression_ratio":
  1.68259385665529, "no_speech_prob": 0.0015949123771861196}, {"id": 575, "seek":
  196444, "start": 1964.52, "end": 1969.72, "text": " Because and that''s where your
  business logic kicks in, like the rules, the product, the vision,", "tokens": [50368,
  1436, 293, 300, 311, 689, 428, 1606, 9952, 21293, 294, 11, 411, 264, 4474, 11, 264,
  1674, 11, 264, 5201, 11, 50628], "temperature": 0.0, "avg_logprob": -0.2012007854602955,
  "compression_ratio": 1.608365019011407, "no_speech_prob": 0.0014215527335181832},
  {"id": 576, "seek": 196444, "start": 1969.72, "end": 1974.1200000000001, "text":
  " the design, there are so many inputs into that process of ranking.", "tokens":
  [50628, 264, 1715, 11, 456, 366, 370, 867, 15743, 666, 300, 1399, 295, 17833, 13,
  50848], "temperature": 0.0, "avg_logprob": -0.2012007854602955, "compression_ratio":
  1.608365019011407, "no_speech_prob": 0.0014215527335181832}, {"id": 577, "seek":
  196444, "start": 1974.1200000000001, "end": 1979.16, "text": " And then ranking
  obviously is like a huge research area as well, you know, with the click", "tokens":
  [50848, 400, 550, 17833, 2745, 307, 411, 257, 2603, 2132, 1859, 382, 731, 11, 291,
  458, 11, 365, 264, 2052, 51100], "temperature": 0.0, "avg_logprob": -0.2012007854602955,
  "compression_ratio": 1.608365019011407, "no_speech_prob": 0.0014215527335181832},
  {"id": 578, "seek": 196444, "start": 1979.16, "end": 1981.48, "text": " biasing
  and things like that, right?", "tokens": [51100, 3228, 3349, 293, 721, 411, 300,
  11, 558, 30, 51216], "temperature": 0.0, "avg_logprob": -0.2012007854602955, "compression_ratio":
  1.608365019011407, "no_speech_prob": 0.0014215527335181832}, {"id": 579, "seek":
  196444, "start": 1982.76, "end": 1984.76, "text": " Yeah, I mean, and it''s also
  interesting.", "tokens": [51280, 865, 11, 286, 914, 11, 293, 309, 311, 611, 1880,
  13, 51380], "temperature": 0.0, "avg_logprob": -0.2012007854602955, "compression_ratio":
  1.608365019011407, "no_speech_prob": 0.0014215527335181832}, {"id": 580, "seek":
  196444, "start": 1984.76, "end": 1991.4, "text": " I just crossed my mind that yesterday,
  Richard Sorter announced his search engine and U.com.", "tokens": [51380, 286, 445,
  14622, 452, 1575, 300, 5186, 11, 9809, 318, 6122, 7548, 702, 3164, 2848, 293, 624,
  13, 1112, 13, 51712], "temperature": 0.0, "avg_logprob": -0.2012007854602955, "compression_ratio":
  1.608365019011407, "no_speech_prob": 0.0014215527335181832}, {"id": 581, "seek":
  199140, "start": 1991.64, "end": 1994.44, "text": " And did you have a chance to
  check it out?", "tokens": [50376, 400, 630, 291, 362, 257, 2931, 281, 1520, 309,
  484, 30, 50516], "temperature": 0.0, "avg_logprob": -0.12663925545556204, "compression_ratio":
  1.6627906976744187, "no_speech_prob": 0.015483730472624302}, {"id": 582, "seek":
  199140, "start": 1994.44, "end": 1999.5600000000002, "text": " Basically for listeners
  who didn''t check it out yet, so it''s a search engine which summarizes", "tokens":
  [50516, 8537, 337, 23274, 567, 994, 380, 1520, 309, 484, 1939, 11, 370, 309, 311,
  257, 3164, 2848, 597, 14611, 5660, 50772], "temperature": 0.0, "avg_logprob": -0.12663925545556204,
  "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.015483730472624302},
  {"id": 583, "seek": 199140, "start": 1999.5600000000002, "end": 2005.24, "text":
  " the web pages and the kind of documents and so on. And so you are kind of, it
  makes it actionable.", "tokens": [50772, 264, 3670, 7183, 293, 264, 733, 295, 8512,
  293, 370, 322, 13, 400, 370, 291, 366, 733, 295, 11, 309, 1669, 309, 45098, 13,
  51056], "temperature": 0.0, "avg_logprob": -0.12663925545556204, "compression_ratio":
  1.6627906976744187, "no_speech_prob": 0.015483730472624302}, {"id": 584, "seek":
  199140, "start": 2005.24, "end": 2011.4, "text": " So just one example, they can
  find you a code snippet on Stack Overflow that you can actually", "tokens": [51056,
  407, 445, 472, 1365, 11, 436, 393, 915, 291, 257, 3089, 35623, 302, 322, 37649,
  4886, 10565, 300, 291, 393, 767, 51364], "temperature": 0.0, "avg_logprob": -0.12663925545556204,
  "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.015483730472624302},
  {"id": 585, "seek": 199140, "start": 2011.4, "end": 2016.68, "text": " copy paste.
  And that''s just one example, right? But there are plenty of more. Any thoughts
  on this?", "tokens": [51364, 5055, 9163, 13, 400, 300, 311, 445, 472, 1365, 11,
  558, 30, 583, 456, 366, 7140, 295, 544, 13, 2639, 4598, 322, 341, 30, 51628], "temperature":
  0.0, "avg_logprob": -0.12663925545556204, "compression_ratio": 1.6627906976744187,
  "no_speech_prob": 0.015483730472624302}, {"id": 586, "seek": 201668, "start": 2017.64,
  "end": 2022.92, "text": " Yeah, well, I mean, first of all, Richard Sacher, his
  research has been incredible. And as I", "tokens": [50412, 865, 11, 731, 11, 286,
  914, 11, 700, 295, 439, 11, 9809, 318, 4062, 11, 702, 2132, 575, 668, 4651, 13,
  400, 382, 286, 50676], "temperature": 0.0, "avg_logprob": -0.21306838019419524,
  "compression_ratio": 1.5985663082437276, "no_speech_prob": 0.04407363012433052},
  {"id": 587, "seek": 201668, "start": 2022.92, "end": 2027.16, "text": " mentioned
  earlier in the podcast, I was listening to systems co-search from Salesforce Research
  was,", "tokens": [50676, 2835, 3071, 294, 264, 7367, 11, 286, 390, 4764, 281, 3652,
  598, 12, 405, 1178, 490, 40398, 10303, 390, 11, 50888], "temperature": 0.0, "avg_logprob":
  -0.21306838019419524, "compression_ratio": 1.5985663082437276, "no_speech_prob":
  0.04407363012433052}, {"id": 588, "seek": 201668, "start": 2028.1200000000001, "end":
  2030.52, "text": " he was one of the authors, I don''t know who led the project.",
  "tokens": [50936, 415, 390, 472, 295, 264, 16552, 11, 286, 500, 380, 458, 567, 4684,
  264, 1716, 13, 51056], "temperature": 0.0, "avg_logprob": -0.21306838019419524,
  "compression_ratio": 1.5985663082437276, "no_speech_prob": 0.04407363012433052},
  {"id": 589, "seek": 201668, "start": 2031.8, "end": 2039.8, "text": " So yeah, U.com,
  I mean, it looks crazy. Like, have I used it quite not really yet, but I definitely",
  "tokens": [51120, 407, 1338, 11, 624, 13, 1112, 11, 286, 914, 11, 309, 1542, 3219,
  13, 1743, 11, 362, 286, 1143, 309, 1596, 406, 534, 1939, 11, 457, 286, 2138, 51520],
  "temperature": 0.0, "avg_logprob": -0.21306838019419524, "compression_ratio": 1.5985663082437276,
  "no_speech_prob": 0.04407363012433052}, {"id": 590, "seek": 201668, "start": 2039.8,
  "end": 2046.04, "text": " believe in the concept and yeah, the research is pointing
  in that direction. It''s exciting.", "tokens": [51520, 1697, 294, 264, 3410, 293,
  1338, 11, 264, 2132, 307, 12166, 294, 300, 3513, 13, 467, 311, 4670, 13, 51832],
  "temperature": 0.0, "avg_logprob": -0.21306838019419524, "compression_ratio": 1.5985663082437276,
  "no_speech_prob": 0.04407363012433052}, {"id": 591, "seek": 204668, "start": 2047.64,
  "end": 2053.48, "text": " But do I think like, solely neural system? Yeah, I mean,
  designing new interfaces around", "tokens": [50412, 583, 360, 286, 519, 411, 11,
  23309, 18161, 1185, 30, 865, 11, 286, 914, 11, 14685, 777, 28416, 926, 50704], "temperature":
  0.0, "avg_logprob": -0.20864842732747396, "compression_ratio": 1.6464285714285714,
  "no_speech_prob": 0.0007735115359537303}, {"id": 592, "seek": 204668, "start": 2053.48,
  "end": 2056.76, "text": " search, started to go around that a little bit as I''m
  trying to like think, well, I talk, but", "tokens": [50704, 3164, 11, 1409, 281,
  352, 926, 300, 257, 707, 857, 382, 286, 478, 1382, 281, 411, 519, 11, 731, 11, 286,
  751, 11, 457, 50868], "temperature": 0.0, "avg_logprob": -0.20864842732747396, "compression_ratio":
  1.6464285714285714, "no_speech_prob": 0.0007735115359537303}, {"id": 593, "seek":
  204668, "start": 2057.32, "end": 2063.16, "text": " yeah, the U.com thing is exciting.
  New spaces for search engines. It''s hard to even completely", "tokens": [50896,
  1338, 11, 264, 624, 13, 1112, 551, 307, 4670, 13, 1873, 7673, 337, 3164, 12982,
  13, 467, 311, 1152, 281, 754, 2584, 51188], "temperature": 0.0, "avg_logprob": -0.20864842732747396,
  "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007735115359537303},
  {"id": 594, "seek": 204668, "start": 2063.16, "end": 2068.04, "text": " conceptualize
  it, I think because it''s such a, you think of Google as like this giant,", "tokens":
  [51188, 24106, 1125, 309, 11, 286, 519, 570, 309, 311, 1270, 257, 11, 291, 519,
  295, 3329, 382, 411, 341, 7410, 11, 51432], "temperature": 0.0, "avg_logprob": -0.20864842732747396,
  "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007735115359537303},
  {"id": 595, "seek": 204668, "start": 2068.04, "end": 2073.0, "text": " undistructible
  search engine, but that''s really not the story. There really is a ton of research",
  "tokens": [51432, 674, 468, 1757, 964, 3164, 2848, 11, 457, 300, 311, 534, 406,
  264, 1657, 13, 821, 534, 307, 257, 2952, 295, 2132, 51680], "temperature": 0.0,
  "avg_logprob": -0.20864842732747396, "compression_ratio": 1.6464285714285714, "no_speech_prob":
  0.0007735115359537303}, {"id": 596, "seek": 207300, "start": 2073.0, "end": 2078.2,
  "text": " and search engines. Yeah, yeah, but actually, I''m currently working for
  WebScale. So,", "tokens": [50364, 293, 3164, 12982, 13, 865, 11, 1338, 11, 457,
  767, 11, 286, 478, 4362, 1364, 337, 9573, 16806, 1220, 13, 407, 11, 50624], "temperature":
  0.0, "avg_logprob": -0.20867106119791667, "compression_ratio": 1.5231788079470199,
  "no_speech_prob": 0.008089895360171795}, {"id": 597, "seek": 207300, "start": 2078.2,
  "end": 2084.28, "text": " Changes, which I cannot mention because it''s my client
  on the NDA, but we basically have all the", "tokens": [50624, 761, 10350, 11, 597,
  286, 2644, 2152, 570, 309, 311, 452, 6423, 322, 264, 426, 7509, 11, 457, 321, 1936,
  362, 439, 264, 50928], "temperature": 0.0, "avg_logprob": -0.20867106119791667,
  "compression_ratio": 1.5231788079470199, "no_speech_prob": 0.008089895360171795},
  {"id": 598, "seek": 207300, "start": 2084.28, "end": 2090.28, "text": " charts and
  we know that Google is like 97%. And then everyone else is close to the bottom.",
  "tokens": [50928, 17767, 293, 321, 458, 300, 3329, 307, 411, 23399, 6856, 400, 550,
  1518, 1646, 307, 1998, 281, 264, 2767, 13, 51228], "temperature": 0.0, "avg_logprob":
  -0.20867106119791667, "compression_ratio": 1.5231788079470199, "no_speech_prob":
  0.008089895360171795}, {"id": 599, "seek": 207300, "start": 2091.16, "end": 2096.52,
  "text": " Unfortunately, well, of course, Bing has a couple percent of the market.
  And then it kind of,", "tokens": [51272, 8590, 11, 731, 11, 295, 1164, 11, 30755,
  575, 257, 1916, 3043, 295, 264, 2142, 13, 400, 550, 309, 733, 295, 11, 51540], "temperature":
  0.0, "avg_logprob": -0.20867106119791667, "compression_ratio": 1.5231788079470199,
  "no_speech_prob": 0.008089895360171795}, {"id": 600, "seek": 207300, "start": 2096.52,
  "end": 2100.52, "text": " if you go inside a specific country, the split might be
  different. Like, if you take Russia,", "tokens": [51540, 498, 291, 352, 1854, 257,
  2685, 1941, 11, 264, 7472, 1062, 312, 819, 13, 1743, 11, 498, 291, 747, 6797, 11,
  51740], "temperature": 0.0, "avg_logprob": -0.20867106119791667, "compression_ratio":
  1.5231788079470199, "no_speech_prob": 0.008089895360171795}, {"id": 601, "seek":
  210052, "start": 2100.52, "end": 2104.68, "text": " for example, Yandex is on top
  and then Google is following them, but very closely, you know,", "tokens": [50364,
  337, 1365, 11, 398, 474, 3121, 307, 322, 1192, 293, 550, 3329, 307, 3480, 552, 11,
  457, 588, 8185, 11, 291, 458, 11, 50572], "temperature": 0.0, "avg_logprob": -0.15013101722012048,
  "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.010685698129236698},
  {"id": 602, "seek": 210052, "start": 2105.8, "end": 2112.7599999999998, "text":
  " but overall, globally, Google is just somewhere beyond the sky. So, you need to
  kind of", "tokens": [50628, 457, 4787, 11, 18958, 11, 3329, 307, 445, 4079, 4399,
  264, 5443, 13, 407, 11, 291, 643, 281, 733, 295, 50976], "temperature": 0.0, "avg_logprob":
  -0.15013101722012048, "compression_ratio": 1.7651515151515151, "no_speech_prob":
  0.010685698129236698}, {"id": 603, "seek": 210052, "start": 2112.7599999999998,
  "end": 2118.04, "text": " differentiate a lot, you know, like you don''t want to
  build another Google. It''s almost like Peter", "tokens": [50976, 23203, 257, 688,
  11, 291, 458, 11, 411, 291, 500, 380, 528, 281, 1322, 1071, 3329, 13, 467, 311,
  1920, 411, 6508, 51240], "temperature": 0.0, "avg_logprob": -0.15013101722012048,
  "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.010685698129236698},
  {"id": 604, "seek": 210052, "start": 2118.04, "end": 2123.0, "text": " Tills book,
  you know, zero to one where he says, if you are building another Facebook, you''re
  not", "tokens": [51240, 314, 2565, 1446, 11, 291, 458, 11, 4018, 281, 472, 689,
  415, 1619, 11, 498, 291, 366, 2390, 1071, 4384, 11, 291, 434, 406, 51488], "temperature":
  0.0, "avg_logprob": -0.15013101722012048, "compression_ratio": 1.7651515151515151,
  "no_speech_prob": 0.010685698129236698}, {"id": 605, "seek": 210052, "start": 2123.0,
  "end": 2126.84, "text": " learning anything from Mark Zuckerberg or if you''re building
  another Google, you''re not,", "tokens": [51488, 2539, 1340, 490, 3934, 34032, 6873,
  420, 498, 291, 434, 2390, 1071, 3329, 11, 291, 434, 406, 11, 51680], "temperature":
  0.0, "avg_logprob": -0.15013101722012048, "compression_ratio": 1.7651515151515151,
  "no_speech_prob": 0.010685698129236698}, {"id": 606, "seek": 212684, "start": 2126.84,
  "end": 2131.32, "text": " you''re not learning anything from the Google founders.
  Like, you need to build that one, right? And", "tokens": [50364, 291, 434, 406,
  2539, 1340, 490, 264, 3329, 25608, 13, 1743, 11, 291, 643, 281, 1322, 300, 472,
  11, 558, 30, 400, 50588], "temperature": 0.0, "avg_logprob": -0.19744549278451615,
  "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.00458178436383605},
  {"id": 607, "seek": 212684, "start": 2131.32, "end": 2136.6000000000004, "text":
  " I think Richard is trying to build that one probably. So, yeah, I mean, it''s
  an interesting", "tokens": [50588, 286, 519, 9809, 307, 1382, 281, 1322, 300, 472,
  1391, 13, 407, 11, 1338, 11, 286, 914, 11, 309, 311, 364, 1880, 50852], "temperature":
  0.0, "avg_logprob": -0.19744549278451615, "compression_ratio": 1.6472602739726028,
  "no_speech_prob": 0.00458178436383605}, {"id": 608, "seek": 212684, "start": 2136.6000000000004,
  "end": 2143.0, "text": " direction that he''s trying to involve the AI much deeper
  in the process, probably already surfacing,", "tokens": [50852, 3513, 300, 415,
  311, 1382, 281, 9494, 264, 7318, 709, 7731, 294, 264, 1399, 11, 1391, 1217, 9684,
  5615, 11, 51172], "temperature": 0.0, "avg_logprob": -0.19744549278451615, "compression_ratio":
  1.6472602739726028, "no_speech_prob": 0.00458178436383605}, {"id": 609, "seek":
  212684, "start": 2143.0, "end": 2149.8, "text": " you know, users. That''s fantastic.
  Yeah, yeah, I don''t have anything to add other than just", "tokens": [51172, 291,
  458, 11, 5022, 13, 663, 311, 5456, 13, 865, 11, 1338, 11, 286, 500, 380, 362, 1340,
  281, 909, 661, 813, 445, 51512], "temperature": 0.0, "avg_logprob": -0.19744549278451615,
  "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.00458178436383605},
  {"id": 610, "seek": 212684, "start": 2149.8, "end": 2156.1200000000003, "text":
  " shared excitement about what you.com will become. It''s certainly exciting. Yeah,
  absolutely. All", "tokens": [51512, 5507, 14755, 466, 437, 291, 13, 1112, 486, 1813,
  13, 467, 311, 3297, 4670, 13, 865, 11, 3122, 13, 1057, 51828], "temperature": 0.0,
  "avg_logprob": -0.19744549278451615, "compression_ratio": 1.6472602739726028, "no_speech_prob":
  0.00458178436383605}, {"id": 611, "seek": 215612, "start": 2156.12, "end": 2165.16,
  "text": " the best Richard. Yeah, and you actually I wanted to make a slight segue
  into you shared like", "tokens": [50364, 264, 1151, 9809, 13, 865, 11, 293, 291,
  767, 286, 1415, 281, 652, 257, 4036, 33850, 666, 291, 5507, 411, 50816], "temperature":
  0.0, "avg_logprob": -0.18123321801843778, "compression_ratio": 1.513089005235602,
  "no_speech_prob": 0.00575678888708353}, {"id": 612, "seek": 215612, "start": 2165.16,
  "end": 2172.92, "text": " a ton of information today. I wonder how do you keep up
  with so much stuff happening? Like, what", "tokens": [50816, 257, 2952, 295, 1589,
  965, 13, 286, 2441, 577, 360, 291, 1066, 493, 365, 370, 709, 1507, 2737, 30, 1743,
  11, 437, 51204], "temperature": 0.0, "avg_logprob": -0.18123321801843778, "compression_ratio":
  1.513089005235602, "no_speech_prob": 0.00575678888708353}, {"id": 613, "seek": 215612,
  "start": 2172.92, "end": 2177.7999999999997, "text": " are your preferred sources
  of information? Like, obviously YouTube is one, but, you know, there is", "tokens":
  [51204, 366, 428, 16494, 7139, 295, 1589, 30, 1743, 11, 2745, 3088, 307, 472, 11,
  457, 11, 291, 458, 11, 456, 307, 51448], "temperature": 0.0, "avg_logprob": -0.18123321801843778,
  "compression_ratio": 1.513089005235602, "no_speech_prob": 0.00575678888708353},
  {"id": 614, "seek": 217780, "start": 2177.8, "end": 2184.6000000000004, "text":
  " also medium. There is publications themselves. How did you structure your sort
  of consumption,", "tokens": [50364, 611, 6399, 13, 821, 307, 25618, 2969, 13, 1012,
  630, 291, 3877, 428, 1333, 295, 12126, 11, 50704], "temperature": 0.0, "avg_logprob":
  -0.24583379357261995, "compression_ratio": 1.5986159169550174, "no_speech_prob":
  0.013005629181861877}, {"id": 615, "seek": 217780, "start": 2185.2400000000002,
  "end": 2190.6000000000004, "text": " you know, parts like the pacing and kind of
  where to pay, put your attention and so on?", "tokens": [50736, 291, 458, 11, 3166,
  411, 264, 43285, 293, 733, 295, 689, 281, 1689, 11, 829, 428, 3202, 293, 370, 322,
  30, 51004], "temperature": 0.0, "avg_logprob": -0.24583379357261995, "compression_ratio":
  1.5986159169550174, "no_speech_prob": 0.013005629181861877}, {"id": 616, "seek":
  217780, "start": 2192.6000000000004, "end": 2197.5600000000004, "text": " Yeah,
  that''s a great question. And, you know, early days of my podcast, I was doing the",
  "tokens": [51104, 865, 11, 300, 311, 257, 869, 1168, 13, 400, 11, 291, 458, 11,
  2440, 1708, 295, 452, 7367, 11, 286, 390, 884, 264, 51352], "temperature": 0.0,
  "avg_logprob": -0.24583379357261995, "compression_ratio": 1.5986159169550174, "no_speech_prob":
  0.013005629181861877}, {"id": 617, "seek": 217780, "start": 2197.5600000000004,
  "end": 2202.36, "text": " Machine Learning Street Talk with Tim Scarf and Yana Kiltcher
  and Tim asked Jonathan Frank,", "tokens": [51352, 22155, 15205, 7638, 8780, 365,
  7172, 23181, 69, 293, 398, 2095, 591, 2352, 6759, 293, 7172, 2351, 15471, 6823,
  11, 51592], "temperature": 0.0, "avg_logprob": -0.24583379357261995, "compression_ratio":
  1.5986159169550174, "no_speech_prob": 0.013005629181861877}, {"id": 618, "seek":
  217780, "start": 2202.36, "end": 2207.0, "text": " the author of the lottery ticket
  hypothesis, the same question. Like, what''s your information diet?", "tokens":
  [51592, 264, 3793, 295, 264, 27391, 10550, 17291, 11, 264, 912, 1168, 13, 1743,
  11, 437, 311, 428, 1589, 6339, 30, 51824], "temperature": 0.0, "avg_logprob": -0.24583379357261995,
  "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.013005629181861877},
  {"id": 619, "seek": 220700, "start": 2207.0, "end": 2213.08, "text": " And I thought
  it''s a really interesting question. So mine is, you know, like most people out
  there", "tokens": [50364, 400, 286, 1194, 309, 311, 257, 534, 1880, 1168, 13, 407,
  3892, 307, 11, 291, 458, 11, 411, 881, 561, 484, 456, 50668], "temperature": 0.0,
  "avg_logprob": -0.13902139282226564, "compression_ratio": 1.7234042553191489, "no_speech_prob":
  0.004591033793985844}, {"id": 620, "seek": 220700, "start": 2213.08, "end": 2217.8,
  "text": " trying to be good at something. It''s chaotic and it gets overwhelming
  and I get really stressed", "tokens": [50668, 1382, 281, 312, 665, 412, 746, 13,
  467, 311, 27013, 293, 309, 2170, 13373, 293, 286, 483, 534, 14471, 50904], "temperature":
  0.0, "avg_logprob": -0.13902139282226564, "compression_ratio": 1.7234042553191489,
  "no_speech_prob": 0.004591033793985844}, {"id": 621, "seek": 220700, "start": 2217.8,
  "end": 2224.36, "text": " out sometimes. So I don''t know if this is the best advice
  to follow, but like, here''s what I do.", "tokens": [50904, 484, 2171, 13, 407,
  286, 500, 380, 458, 498, 341, 307, 264, 1151, 5192, 281, 1524, 11, 457, 411, 11,
  510, 311, 437, 286, 360, 13, 51232], "temperature": 0.0, "avg_logprob": -0.13902139282226564,
  "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.004591033793985844},
  {"id": 622, "seek": 220700, "start": 2224.36, "end": 2229.88, "text": " So I, you
  know, I''m very active on Twitter, like maybe to the point of detrimental to my
  health,", "tokens": [51232, 407, 286, 11, 291, 458, 11, 286, 478, 588, 4967, 322,
  5794, 11, 411, 1310, 281, 264, 935, 295, 45694, 281, 452, 1585, 11, 51508], "temperature":
  0.0, "avg_logprob": -0.13902139282226564, "compression_ratio": 1.7234042553191489,
  "no_speech_prob": 0.004591033793985844}, {"id": 623, "seek": 220700, "start": 2229.88,
  "end": 2234.76, "text": " like I checked Twitter, like, all the time. Like, so I''m
  always refreshing Twitter and seeing the", "tokens": [51508, 411, 286, 10033, 5794,
  11, 411, 11, 439, 264, 565, 13, 1743, 11, 370, 286, 478, 1009, 19772, 5794, 293,
  2577, 264, 51752], "temperature": 0.0, "avg_logprob": -0.13902139282226564, "compression_ratio":
  1.7234042553191489, "no_speech_prob": 0.004591033793985844}, {"id": 624, "seek":
  223476, "start": 2234.76, "end": 2239.96, "text": " new headlines. And so I, when
  I see like an archive link, I''ll try to, like, if I like it,", "tokens": [50364,
  777, 23867, 13, 400, 370, 286, 11, 562, 286, 536, 411, 364, 23507, 2113, 11, 286,
  603, 853, 281, 11, 411, 11, 498, 286, 411, 309, 11, 50624], "temperature": 0.0,
  "avg_logprob": -0.1379076385498047, "compression_ratio": 1.610344827586207, "no_speech_prob":
  0.0018856344977393746}, {"id": 625, "seek": 223476, "start": 2239.96, "end": 2243.5600000000004,
  "text": " I''ve tried to discipline myself to be like, don''t just like it. Like
  read the abstract,", "tokens": [50624, 286, 600, 3031, 281, 13635, 2059, 281, 312,
  411, 11, 500, 380, 445, 411, 309, 13, 1743, 1401, 264, 12649, 11, 50804], "temperature":
  0.0, "avg_logprob": -0.1379076385498047, "compression_ratio": 1.610344827586207,
  "no_speech_prob": 0.0018856344977393746}, {"id": 626, "seek": 223476, "start": 2243.5600000000004,
  "end": 2248.84, "text": " like get a couple sentences in because clearly, you know,
  the titles caught your attention. So,", "tokens": [50804, 411, 483, 257, 1916, 16579,
  294, 570, 4448, 11, 291, 458, 11, 264, 12992, 5415, 428, 3202, 13, 407, 11, 51068],
  "temperature": 0.0, "avg_logprob": -0.1379076385498047, "compression_ratio": 1.610344827586207,
  "no_speech_prob": 0.0018856344977393746}, {"id": 627, "seek": 223476, "start": 2248.84,
  "end": 2254.0400000000004, "text": " so Twitter is really where I get all my news.
  And then the art form of making these YouTube videos,", "tokens": [51068, 370, 5794,
  307, 534, 689, 286, 483, 439, 452, 2583, 13, 400, 550, 264, 1523, 1254, 295, 1455,
  613, 3088, 2145, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1379076385498047,
  "compression_ratio": 1.610344827586207, "no_speech_prob": 0.0018856344977393746},
  {"id": 628, "seek": 223476, "start": 2254.0400000000004, "end": 2259.0, "text":
  " I mean, like Yana Kiltcher and Tim Scarf that I mentioned, the Machine Learning
  Street Talk,", "tokens": [51328, 286, 914, 11, 411, 398, 2095, 591, 2352, 6759,
  293, 7172, 23181, 69, 300, 286, 2835, 11, 264, 22155, 15205, 7638, 8780, 11, 51576],
  "temperature": 0.0, "avg_logprob": -0.1379076385498047, "compression_ratio": 1.610344827586207,
  "no_speech_prob": 0.0018856344977393746}, {"id": 629, "seek": 225900, "start": 2259.08,
  "end": 2265.16, "text": " these kind of, this kind of medium. It''s, I watch that.
  It''s pretty good. I think I watch it on", "tokens": [50368, 613, 733, 295, 11,
  341, 733, 295, 6399, 13, 467, 311, 11, 286, 1159, 300, 13, 467, 311, 1238, 665,
  13, 286, 519, 286, 1159, 309, 322, 50672], "temperature": 0.0, "avg_logprob": -0.21075267222390245,
  "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.028601376339793205},
  {"id": 630, "seek": 225900, "start": 2265.16, "end": 2270.36, "text": " like, Exploratory
  Street also Alexa, Miss Coffee Bean to kind of go on the list, you know, they''re
  not", "tokens": [50672, 411, 11, 12514, 284, 4745, 7638, 611, 22595, 11, 5275, 25481,
  38454, 281, 733, 295, 352, 322, 264, 1329, 11, 291, 458, 11, 436, 434, 406, 50932],
  "temperature": 0.0, "avg_logprob": -0.21075267222390245, "compression_ratio": 1.6778523489932886,
  "no_speech_prob": 0.028601376339793205}, {"id": 631, "seek": 225900, "start": 2270.36,
  "end": 2274.68, "text": " the only ones doing it well. A lot of people are starting
  to make really great YouTube videos. And I", "tokens": [50932, 264, 787, 2306, 884,
  309, 731, 13, 316, 688, 295, 561, 366, 2891, 281, 652, 534, 869, 3088, 2145, 13,
  400, 286, 51148], "temperature": 0.0, "avg_logprob": -0.21075267222390245, "compression_ratio":
  1.6778523489932886, "no_speech_prob": 0.028601376339793205}, {"id": 632, "seek":
  225900, "start": 2274.68, "end": 2280.2, "text": " love that kind of medium of showing
  these things. So on my, my work, my like, my workout, say I''m a", "tokens": [51148,
  959, 300, 733, 295, 6399, 295, 4099, 613, 721, 13, 407, 322, 452, 11, 452, 589,
  11, 452, 411, 11, 452, 12169, 11, 584, 286, 478, 257, 51424], "temperature": 0.0,
  "avg_logprob": -0.21075267222390245, "compression_ratio": 1.6778523489932886, "no_speech_prob":
  0.028601376339793205}, {"id": 633, "seek": 225900, "start": 2280.2, "end": 2286.04,
  "text": " basketball player and I''ve got to work on my deep learning skills is
  it''s mostly about reading these", "tokens": [51424, 11767, 4256, 293, 286, 600,
  658, 281, 589, 322, 452, 2452, 2539, 3942, 307, 309, 311, 5240, 466, 3760, 613,
  51716], "temperature": 0.0, "avg_logprob": -0.21075267222390245, "compression_ratio":
  1.6778523489932886, "no_speech_prob": 0.028601376339793205}, {"id": 634, "seek":
  228604, "start": 2286.04, "end": 2292.2, "text": " papers. My experiments, I''d
  say the coding part is not super challenging. Thanks to things like", "tokens":
  [50364, 10577, 13, 1222, 12050, 11, 286, 1116, 584, 264, 17720, 644, 307, 406, 1687,
  7595, 13, 2561, 281, 721, 411, 50672], "temperature": 0.0, "avg_logprob": -0.18756159069468675,
  "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0033280516508966684},
  {"id": 635, "seek": 228604, "start": 2292.2, "end": 2296.84, "text": " Keras coding
  examples and like thanks to them, major thanks to them because that saves me so
  much", "tokens": [50672, 591, 6985, 17720, 5110, 293, 411, 3231, 281, 552, 11, 2563,
  3231, 281, 552, 570, 300, 19155, 385, 370, 709, 50904], "temperature": 0.0, "avg_logprob":
  -0.18756159069468675, "compression_ratio": 1.603305785123967, "no_speech_prob":
  0.0033280516508966684}, {"id": 636, "seek": 228604, "start": 2296.84, "end": 2303.0,
  "text": " headache in just getting running. So, so yeah, I try to, I try to read
  like five papers at a time.", "tokens": [50904, 23520, 294, 445, 1242, 2614, 13,
  407, 11, 370, 1338, 11, 286, 853, 281, 11, 286, 853, 281, 1401, 411, 1732, 10577,
  412, 257, 565, 13, 51212], "temperature": 0.0, "avg_logprob": -0.18756159069468675,
  "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0033280516508966684},
  {"id": 637, "seek": 228604, "start": 2303.0, "end": 2311.64, "text": " I tried to
  switch, I try to set 20 minute timers, drink a lot of coffee. And what else do I
  do?", "tokens": [51212, 286, 3031, 281, 3679, 11, 286, 853, 281, 992, 945, 3456,
  524, 433, 11, 2822, 257, 688, 295, 4982, 13, 400, 437, 1646, 360, 286, 360, 30,
  51644], "temperature": 0.0, "avg_logprob": -0.18756159069468675, "compression_ratio":
  1.603305785123967, "no_speech_prob": 0.0033280516508966684}, {"id": 638, "seek":
  231164, "start": 2312.52, "end": 2316.52, "text": " Yeah, I guess that''s it really
  reading the really reading the papers. I mean, if you make paper", "tokens": [50408,
  865, 11, 286, 2041, 300, 311, 309, 534, 3760, 264, 534, 3760, 264, 10577, 13, 286,
  914, 11, 498, 291, 652, 3035, 50608], "temperature": 0.0, "avg_logprob": -0.16035889867526382,
  "compression_ratio": 1.6723549488054608, "no_speech_prob": 0.009077411144971848},
  {"id": 639, "seek": 231164, "start": 2316.52, "end": 2321.24, "text": " summary
  videos and write blog posts, that''s also a huge way to retain it. I try to talk
  to a lot of", "tokens": [50608, 12691, 2145, 293, 2464, 6968, 12300, 11, 300, 311,
  611, 257, 2603, 636, 281, 18340, 309, 13, 286, 853, 281, 751, 281, 257, 688, 295,
  50844], "temperature": 0.0, "avg_logprob": -0.16035889867526382, "compression_ratio":
  1.6723549488054608, "no_speech_prob": 0.009077411144971848}, {"id": 640, "seek":
  231164, "start": 2321.24, "end": 2327.16, "text": " people also just, you know,
  I try to keep a lot of contact. Like I''m organized all this through", "tokens":
  [50844, 561, 611, 445, 11, 291, 458, 11, 286, 853, 281, 1066, 257, 688, 295, 3385,
  13, 1743, 286, 478, 9983, 439, 341, 807, 51140], "temperature": 0.0, "avg_logprob":
  -0.16035889867526382, "compression_ratio": 1.6723549488054608, "no_speech_prob":
  0.009077411144971848}, {"id": 641, "seek": 231164, "start": 2327.16, "end": 2334.3599999999997,
  "text": " Twitter. So like, you know, I might just send messages to say, Syek Paul
  from who makes, I think", "tokens": [51140, 5794, 13, 407, 411, 11, 291, 458, 11,
  286, 1062, 445, 2845, 7897, 281, 584, 11, 3902, 916, 4552, 490, 567, 1669, 11, 286,
  519, 51500], "temperature": 0.0, "avg_logprob": -0.16035889867526382, "compression_ratio":
  1.6723549488054608, "no_speech_prob": 0.009077411144971848}, {"id": 642, "seek":
  231164, "start": 2334.3599999999997, "end": 2339.64, "text": " he works at Cardid
  and he makes, he''s one of the leaders of Keras code examples. I''ll send him ideas.",
  "tokens": [51500, 415, 1985, 412, 11877, 327, 293, 415, 1669, 11, 415, 311, 472,
  295, 264, 3523, 295, 591, 6985, 3089, 5110, 13, 286, 603, 2845, 796, 3487, 13, 51764],
  "temperature": 0.0, "avg_logprob": -0.16035889867526382, "compression_ratio": 1.6723549488054608,
  "no_speech_prob": 0.009077411144971848}, {"id": 643, "seek": 233964, "start": 2339.64,
  "end": 2343.08, "text": " I''ll be like, you know, I saw this paper on Twitter.
  I think, you know, this reminds me of what", "tokens": [50364, 286, 603, 312, 411,
  11, 291, 458, 11, 286, 1866, 341, 3035, 322, 5794, 13, 286, 519, 11, 291, 458, 11,
  341, 12025, 385, 295, 437, 50536], "temperature": 0.0, "avg_logprob": -0.14780119436758535,
  "compression_ratio": 1.7805755395683454, "no_speech_prob": 0.06597090512514114},
  {"id": 644, "seek": 233964, "start": 2343.08, "end": 2347.64, "text": " you''re
  doing. And, and yes, I guess overall, that''s my information diet. I''m probably
  leaving", "tokens": [50536, 291, 434, 884, 13, 400, 11, 293, 2086, 11, 286, 2041,
  4787, 11, 300, 311, 452, 1589, 6339, 13, 286, 478, 1391, 5012, 50764], "temperature":
  0.0, "avg_logprob": -0.14780119436758535, "compression_ratio": 1.7805755395683454,
  "no_speech_prob": 0.06597090512514114}, {"id": 645, "seek": 233964, "start": 2347.64,
  "end": 2351.3199999999997, "text": " something that I didn''t really, you know,
  prepare something for this, but no, it''s okay. I mean, it''s", "tokens": [50764,
  746, 300, 286, 994, 380, 534, 11, 291, 458, 11, 5940, 746, 337, 341, 11, 457, 572,
  11, 309, 311, 1392, 13, 286, 914, 11, 309, 311, 50948], "temperature": 0.0, "avg_logprob":
  -0.14780119436758535, "compression_ratio": 1.7805755395683454, "no_speech_prob":
  0.06597090512514114}, {"id": 646, "seek": 233964, "start": 2351.3199999999997, "end":
  2356.52, "text": " also, it''s also great that you''re speaking your mind, but and
  things that really stick, you know,", "tokens": [50948, 611, 11, 309, 311, 611,
  869, 300, 291, 434, 4124, 428, 1575, 11, 457, 293, 721, 300, 534, 2897, 11, 291,
  458, 11, 51208], "temperature": 0.0, "avg_logprob": -0.14780119436758535, "compression_ratio":
  1.7805755395683454, "no_speech_prob": 0.06597090512514114}, {"id": 647, "seek":
  233964, "start": 2356.52, "end": 2361.8799999999997, "text": " you mentioned them,
  right? But where on that scale, you would put medium, you know, the blogging platform",
  "tokens": [51208, 291, 2835, 552, 11, 558, 30, 583, 689, 322, 300, 4373, 11, 291,
  576, 829, 6399, 11, 291, 458, 11, 264, 6968, 3249, 3663, 51476], "temperature":
  0.0, "avg_logprob": -0.14780119436758535, "compression_ratio": 1.7805755395683454,
  "no_speech_prob": 0.06597090512514114}, {"id": 648, "seek": 236188, "start": 2361.88,
  "end": 2369.8, "text": " where it kind of thrives with tutorials. And sometimes
  these tutorials, they''re kind of okay,", "tokens": [50364, 689, 309, 733, 295,
  23949, 977, 365, 17616, 13, 400, 2171, 613, 17616, 11, 436, 434, 733, 295, 1392,
  11, 50760], "temperature": 0.0, "avg_logprob": -0.0996705334762047, "compression_ratio":
  1.7253521126760563, "no_speech_prob": 0.06096908077597618}, {"id": 649, "seek":
  236188, "start": 2369.8, "end": 2374.52, "text": " but you kind of like, okay, are
  they going deep enough? But then there are other things where they", "tokens": [50760,
  457, 291, 733, 295, 411, 11, 1392, 11, 366, 436, 516, 2452, 1547, 30, 583, 550,
  456, 366, 661, 721, 689, 436, 50996], "temperature": 0.0, "avg_logprob": -0.0996705334762047,
  "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.06096908077597618},
  {"id": 650, "seek": 236188, "start": 2374.52, "end": 2379.4, "text": " summarize
  papers in such a way that they actually try to explain it. It''s almost like popularizing",
  "tokens": [50996, 20858, 10577, 294, 1270, 257, 636, 300, 436, 767, 853, 281, 2903,
  309, 13, 467, 311, 1920, 411, 3743, 3319, 51240], "temperature": 0.0, "avg_logprob":
  -0.0996705334762047, "compression_ratio": 1.7253521126760563, "no_speech_prob":
  0.06096908077597618}, {"id": 651, "seek": 236188, "start": 2379.4, "end": 2385.1600000000003,
  "text": " science because you do want to breed that next, you know, generation as
  well. And maybe you will", "tokens": [51240, 3497, 570, 291, 360, 528, 281, 18971,
  300, 958, 11, 291, 458, 11, 5125, 382, 731, 13, 400, 1310, 291, 486, 51528], "temperature":
  0.0, "avg_logprob": -0.0996705334762047, "compression_ratio": 1.7253521126760563,
  "no_speech_prob": 0.06096908077597618}, {"id": 652, "seek": 236188, "start": 2385.1600000000003,
  "end": 2390.6, "text": " have some feedback to your ideas because don''t you think
  when you publish a research paper, you know,", "tokens": [51528, 362, 512, 5824,
  281, 428, 3487, 570, 500, 380, 291, 519, 562, 291, 11374, 257, 2132, 3035, 11, 291,
  458, 11, 51800], "temperature": 0.0, "avg_logprob": -0.0996705334762047, "compression_ratio":
  1.7253521126760563, "no_speech_prob": 0.06096908077597618}, {"id": 653, "seek":
  239060, "start": 2390.6, "end": 2396.04, "text": " for the most part of the humanity,
  it''s dry text. For some, it''s just Greek, right? They will not", "tokens": [50364,
  337, 264, 881, 644, 295, 264, 10243, 11, 309, 311, 4016, 2487, 13, 1171, 512, 11,
  309, 311, 445, 10281, 11, 558, 30, 814, 486, 406, 50636], "temperature": 0.0, "avg_logprob":
  -0.16995952636238157, "compression_ratio": 1.8262548262548262, "no_speech_prob":
  0.03476051613688469}, {"id": 654, "seek": 239060, "start": 2396.04, "end": 2400.8399999999997,
  "text": " even understand it. They will never, they will never read it. And so,
  but they still might be curious,", "tokens": [50636, 754, 1223, 309, 13, 814, 486,
  1128, 11, 436, 486, 1128, 1401, 309, 13, 400, 370, 11, 457, 436, 920, 1062, 312,
  6369, 11, 50876], "temperature": 0.0, "avg_logprob": -0.16995952636238157, "compression_ratio":
  1.8262548262548262, "no_speech_prob": 0.03476051613688469}, {"id": 655, "seek":
  239060, "start": 2400.8399999999997, "end": 2405.72, "text": " like, okay, how,
  you know, robots make decisions or something like that. You know, so,", "tokens":
  [50876, 411, 11, 1392, 11, 577, 11, 291, 458, 11, 14733, 652, 5327, 420, 746, 411,
  300, 13, 509, 458, 11, 370, 11, 51120], "temperature": 0.0, "avg_logprob": -0.16995952636238157,
  "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.03476051613688469},
  {"id": 656, "seek": 239060, "start": 2406.2799999999997, "end": 2411.3199999999997,
  "text": " how does my car, how does my car keep the lane keeps the lane? And actually
  today I was driving,", "tokens": [51148, 577, 775, 452, 1032, 11, 577, 775, 452,
  1032, 1066, 264, 12705, 5965, 264, 12705, 30, 400, 767, 965, 286, 390, 4840, 11,
  51400], "temperature": 0.0, "avg_logprob": -0.16995952636238157, "compression_ratio":
  1.8262548262548262, "no_speech_prob": 0.03476051613688469}, {"id": 657, "seek":
  239060, "start": 2411.3199999999997, "end": 2416.6, "text": " I was driving to work
  and I was like, my car actually switched to the lane keeping mode.", "tokens": [51400,
  286, 390, 4840, 281, 589, 293, 286, 390, 411, 11, 452, 1032, 767, 16858, 281, 264,
  12705, 5145, 4391, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16995952636238157,
  "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.03476051613688469},
  {"id": 658, "seek": 241660, "start": 2417.24, "end": 2422.2799999999997, "text":
  " And it was telling me that I should not, you know, steer to the left that much.
  So it was actually", "tokens": [50396, 400, 309, 390, 3585, 385, 300, 286, 820,
  406, 11, 291, 458, 11, 30814, 281, 264, 1411, 300, 709, 13, 407, 309, 390, 767,
  50648], "temperature": 0.0, "avg_logprob": -0.155682006249061, "compression_ratio":
  1.775735294117647, "no_speech_prob": 0.08642230182886124}, {"id": 659, "seek": 241660,
  "start": 2422.2799999999997, "end": 2426.68, "text": " steering to the right. But
  the moment it noticed that I put my hands away from the steering wheel,", "tokens":
  [50648, 14823, 281, 264, 558, 13, 583, 264, 1623, 309, 5694, 300, 286, 829, 452,
  2377, 1314, 490, 264, 14823, 5589, 11, 50868], "temperature": 0.0, "avg_logprob":
  -0.155682006249061, "compression_ratio": 1.775735294117647, "no_speech_prob": 0.08642230182886124},
  {"id": 660, "seek": 241660, "start": 2426.68, "end": 2431.64, "text": " it actually
  started alarming me and saying, hey, I''ll sleep or something, you know. So it''s
  also", "tokens": [50868, 309, 767, 1409, 44043, 385, 293, 1566, 11, 4177, 11, 286,
  603, 2817, 420, 746, 11, 291, 458, 13, 407, 309, 311, 611, 51116], "temperature":
  0.0, "avg_logprob": -0.155682006249061, "compression_ratio": 1.775735294117647,
  "no_speech_prob": 0.08642230182886124}, {"id": 661, "seek": 241660, "start": 2431.64,
  "end": 2436.52, "text": " like kind of caring for you, right? In a way, so it''s
  not trying to do so much more work,", "tokens": [51116, 411, 733, 295, 15365, 337,
  291, 11, 558, 30, 682, 257, 636, 11, 370, 309, 311, 406, 1382, 281, 360, 370, 709,
  544, 589, 11, 51360], "temperature": 0.0, "avg_logprob": -0.155682006249061, "compression_ratio":
  1.775735294117647, "no_speech_prob": 0.08642230182886124}, {"id": 662, "seek": 241660,
  "start": 2437.56, "end": 2444.2799999999997, "text": " in that sense. Yeah, like,
  the idea of popular science, I mean, you know, I''m recording my podcast", "tokens":
  [51412, 294, 300, 2020, 13, 865, 11, 411, 11, 264, 1558, 295, 3743, 3497, 11, 286,
  914, 11, 291, 458, 11, 286, 478, 6613, 452, 7367, 51748], "temperature": 0.0, "avg_logprob":
  -0.155682006249061, "compression_ratio": 1.775735294117647, "no_speech_prob": 0.08642230182886124},
  {"id": 663, "seek": 244428, "start": 2444.36, "end": 2451.2400000000002, "text":
  " behind a bookshelf, like it makes me look smarter, but I only really, I only really
  read books like,", "tokens": [50368, 2261, 257, 1446, 46626, 11, 411, 309, 1669,
  385, 574, 20294, 11, 457, 286, 787, 534, 11, 286, 787, 534, 1401, 3642, 411, 11,
  50712], "temperature": 0.0, "avg_logprob": -0.19112039581546938, "compression_ratio":
  1.8275862068965518, "no_speech_prob": 0.00562828965485096}, {"id": 664, "seek":
  244428, "start": 2451.2400000000002, "end": 2454.6800000000003, "text": " you know,
  like the book of, I mean, the book of why is a bad example. That''s a really great
  book,", "tokens": [50712, 291, 458, 11, 411, 264, 1446, 295, 11, 286, 914, 11, 264,
  1446, 295, 983, 307, 257, 1578, 1365, 13, 663, 311, 257, 534, 869, 1446, 11, 50884],
  "temperature": 0.0, "avg_logprob": -0.19112039581546938, "compression_ratio": 1.8275862068965518,
  "no_speech_prob": 0.00562828965485096}, {"id": 665, "seek": 244428, "start": 2454.6800000000003,
  "end": 2459.88, "text": " like technical and I really really like that one. But
  most of these like popular science books,", "tokens": [50884, 411, 6191, 293, 286,
  534, 534, 411, 300, 472, 13, 583, 881, 295, 613, 411, 3743, 3497, 3642, 11, 51144],
  "temperature": 0.0, "avg_logprob": -0.19112039581546938, "compression_ratio": 1.8275862068965518,
  "no_speech_prob": 0.00562828965485096}, {"id": 666, "seek": 244428, "start": 2459.88,
  "end": 2464.44, "text": " I''d have to be like on an airplane or something like
  I, or are in the same with the category", "tokens": [51144, 286, 1116, 362, 281,
  312, 411, 322, 364, 17130, 420, 746, 411, 286, 11, 420, 366, 294, 264, 912, 365,
  264, 7719, 51372], "temperature": 0.0, "avg_logprob": -0.19112039581546938, "compression_ratio":
  1.8275862068965518, "no_speech_prob": 0.00562828965485096}, {"id": 667, "seek":
  244428, "start": 2464.44, "end": 2469.7200000000003, "text": " of medium articles
  that are popular science. Like, you know, I read research papers only,", "tokens":
  [51372, 295, 6399, 11290, 300, 366, 3743, 3497, 13, 1743, 11, 291, 458, 11, 286,
  1401, 2132, 10577, 787, 11, 51636], "temperature": 0.0, "avg_logprob": -0.19112039581546938,
  "compression_ratio": 1.8275862068965518, "no_speech_prob": 0.00562828965485096},
  {"id": 668, "seek": 246972, "start": 2470.68, "end": 2474.52, "text": " not to like
  be dismissive of anything else, but that''s just like the question of what particularly",
  "tokens": [50412, 406, 281, 411, 312, 16974, 488, 295, 1340, 1646, 11, 457, 300,
  311, 445, 411, 264, 1168, 295, 437, 4098, 50604], "temperature": 0.0, "avg_logprob":
  -0.25637316509960145, "compression_ratio": 1.5765472312703583, "no_speech_prob":
  0.004839413333684206}, {"id": 669, "seek": 246972, "start": 2474.52, "end": 2481.64,
  "text": " do I study. And in my approach is very people-centric. Like, you know,
  like when, say, Chelsea Finn", "tokens": [50604, 360, 286, 2979, 13, 400, 294, 452,
  3109, 307, 588, 561, 12, 45300, 13, 1743, 11, 291, 458, 11, 411, 562, 11, 584, 11,
  26527, 21066, 50960], "temperature": 0.0, "avg_logprob": -0.25637316509960145, "compression_ratio":
  1.5765472312703583, "no_speech_prob": 0.004839413333684206}, {"id": 670, "seek":
  246972, "start": 2482.52, "end": 2487.8799999999997, "text": " publishes a new paper
  on Twitter, I''ll go read that because I kind of have been following her", "tokens":
  [51004, 11374, 279, 257, 777, 3035, 322, 5794, 11, 286, 603, 352, 1401, 300, 570,
  286, 733, 295, 362, 668, 3480, 720, 51272], "temperature": 0.0, "avg_logprob": -0.25637316509960145,
  "compression_ratio": 1.5765472312703583, "no_speech_prob": 0.004839413333684206},
  {"id": 671, "seek": 246972, "start": 2487.8799999999997, "end": 2493.7999999999997,
  "text": " thinking, like Jeff Cloon is another example with the AIGA''s or Fran\u00e7ois
  Shalide. These kind of", "tokens": [51272, 1953, 11, 411, 7506, 31901, 266, 307,
  1071, 1365, 365, 264, 7318, 12570, 311, 420, 1526, 12368, 7376, 1160, 304, 482,
  13, 1981, 733, 295, 51568], "temperature": 0.0, "avg_logprob": -0.25637316509960145,
  "compression_ratio": 1.5765472312703583, "no_speech_prob": 0.004839413333684206},
  {"id": 672, "seek": 246972, "start": 2493.7999999999997, "end": 2498.2, "text":
  " people like I, like Michael Bronson with the geometric deep learning is another
  great example.", "tokens": [51568, 561, 411, 286, 11, 411, 5116, 1603, 892, 266,
  365, 264, 33246, 2452, 2539, 307, 1071, 869, 1365, 13, 51788], "temperature": 0.0,
  "avg_logprob": -0.25637316509960145, "compression_ratio": 1.5765472312703583, "no_speech_prob":
  0.004839413333684206}, {"id": 673, "seek": 249820, "start": 2498.9199999999996,
  "end": 2503.64, "text": " I hate doing these lists. I never like to do these lists
  because it''s so endless, like the vocabulary", "tokens": [50400, 286, 4700, 884,
  613, 14511, 13, 286, 1128, 411, 281, 360, 613, 14511, 570, 309, 311, 370, 16144,
  11, 411, 264, 19864, 50636], "temperature": 0.0, "avg_logprob": -0.1472941607963748,
  "compression_ratio": 1.794776119402985, "no_speech_prob": 0.04324910417199135},
  {"id": 674, "seek": 249820, "start": 2503.64, "end": 2509.72, "text": " you need
  to kind of assess, like I''ve left off so many people, but you know, I like the
  people''s", "tokens": [50636, 291, 643, 281, 733, 295, 5877, 11, 411, 286, 600,
  1411, 766, 370, 867, 561, 11, 457, 291, 458, 11, 286, 411, 264, 561, 311, 50940],
  "temperature": 0.0, "avg_logprob": -0.1472941607963748, "compression_ratio": 1.794776119402985,
  "no_speech_prob": 0.04324910417199135}, {"id": 675, "seek": 249820, "start": 2509.72,
  "end": 2513.8799999999997, "text": " centric focus and I try to get to know these
  people and understand like how they think of these", "tokens": [50940, 1489, 1341,
  1879, 293, 286, 853, 281, 483, 281, 458, 613, 561, 293, 1223, 411, 577, 436, 519,
  295, 613, 51148], "temperature": 0.0, "avg_logprob": -0.1472941607963748, "compression_ratio":
  1.794776119402985, "no_speech_prob": 0.04324910417199135}, {"id": 676, "seek": 249820,
  "start": 2513.8799999999997, "end": 2519.48, "text": " things. It''s like the same
  thing as you go to the conference. Sometimes you don''t go to that", "tokens": [51148,
  721, 13, 467, 311, 411, 264, 912, 551, 382, 291, 352, 281, 264, 7586, 13, 4803,
  291, 500, 380, 352, 281, 300, 51428], "temperature": 0.0, "avg_logprob": -0.1472941607963748,
  "compression_ratio": 1.794776119402985, "no_speech_prob": 0.04324910417199135},
  {"id": 677, "seek": 249820, "start": 2519.48, "end": 2525.3199999999997, "text":
  " specific topic. Maybe when you''re a little bit more junior, you do, but later
  in your career,", "tokens": [51428, 2685, 4829, 13, 2704, 562, 291, 434, 257, 707,
  857, 544, 16195, 11, 291, 360, 11, 457, 1780, 294, 428, 3988, 11, 51720], "temperature":
  0.0, "avg_logprob": -0.1472941607963748, "compression_ratio": 1.794776119402985,
  "no_speech_prob": 0.04324910417199135}, {"id": 678, "seek": 252532, "start": 2525.4,
  "end": 2531.2400000000002, "text": " like academic or industrial, you actually go
  to listen to that person because they might not", "tokens": [50368, 411, 7778, 420,
  9987, 11, 291, 767, 352, 281, 2140, 281, 300, 954, 570, 436, 1062, 406, 50660],
  "temperature": 0.0, "avg_logprob": -0.1715004298997962, "compression_ratio": 1.7107142857142856,
  "no_speech_prob": 0.022812463343143463}, {"id": 679, "seek": 252532, "start": 2531.2400000000002,
  "end": 2538.2000000000003, "text": " give you any novel idea, but they might give
  you so much experience that you daily, like really need,", "tokens": [50660, 976,
  291, 604, 7613, 1558, 11, 457, 436, 1062, 976, 291, 370, 709, 1752, 300, 291, 5212,
  11, 411, 534, 643, 11, 51008], "temperature": 0.0, "avg_logprob": -0.1715004298997962,
  "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.022812463343143463},
  {"id": 680, "seek": 252532, "start": 2538.2000000000003, "end": 2544.84, "text":
  " right? Yeah, and just following the timeline of their work, it helped, like their
  newest work will", "tokens": [51008, 558, 30, 865, 11, 293, 445, 3480, 264, 12933,
  295, 641, 589, 11, 309, 4254, 11, 411, 641, 17569, 589, 486, 51340], "temperature":
  0.0, "avg_logprob": -0.1715004298997962, "compression_ratio": 1.7107142857142856,
  "no_speech_prob": 0.022812463343143463}, {"id": 681, "seek": 252532, "start": 2544.84,
  "end": 2549.32, "text": " help you realize, oh, that''s their thinking in the past
  work too. I kind of see how they''re", "tokens": [51340, 854, 291, 4325, 11, 1954,
  11, 300, 311, 641, 1953, 294, 264, 1791, 589, 886, 13, 286, 733, 295, 536, 577,
  436, 434, 51564], "temperature": 0.0, "avg_logprob": -0.1715004298997962, "compression_ratio":
  1.7107142857142856, "no_speech_prob": 0.022812463343143463}, {"id": 682, "seek":
  252532, "start": 2549.32, "end": 2553.88, "text": " thinking about these things.
  And it''s like, you know, everybody thinks so abstract. They have", "tokens": [51564,
  1953, 466, 613, 721, 13, 400, 309, 311, 411, 11, 291, 458, 11, 2201, 7309, 370,
  12649, 13, 814, 362, 51792], "temperature": 0.0, "avg_logprob": -0.1715004298997962,
  "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.022812463343143463},
  {"id": 683, "seek": 255388, "start": 2553.88, "end": 2559.56, "text": " this idea,
  this vision, and it can be hard to communicate the vision in writing or videos.
  So", "tokens": [50364, 341, 1558, 11, 341, 5201, 11, 293, 309, 393, 312, 1152, 281,
  7890, 264, 5201, 294, 3579, 420, 2145, 13, 407, 50648], "temperature": 0.0, "avg_logprob":
  -0.214063028494517, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.013443772681057453},
  {"id": 684, "seek": 255388, "start": 2559.56, "end": 2566.2000000000003, "text":
  " yeah, just like you said, I think just repeated exposure to the same person is
  like, hopefully", "tokens": [50648, 1338, 11, 445, 411, 291, 848, 11, 286, 519,
  445, 10477, 10420, 281, 264, 912, 954, 307, 411, 11, 4696, 50980], "temperature":
  0.0, "avg_logprob": -0.214063028494517, "compression_ratio": 1.5679012345679013,
  "no_speech_prob": 0.013443772681057453}, {"id": 685, "seek": 255388, "start": 2566.2000000000003,
  "end": 2572.36, "text": " that''s Henry AI last thing. Yeah, absolutely. I''m pretty
  sure. I saw some really great comments", "tokens": [50980, 300, 311, 11085, 7318,
  1036, 551, 13, 865, 11, 3122, 13, 286, 478, 1238, 988, 13, 286, 1866, 512, 534,
  869, 3053, 51288], "temperature": 0.0, "avg_logprob": -0.214063028494517, "compression_ratio":
  1.5679012345679013, "no_speech_prob": 0.013443772681057453}, {"id": 686, "seek":
  255388, "start": 2572.36, "end": 2577.08, "text": " underneath your videos, you
  know, some people were saying, I can''t wait for the next one. So you", "tokens":
  [51288, 7223, 428, 2145, 11, 291, 458, 11, 512, 561, 645, 1566, 11, 286, 393, 380,
  1699, 337, 264, 958, 472, 13, 407, 291, 51524], "temperature": 0.0, "avg_logprob":
  -0.214063028494517, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.013443772681057453},
  {"id": 687, "seek": 257708, "start": 2577.16, "end": 2584.04, "text": " definitely
  doing great job there. So could as to you for doing that for so long actually. I",
  "tokens": [50368, 2138, 884, 869, 1691, 456, 13, 407, 727, 382, 281, 291, 337, 884,
  300, 337, 370, 938, 767, 13, 286, 50712], "temperature": 0.0, "avg_logprob": -0.1759114424387614,
  "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.03125854954123497},
  {"id": 688, "seek": 257708, "start": 2584.04, "end": 2588.2799999999997, "text":
  " don''t know for how long you''ve been doing this, but you have a ton of videos.
  Yeah, and I really", "tokens": [50712, 500, 380, 458, 337, 577, 938, 291, 600, 668,
  884, 341, 11, 457, 291, 362, 257, 2952, 295, 2145, 13, 865, 11, 293, 286, 534, 50924],
  "temperature": 0.0, "avg_logprob": -0.1759114424387614, "compression_ratio": 1.7272727272727273,
  "no_speech_prob": 0.03125854954123497}, {"id": 689, "seek": 257708, "start": 2588.2799999999997,
  "end": 2592.92, "text": " appreciate it. You know, the people who keep commenting,
  I, you know, I recognize your profiles,", "tokens": [50924, 4449, 309, 13, 509,
  458, 11, 264, 561, 567, 1066, 29590, 11, 286, 11, 291, 458, 11, 286, 5521, 428,
  23693, 11, 51156], "temperature": 0.0, "avg_logprob": -0.1759114424387614, "compression_ratio":
  1.7272727272727273, "no_speech_prob": 0.03125854954123497}, {"id": 690, "seek":
  257708, "start": 2592.92, "end": 2598.84, "text": " and I do really, really appreciate
  it. So it helps me keep making the videos and staying convinced of", "tokens": [51156,
  293, 286, 360, 534, 11, 534, 4449, 309, 13, 407, 309, 3665, 385, 1066, 1455, 264,
  2145, 293, 7939, 12561, 295, 51452], "temperature": 0.0, "avg_logprob": -0.1759114424387614,
  "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.03125854954123497},
  {"id": 691, "seek": 257708, "start": 2598.84, "end": 2604.92, "text": " that medium
  of YouTube being one of the ways to express these ideas. I''d say like even,", "tokens":
  [51452, 300, 6399, 295, 3088, 885, 472, 295, 264, 2098, 281, 5109, 613, 3487, 13,
  286, 1116, 584, 411, 754, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1759114424387614,
  "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.03125854954123497},
  {"id": 692, "seek": 260492, "start": 2605.8, "end": 2611.0, "text": " even more
  so than writing papers that you submit to these conferences. Sometimes I, you know,",
  "tokens": [50408, 754, 544, 370, 813, 3579, 10577, 300, 291, 10315, 281, 613, 22032,
  13, 4803, 286, 11, 291, 458, 11, 50668], "temperature": 0.0, "avg_logprob": -0.13820074438079585,
  "compression_ratio": 1.685121107266436, "no_speech_prob": 0.00940753985196352},
  {"id": 693, "seek": 260492, "start": 2611.0, "end": 2616.6800000000003, "text":
  " I think making a YouTube video can be a powerful way to share ideas. I don''t
  know if I want to", "tokens": [50668, 286, 519, 1455, 257, 3088, 960, 393, 312,
  257, 4005, 636, 281, 2073, 3487, 13, 286, 500, 380, 458, 498, 286, 528, 281, 50952],
  "temperature": 0.0, "avg_logprob": -0.13820074438079585, "compression_ratio": 1.685121107266436,
  "no_speech_prob": 0.00940753985196352}, {"id": 694, "seek": 260492, "start": 2616.6800000000003,
  "end": 2620.76, "text": " completely put my flag on that idea because I, you know,
  these reviews, you do get some really good", "tokens": [50952, 2584, 829, 452, 7166,
  322, 300, 1558, 570, 286, 11, 291, 458, 11, 613, 10229, 11, 291, 360, 483, 512,
  534, 665, 51156], "temperature": 0.0, "avg_logprob": -0.13820074438079585, "compression_ratio":
  1.685121107266436, "no_speech_prob": 0.00940753985196352}, {"id": 695, "seek": 260492,
  "start": 2620.76, "end": 2624.92, "text": " reviews. Like as I mentioned previously
  at the beginning of the video, I, you know, I literally got", "tokens": [51156,
  10229, 13, 1743, 382, 286, 2835, 8046, 412, 264, 2863, 295, 264, 960, 11, 286, 11,
  291, 458, 11, 286, 3736, 658, 51364], "temperature": 0.0, "avg_logprob": -0.13820074438079585,
  "compression_ratio": 1.685121107266436, "no_speech_prob": 0.00940753985196352},
  {"id": 696, "seek": 260492, "start": 2624.92, "end": 2632.04, "text": " smashed
  on my ICLR reviews. They were not good, but I got, I got really high quality feedback.
  So,", "tokens": [51364, 33269, 322, 452, 14360, 31722, 10229, 13, 814, 645, 406,
  665, 11, 457, 286, 658, 11, 286, 658, 534, 1090, 3125, 5824, 13, 407, 11, 51720],
  "temperature": 0.0, "avg_logprob": -0.13820074438079585, "compression_ratio": 1.685121107266436,
  "no_speech_prob": 0.00940753985196352}, {"id": 697, "seek": 263204, "start": 2632.04,
  "end": 2637.16, "text": " yes. You know, you''re learning from it. You''re learning.
  Right. Yeah. Actually, one of my managers used", "tokens": [50364, 2086, 13, 509,
  458, 11, 291, 434, 2539, 490, 309, 13, 509, 434, 2539, 13, 1779, 13, 865, 13, 5135,
  11, 472, 295, 452, 14084, 1143, 50620], "temperature": 0.0, "avg_logprob": -0.1615606689453125,
  "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.015546012669801712},
  {"id": 698, "seek": 263204, "start": 2637.16, "end": 2644.68, "text": " to say feedback
  is gold. So even if it feels painful, take it because because the problem is that",
  "tokens": [50620, 281, 584, 5824, 307, 3821, 13, 407, 754, 498, 309, 3417, 11697,
  11, 747, 309, 570, 570, 264, 1154, 307, 300, 50996], "temperature": 0.0, "avg_logprob":
  -0.1615606689453125, "compression_ratio": 1.7857142857142858, "no_speech_prob":
  0.015546012669801712}, {"id": 699, "seek": 263204, "start": 2644.68, "end": 2649.56,
  "text": " sometimes, especially as you grow in your career, you know, at some point
  you will be the role model", "tokens": [50996, 2171, 11, 2318, 382, 291, 1852, 294,
  428, 3988, 11, 291, 458, 11, 412, 512, 935, 291, 486, 312, 264, 3090, 2316, 51240],
  "temperature": 0.0, "avg_logprob": -0.1615606689453125, "compression_ratio": 1.7857142857142858,
  "no_speech_prob": 0.015546012669801712}, {"id": 700, "seek": 263204, "start": 2649.56,
  "end": 2654.6, "text": " for some other people. Now, where do you get the feedback
  from nowhere? Because you''re the person", "tokens": [51240, 337, 512, 661, 561,
  13, 823, 11, 689, 360, 291, 483, 264, 5824, 490, 11159, 30, 1436, 291, 434, 264,
  954, 51492], "temperature": 0.0, "avg_logprob": -0.1615606689453125, "compression_ratio":
  1.7857142857142858, "no_speech_prob": 0.015546012669801712}, {"id": 701, "seek":
  263204, "start": 2654.6, "end": 2660.12, "text": " giving feedback. But you still
  need to grow. You still have pains, you have doubts, you have ideas,", "tokens":
  [51492, 2902, 5824, 13, 583, 291, 920, 643, 281, 1852, 13, 509, 920, 362, 29774,
  11, 291, 362, 22618, 11, 291, 362, 3487, 11, 51768], "temperature": 0.0, "avg_logprob":
  -0.1615606689453125, "compression_ratio": 1.7857142857142858, "no_speech_prob":
  0.015546012669801712}, {"id": 702, "seek": 266012, "start": 2660.12, "end": 2664.44,
  "text": " you need validation. And maybe you''re doing something wrong as well at
  some point. Maybe somebody", "tokens": [50364, 291, 643, 24071, 13, 400, 1310, 291,
  434, 884, 746, 2085, 382, 731, 412, 512, 935, 13, 2704, 2618, 50580], "temperature":
  0.0, "avg_logprob": -0.16474604399307916, "compression_ratio": 1.721254355400697,
  "no_speech_prob": 0.013061142526566982}, {"id": 703, "seek": 266012, "start": 2664.44,
  "end": 2669.48, "text": " is intimidated to tell you that because you are at the
  top. You are like the boss or whatever. You", "tokens": [50580, 307, 40234, 281,
  980, 291, 300, 570, 291, 366, 412, 264, 1192, 13, 509, 366, 411, 264, 5741, 420,
  2035, 13, 509, 50832], "temperature": 0.0, "avg_logprob": -0.16474604399307916,
  "compression_ratio": 1.721254355400697, "no_speech_prob": 0.013061142526566982},
  {"id": 704, "seek": 266012, "start": 2669.48, "end": 2676.8399999999997, "text":
  " know, like who gives you feedback at that point? They actually recommend to turn
  to, you know,", "tokens": [50832, 458, 11, 411, 567, 2709, 291, 5824, 412, 300,
  935, 30, 814, 767, 2748, 281, 1261, 281, 11, 291, 458, 11, 51200], "temperature":
  0.0, "avg_logprob": -0.16474604399307916, "compression_ratio": 1.721254355400697,
  "no_speech_prob": 0.013061142526566982}, {"id": 705, "seek": 266012, "start": 2676.8399999999997,
  "end": 2681.7999999999997, "text": " professional coaches and kind of those people
  who can actually steer you in some direction. Right.", "tokens": [51200, 4843, 17503,
  293, 733, 295, 729, 561, 567, 393, 767, 30814, 291, 294, 512, 3513, 13, 1779, 13,
  51448], "temperature": 0.0, "avg_logprob": -0.16474604399307916, "compression_ratio":
  1.721254355400697, "no_speech_prob": 0.013061142526566982}, {"id": 706, "seek":
  266012, "start": 2681.7999999999997, "end": 2687.72, "text": " Oh, maybe you can
  unload your thoughts. Have you found yourself in that situation? Or what, what do
  you", "tokens": [51448, 876, 11, 1310, 291, 393, 32165, 428, 4598, 13, 3560, 291,
  1352, 1803, 294, 300, 2590, 30, 1610, 437, 11, 437, 360, 291, 51744], "temperature":
  0.0, "avg_logprob": -0.16474604399307916, "compression_ratio": 1.721254355400697,
  "no_speech_prob": 0.013061142526566982}, {"id": 707, "seek": 268772, "start": 2687.72,
  "end": 2697.24, "text": " think? Yeah. Well, I mean, I''m in a lucky situation where
  I do have a formal PhD advisor that,", "tokens": [50364, 519, 30, 865, 13, 1042,
  11, 286, 914, 11, 286, 478, 294, 257, 6356, 2590, 689, 286, 360, 362, 257, 9860,
  14476, 19161, 300, 11, 50840], "temperature": 0.0, "avg_logprob": -0.14555221973079266,
  "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.001687857904471457},
  {"id": 708, "seek": 268772, "start": 2697.24, "end": 2703.3999999999996, "text":
  " as I mentioned, I speak on the phone with very often. And, and you know, my PhD
  advisor and I", "tokens": [50840, 382, 286, 2835, 11, 286, 1710, 322, 264, 2593,
  365, 588, 2049, 13, 400, 11, 293, 291, 458, 11, 452, 14476, 19161, 293, 286, 51148],
  "temperature": 0.0, "avg_logprob": -0.14555221973079266, "compression_ratio": 1.5666666666666667,
  "no_speech_prob": 0.001687857904471457}, {"id": 709, "seek": 268772, "start": 2703.3999999999996,
  "end": 2708.04, "text": " had a relationship for so long that he like introduced
  machine learning to me. So it''s like,", "tokens": [51148, 632, 257, 2480, 337,
  370, 938, 300, 415, 411, 7268, 3479, 2539, 281, 385, 13, 407, 309, 311, 411, 11,
  51380], "temperature": 0.0, "avg_logprob": -0.14555221973079266, "compression_ratio":
  1.5666666666666667, "no_speech_prob": 0.001687857904471457}, {"id": 710, "seek":
  268772, "start": 2708.04, "end": 2714.4399999999996, "text": " I was a basketball
  player, you know, taking classes. And I, and so this was my introduction to", "tokens":
  [51380, 286, 390, 257, 11767, 4256, 11, 291, 458, 11, 1940, 5359, 13, 400, 286,
  11, 293, 370, 341, 390, 452, 9339, 281, 51700], "temperature": 0.0, "avg_logprob":
  -0.14555221973079266, "compression_ratio": 1.5666666666666667, "no_speech_prob":
  0.001687857904471457}, {"id": 711, "seek": 271444, "start": 2714.44, "end": 2720.76,
  "text": " machine learning. I like, I hardly understood like, you know, like a tea
  test statistical regression", "tokens": [50364, 3479, 2539, 13, 286, 411, 11, 286,
  13572, 7320, 411, 11, 291, 458, 11, 411, 257, 5817, 1500, 22820, 24590, 50680],
  "temperature": 0.0, "avg_logprob": -0.130888427734375, "compression_ratio": 1.7392857142857143,
  "no_speech_prob": 0.004426426719874144}, {"id": 712, "seek": 271444, "start": 2720.76,
  "end": 2725.64, "text": " analysis before this class. So it''s like, so I''m, I''ve
  had the same advisor for a long time in", "tokens": [50680, 5215, 949, 341, 1508,
  13, 407, 309, 311, 411, 11, 370, 286, 478, 11, 286, 600, 632, 264, 912, 19161, 337,
  257, 938, 565, 294, 50924], "temperature": 0.0, "avg_logprob": -0.130888427734375,
  "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.004426426719874144},
  {"id": 713, "seek": 271444, "start": 2725.64, "end": 2730.68, "text": " that regard,
  like a formal academic advisor. And then meeting people like Bob and, you know,",
  "tokens": [50924, 300, 3843, 11, 411, 257, 9860, 7778, 19161, 13, 400, 550, 3440,
  561, 411, 6085, 293, 11, 291, 458, 11, 51176], "temperature": 0.0, "avg_logprob":
  -0.130888427734375, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.004426426719874144},
  {"id": 714, "seek": 271444, "start": 2730.68, "end": 2736.04, "text": " you and
  I as we talk now, I, you know, trying to reach out and pick the brains of people
  and see", "tokens": [51176, 291, 293, 286, 382, 321, 751, 586, 11, 286, 11, 291,
  458, 11, 1382, 281, 2524, 484, 293, 1888, 264, 15442, 295, 561, 293, 536, 51444],
  "temperature": 0.0, "avg_logprob": -0.130888427734375, "compression_ratio": 1.7392857142857143,
  "no_speech_prob": 0.004426426719874144}, {"id": 715, "seek": 271444, "start": 2736.04,
  "end": 2741.4, "text": " what they think. I guess. Yeah. So basically they are like,
  they become like, you might have multiple", "tokens": [51444, 437, 436, 519, 13,
  286, 2041, 13, 865, 13, 407, 1936, 436, 366, 411, 11, 436, 1813, 411, 11, 291, 1062,
  362, 3866, 51712], "temperature": 0.0, "avg_logprob": -0.130888427734375, "compression_ratio":
  1.7392857142857143, "no_speech_prob": 0.004426426719874144}, {"id": 716, "seek":
  274140, "start": 2741.4, "end": 2746.2000000000003, "text": " role models. And sometimes,
  you know, like they also say, you do not need a physical person with", "tokens":
  [50364, 3090, 5245, 13, 400, 2171, 11, 291, 458, 11, 411, 436, 611, 584, 11, 291,
  360, 406, 643, 257, 4001, 954, 365, 50604], "temperature": 0.0, "avg_logprob": -0.09971632379474062,
  "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.03275059908628464},
  {"id": 717, "seek": 274140, "start": 2746.2000000000003, "end": 2751.64, "text":
  " whom you talk, but it could be some kind of online person. Like for me, it used
  to be for a long", "tokens": [50604, 7101, 291, 751, 11, 457, 309, 727, 312, 512,
  733, 295, 2950, 954, 13, 1743, 337, 385, 11, 309, 1143, 281, 312, 337, 257, 938,
  50876], "temperature": 0.0, "avg_logprob": -0.09971632379474062, "compression_ratio":
  1.6802721088435375, "no_speech_prob": 0.03275059908628464}, {"id": 718, "seek":
  274140, "start": 2751.64, "end": 2757.48, "text": " time, Elon Musk, because I''ve
  been focusing on building startups. And, and his approach to startups", "tokens":
  [50876, 565, 11, 28498, 26019, 11, 570, 286, 600, 668, 8416, 322, 2390, 28041, 13,
  400, 11, 293, 702, 3109, 281, 28041, 51168], "temperature": 0.0, "avg_logprob":
  -0.09971632379474062, "compression_ratio": 1.6802721088435375, "no_speech_prob":
  0.03275059908628464}, {"id": 719, "seek": 274140, "start": 2757.48, "end": 2763.64,
  "text": " was not like, hey, you know, go unleash yourself, get rid of your doubt
  and just do it. No, he''s so", "tokens": [51168, 390, 406, 411, 11, 4177, 11, 291,
  458, 11, 352, 49814, 1803, 11, 483, 3973, 295, 428, 6385, 293, 445, 360, 309, 13,
  883, 11, 415, 311, 370, 51476], "temperature": 0.0, "avg_logprob": -0.09971632379474062,
  "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.03275059908628464},
  {"id": 720, "seek": 274140, "start": 2763.64, "end": 2768.6, "text": " deep into
  what he does. Like at some point, I want to record a podcast where I would like
  to talk to", "tokens": [51476, 2452, 666, 437, 415, 775, 13, 1743, 412, 512, 935,
  11, 286, 528, 281, 2136, 257, 7367, 689, 286, 576, 411, 281, 751, 281, 51724], "temperature":
  0.0, "avg_logprob": -0.09971632379474062, "compression_ratio": 1.6802721088435375,
  "no_speech_prob": 0.03275059908628464}, {"id": 721, "seek": 276860, "start": 2768.6,
  "end": 2773.72, "text": " you or talk to somebody to actually explain and kind of
  does it resonate with you, like he''s", "tokens": [50364, 291, 420, 751, 281, 2618,
  281, 767, 2903, 293, 733, 295, 775, 309, 34285, 365, 291, 11, 411, 415, 311, 50620],
  "temperature": 0.0, "avg_logprob": -0.15541689736502512, "compression_ratio": 1.7464285714285714,
  "no_speech_prob": 0.0054707396775484085}, {"id": 722, "seek": 276860, "start": 2773.72,
  "end": 2778.12, "text": " thinking, like, first, you need to try this before automating
  this. You need to repeat it several", "tokens": [50620, 1953, 11, 411, 11, 700,
  11, 291, 643, 281, 853, 341, 949, 3553, 990, 341, 13, 509, 643, 281, 7149, 309,
  2940, 50840], "temperature": 0.0, "avg_logprob": -0.15541689736502512, "compression_ratio":
  1.7464285714285714, "no_speech_prob": 0.0054707396775484085}, {"id": 723, "seek":
  276860, "start": 2778.12, "end": 2783.16, "text": " times to learn new mistakes
  and blah, blah, blah. So it''s like an amazing way. And he like build this", "tokens":
  [50840, 1413, 281, 1466, 777, 8038, 293, 12288, 11, 12288, 11, 12288, 13, 407, 309,
  311, 411, 364, 2243, 636, 13, 400, 415, 411, 1322, 341, 51092], "temperature": 0.0,
  "avg_logprob": -0.15541689736502512, "compression_ratio": 1.7464285714285714, "no_speech_prob":
  0.0054707396775484085}, {"id": 724, "seek": 276860, "start": 2783.16, "end": 2789.08,
  "text": " kind of, you know, a thought machinery that he applies to any problem,
  right? So any problem that", "tokens": [51092, 733, 295, 11, 291, 458, 11, 257,
  1194, 27302, 300, 415, 13165, 281, 604, 1154, 11, 558, 30, 407, 604, 1154, 300,
  51388], "temperature": 0.0, "avg_logprob": -0.15541689736502512, "compression_ratio":
  1.7464285714285714, "no_speech_prob": 0.0054707396775484085}, {"id": 725, "seek":
  276860, "start": 2789.08, "end": 2795.56, "text": " lands in his hands, he''s like,
  I can try it step by step like that and see what happens. And maybe", "tokens":
  [51388, 5949, 294, 702, 2377, 11, 415, 311, 411, 11, 286, 393, 853, 309, 1823, 538,
  1823, 411, 300, 293, 536, 437, 2314, 13, 400, 1310, 51712], "temperature": 0.0,
  "avg_logprob": -0.15541689736502512, "compression_ratio": 1.7464285714285714, "no_speech_prob":
  0.0054707396775484085}, {"id": 726, "seek": 279556, "start": 2795.56, "end": 2799.48,
  "text": " at some point it just drops out and you''re like, okay, I''m done here.
  I''m moving to the next one,", "tokens": [50364, 412, 512, 935, 309, 445, 11438,
  484, 293, 291, 434, 411, 11, 1392, 11, 286, 478, 1096, 510, 13, 286, 478, 2684,
  281, 264, 958, 472, 11, 50560], "temperature": 0.0, "avg_logprob": -0.16007035573323566,
  "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.009614890441298485},
  {"id": 727, "seek": 279556, "start": 2799.48, "end": 2802.92, "text": " right? So
  I''m not going to waste my time. And he''s a super productive guy, as we know.",
  "tokens": [50560, 558, 30, 407, 286, 478, 406, 516, 281, 5964, 452, 565, 13, 400,
  415, 311, 257, 1687, 13304, 2146, 11, 382, 321, 458, 13, 50732], "temperature":
  0.0, "avg_logprob": -0.16007035573323566, "compression_ratio": 1.6346153846153846,
  "no_speech_prob": 0.009614890441298485}, {"id": 728, "seek": 279556, "start": 2804.12,
  "end": 2807.88, "text": " So I mean, sometimes it could be just an online person
  that you follow. And as you said,", "tokens": [50792, 407, 286, 914, 11, 2171, 309,
  727, 312, 445, 364, 2950, 954, 300, 291, 1524, 13, 400, 382, 291, 848, 11, 50980],
  "temperature": 0.0, "avg_logprob": -0.16007035573323566, "compression_ratio": 1.6346153846153846,
  "no_speech_prob": 0.009614890441298485}, {"id": 729, "seek": 279556, "start": 2808.44,
  "end": 2812.84, "text": " you do this on Twitter, like you said, like maniacally
  refreshing the tweeters.", "tokens": [51008, 291, 360, 341, 322, 5794, 11, 411,
  291, 848, 11, 411, 47193, 379, 19772, 264, 6986, 6202, 13, 51228], "temperature":
  0.0, "avg_logprob": -0.16007035573323566, "compression_ratio": 1.6346153846153846,
  "no_speech_prob": 0.009614890441298485}, {"id": 730, "seek": 279556, "start": 2814.52,
  "end": 2820.68, "text": " So just stay stay safe as well there. But at the same
  time, I think the", "tokens": [51312, 407, 445, 1754, 1754, 3273, 382, 731, 456,
  13, 583, 412, 264, 912, 565, 11, 286, 519, 264, 51620], "temperature": 0.0, "avg_logprob":
  -0.16007035573323566, "compression_ratio": 1.6346153846153846, "no_speech_prob":
  0.009614890441298485}, {"id": 731, "seek": 282068, "start": 2820.68, "end": 2826.6,
  "text": " respiratory time in your life, when you''re learning a ton. And later
  in your life, you will be kind", "tokens": [50364, 27038, 565, 294, 428, 993, 11,
  562, 291, 434, 2539, 257, 2952, 13, 400, 1780, 294, 428, 993, 11, 291, 486, 312,
  733, 50660], "temperature": 0.0, "avg_logprob": -0.1959641436313061, "compression_ratio":
  1.6919642857142858, "no_speech_prob": 0.031405240297317505}, {"id": 732, "seek":
  282068, "start": 2826.6, "end": 2832.52, "text": " of generating fruit out of it
  mostly. Or maybe you will be telling to other people and maybe", "tokens": [50660,
  295, 17746, 6773, 484, 295, 309, 5240, 13, 1610, 1310, 291, 486, 312, 3585, 281,
  661, 561, 293, 1310, 50956], "temperature": 0.0, "avg_logprob": -0.1959641436313061,
  "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.031405240297317505},
  {"id": 733, "seek": 282068, "start": 2832.52, "end": 2838.44, "text": " inspiring
  them more and more. And then leading some research groups and the work, you know,",
  "tokens": [50956, 15883, 552, 544, 293, 544, 13, 400, 550, 5775, 512, 2132, 3935,
  293, 264, 589, 11, 291, 458, 11, 51252], "temperature": 0.0, "avg_logprob": -0.1959641436313061,
  "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.031405240297317505},
  {"id": 734, "seek": 282068, "start": 2838.44, "end": 2846.2799999999997, "text":
  " teams. And that''s that''s totally fine. But I also wanted to call out your idea
  that I think is", "tokens": [51252, 5491, 13, 400, 300, 311, 300, 311, 3879, 2489,
  13, 583, 286, 611, 1415, 281, 818, 484, 428, 1558, 300, 286, 519, 307, 51644], "temperature":
  0.0, "avg_logprob": -0.1959641436313061, "compression_ratio": 1.6919642857142858,
  "no_speech_prob": 0.031405240297317505}, {"id": 735, "seek": 284628, "start": 2846.28,
  "end": 2851.48, "text": " quite instructive for many of us. And hopefully to our
  listeners that yes, do go go and read", "tokens": [50364, 1596, 7232, 488, 337,
  867, 295, 505, 13, 400, 4696, 281, 527, 23274, 300, 2086, 11, 360, 352, 352, 293,
  1401, 50624], "temperature": 0.0, "avg_logprob": -0.12946812006143424, "compression_ratio":
  1.6566523605150214, "no_speech_prob": 0.04035257175564766}, {"id": 736, "seek":
  284628, "start": 2851.48, "end": 2858.76, "text": " papers because as Andrew Ang
  put it, he said, if you read a paper every weekend, let''s say you have", "tokens":
  [50624, 10577, 570, 382, 10110, 4521, 829, 309, 11, 415, 848, 11, 498, 291, 1401,
  257, 3035, 633, 6711, 11, 718, 311, 584, 291, 362, 50988], "temperature": 0.0, "avg_logprob":
  -0.12946812006143424, "compression_ratio": 1.6566523605150214, "no_speech_prob":
  0.04035257175564766}, {"id": 737, "seek": 284628, "start": 2858.76, "end": 2865.0,
  "text": " a full-time job, you don''t have time to read it, you can read it on the
  weekend. At some point,", "tokens": [50988, 257, 1577, 12, 3766, 1691, 11, 291,
  500, 380, 362, 565, 281, 1401, 309, 11, 291, 393, 1401, 309, 322, 264, 6711, 13,
  1711, 512, 935, 11, 51300], "temperature": 0.0, "avg_logprob": -0.12946812006143424,
  "compression_ratio": 1.6566523605150214, "no_speech_prob": 0.04035257175564766},
  {"id": 738, "seek": 284628, "start": 2866.0400000000004, "end": 2870.76, "text":
  " and he also recommended to start coding, you know, like actually you didn''t find
  the code for it,", "tokens": [51352, 293, 415, 611, 9628, 281, 722, 17720, 11, 291,
  458, 11, 411, 767, 291, 994, 380, 915, 264, 3089, 337, 309, 11, 51588], "temperature":
  0.0, "avg_logprob": -0.12946812006143424, "compression_ratio": 1.6566523605150214,
  "no_speech_prob": 0.04035257175564766}, {"id": 739, "seek": 287076, "start": 2870.76,
  "end": 2876.6000000000004, "text": " just try to implement the idea, right? At some
  point, after reading the papers, you will actually", "tokens": [50364, 445, 853,
  281, 4445, 264, 1558, 11, 558, 30, 1711, 512, 935, 11, 934, 3760, 264, 10577, 11,
  291, 486, 767, 50656], "temperature": 0.0, "avg_logprob": -0.14235063129001194,
  "compression_ratio": 1.634453781512605, "no_speech_prob": 0.002434796653687954},
  {"id": 740, "seek": 287076, "start": 2876.6000000000004, "end": 2883.0800000000004,
  "text": " start generating ideas because you will find gaps in the thinking of the
  authors on all of these", "tokens": [50656, 722, 17746, 3487, 570, 291, 486, 915,
  15031, 294, 264, 1953, 295, 264, 16552, 322, 439, 295, 613, 50980], "temperature":
  0.0, "avg_logprob": -0.14235063129001194, "compression_ratio": 1.634453781512605,
  "no_speech_prob": 0.002434796653687954}, {"id": 741, "seek": 287076, "start": 2883.0800000000004,
  "end": 2888.44, "text": " papers. And nobody is doing perfect job there. They''re
  doing the publishable work, right? And so", "tokens": [50980, 10577, 13, 400, 5079,
  307, 884, 2176, 1691, 456, 13, 814, 434, 884, 264, 11374, 712, 589, 11, 558, 30,
  400, 370, 51248], "temperature": 0.0, "avg_logprob": -0.14235063129001194, "compression_ratio":
  1.634453781512605, "no_speech_prob": 0.002434796653687954}, {"id": 742, "seek":
  287076, "start": 2889.2400000000002, "end": 2896.6000000000004, "text": " I think
  that resonates with you as well. Yeah, definitely. You definitely like switch gears
  where", "tokens": [51288, 286, 519, 300, 41051, 365, 291, 382, 731, 13, 865, 11,
  2138, 13, 509, 2138, 411, 3679, 20915, 689, 51656], "temperature": 0.0, "avg_logprob":
  -0.14235063129001194, "compression_ratio": 1.634453781512605, "no_speech_prob":
  0.002434796653687954}, {"id": 743, "seek": 289660, "start": 2897.16, "end": 2901.96,
  "text": " you become an idea machine like you say where you read a paper and you''ll
  have like a billion ideas", "tokens": [50392, 291, 1813, 364, 1558, 3479, 411, 291,
  584, 689, 291, 1401, 257, 3035, 293, 291, 603, 362, 411, 257, 5218, 3487, 50632],
  "temperature": 0.0, "avg_logprob": -0.15720769130822385, "compression_ratio": 1.810035842293907,
  "no_speech_prob": 0.004141695331782103}, {"id": 744, "seek": 289660, "start": 2901.96,
  "end": 2907.48, "text": " for how to extend it. And then you''ll transition to this
  part, which is what I''m learning now. And,", "tokens": [50632, 337, 577, 281, 10101,
  309, 13, 400, 550, 291, 603, 6034, 281, 341, 644, 11, 597, 307, 437, 286, 478, 2539,
  586, 13, 400, 11, 50908], "temperature": 0.0, "avg_logprob": -0.15720769130822385,
  "compression_ratio": 1.810035842293907, "no_speech_prob": 0.004141695331782103},
  {"id": 745, "seek": 289660, "start": 2907.48, "end": 2913.0, "text": " you know,
  as I''m in my last year, I''ve been two years in my PhD and the transition for me
  is going", "tokens": [50908, 291, 458, 11, 382, 286, 478, 294, 452, 1036, 1064,
  11, 286, 600, 668, 732, 924, 294, 452, 14476, 293, 264, 6034, 337, 385, 307, 516,
  51184], "temperature": 0.0, "avg_logprob": -0.15720769130822385, "compression_ratio":
  1.810035842293907, "no_speech_prob": 0.004141695331782103}, {"id": 746, "seek":
  289660, "start": 2913.0, "end": 2918.7599999999998, "text": " from idea machine
  to, okay, can you really build the idea for real? Do you really know how to test
  this?", "tokens": [51184, 490, 1558, 3479, 281, 11, 1392, 11, 393, 291, 534, 1322,
  264, 1558, 337, 957, 30, 1144, 291, 534, 458, 577, 281, 1500, 341, 30, 51472], "temperature":
  0.0, "avg_logprob": -0.15720769130822385, "compression_ratio": 1.810035842293907,
  "no_speech_prob": 0.004141695331782103}, {"id": 747, "seek": 289660, "start": 2918.7599999999998,
  "end": 2925.24, "text": " And so, and that transition isn''t super obvious. And
  it''s painful to be going back and forth between,", "tokens": [51472, 400, 370,
  11, 293, 300, 6034, 1943, 380, 1687, 6322, 13, 400, 309, 311, 11697, 281, 312, 516,
  646, 293, 5220, 1296, 11, 51796], "temperature": 0.0, "avg_logprob": -0.15720769130822385,
  "compression_ratio": 1.810035842293907, "no_speech_prob": 0.004141695331782103},
  {"id": 748, "seek": 292524, "start": 2925.8799999999997, "end": 2930.52, "text":
  " you know, theoretical idea machine. I''m reading these papers because like in
  terms of like that", "tokens": [50396, 291, 458, 11, 20864, 1558, 3479, 13, 286,
  478, 3760, 613, 10577, 570, 411, 294, 2115, 295, 411, 300, 50628], "temperature":
  0.0, "avg_logprob": -0.16231918334960938, "compression_ratio": 1.8181818181818181,
  "no_speech_prob": 0.006498075556010008}, {"id": 749, "seek": 292524, "start": 2930.52,
  "end": 2935.08, "text": " flow state of creativity that you get into when you''re
  when you''re working on things, for me,", "tokens": [50628, 3095, 1785, 295, 12915,
  300, 291, 483, 666, 562, 291, 434, 562, 291, 434, 1364, 322, 721, 11, 337, 385,
  11, 50856], "temperature": 0.0, "avg_logprob": -0.16231918334960938, "compression_ratio":
  1.8181818181818181, "no_speech_prob": 0.006498075556010008}, {"id": 750, "seek":
  292524, "start": 2935.08, "end": 2940.3599999999997, "text": " personally, reading
  papers is like the most satisfying thing. I feel very like productive when I''m",
  "tokens": [50856, 5665, 11, 3760, 10577, 307, 411, 264, 881, 18348, 551, 13, 286,
  841, 588, 411, 13304, 562, 286, 478, 51120], "temperature": 0.0, "avg_logprob":
  -0.16231918334960938, "compression_ratio": 1.8181818181818181, "no_speech_prob":
  0.006498075556010008}, {"id": 751, "seek": 292524, "start": 2940.3599999999997,
  "end": 2945.8799999999997, "text": " reading papers. I might, you know, I feel good.
  But when I''m engineering things, I feel more", "tokens": [51120, 3760, 10577, 13,
  286, 1062, 11, 291, 458, 11, 286, 841, 665, 13, 583, 562, 286, 478, 7043, 721, 11,
  286, 841, 544, 51396], "temperature": 0.0, "avg_logprob": -0.16231918334960938,
  "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.006498075556010008},
  {"id": 752, "seek": 292524, "start": 2945.8799999999997, "end": 2952.3599999999997,
  "text": " pain, man, because it''s more painful, I''d say. Yes, yes. And this is
  where, of course, you do want", "tokens": [51396, 1822, 11, 587, 11, 570, 309, 311,
  544, 11697, 11, 286, 1116, 584, 13, 1079, 11, 2086, 13, 400, 341, 307, 689, 11,
  295, 1164, 11, 291, 360, 528, 51720], "temperature": 0.0, "avg_logprob": -0.16231918334960938,
  "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.006498075556010008},
  {"id": 753, "seek": 295236, "start": 2952.36, "end": 2957.1600000000003, "text":
  " to have those oiled well, well, well, oiled software systems that you don''t need
  to waste your time", "tokens": [50364, 281, 362, 729, 3184, 292, 731, 11, 731, 11,
  731, 11, 3184, 292, 4722, 3652, 300, 291, 500, 380, 643, 281, 5964, 428, 565, 50604],
  "temperature": 0.0, "avg_logprob": -0.2874270500020778, "compression_ratio": 1.592274678111588,
  "no_speech_prob": 0.010654205456376076}, {"id": 754, "seek": 295236, "start": 2957.1600000000003,
  "end": 2964.76, "text": " setting things up or running out of disco, whatever, you
  know, heaven so, so frequently.", "tokens": [50604, 3287, 721, 493, 420, 2614, 484,
  295, 3622, 11, 2035, 11, 291, 458, 11, 7162, 370, 11, 370, 10374, 13, 50984], "temperature":
  0.0, "avg_logprob": -0.2874270500020778, "compression_ratio": 1.592274678111588,
  "no_speech_prob": 0.010654205456376076}, {"id": 755, "seek": 295236, "start": 2965.8,
  "end": 2970.92, "text": " So like even the innocuous things like before I had integrated
  Google Drive with Google collab,", "tokens": [51036, 407, 411, 754, 264, 10843,
  12549, 721, 411, 949, 286, 632, 10919, 3329, 15622, 365, 3329, 44228, 11, 51292],
  "temperature": 0.0, "avg_logprob": -0.2874270500020778, "compression_ratio": 1.592274678111588,
  "no_speech_prob": 0.010654205456376076}, {"id": 756, "seek": 295236, "start": 2970.92,
  "end": 2975.96, "text": " and it would crash. And I feel like I''ve just lost 10
  hours of running this thing. So,", "tokens": [51292, 293, 309, 576, 8252, 13, 400,
  286, 841, 411, 286, 600, 445, 2731, 1266, 2496, 295, 2614, 341, 551, 13, 407, 11,
  51544], "temperature": 0.0, "avg_logprob": -0.2874270500020778, "compression_ratio":
  1.592274678111588, "no_speech_prob": 0.010654205456376076}, {"id": 757, "seek":
  297596, "start": 2976.6, "end": 2982.76, "text": " and that is not good. Like, this
  is I think what Joel Spolski said at some point, you know,", "tokens": [50396, 293,
  300, 307, 406, 665, 13, 1743, 11, 341, 307, 286, 519, 437, 21522, 1738, 401, 18020,
  848, 412, 512, 935, 11, 291, 458, 11, 50704], "temperature": 0.0, "avg_logprob":
  -0.21380058167472718, "compression_ratio": 1.7427536231884058, "no_speech_prob":
  0.02069966495037079}, {"id": 758, "seek": 297596, "start": 2982.76, "end": 2989.4,
  "text": " the co-founder of Stack or Flow, you know, he said like, imagine that
  you want to print a piece of", "tokens": [50704, 264, 598, 12, 33348, 295, 37649,
  420, 32792, 11, 291, 458, 11, 415, 848, 411, 11, 3811, 300, 291, 528, 281, 4482,
  257, 2522, 295, 51036], "temperature": 0.0, "avg_logprob": -0.21380058167472718,
  "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02069966495037079},
  {"id": 759, "seek": 297596, "start": 2989.4, "end": 2995.32, "text": " paper and
  you log into your computer and it says, please upgrade the driver. So you upgrade
  the", "tokens": [51036, 3035, 293, 291, 3565, 666, 428, 3820, 293, 309, 1619, 11,
  1767, 11484, 264, 6787, 13, 407, 291, 11484, 264, 51332], "temperature": 0.0, "avg_logprob":
  -0.21380058167472718, "compression_ratio": 1.7427536231884058, "no_speech_prob":
  0.02069966495037079}, {"id": 760, "seek": 297596, "start": 2995.32, "end": 3000.12,
  "text": " driver and then operating system says I need to reboot. So it reboots
  and it basically waits 10", "tokens": [51332, 6787, 293, 550, 7447, 1185, 1619,
  286, 643, 281, 33818, 13, 407, 309, 26802, 1971, 293, 309, 1936, 40597, 1266, 51572],
  "temperature": 0.0, "avg_logprob": -0.21380058167472718, "compression_ratio": 1.7427536231884058,
  "no_speech_prob": 0.02069966495037079}, {"id": 761, "seek": 297596, "start": 3000.12,
  "end": 3005.64, "text": " minutes of your time. And then you, and then again, it
  says, hey, actually, I cannot print because", "tokens": [51572, 2077, 295, 428,
  565, 13, 400, 550, 291, 11, 293, 550, 797, 11, 309, 1619, 11, 4177, 11, 767, 11,
  286, 2644, 4482, 570, 51848], "temperature": 0.0, "avg_logprob": -0.21380058167472718,
  "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02069966495037079},
  {"id": 762, "seek": 300564, "start": 3005.64, "end": 3010.7599999999998, "text":
  " you ran out of something now. Again, it installs them. And you like, instead of
  solving the problem,", "tokens": [50364, 291, 5872, 484, 295, 746, 586, 13, 3764,
  11, 309, 3625, 82, 552, 13, 400, 291, 411, 11, 2602, 295, 12606, 264, 1154, 11,
  50620], "temperature": 0.0, "avg_logprob": -0.1803751770330935, "compression_ratio":
  1.6270491803278688, "no_speech_prob": 0.0008852415485307574}, {"id": 763, "seek":
  300564, "start": 3010.7599999999998, "end": 3016.92, "text": " you become the administrator
  of your computer, right? And that''s the same, the same thing can happen", "tokens":
  [50620, 291, 1813, 264, 25529, 295, 428, 3820, 11, 558, 30, 400, 300, 311, 264,
  912, 11, 264, 912, 551, 393, 1051, 50928], "temperature": 0.0, "avg_logprob": -0.1803751770330935,
  "compression_ratio": 1.6270491803278688, "no_speech_prob": 0.0008852415485307574},
  {"id": 764, "seek": 300564, "start": 3016.92, "end": 3025.08, "text": " so much,
  so often in software, you know, development and research as well, because, because
  I think", "tokens": [50928, 370, 709, 11, 370, 2049, 294, 4722, 11, 291, 458, 11,
  3250, 293, 2132, 382, 731, 11, 570, 11, 570, 286, 519, 51336], "temperature": 0.0,
  "avg_logprob": -0.1803751770330935, "compression_ratio": 1.6270491803278688, "no_speech_prob":
  0.0008852415485307574}, {"id": 765, "seek": 300564, "start": 3025.96, "end": 3033.7999999999997,
  "text": " somebody will put on Twitter, we do not actually choose between big and
  small, like do a lot of", "tokens": [51380, 2618, 486, 829, 322, 5794, 11, 321,
  360, 406, 767, 2826, 1296, 955, 293, 1359, 11, 411, 360, 257, 688, 295, 51772],
  "temperature": 0.0, "avg_logprob": -0.1803751770330935, "compression_ratio": 1.6270491803278688,
  "no_speech_prob": 0.0008852415485307574}, {"id": 766, "seek": 303380, "start": 3033.8,
  "end": 3038.6800000000003, "text": " things and do like small amount of things.
  We usually choose between small and nothing.", "tokens": [50364, 721, 293, 360,
  411, 1359, 2372, 295, 721, 13, 492, 2673, 2826, 1296, 1359, 293, 1825, 13, 50608],
  "temperature": 0.0, "avg_logprob": -0.18173430138027546, "compression_ratio": 1.6304347826086956,
  "no_speech_prob": 0.0045081875286996365}, {"id": 767, "seek": 303380, "start": 3039.32,
  "end": 3045.7200000000003, "text": " And so I guess when those things eating a lot
  of your small time, right, to nothing, you''re like", "tokens": [50640, 400, 370,
  286, 2041, 562, 729, 721, 3936, 257, 688, 295, 428, 1359, 565, 11, 558, 11, 281,
  1825, 11, 291, 434, 411, 50960], "temperature": 0.0, "avg_logprob": -0.18173430138027546,
  "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0045081875286996365},
  {"id": 768, "seek": 303380, "start": 3045.7200000000003, "end": 3051.2400000000002,
  "text": " frustrated and you''re like, okay, I''m just down the rabbit hole. What
  am I doing? And so I think", "tokens": [50960, 15751, 293, 291, 434, 411, 11, 1392,
  11, 286, 478, 445, 760, 264, 19509, 5458, 13, 708, 669, 286, 884, 30, 400, 370,
  286, 519, 51236], "temperature": 0.0, "avg_logprob": -0.18173430138027546, "compression_ratio":
  1.6304347826086956, "no_speech_prob": 0.0045081875286996365}, {"id": 769, "seek":
  303380, "start": 3051.2400000000002, "end": 3057.4, "text": " tools like VEVIates
  save a ton of time and everybody who is innovating in this space from the", "tokens":
  [51236, 3873, 411, 691, 36, 25322, 1024, 3155, 257, 2952, 295, 565, 293, 2201, 567,
  307, 5083, 990, 294, 341, 1901, 490, 264, 51544], "temperature": 0.0, "avg_logprob":
  -0.18173430138027546, "compression_ratio": 1.6304347826086956, "no_speech_prob":
  0.0045081875286996365}, {"id": 770, "seek": 305740, "start": 3057.4, "end": 3063.88,
  "text": " direction of usability, you know, like and saving time, shaving those
  minutes off of, you know,", "tokens": [50364, 3513, 295, 46878, 11, 291, 458, 11,
  411, 293, 6816, 565, 11, 36481, 729, 2077, 766, 295, 11, 291, 458, 11, 50688], "temperature":
  0.0, "avg_logprob": -0.21558744399273982, "compression_ratio": 1.6618705035971224,
  "no_speech_prob": 0.005872700363397598}, {"id": 771, "seek": 305740, "start": 3063.88,
  "end": 3067.96, "text": " your experience, I think that will save so much time for
  your thinking as well.", "tokens": [50688, 428, 1752, 11, 286, 519, 300, 486, 3155,
  370, 709, 565, 337, 428, 1953, 382, 731, 13, 50892], "temperature": 0.0, "avg_logprob":
  -0.21558744399273982, "compression_ratio": 1.6618705035971224, "no_speech_prob":
  0.005872700363397598}, {"id": 772, "seek": 305740, "start": 3069.1600000000003,
  "end": 3075.08, "text": " Yeah. And before VEVIate, I was doing a little bit of
  the sponsored content work, and which for me", "tokens": [50952, 865, 13, 400, 949,
  691, 36, 25322, 473, 11, 286, 390, 884, 257, 707, 857, 295, 264, 16621, 2701, 589,
  11, 293, 597, 337, 385, 51248], "temperature": 0.0, "avg_logprob": -0.21558744399273982,
  "compression_ratio": 1.6618705035971224, "no_speech_prob": 0.005872700363397598},
  {"id": 773, "seek": 305740, "start": 3075.08, "end": 3081.08, "text": " is great
  because I get to talk to these people and they teach me a lot. And so this is with",
  "tokens": [51248, 307, 869, 570, 286, 483, 281, 751, 281, 613, 561, 293, 436, 2924,
  385, 257, 688, 13, 400, 370, 341, 307, 365, 51548], "temperature": 0.0, "avg_logprob":
  -0.21558744399273982, "compression_ratio": 1.6618705035971224, "no_speech_prob":
  0.005872700363397598}, {"id": 774, "seek": 305740, "start": 3081.08, "end": 3085.8,
  "text": " the term in AI, which is now a part of you who have packered. And so yeah,
  they''re building the", "tokens": [51548, 264, 1433, 294, 7318, 11, 597, 307, 586,
  257, 644, 295, 291, 567, 362, 2844, 4073, 13, 400, 370, 1338, 11, 436, 434, 2390,
  264, 51784], "temperature": 0.0, "avg_logprob": -0.21558744399273982, "compression_ratio":
  1.6618705035971224, "no_speech_prob": 0.005872700363397598}, {"id": 775, "seek":
  308580, "start": 3085.8, "end": 3090.92, "text": " hyper-pram, like distributed
  training hyper-pram, reorganization, which what we''re talking about, like", "tokens":
  [50364, 9848, 12, 1424, 335, 11, 411, 12631, 3097, 9848, 12, 1424, 335, 11, 41203,
  2144, 11, 597, 437, 321, 434, 1417, 466, 11, 411, 50620], "temperature": 0.0, "avg_logprob":
  -0.2799730023134102, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0037699940148741007},
  {"id": 776, "seek": 308580, "start": 3090.92, "end": 3096.28, "text": " the administer
  of the system, they''re doing a lot of this work. And you know, as anyone, I''m
  sure", "tokens": [50620, 264, 22096, 295, 264, 1185, 11, 436, 434, 884, 257, 688,
  295, 341, 589, 13, 400, 291, 458, 11, 382, 2878, 11, 286, 478, 988, 50888], "temperature":
  0.0, "avg_logprob": -0.2799730023134102, "compression_ratio": 1.565040650406504,
  "no_speech_prob": 0.0037699940148741007}, {"id": 777, "seek": 308580, "start": 3096.28,
  "end": 3100.2000000000003, "text": " people listening to this have gotten smoked
  with the cost of one of these experiments too.", "tokens": [50888, 561, 4764, 281,
  341, 362, 5768, 27205, 365, 264, 2063, 295, 472, 295, 613, 12050, 886, 13, 51084],
  "temperature": 0.0, "avg_logprob": -0.2799730023134102, "compression_ratio": 1.565040650406504,
  "no_speech_prob": 0.0037699940148741007}, {"id": 778, "seek": 308580, "start": 3100.92,
  "end": 3106.52, "text": " So it''s not just your time. It''s not fun.", "tokens":
  [51120, 407, 309, 311, 406, 445, 428, 565, 13, 467, 311, 406, 1019, 13, 51400],
  "temperature": 0.0, "avg_logprob": -0.2799730023134102, "compression_ratio": 1.565040650406504,
  "no_speech_prob": 0.0037699940148741007}, {"id": 779, "seek": 308580, "start": 3106.52,
  "end": 3112.04, "text": " Yeah, actually, you reminded me of on Google Cloud.",
  "tokens": [51400, 865, 11, 767, 11, 291, 15920, 385, 295, 322, 3329, 8061, 13, 51676],
  "temperature": 0.0, "avg_logprob": -0.2799730023134102, "compression_ratio": 1.565040650406504,
  "no_speech_prob": 0.0037699940148741007}, {"id": 780, "seek": 311204, "start": 3112.04,
  "end": 3119.08, "text": " It was a tutorial, like a workshop. It was a free one.
  They even like gave us food.", "tokens": [50364, 467, 390, 257, 7073, 11, 411, 257,
  13541, 13, 467, 390, 257, 1737, 472, 13, 814, 754, 411, 2729, 505, 1755, 13, 50716],
  "temperature": 0.0, "avg_logprob": -0.224522705078125, "compression_ratio": 1.635135135135135,
  "no_speech_prob": 0.02530473656952381}, {"id": 781, "seek": 311204, "start": 3121.08,
  "end": 3128.04, "text": " So you just show up, they video and then they tell you
  things. And it was a practical one.", "tokens": [50816, 407, 291, 445, 855, 493,
  11, 436, 960, 293, 550, 436, 980, 291, 721, 13, 400, 309, 390, 257, 8496, 472, 13,
  51164], "temperature": 0.0, "avg_logprob": -0.224522705078125, "compression_ratio":
  1.635135135135135, "no_speech_prob": 0.02530473656952381}, {"id": 782, "seek": 311204,
  "start": 3128.04, "end": 3133.24, "text": " And I remember one of the instructors,
  he was not an employee of Google, but he was certified.", "tokens": [51164, 400,
  286, 1604, 472, 295, 264, 28367, 11, 415, 390, 406, 364, 10738, 295, 3329, 11, 457,
  415, 390, 18580, 13, 51424], "temperature": 0.0, "avg_logprob": -0.224522705078125,
  "compression_ratio": 1.635135135135135, "no_speech_prob": 0.02530473656952381},
  {"id": 783, "seek": 311204, "start": 3133.88, "end": 3139.8, "text": " And you know,
  like he said, hey, now we''re gonna spin the Spanner cluster. And Spanner is the",
  "tokens": [51456, 400, 291, 458, 11, 411, 415, 848, 11, 4177, 11, 586, 321, 434,
  799, 6060, 264, 1738, 9805, 13630, 13, 400, 1738, 9805, 307, 264, 51752], "temperature":
  0.0, "avg_logprob": -0.224522705078125, "compression_ratio": 1.635135135135135,
  "no_speech_prob": 0.02530473656952381}, {"id": 784, "seek": 313980, "start": 3139.8,
  "end": 3146.2000000000003, "text": " my SQL planet scale with all the consistency
  and semantic guarantees using atomic clocks. And", "tokens": [50364, 452, 19200,
  5054, 4373, 365, 439, 264, 14416, 293, 47982, 32567, 1228, 22275, 41528, 13, 400,
  50684], "temperature": 0.0, "avg_logprob": -0.15851313344548257, "compression_ratio":
  1.5793991416309012, "no_speech_prob": 0.0028392812237143517}, {"id": 785, "seek":
  313980, "start": 3146.2000000000003, "end": 3151.88, "text": " there is like a fantastic
  presentation by one of its engineers that I have in my recordings. I", "tokens":
  [50684, 456, 307, 411, 257, 5456, 5860, 538, 472, 295, 1080, 11955, 300, 286, 362,
  294, 452, 25162, 13, 286, 50968], "temperature": 0.0, "avg_logprob": -0.15851313344548257,
  "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.0028392812237143517},
  {"id": 786, "seek": 313980, "start": 3151.88, "end": 3156.04, "text": " have not
  published yet because I don''t know if Google will try to sue me. But you know,",
  "tokens": [50968, 362, 406, 6572, 1939, 570, 286, 500, 380, 458, 498, 3329, 486,
  853, 281, 20416, 385, 13, 583, 291, 458, 11, 51176], "temperature": 0.0, "avg_logprob":
  -0.15851313344548257, "compression_ratio": 1.5793991416309012, "no_speech_prob":
  0.0028392812237143517}, {"id": 787, "seek": 313980, "start": 3156.84, "end": 3162.6000000000004,
  "text": " the idea is that it''s a fantastic system. And there is a paper as well.
  And then the guide,", "tokens": [51216, 264, 1558, 307, 300, 309, 311, 257, 5456,
  1185, 13, 400, 456, 307, 257, 3035, 382, 731, 13, 400, 550, 264, 5934, 11, 51504],
  "temperature": 0.0, "avg_logprob": -0.15851313344548257, "compression_ratio": 1.5793991416309012,
  "no_speech_prob": 0.0028392812237143517}, {"id": 788, "seek": 316260, "start": 3162.6,
  "end": 3169.56, "text": " the teacher, he said, well, hold on. Don''t spin too many
  of them because I get the bill.", "tokens": [50364, 264, 5027, 11, 415, 848, 11,
  731, 11, 1797, 322, 13, 1468, 380, 6060, 886, 867, 295, 552, 570, 286, 483, 264,
  2961, 13, 50712], "temperature": 0.0, "avg_logprob": -0.19513399784381574, "compression_ratio":
  1.5565610859728507, "no_speech_prob": 0.020596634596586227}, {"id": 789, "seek":
  316260, "start": 3169.56, "end": 3175.7999999999997, "text": " And last month, I
  got a bill of $4,000. And Google could not reimburse it because they said,", "tokens":
  [50712, 400, 1036, 1618, 11, 286, 658, 257, 2961, 295, 1848, 19, 11, 1360, 13, 400,
  3329, 727, 406, 41685, 309, 570, 436, 848, 11, 51024], "temperature": 0.0, "avg_logprob":
  -0.19513399784381574, "compression_ratio": 1.5565610859728507, "no_speech_prob":
  0.020596634596586227}, {"id": 790, "seek": 316260, "start": 3175.7999999999997,
  "end": 3181.7999999999997, "text": " you''re not an internal employee. So he was
  like, it''s fun. But you know, to the point when you might.", "tokens": [51024,
  291, 434, 406, 364, 6920, 10738, 13, 407, 415, 390, 411, 11, 309, 311, 1019, 13,
  583, 291, 458, 11, 281, 264, 935, 562, 291, 1062, 13, 51324], "temperature": 0.0,
  "avg_logprob": -0.19513399784381574, "compression_ratio": 1.5565610859728507, "no_speech_prob":
  0.020596634596586227}, {"id": 791, "seek": 316260, "start": 3183.08, "end": 3187.24,
  "text": " Yeah, it''s funny. It''s funny now, but it''s not funny at all.", "tokens":
  [51388, 865, 11, 309, 311, 4074, 13, 467, 311, 4074, 586, 11, 457, 309, 311, 406,
  4074, 412, 439, 13, 51596], "temperature": 0.0, "avg_logprob": -0.19513399784381574,
  "compression_ratio": 1.5565610859728507, "no_speech_prob": 0.020596634596586227},
  {"id": 792, "seek": 318724, "start": 3187.24, "end": 3195.8799999999997, "text":
  " Yeah, that determined AI calls it lunch and learn. There are this kind of concept
  for deep learning,", "tokens": [50364, 865, 11, 300, 9540, 7318, 5498, 309, 6349,
  293, 1466, 13, 821, 366, 341, 733, 295, 3410, 337, 2452, 2539, 11, 50796], "temperature":
  0.0, "avg_logprob": -0.18992400938464749, "compression_ratio": 1.6610169491525424,
  "no_speech_prob": 0.00892741046845913}, {"id": 793, "seek": 318724, "start": 3195.8799999999997,
  "end": 3201.24, "text": " or like I''d say to science content, like even like, you
  know, with physics and they''re going to be", "tokens": [50796, 420, 411, 286, 1116,
  584, 281, 3497, 2701, 11, 411, 754, 411, 11, 291, 458, 11, 365, 10649, 293, 436,
  434, 516, 281, 312, 51064], "temperature": 0.0, "avg_logprob": -0.18992400938464749,
  "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.00892741046845913},
  {"id": 794, "seek": 318724, "start": 3201.24, "end": 3205.8799999999997, "text":
  " doing experiments where it''s expensive. So we''re not going to each be doing
  it. We''re going to", "tokens": [51064, 884, 12050, 689, 309, 311, 5124, 13, 407,
  321, 434, 406, 516, 281, 1184, 312, 884, 309, 13, 492, 434, 516, 281, 51296], "temperature":
  0.0, "avg_logprob": -0.18992400938464749, "compression_ratio": 1.6610169491525424,
  "no_speech_prob": 0.00892741046845913}, {"id": 795, "seek": 318724, "start": 3205.8799999999997,
  "end": 3210.8399999999997, "text": " watch one person do it and kind of gather around
  as a community. And yeah, I see that as being a", "tokens": [51296, 1159, 472, 954,
  360, 309, 293, 733, 295, 5448, 926, 382, 257, 1768, 13, 400, 1338, 11, 286, 536,
  300, 382, 885, 257, 51544], "temperature": 0.0, "avg_logprob": -0.18992400938464749,
  "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.00892741046845913},
  {"id": 796, "seek": 318724, "start": 3210.8399999999997, "end": 3216.52, "text":
  " huge part. Just like Uber eats coupons, I think is a brilliant interface for it.
  And then everyone", "tokens": [51544, 2603, 644, 13, 1449, 411, 21839, 18109, 8682,
  892, 11, 286, 519, 307, 257, 10248, 9226, 337, 309, 13, 400, 550, 1518, 51828],
  "temperature": 0.0, "avg_logprob": -0.18992400938464749, "compression_ratio": 1.6610169491525424,
  "no_speech_prob": 0.00892741046845913}, {"id": 797, "seek": 321652, "start": 3216.52,
  "end": 3221.48, "text": " attends the thing. But yeah, I love that kind of. And
  then just quickly, so like one thing we''re", "tokens": [50364, 49837, 264, 551,
  13, 583, 1338, 11, 286, 959, 300, 733, 295, 13, 400, 550, 445, 2661, 11, 370, 411,
  472, 551, 321, 434, 50612], "temperature": 0.0, "avg_logprob": -0.23003231532989987,
  "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.0013813048135489225},
  {"id": 798, "seek": 321652, "start": 3221.48, "end": 3226.84, "text": " working
  on at Weve 8. And as people have seen with hugging face data sets and the Kaggle
  competitions,", "tokens": [50612, 1364, 322, 412, 492, 303, 1649, 13, 400, 382,
  561, 362, 1612, 365, 41706, 1851, 1412, 6352, 293, 264, 48751, 22631, 26185, 11,
  50880], "temperature": 0.0, "avg_logprob": -0.23003231532989987, "compression_ratio":
  1.7234042553191489, "no_speech_prob": 0.0013813048135489225}, {"id": 799, "seek":
  321652, "start": 3226.84, "end": 3233.8, "text": " well, hugging face data is a
  little different, but it is hosting the demos cheaply. So that so", "tokens": [50880,
  731, 11, 41706, 1851, 1412, 307, 257, 707, 819, 11, 457, 309, 307, 16058, 264, 33788,
  7084, 356, 13, 407, 300, 370, 51228], "temperature": 0.0, "avg_logprob": -0.23003231532989987,
  "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.0013813048135489225},
  {"id": 800, "seek": 321652, "start": 3233.8, "end": 3238.52, "text": " in Weve 8,
  we''re working on this. The wiki data is going to be the next big release where
  we have", "tokens": [51228, 294, 492, 303, 1649, 11, 321, 434, 1364, 322, 341, 13,
  440, 261, 9850, 1412, 307, 516, 281, 312, 264, 958, 955, 4374, 689, 321, 362, 51464],
  "temperature": 0.0, "avg_logprob": -0.23003231532989987, "compression_ratio": 1.7234042553191489,
  "no_speech_prob": 0.0013813048135489225}, {"id": 801, "seek": 321652, "start": 3238.52,
  "end": 3243.56, "text": " the pie torch, big graph embeddings, which is the graph
  structure makes it different from say", "tokens": [51464, 264, 1730, 27822, 11,
  955, 4295, 12240, 29432, 11, 597, 307, 264, 4295, 3877, 1669, 309, 819, 490, 584,
  51716], "temperature": 0.0, "avg_logprob": -0.23003231532989987, "compression_ratio":
  1.7234042553191489, "no_speech_prob": 0.0013813048135489225}, {"id": 802, "seek":
  324356, "start": 3243.56, "end": 3248.2, "text": " Wikipedia, because it''s really
  good at entity embedding. As we mentioned London and Barcelona,", "tokens": [50364,
  28999, 11, 570, 309, 311, 534, 665, 412, 13977, 12240, 3584, 13, 1018, 321, 2835,
  7042, 293, 21247, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1814723368044253,
  "compression_ratio": 1.6775362318840579, "no_speech_prob": 0.004239059053361416},
  {"id": 803, "seek": 324356, "start": 3248.2, "end": 3253.24, "text": " if you construct
  a knowledge graph of Barcelona compared to London, that''s going to have a better",
  "tokens": [50596, 498, 291, 7690, 257, 3601, 4295, 295, 21247, 5347, 281, 7042,
  11, 300, 311, 516, 281, 362, 257, 1101, 50848], "temperature": 0.0, "avg_logprob":
  -0.1814723368044253, "compression_ratio": 1.6775362318840579, "no_speech_prob":
  0.004239059053361416}, {"id": 804, "seek": 324356, "start": 3253.24, "end": 3257.4,
  "text": " entity representation using learning techniques like deep walk or note
  to veck or maybe", "tokens": [50848, 13977, 10290, 1228, 2539, 7512, 411, 2452,
  1792, 420, 3637, 281, 1241, 547, 420, 1310, 51056], "temperature": 0.0, "avg_logprob":
  -0.1814723368044253, "compression_ratio": 1.6775362318840579, "no_speech_prob":
  0.004239059053361416}, {"id": 805, "seek": 324356, "start": 3258.7599999999998,
  "end": 3262.68, "text": " maybe like a graph convolutional network with an auto
  encoder loss, but probably deep walk or", "tokens": [51124, 1310, 411, 257, 4295,
  45216, 304, 3209, 365, 364, 8399, 2058, 19866, 4470, 11, 457, 1391, 2452, 1792,
  420, 51320], "temperature": 0.0, "avg_logprob": -0.1814723368044253, "compression_ratio":
  1.6775362318840579, "no_speech_prob": 0.004239059053361416}, {"id": 806, "seek":
  324356, "start": 3262.68, "end": 3267.72, "text": " note to veck is what I would
  say is, I mean, I''m not completely caught up with that, but", "tokens": [51320,
  3637, 281, 1241, 547, 307, 437, 286, 576, 584, 307, 11, 286, 914, 11, 286, 478,
  406, 2584, 5415, 493, 365, 300, 11, 457, 51572], "temperature": 0.0, "avg_logprob":
  -0.1814723368044253, "compression_ratio": 1.6775362318840579, "no_speech_prob":
  0.004239059053361416}, {"id": 807, "seek": 326772, "start": 3268.3599999999997,
  "end": 3274.4399999999996, "text": " anyway, so having that kind of data set, the
  wiki data, and now it''s cheaper. That''s the huge", "tokens": [50396, 4033, 11,
  370, 1419, 300, 733, 295, 1412, 992, 11, 264, 261, 9850, 1412, 11, 293, 586, 309,
  311, 12284, 13, 663, 311, 264, 2603, 50700], "temperature": 0.0, "avg_logprob":
  -0.1558747725053267, "compression_ratio": 1.7295373665480427, "no_speech_prob":
  0.003404415911063552}, {"id": 808, "seek": 326772, "start": 3274.4399999999996,
  "end": 3279.08, "text": " difference. That''s the change in deep learning is hugging
  face is hosting all these data sets,", "tokens": [50700, 2649, 13, 663, 311, 264,
  1319, 294, 2452, 2539, 307, 41706, 1851, 307, 16058, 439, 613, 1412, 6352, 11, 50932],
  "temperature": 0.0, "avg_logprob": -0.1558747725053267, "compression_ratio": 1.7295373665480427,
  "no_speech_prob": 0.003404415911063552}, {"id": 809, "seek": 326772, "start": 3279.08,
  "end": 3283.48, "text": " so you don''t have to host them yourself. You can just
  quickly access them. And with Weve 8, it''s", "tokens": [50932, 370, 291, 500, 380,
  362, 281, 3975, 552, 1803, 13, 509, 393, 445, 2661, 2105, 552, 13, 400, 365, 492,
  303, 1649, 11, 309, 311, 51152], "temperature": 0.0, "avg_logprob": -0.1558747725053267,
  "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.003404415911063552},
  {"id": 810, "seek": 326772, "start": 3283.48, "end": 3288.68, "text": " even more
  exciting, in my opinion, because they''re hosting a vector search engine with model
  inference,", "tokens": [51152, 754, 544, 4670, 11, 294, 452, 4800, 11, 570, 436,
  434, 16058, 257, 8062, 3164, 2848, 365, 2316, 38253, 11, 51412], "temperature":
  0.0, "avg_logprob": -0.1558747725053267, "compression_ratio": 1.7295373665480427,
  "no_speech_prob": 0.003404415911063552}, {"id": 811, "seek": 326772, "start": 3288.68,
  "end": 3292.2, "text": " I mean, hugging face is doing model inference too, as we
  talked about infinity where they''ve got", "tokens": [51412, 286, 914, 11, 41706,
  1851, 307, 884, 2316, 38253, 886, 11, 382, 321, 2825, 466, 13202, 689, 436, 600,
  658, 51588], "temperature": 0.0, "avg_logprob": -0.1558747725053267, "compression_ratio":
  1.7295373665480427, "no_speech_prob": 0.003404415911063552}, {"id": 812, "seek":
  329220, "start": 3292.4399999999996, "end": 3298.2799999999997, "text": " inference
  time data like milliseconds for these massive models is, yeah, is you don''t have
  to pay", "tokens": [50376, 38253, 565, 1412, 411, 34184, 337, 613, 5994, 5245, 307,
  11, 1338, 11, 307, 291, 500, 380, 362, 281, 1689, 50668], "temperature": 0.0, "avg_logprob":
  -0.23698940905895863, "compression_ratio": 1.6986899563318778, "no_speech_prob":
  0.014457867480814457}, {"id": 813, "seek": 329220, "start": 3298.2799999999997,
  "end": 3305.16, "text": " for the hosting of these things, which is obviously good.
  Absolutely, absolutely. And also not", "tokens": [50668, 337, 264, 16058, 295, 613,
  721, 11, 597, 307, 2745, 665, 13, 7021, 11, 3122, 13, 400, 611, 406, 51012], "temperature":
  0.0, "avg_logprob": -0.23698940905895863, "compression_ratio": 1.6986899563318778,
  "no_speech_prob": 0.014457867480814457}, {"id": 814, "seek": 329220, "start": 3305.16,
  "end": 3311.24, "text": " like massive with hosting things, because that''s also
  the cost of maintaining is the cost not to", "tokens": [51012, 411, 5994, 365, 16058,
  721, 11, 570, 300, 311, 611, 264, 2063, 295, 14916, 307, 264, 2063, 406, 281, 51316],
  "temperature": 0.0, "avg_logprob": -0.23698940905895863, "compression_ratio": 1.6986899563318778,
  "no_speech_prob": 0.014457867480814457}, {"id": 815, "seek": 329220, "start": 3311.24,
  "end": 3317.7999999999997, "text": " neglect. So absolutely. Yeah, yeah. Absolutely.
  Hey, it was such a packed conversation. I think the", "tokens": [51316, 17745, 13,
  407, 3122, 13, 865, 11, 1338, 13, 7021, 13, 1911, 11, 309, 390, 1270, 257, 13265,
  3761, 13, 286, 519, 264, 51644], "temperature": 0.0, "avg_logprob": -0.23698940905895863,
  "compression_ratio": 1.6986899563318778, "no_speech_prob": 0.014457867480814457},
  {"id": 816, "seek": 331780, "start": 3317.8, "end": 3323.48, "text": " show notes
  will be infinite, because you mentioned so many names, so many articles, and that''s
  fantastic.", "tokens": [50364, 855, 5570, 486, 312, 13785, 11, 570, 291, 2835, 370,
  867, 5288, 11, 370, 867, 11290, 11, 293, 300, 311, 5456, 13, 50648], "temperature":
  0.0, "avg_logprob": -0.13224154403529217, "compression_ratio": 1.672340425531915,
  "no_speech_prob": 0.022737151011824608}, {"id": 817, "seek": 331780, "start": 3323.48,
  "end": 3329.88, "text": " Thanks so much for doing this. I wanted to just still
  kind of end on kind of a little bit like that", "tokens": [50648, 2561, 370, 709,
  337, 884, 341, 13, 286, 1415, 281, 445, 920, 733, 295, 917, 322, 733, 295, 257,
  707, 857, 411, 300, 50968], "temperature": 0.0, "avg_logprob": -0.13224154403529217,
  "compression_ratio": 1.672340425531915, "no_speech_prob": 0.022737151011824608},
  {"id": 818, "seek": 331780, "start": 3329.88, "end": 3334.6800000000003, "text":
  " philosophical stance, which I usually do. And I think we touched a lot on that
  and thanks for doing", "tokens": [50968, 25066, 21033, 11, 597, 286, 2673, 360,
  13, 400, 286, 519, 321, 9828, 257, 688, 322, 300, 293, 3231, 337, 884, 51208], "temperature":
  0.0, "avg_logprob": -0.13224154403529217, "compression_ratio": 1.672340425531915,
  "no_speech_prob": 0.022737151011824608}, {"id": 819, "seek": 331780, "start": 3334.6800000000003,
  "end": 3340.6000000000004, "text": " this. But like in summary, what drives you?
  Why are you doing this? What you are doing?", "tokens": [51208, 341, 13, 583, 411,
  294, 12691, 11, 437, 11754, 291, 30, 1545, 366, 291, 884, 341, 30, 708, 291, 366,
  884, 30, 51504], "temperature": 0.0, "avg_logprob": -0.13224154403529217, "compression_ratio":
  1.672340425531915, "no_speech_prob": 0.022737151011824608}, {"id": 820, "seek":
  334780, "start": 3347.88, "end": 3355.48, "text": " That''s great question. I mean,
  I guess like, and I''ve heard, as you mentioned, Elon Musk, I''ve heard", "tokens":
  [50368, 663, 311, 869, 1168, 13, 286, 914, 11, 286, 2041, 411, 11, 293, 286, 600,
  2198, 11, 382, 291, 2835, 11, 28498, 26019, 11, 286, 600, 2198, 50748], "temperature":
  0.0, "avg_logprob": -0.19293104927494842, "compression_ratio": 1.7234042553191489,
  "no_speech_prob": 0.029761046171188354}, {"id": 821, "seek": 334780, "start": 3355.48,
  "end": 3362.2000000000003, "text": " that he says, like, I want to be useful. That''s
  one thing he says. Yeah. And I guess in the same", "tokens": [50748, 300, 415, 1619,
  11, 411, 11, 286, 528, 281, 312, 4420, 13, 663, 311, 472, 551, 415, 1619, 13, 865,
  13, 400, 286, 2041, 294, 264, 912, 51084], "temperature": 0.0, "avg_logprob": -0.19293104927494842,
  "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.029761046171188354},
  {"id": 822, "seek": 334780, "start": 3362.2000000000003, "end": 3371.32, "text":
  " way, trying to do the useful thing. And I guess like, obviously, I like these
  big grandiose visions of", "tokens": [51084, 636, 11, 1382, 281, 360, 264, 4420,
  551, 13, 400, 286, 2041, 411, 11, 2745, 11, 286, 411, 613, 955, 45155, 541, 30746,
  295, 51540], "temperature": 0.0, "avg_logprob": -0.19293104927494842, "compression_ratio":
  1.7234042553191489, "no_speech_prob": 0.029761046171188354}, {"id": 823, "seek":
  334780, "start": 3371.32, "end": 3377.7200000000003, "text": " things like helping
  with health care and self-driving cars and helping with poverty and creating housing",
  "tokens": [51540, 721, 411, 4315, 365, 1585, 1127, 293, 2698, 12, 47094, 5163, 293,
  4315, 365, 10958, 293, 4084, 6849, 51860], "temperature": 0.0, "avg_logprob": -0.19293104927494842,
  "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.029761046171188354},
  {"id": 824, "seek": 337772, "start": 3377.72, "end": 3383.0, "text": " climate science,
  all these kind of things, obviously. So obviously, there are these big grandiose",
  "tokens": [50364, 5659, 3497, 11, 439, 613, 733, 295, 721, 11, 2745, 13, 407, 2745,
  11, 456, 366, 613, 955, 45155, 541, 50628], "temperature": 0.0, "avg_logprob": -0.1253102099309202,
  "compression_ratio": 1.7509025270758123, "no_speech_prob": 0.0016097030602395535},
  {"id": 825, "seek": 337772, "start": 3383.0, "end": 3387.7999999999997, "text":
  " goals that I think we all share truthfully. But then it''s more of a question
  of how do you stay in", "tokens": [50628, 5493, 300, 286, 519, 321, 439, 2073, 3494,
  2277, 13, 583, 550, 309, 311, 544, 295, 257, 1168, 295, 577, 360, 291, 1754, 294,
  50868], "temperature": 0.0, "avg_logprob": -0.1253102099309202, "compression_ratio":
  1.7509025270758123, "no_speech_prob": 0.0016097030602395535}, {"id": 826, "seek":
  337772, "start": 3387.7999999999997, "end": 3394.2799999999997, "text": " the grind
  of it? And how do you keep waking up and keep getting at it? And so I''d say that
  kind of", "tokens": [50868, 264, 16700, 295, 309, 30, 400, 577, 360, 291, 1066,
  20447, 493, 293, 1066, 1242, 412, 309, 30, 400, 370, 286, 1116, 584, 300, 733, 295,
  51192], "temperature": 0.0, "avg_logprob": -0.1253102099309202, "compression_ratio":
  1.7509025270758123, "no_speech_prob": 0.0016097030602395535}, {"id": 827, "seek":
  337772, "start": 3394.2799999999997, "end": 3398.8399999999997, "text": " heuristic
  of just trying to do useful things every day is actually a pretty good guide. And
  so", "tokens": [51192, 415, 374, 3142, 295, 445, 1382, 281, 360, 4420, 721, 633,
  786, 307, 767, 257, 1238, 665, 5934, 13, 400, 370, 51420], "temperature": 0.0, "avg_logprob":
  -0.1253102099309202, "compression_ratio": 1.7509025270758123, "no_speech_prob":
  0.0016097030602395535}, {"id": 828, "seek": 337772, "start": 3399.72, "end": 3405.64,
  "text": " we all share these big visions. But we need the motivation to pick ourselves
  off the couch and", "tokens": [51464, 321, 439, 2073, 613, 955, 30746, 13, 583,
  321, 643, 264, 12335, 281, 1888, 4175, 766, 264, 16511, 293, 51760], "temperature":
  0.0, "avg_logprob": -0.1253102099309202, "compression_ratio": 1.7509025270758123,
  "no_speech_prob": 0.0016097030602395535}, {"id": 829, "seek": 340564, "start": 3405.64,
  "end": 3410.6, "text": " achieve to do that. Yeah, absolutely. And it also sounds
  like you mentioned you played basketball", "tokens": [50364, 4584, 281, 360, 300,
  13, 865, 11, 3122, 13, 400, 309, 611, 3263, 411, 291, 2835, 291, 3737, 11767, 50612],
  "temperature": 0.0, "avg_logprob": -0.17737797113854115, "compression_ratio": 1.776978417266187,
  "no_speech_prob": 0.020927393808960915}, {"id": 830, "seek": 340564, "start": 3410.6,
  "end": 3417.0, "text": " and you continue playing that, right? So that thing, when
  you do the sport, you need to be persistent,", "tokens": [50612, 293, 291, 2354,
  2433, 300, 11, 558, 30, 407, 300, 551, 11, 562, 291, 360, 264, 7282, 11, 291, 643,
  281, 312, 24315, 11, 50932], "temperature": 0.0, "avg_logprob": -0.17737797113854115,
  "compression_ratio": 1.776978417266187, "no_speech_prob": 0.020927393808960915},
  {"id": 831, "seek": 340564, "start": 3417.0, "end": 3421.7999999999997, "text":
  " right? And your body sometimes doesn''t want to do it, maybe. But you know in
  your mind that you", "tokens": [50932, 558, 30, 400, 428, 1772, 2171, 1177, 380,
  528, 281, 360, 309, 11, 1310, 13, 583, 291, 458, 294, 428, 1575, 300, 291, 51172],
  "temperature": 0.0, "avg_logprob": -0.17737797113854115, "compression_ratio": 1.776978417266187,
  "no_speech_prob": 0.020927393808960915}, {"id": 832, "seek": 340564, "start": 3421.7999999999997,
  "end": 3428.04, "text": " do want to do it. And so that persistence, I think, also
  translates into, you know, the research", "tokens": [51172, 360, 528, 281, 360,
  309, 13, 400, 370, 300, 37617, 11, 286, 519, 11, 611, 28468, 666, 11, 291, 458,
  11, 264, 2132, 51484], "temperature": 0.0, "avg_logprob": -0.17737797113854115,
  "compression_ratio": 1.776978417266187, "no_speech_prob": 0.020927393808960915},
  {"id": 833, "seek": 340564, "start": 3428.04, "end": 3433.4, "text": " and keeping
  up with things, right? Yeah. Yeah. And to stay on that kind of analogy, I''d say
  like the", "tokens": [51484, 293, 5145, 493, 365, 721, 11, 558, 30, 865, 13, 865,
  13, 400, 281, 1754, 322, 300, 733, 295, 21663, 11, 286, 1116, 584, 411, 264, 51752],
  "temperature": 0.0, "avg_logprob": -0.17737797113854115, "compression_ratio": 1.776978417266187,
  "no_speech_prob": 0.020927393808960915}, {"id": 834, "seek": 343340, "start": 3433.56,
  "end": 3437.56, "text": " physical pain of basketball is like, you might hurt your
  knee, you might have some tendonitis,", "tokens": [50372, 4001, 1822, 295, 11767,
  307, 411, 11, 291, 1062, 4607, 428, 9434, 11, 291, 1062, 362, 512, 46479, 16074,
  11, 50572], "temperature": 0.0, "avg_logprob": -0.1353157483614408, "compression_ratio":
  1.8571428571428572, "no_speech_prob": 0.0008999018464237452}, {"id": 835, "seek":
  343340, "start": 3437.56, "end": 3442.2000000000003, "text": " is that kind of physical
  pain or the physical pain of when you''re doing conditioning and you can''t", "tokens":
  [50572, 307, 300, 733, 295, 4001, 1822, 420, 264, 4001, 1822, 295, 562, 291, 434,
  884, 21901, 293, 291, 393, 380, 50804], "temperature": 0.0, "avg_logprob": -0.1353157483614408,
  "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0008999018464237452},
  {"id": 836, "seek": 343340, "start": 3442.2000000000003, "end": 3447.7200000000003,
  "text": " breathe, that you''re going to have that same kind of analog with this
  kind of mental work. And", "tokens": [50804, 10192, 11, 300, 291, 434, 516, 281,
  362, 300, 912, 733, 295, 16660, 365, 341, 733, 295, 4973, 589, 13, 400, 51080],
  "temperature": 0.0, "avg_logprob": -0.1353157483614408, "compression_ratio": 1.8571428571428572,
  "no_speech_prob": 0.0008999018464237452}, {"id": 837, "seek": 343340, "start": 3447.7200000000003,
  "end": 3453.4, "text": " it''ll manifest itself in like depression and burnout.
  And so you have to be like, as you do more", "tokens": [51080, 309, 603, 10067,
  2564, 294, 411, 10799, 293, 44841, 13, 400, 370, 291, 362, 281, 312, 411, 11, 382,
  291, 360, 544, 51364], "temperature": 0.0, "avg_logprob": -0.1353157483614408, "compression_ratio":
  1.8571428571428572, "no_speech_prob": 0.0008999018464237452}, {"id": 838, "seek":
  343340, "start": 3453.4, "end": 3458.28, "text": " training, you get better at the
  pain of the injuries. So to say like it''s like injuries to your", "tokens": [51364,
  3097, 11, 291, 483, 1101, 412, 264, 1822, 295, 264, 14799, 13, 407, 281, 584, 411,
  309, 311, 411, 14799, 281, 428, 51608], "temperature": 0.0, "avg_logprob": -0.1353157483614408,
  "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0008999018464237452},
  {"id": 839, "seek": 345828, "start": 3458.28, "end": 3464.76, "text": " mind and
  the same kind of analog as physical injuries would be. And I think understanding
  that", "tokens": [50364, 1575, 293, 264, 912, 733, 295, 16660, 382, 4001, 14799,
  576, 312, 13, 400, 286, 519, 3701, 300, 50688], "temperature": 0.0, "avg_logprob":
  -0.2401774525642395, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.004428073298186064},
  {"id": 840, "seek": 345828, "start": 3464.76, "end": 3470.1200000000003, "text":
  " and accepting it and dealing with it is important as well. And then it kind of
  translates into maybe", "tokens": [50688, 293, 17391, 309, 293, 6260, 365, 309,
  307, 1021, 382, 731, 13, 400, 550, 309, 733, 295, 28468, 666, 1310, 50956], "temperature":
  0.0, "avg_logprob": -0.2401774525642395, "compression_ratio": 1.582995951417004,
  "no_speech_prob": 0.004428073298186064}, {"id": 841, "seek": 345828, "start": 3470.1200000000003,
  "end": 3476.84, "text": " some other region of your brain when you have this page
  from like, you know, reviews or like", "tokens": [50956, 512, 661, 4458, 295, 428,
  3567, 562, 291, 362, 341, 3028, 490, 411, 11, 291, 458, 11, 10229, 420, 411, 51292],
  "temperature": 0.0, "avg_logprob": -0.2401774525642395, "compression_ratio": 1.582995951417004,
  "no_speech_prob": 0.004428073298186064}, {"id": 842, "seek": 345828, "start": 3476.84,
  "end": 3482.92, "text": " your experiment going, hey, why are you can make? Oh yeah.
  Oh yeah. Fine. I got to get a cup of coffee", "tokens": [51292, 428, 5120, 516,
  11, 4177, 11, 983, 366, 291, 393, 652, 30, 876, 1338, 13, 876, 1338, 13, 12024,
  13, 286, 658, 281, 483, 257, 4414, 295, 4982, 51596], "temperature": 0.0, "avg_logprob":
  -0.2401774525642395, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.004428073298186064},
  {"id": 843, "seek": 348292, "start": 3483.08, "end": 3489.64, "text": " and you
  know, in five minutes, I''m okay. Maybe. Yeah. The coffee is the key supplement.",
  "tokens": [50372, 293, 291, 458, 11, 294, 1732, 2077, 11, 286, 478, 1392, 13, 2704,
  13, 865, 13, 440, 4982, 307, 264, 2141, 15436, 13, 50700], "temperature": 0.0, "avg_logprob":
  -0.21079522736218512, "compression_ratio": 1.488, "no_speech_prob": 0.013565145432949066},
  {"id": 844, "seek": 348292, "start": 3492.12, "end": 3498.36, "text": " Absolutely.
  Corner, thanks so much. This was such a fantastic conversation. I''m pretty sure
  we", "tokens": [50824, 7021, 13, 42391, 11, 3231, 370, 709, 13, 639, 390, 1270,
  257, 5456, 3761, 13, 286, 478, 1238, 988, 321, 51136], "temperature": 0.0, "avg_logprob":
  -0.21079522736218512, "compression_ratio": 1.488, "no_speech_prob": 0.013565145432949066},
  {"id": 845, "seek": 348292, "start": 3498.36, "end": 3504.76, "text": " can repeat
  it. Have another one. And I can''t wait to see what development you''re doing with
  VIAVIAT", "tokens": [51136, 393, 7149, 309, 13, 3560, 1071, 472, 13, 400, 286, 393,
  380, 1699, 281, 536, 437, 3250, 291, 434, 884, 365, 691, 6914, 25322, 2218, 51456],
  "temperature": 0.0, "avg_logprob": -0.21079522736218512, "compression_ratio": 1.488,
  "no_speech_prob": 0.013565145432949066}, {"id": 846, "seek": 348292, "start": 3504.76,
  "end": 3509.8, "text": " and also in all your research projects. You know, stay
  active, stay hungry, stay foolish,", "tokens": [51456, 293, 611, 294, 439, 428,
  2132, 4455, 13, 509, 458, 11, 1754, 4967, 11, 1754, 8067, 11, 1754, 23478, 11, 51708],
  "temperature": 0.0, "avg_logprob": -0.21079522736218512, "compression_ratio": 1.488,
  "no_speech_prob": 0.013565145432949066}, {"id": 847, "seek": 350980, "start": 3509.8,
  "end": 3514.28, "text": " as Steve Jobs used to say. And I think that''s fantastic
  what you''re doing. Thanks so much.", "tokens": [50364, 382, 7466, 29169, 1143,
  281, 584, 13, 400, 286, 519, 300, 311, 5456, 437, 291, 434, 884, 13, 2561, 370,
  709, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2781473875045776, "compression_ratio":
  1.2300884955752212, "no_speech_prob": 0.01643732562661171}, {"id": 848, "seek":
  350980, "start": 3515.0, "end": 3518.1200000000003, "text": " Thank you so much
  for having me to meet me. Bye.", "tokens": [50624, 1044, 291, 370, 709, 337, 1419,
  385, 281, 1677, 385, 13, 4621, 13, 50780], "temperature": 0.0, "avg_logprob": -0.2781473875045776,
  "compression_ratio": 1.2300884955752212, "no_speech_prob": 0.01643732562661171}]'
---

Hey everyone, Dr. Podgas here. And today we have Connor Shorten with me who will talk a bit about his research about lecture databases, about YouTube hopefully as well. So I'm expecting a really nice discussion today.
Hey Connor, how are you doing? Hey Dmitra, thanks so much for having me on the podcast. I'm really excited to continue our episode and maybe dive more into the deep learning research side.
 I think our first podcast on Henry AI labs went really into the detail and the practical implementation and the history of Burton Elasticsearch and then all the different vector databases and I think so now we can kind of maybe look more in the research side of things and sort of discuss together about where we think all this vector search engine stuff is headed.
Oh yeah, absolutely. And it's exciting to be recording based on the day when you actually released that video. So obviously we will link it so for our listeners and our audiences. And hey, could you please introduce yourself? Yeah, great.
So to say to introduce myself, I guess I would like to kind of like be reintroducing myself almost every like year. So as obviously I make these YouTube videos and I'm kind of like still discovering my role in deep learning research and still learning myself.
In my journey, I'm in my second year of my PhD. I finished my master's degree where I got started with research on generative adversarial networks and data augmentation, published literature reviews on data augmentation for images and text.
And this has really been my research focus is data augmentation, the idea. Primarily my interest was I started out with when I first learned about deep learning right away, I come from being a basketball player. I played basketball in college and I was ready to go deep learning for basketball.
How can this improve basketball? So one thing about basketball is when you're playing, you want to have a highlight mix tape where you have all your best moves and helps you get the college scholarship.
And so I was really familiar with that process of what it takes to be recruited to play college basketball. So I wanted to build this computer vision system that would crop out, you know, you're made baskets from full game tapes automatically.
And so I came into this problem that everyone has seen where if you try to do supervised learning with small data sets, it does not work. So like annotating data is extremely difficult.
Like you can, if you're doing it yourself, you can probably get yourself like, you know, in my case, I was annotating made baskets and video clips, which is already high dimensional data already, you know, paying to store all that data. So, you know, and labeling it was a problem.
So I said, maybe data augmentation because I'm overfitting this data. So I can try to rotate it, crop it horizontally, flip it, increase the brightness, this whole package of things you can do. Yeah, and orientation. Yeah. Right. And so it worked pretty well.
So I was pretty inspired by this idea of data augmentation.
I really like papers like Francois Chalets on the measure of intelligence where discussing the ideas of like system centric generalization developer, where generalization known unknowns is kind of, you know, matrix of known and unknowns with generalization cases.
So I hold the belief that we can kind of steer the data in the direction that enables more generalization. And the key to mocking more generalization is mostly going to be in the data space.
So I'd say I'm in this data centric AI category, which is, you know, lately become one of the buzzwords of where your camp is. I love things like neural architecture search and different learning strategies and all that, but I really love the data augmentation.
I think there's so much opportunity and research to explore this further. And then. And so yeah, so I have a few ideas of how this could intersect with vector search engines and vector representation learning. So that's on one end.
So that's kind of, you know, my research interest is in data augmentation and a bit of a background about how I became so inspired in data augmentation. So then to say kind of what I'm doing right now is, you know, I've, so I've started doing some experiment papers.
Most of my computing is managed with Google collab, which is pretty nice.
You know, like, you have the Google collab notebooks and then you have the Google Drive integration for persistence and, you know, you can make it pretty far without putting a dent in your wallet by doing it by getting too carried away. And so that's kind of how I'm setting that up.
And, you know, I have, you know, I can tell people about like, as I mentioned, beginning trying to reintroduce myself and figure out my role. So I had kind of like recently, like a high of achieving the best student paper at this ICT AI conference on something about inductive biases.
And then the next day I get my ICLR reviews back, which were not great. So, you know, and that's kind of the journey of this, you know, I'm just setting, setting forward to ICML and trying to just bounce back and stay on this journey of figuring out how to do deep learning research.
So it's definitely a high. Isn't it? It's like almost always like that, you know, like in machine learning, nothing is predictable and nothing is given, you know, like, and you need to be kind of averse to that. Well, not averse, but resistant, right? Like, okay, I'm fine.
I can take risks, but it's like a marathon. It's not a sprint. Oh, yeah, definitely. And just the disappointment of investing a month or two into a research project and then you just start running the experiments. And you're like, oh, this is not working.
And your advisor's on the phone twice a week and saying, how's it going? And you're like, not good. You know, like, so that's stressful. And, you know, anyone else going through that, I can definitely relate to that kind of struggle. Is this by the way, why you do YouTube show Henry A. L.A.
Labs? Is this why you do it? Or is there something else as well? I just wanted to kind of tap into the psychological element of it if you thought about it. Yeah, yeah, I love to talk about it.
I mean, my inspiration for YouTube came from, I guess I was just like one of these people who really enjoyed like we would have guest lectures come to Florida Atlantic University.
One that stood out to me more than anything else is researchers from Johns Hopkins came to, they had built a prosthetic limb that connects to a brain computer interface.
And they have people who have lost their limbs and they can, you know, blindfolded touch an orange and say, this is an orange, this is an apple, this is a banana. And they came to talk to us at Florida Atlantic. And I mean, it was, it was inspiring.
I like, I love these kind of seminars and just, I guess like falling in love with this kind of presentation.
It's almost like, say like to me, it's kind of like an allegace to like maybe like stand-up comedy, how you have someone who gets up on stage and puts the show on, you know, the benefit of the slides behind them. And, you know, I really like these, these kind of talks.
And that's kind of, so that's kind of like the art of it is what I really like about YouTube. I mean, I definitely believe in YouTube as the medium for communicating these ideas right now.
 You know, like, and we'll get into talking about writing on medium and like, yeah, like the different ways you can write on Twitter, you can write on medium, you can record podcasts and put it on Spotify, Apple, and you can write these research papers obviously just, you know, upload it to archive, treat it like a medium of the number of user on archive is probably less than what you get on YouTube.
The content is different too. So, yeah. Yeah. So, yeah, I really believe in the medium and then I just want to see the art form develop further. Like, I'm really impressed with what Yannick Kiltch was doing.
Like, right now he's just released auto regressive diffusion models and, you know, I'm excited to watch it and that's, and that's the fun about it is, is you have this excitement about it. Let's link that as well. It's a YouTube as well or like another show you mentioned. Yeah, yeah.
I think just YouTube, Yannick Kiltch, I think most of our viewers will know what we're talking about. I just want to make sure that I will also educate myself. So, so let's link that. Awesome.
Yeah, I mean, and so yeah, you said that data augmentation is one thing you worked on and I guess continue working on.
It's actually interesting that you did that in CV space, but there is also somehow connection in text, right? Can you tell a bit more about that? Yeah, so I, so I spent the, I think it was this, sorry, I'm getting my dates wrong. It's currently the fall.
So, I think I spent the summer spring of last year trying to transition these ideas into text. I did the image data augmentation survey in 2019 where the sentiment was still extremely hot around GANs, gender, vatricero networks. Everyone was really excited about this real fake loss.
We can generate data and then add that to the data set and then, you know, suddenly we have this very broad coverage for interpolation in our data space. So then I was trying to look into text. Text is, I say the key lesson I learned is that it's harder to be labeled preserving.
When you're forming the X prime Y, it's less likely that the Y is going to have that same high level class labels as you're trying to do things like say, like the starter kit would be random swapping, random insertion, random deletion, those kind of things.
And then you kind of transition into maybe trying to use a knowledge graph to better guide the text you're replacing. And then ideas like say mix up where you cut and paste and glue sentences together. I'm not like a huge fan of that, but it's kind of interesting. Yes.
Might as well have like drop out. It's kind of like a, you know, like I don't think there's a lot of intuition in the data space of why just smashing them together would work so well. But it does kind of work.
And then, and then I really like this category of generative data augmentation is obviously mentioning my start in gendered adversarial networks. And this idea that you learn the data distribution.
So you sample from the data distribution to learn classifiers and kind of classifiers being almost like a appendage of the generative model, which is, which is like what we're talking about with the modules, the supervised learning tasks that you append onto the vector search engine database.
It's like this task of having a generative model or say a representative vector space is kind of like the real context that built into the supervised learning task. Or at least that's the way I see it. And, you know, maybe anyone can leave a comment if they are have a different idea about that.
I think it's ill aimed. But so that's kind of how I see those two things integrating. So to connect this back to text, what we can do is text is we can use things like GPT three or more so what they do is you would prompt GPT three.
So you'd say, you know, please finish this movie review with a positive sentiment as the prompt. And then you can just remove whatever you want from the original data point. And GPT three can generate a new movie review.
And then you can blow up your data set size, avoid the pitfalls of overfitting and that kind of promise of data augmentation. So hopefully that kind of answers the question of how I did this transition from image to text data augmentation. Yeah, it does.
And I mean, why I'm asking also is because, you know, you can also treat these two sources of data in like kind of in a joint training task, right? So you can kind of train the joint neural network.
And for example, when you watch, let's say watch using the algorithm, you watch the movie or cartoon and you see some scene where, you know, one hero is kind of crying. The other one is cheering him up.
You know, now where do you pay attention to? It's also important, right? Because it's the whole scene. Now you need to pay attention, maybe just to that pin on his neck, you know, that he's not happy about. And you know, things like that.
So have you thought about that as well? Or are you still considering them as independent? Yeah, I know. Yeah, I love that idea. Like I think what we're the word that most people are using is multimodal learning. And I'd call that paper multimodal data augmentation.
And you know, just last night Microsoft released a new 2.5 billion parameter image text embedding space. You know, everyone's knows about OpenAI's clip image text spaces and the dolly, the avocado shaved armchair generation. Everyone likes that. So yeah, I mean, multimodal learning is so exciting.
Yeah, I'd say it's going to be an interesting thing with the computation of it and what kind of in what the computation requires, we're setting up these kind of tests.
I'd say, especially with video data, like you just mentioned, I, you know, I wouldn't really want to play around with video data with my collab Google Drive workflow that I mentioned earlier. Yeah. Yeah.
But it's interesting also that big players, like you mentioned Microsoft and I mean, others, they're moving in direction of increasing number of parameters in the model. But when you go to practice and you need to build a classifier, you know, you don't have that much capacity.
Like you don't want to spend that much capacity really unless you're building like a terminator level AI, which will handle all tasks that you have. But probably you won't do that because it's still not there.
So do you also think about that kind of the practical element or are you still kind of fencing the beauty of these complex models? Well, wait, do you see that? Yeah, well, I'll stake my flag in the same campus, the foundation models, researchers, and I think it was mostly Stanford.
They published this paper titled on the opportunities and risk of foundation models, some title like that. I'm sorry, it's not exactly correct. But, you know, this kind of ideology that big companies like Microsoft and Vitya Google Facebook, they'll build these big, big models.
And then what we'll do is we'll use this knowledge distillation interface to compress it into practical use cases.
And so we've seen, I'd say this started with Colin Raffle and the people who worked on my paper with the text to text transfer transform of the T5 model, not showed how you could unify all text supervised learning tasks through the same kind of language modeling style interface.
You just prompt it with, you know, natural language inference and then you give it the input or you say, answer this question, give it the input or you say, re-rank these documents and give them the document. So it's the same interface for every supervised learning task.
So yeah, I'm, and then just one more thing to kind of put in the citation context is this general purpose, like, opening iClip and it looks like Microsoft, I think they're calling it bletchly or something like that.
 But this idea of just having two vector embedding spaces and then using the contrast of alignment as the general interface for any kind of task, because as we mentioned, you can put any task into natural language, any task that you're going to do with supervised learning could be described with natural language.
So you have that kind of interface and the Allen Institute has another architecture called general purpose vision systems that, you know, unifies all these tasks, object detection, semantic segmentation, service, normal estimation, all these kind of ideas are unifying one architecture interface.
So to kind of wrap up my answer to the question, I think it's going to be Microsoft and them scaling up like crazy. Maybe they're going to run it out of internet scale data eventually. I think Microsoft has said that they can train like a 32 trillion parameter model if they were motivated to do so.
 So I think they're going to run out of internet scale data and then the data augmentation will be the next step from going from say like the 400 million image taxpayers that are now open sourced or Luther AI has the pile, which is like 800 gigabytes of raw text if you want to do something with that.
So I think eventually as you go into the 32 trillion parameter and on, they're going to use data augmentation to have these inductive biases about how we can keep scaling the data side of it. So yeah, so I think they can scale the models for a while.
Yeah, I guess they probably they are doing an amazing job, but like they are probably still writing the horse of what Peter Norby called the unreasonable effectiveness of data, right?
So like your algorithm might not be kind of as as nuanced as your data is and so just give it to the machine learning algorithm as much as possible and then kind of it will learn, right? But you know, like in practical situations, this is what I alluded to.
Like you just don't have that much data. On the other hand, you don't want you don't have that much choice and you also mentioned this. This is a very interesting topic of data augmentation in text because in images, you can do like cropping rotation and huge changes and whatnot.
In text, you can do that like so easily. For example, if you say you have a sentence London is the capital of Great Britain, you cannot put Barcelona there. It will not make sense.
So, you know, but like you can still find another example where you could probably swap cities and that's how you build, you know, the augmentation. But then there are other things. For example, if you take machine translation, you know, it suffers from hallucination problem.
I don't know if you heard about it, but like if you have certain like distortion in your data, for example, you call the websites and you also called erroneously the advertisement.
So you glued the advertisement to the source pair, source target pair, right? Now your model is hallucinating about that advertisement when the student has, right? So, and it's flipping facts. It's also switching, you know, object and subject easily. So it's not something.
And again, now I'm stepping on the territory of the model itself, right? But like, and model robustness. But I think data augmentation plays a key role in actually making sure that your model can kind of at least not hiccup on some very basic things, right? So.
Yeah, and we're completely in agreement with that. I think one other part to that story will be how, say, so Facebook has this model called retrieval augmented generation, where the whole idea is to add more context to avoid this hallucination problem.
So to kind of break down three things, you just said, I want to start off with the, yeah, the hallucination thing and transitioning right into that.
So, so I think the idea of adding more context is our best solution to stopping hallucination and maybe using consistency, contrastive loss, loss functions for the fine tuning to, to make sure they're attending on the context.
Because like I recently reviewed a paper on my channel titled open, open, open challenges in open domain generalization, some title like that, where, um, where yeah, these models, you get them the context. So they have additional context in the input, but they just don't read it.
And they just generalize as if it's not there. So fixing that problem is definitely step one. And so then to go into the second thing that you mentioned where you replaced London with Barcelona and that's the thing about tech data augmentation is, it's, it's not label preserving really.
It's harder to find symmetries in the space. It's easier to find these differences. So there's one paper. Maybe I'd like to point readers to titled on negative data augmentation.
And so they're kind of flipping the, so it's like, how do we use augmented data? Should we just keep using this, you know, kale divergence between the one hot class vectors or should we do something different with the augmented data?
I mentioned consistency losses where the loss would be, you know, the representations of X and X prime ignoring whatever the Y label is and negative data augmentation is saying, you know, push them apart.
These are not the same label. We've switched London with Barcelona. And so then I think the last thing, as we're talking about, like the practical implementation, I think you say two things, there's like two directions that which are really interesting.
And I think what you're getting to with the data augmentation is, is you want to prevent overfitting. And if you have, if you're, you know, grabbing Microsoft's 32 trillion parameter model, and you've only got 100 labeled examples, there's no way that's going to work.
So you want to prevent overfitting. And then I think kind of the second part to that story when people talk about this kind of topic is, is like storage and inference cost and obviously training costs. You're going to fine tune this.
So maybe training costs has been solved with prompting where you don't actually need to do any grading to send updates. You just give more in the input context. But then I think inference cost is solved with this knowledge installation interface.
And I think hugging face, man, I think the name of their product is lightning or something like that where it's about inference acceleration. And it looks like they're, you know, they're doing it pretty well. So I certainly bet on hugging face to solve that problem. Oh, yeah, absolutely.
I think they call it infinity, you know? Infinity. Yeah, sorry about that. Oh, it's okay. It's also like testing your memory, you know, like we remember. And I think it's still also like at some point, and I think Elon Musk is afraid of it.
Hey, Elon, if you're listening to this, hello, you know, like he's afraid of that our interface is way too slow, right? And so eventually I will basically supersede us, which I don't think so, but let's see.
 But also like what's interesting, I was thinking that maybe a little bit like developing this topic further, but it sounds you have so much knowledge on this and it's so packed, what you said, you know, like, for example, if we could use the language model itself to help us generate, you said GPT, right?
It's generative model, but there could be some others, which will kind of help us to generate things and then augment the dataset.
But there is one beautiful that I don't know if you've read this paper. It's called what bird is not lessons from a new suite of cycling, holistic diagnostics for language models. And so basically the paper essentially claims that bird does not distinguish the negations.
And that can be super, super sensitive, like in sentiment analysis, right? At least, but also like in machine translation and other downstream tasks. So have you thought about this? Like basically there is actually a now a development.
I think it's also on Microsoft side to try to bring knowledge into the language model. And you can do it in a variety of ways you mentioned knowledge graph, but there are other ways kind of to bring in the structured knowledge.
So any thoughts on that on that topic? Yeah, and this is where I'm just starting getting back into we V8 because I think we V8 is going to be a huge part of solving that problem and adding the additional context. But first I want to raise you one paper.
So from the psycholinguistic thing, I want to point readers in the direction of viewers in the direction of checklist. It was one of the best paper awards at a recent ACL conference. ACL is I think ACL EM and OP, like the top NLP conferences checklist is exactly what you say.
It's a complete suite of tests for negations named entity swapping. And it's really nice to use. It's on GitHub. So yeah, so they have the interfaces for testing for that kind of thing, which I think once you have the test, you can start hacking away, it's solving it.
It's not theoretically grounded. If you have the right test, you could hack away until you pass the test. So checklist is the test for that. But then so yeah, so then the idea of context and and we V8.
 So so V8 is so the vector search engine part and you know, Facebook paper dense passage retrieval is their current approach where they have, you know, the text embeddings, the documents and they're going to go retrieve the context so that you can avoid hallucination, hopefully avoid these kind of vulnerabilities through robustness.
But so vector search engines is what I see as being a huge player in solving that particular problem. And I see that transitioning not just from text, but image text of video text like the idea that you want to add some more context from your database to the current inference. Yeah, yeah.
I mean, V8 is doing fantastic work. Actually, we have a podcast recorded with mob and so, you know, my listener's can actually watch it and then we also had an episode with you where we covered some of the things. And you also recorded a bunch of videos like walking through the feature set.
What caught your attention in V8 when kind of if you can slightly compare to other database vendors? Okay, well, I don't have much of a comparison to other database vendors. And so I'm, you know, apologies to everyone out there working on this.
My experience with it doesn't come from the practical software engineering side of it. It comes from reading these research papers and then being familiar with these ideas. And then, I mean, V8 is easy to use. It's really well, the documentation is great. It's easy to get started with it.
So that was a huge thing for me is, you know, when I first met Bob, first of all, you know, he's a great guy and, you know, meeting this team. They're all really on top of everything and their slack chat is really great. People, you know, pitching in their problems and it's just a great community.
But, you know, what, what did it for me is, so I met Bob and then I spent about two weeks going through their documentation, the quick start, the installation set up, you know, get my data sets in there. And it's just really easy to use.
So I, and then, and then learning about all these other things like the Python client.
Like as we talk about fetching the context, I mean, we want to ingrate that into a training loop where say Facebook also recently released internet augmented generation where they're using the Bing API to bring in the context and then learn with that extra training.
So they have a Python client that lets you integrate that into your model workflows. And then something we talked about in our last podcast, I love the GraphQL interface. I think it's really cool. And I love the web demo.
So you can, you know, get started with the GraphQL interface and you can practice your queries, you know, you know, learn it quickly before you make any commitment of installing your mouse database.
So yeah, and I just think we be it is like a beautiful technology that's making my, my life is trying to do deep learning research just a lot easier. So, you know, it's awesome that they're willing to support Henry AI labs and help me continue making content on YouTube.
Well, at the same time, it's a, you know, it's a tool that helps me do what I want to do with this kind of research. Yeah. And are you like already using via V8 in your research or planning to use? Yeah.
So I haven't really made a Henry AI labs video on this yet, but it's something I'm really excited about. So one paper I recently had accepted in ICML A, not quite ICML, but ICML A, it's application to add it to it.
But it's a, it's a caros, Bert is the title of the paper and it's about, you know, language modeling with caros documentation and caros code examples and, you know, like Syek Paul, Franceschal Leigh, they're going crazy with these caros code examples. And there's so many examples.
Like you could, you have like a PhD and more organized completely online on this caros code examples to me. It's like the most interesting collection of deep learning information on the internet as the caros code examples.
So from there, there's like two ideas is like, can we build a language model that can like debug your caros code for you and, you know, open AI code X. Everyone knows that it looks like the answer to that is yes. And you know, they have the lead code, they have data sets of like lead code.
I know everyone loves lead code. And everyone is looking for a job. Yeah, code X is, you know, able to pass these lead code tests. So, you know, and I, you know, I'd say some lead code tests are harder than the deep learning debugging.
So, you know, it looks like it looks like a pretty promising solution. And so in the second project I have that I'm integrating WeeVeate, what to help me do is, is, you know, Facebook is big on unsupervised machine translation.
They did a paper where they're translating between Python and JavaScript without any annotation. So maybe we can translate between caros and PyTorch without needing to, or PyTorch and Jack's even to, without, you know, somehow without much labeling. And this is very much an infant research project.
But if you have that, if you could bring the caros code examples to PyTorch and Jack's and just, you know, help people share this knowledge.
So, so this is like two of my personal projects that I've started integrating WeeVeate in and then one of the project that I'm, you know, extremely passionate about and really into with my involvement with the university.
And this is kind of a separate thing that I'm not too heavy on because I don't want to like kind of push the commercial interest too much. It's, you know, and WeeVeate is open source. So it's an open source software. We have, we can download it from GitHub and we have it.
So they can't, you know, take it away.
And so, so this other project is, we're trying to build patient information retrieval systems where you, you know, you come to the hospital and they start to record your, you know, coagulation studies, they, all the physiological markers and the genetic history.
And we want to go query the literature maybe. So this is, you know, as a research project and the on Institute has been pioneering this with data sets like core 19 and their system called sub.ai. Salesforce research had a system called co-search. I'm just kind of naming things for people.
Oh my god, I'm not going to describe these things.
So these are like literature scientific literature mining systems where you, you know, you want information about say COVID-19 and or, you know, someone's coming in there with some obscure disease, you want to be able to query the literature with particular information about this patient.
And so this is the information retrieval problem that, you know, we're super interested in as spectrature search engine people. So we're trying to turn these patients into, which is what I have is mostly tabular data.
You might get a little bit of medical images, some clinical reports for some text, but, yeah, mostly tabular data. So we want to encode that into vectors, send those vectors into the scientific literature, and then maybe there's some clinical trial, you know, because it's so much data.
Once you really download, like say the core 19 data set from the on Institute, you'll realize that, you know, 500,000 papers about COVID is nothing anyone could read. You know, I already know this from reading deep learning papers. It's like no one can read this.
And even like, if you go traditional way, and I wanted those at the top in, in this area, you know, like if you go traditional way, let's say you have a keyword look up, right?
So keyword search, you would have to build like some kind of synonym layer, which means you need to understand what you're doing, or you will need to hire somebody to do that.
And that's like an additional step, which kind of like, you know, doesn't reduce the journey for you. You have to do that and this is that you feel like you have more control, maybe, but at the same time, it's very laborious.
So at the same time, similarity search kind of doesn't have that boundary, right? So essentially you haven't coded it and now you, you know, now that the challenge, the complexity moves more into the space of choosing the right neural network and then choosing the right database.
Everyone knows which is the right database. So, but anyway, but I'm just saying, like, but, but I'm just saying, like, do you think that similarity search will completely supersede keyword or you still see some synergy between them? Yeah.
And well, I like, before I get into saying my opinion on this, I'd say that I'm not the expert on keyword search. So, so here's my opinion on it. I, you know, we V8 has a symbolic filtering where you can still do symbolic searches. You can still do the keyword filtering.
You can still have these symbolic characteristics. And, you know, I'm in the same, I believe things like what Gary Marcus talks about, about, you know, it's not really robust to these symbolic queries. What we mentioned earlier, where you insert negation and it might completely throw it off.
So robustness is like not completely solved that. I was reading a paper this morning called from DeepMind Researcher's data augmentation can help robustness. It was like such a on the nose title, like that, like data augmentation helps robustness. So, so yeah, solving robustness.
And I'm, you know, I saw a, I'm not like, I still think solving robustness is a huge issue for this. It's not completely put together yet. Yeah, absolutely. I agree. I agree.
So, but like, yeah, you mentioned you are not an expert on keyword search, but at the same time, I think you were the expert of using like Google, right? So like you still type keywords.
And, and I think psychologically, you still expect, you know, the snippets to contain some of your keywords as a validation that the search engine got it, right? So like otherwise, search engine maybe that just, you know, returns you garbage in return to what you want.
Yeah, and that's why I think like like the page rank, transition dynamic matrices, though, those kind of things that that's like, it won't be enough to just have the vector search engine probably. You'll probably need some kind of like tuning layer.
And that's why, so we've got has the Python client. As I mentioned previously, a research project for this would be to integrate that Python client into the training loop of the, you know, whatever is doing the supervised learning task. So it kind of isn't just retrieving.
It's like when we talked about the difference in information retrieval and approximate nearest neighbor search, it's kind of like the semantics differences between the things you're encoding, where you might be encoding a like the email title and then the email body.
And so you have these different kind of like transitions between the categories of objects you're encoding.
So, so yeah, like the, you know, I still think that there's like a layer of, I don't know how to describe it, maybe like that system one system two, I know people like that analogy, but there's some kind of layer between keyword search and vector neural representations.
There's something in the middle of that. And, you know, I don't know what it is, but yeah, I guess page rank. Yeah.
Yeah, like basically you're talking about sort of even, even after vector database has returned to the nearest neighbors, you still have a sort of liberty to apply a re-runker, right?
Because and that's where your business logic kicks in, like the rules, the product, the vision, the design, there are so many inputs into that process of ranking.
And then ranking obviously is like a huge research area as well, you know, with the click biasing and things like that, right? Yeah, I mean, and it's also interesting. I just crossed my mind that yesterday, Richard Sorter announced his search engine and U.com.
And did you have a chance to check it out? Basically for listeners who didn't check it out yet, so it's a search engine which summarizes the web pages and the kind of documents and so on. And so you are kind of, it makes it actionable.
So just one example, they can find you a code snippet on Stack Overflow that you can actually copy paste. And that's just one example, right? But there are plenty of more. Any thoughts on this? Yeah, well, I mean, first of all, Richard Sacher, his research has been incredible.
And as I mentioned earlier in the podcast, I was listening to systems co-search from Salesforce Research was, he was one of the authors, I don't know who led the project. So yeah, U.com, I mean, it looks crazy.
Like, have I used it quite not really yet, but I definitely believe in the concept and yeah, the research is pointing in that direction. It's exciting.
But do I think like, solely neural system? Yeah, I mean, designing new interfaces around search, started to go around that a little bit as I'm trying to like think, well, I talk, but yeah, the U.com thing is exciting. New spaces for search engines.
It's hard to even completely conceptualize it, I think because it's such a, you think of Google as like this giant, undistructible search engine, but that's really not the story. There really is a ton of research and search engines. Yeah, yeah, but actually, I'm currently working for WebScale.
So, Changes, which I cannot mention because it's my client on the NDA, but we basically have all the charts and we know that Google is like 97%. And then everyone else is close to the bottom. Unfortunately, well, of course, Bing has a couple percent of the market.
And then it kind of, if you go inside a specific country, the split might be different. Like, if you take Russia, for example, Yandex is on top and then Google is following them, but very closely, you know, but overall, globally, Google is just somewhere beyond the sky.
So, you need to kind of differentiate a lot, you know, like you don't want to build another Google.
It's almost like Peter Tills book, you know, zero to one where he says, if you are building another Facebook, you're not learning anything from Mark Zuckerberg or if you're building another Google, you're not, you're not learning anything from the Google founders.
Like, you need to build that one, right? And I think Richard is trying to build that one probably. So, yeah, I mean, it's an interesting direction that he's trying to involve the AI much deeper in the process, probably already surfacing, you know, users. That's fantastic.
Yeah, yeah, I don't have anything to add other than just shared excitement about what you.com will become. It's certainly exciting. Yeah, absolutely. All the best Richard. Yeah, and you actually I wanted to make a slight segue into you shared like a ton of information today.
I wonder how do you keep up with so much stuff happening? Like, what are your preferred sources of information? Like, obviously YouTube is one, but, you know, there is also medium. There is publications themselves.
How did you structure your sort of consumption, you know, parts like the pacing and kind of where to pay, put your attention and so on? Yeah, that's a great question.
And, you know, early days of my podcast, I was doing the Machine Learning Street Talk with Tim Scarf and Yana Kiltcher and Tim asked Jonathan Frank, the author of the lottery ticket hypothesis, the same question. Like, what's your information diet? And I thought it's a really interesting question.
So mine is, you know, like most people out there trying to be good at something. It's chaotic and it gets overwhelming and I get really stressed out sometimes. So I don't know if this is the best advice to follow, but like, here's what I do.
So I, you know, I'm very active on Twitter, like maybe to the point of detrimental to my health, like I checked Twitter, like, all the time. Like, so I'm always refreshing Twitter and seeing the new headlines.
And so I, when I see like an archive link, I'll try to, like, if I like it, I've tried to discipline myself to be like, don't just like it. Like read the abstract, like get a couple sentences in because clearly, you know, the titles caught your attention.
So, so Twitter is really where I get all my news. And then the art form of making these YouTube videos, I mean, like Yana Kiltcher and Tim Scarf that I mentioned, the Machine Learning Street Talk, these kind of, this kind of medium. It's, I watch that. It's pretty good.
I think I watch it on like, Exploratory Street also Alexa, Miss Coffee Bean to kind of go on the list, you know, they're not the only ones doing it well. A lot of people are starting to make really great YouTube videos. And I love that kind of medium of showing these things.
So on my, my work, my like, my workout, say I'm a basketball player and I've got to work on my deep learning skills is it's mostly about reading these papers. My experiments, I'd say the coding part is not super challenging.
Thanks to things like Keras coding examples and like thanks to them, major thanks to them because that saves me so much headache in just getting running. So, so yeah, I try to, I try to read like five papers at a time. I tried to switch, I try to set 20 minute timers, drink a lot of coffee.
And what else do I do? Yeah, I guess that's it really reading the really reading the papers. I mean, if you make paper summary videos and write blog posts, that's also a huge way to retain it. I try to talk to a lot of people also just, you know, I try to keep a lot of contact.
Like I'm organized all this through Twitter. So like, you know, I might just send messages to say, Syek Paul from who makes, I think he works at Cardid and he makes, he's one of the leaders of Keras code examples. I'll send him ideas. I'll be like, you know, I saw this paper on Twitter.
I think, you know, this reminds me of what you're doing. And, and yes, I guess overall, that's my information diet. I'm probably leaving something that I didn't really, you know, prepare something for this, but no, it's okay.
I mean, it's also, it's also great that you're speaking your mind, but and things that really stick, you know, you mentioned them, right? But where on that scale, you would put medium, you know, the blogging platform where it kind of thrives with tutorials.
And sometimes these tutorials, they're kind of okay, but you kind of like, okay, are they going deep enough? But then there are other things where they summarize papers in such a way that they actually try to explain it.
It's almost like popularizing science because you do want to breed that next, you know, generation as well. And maybe you will have some feedback to your ideas because don't you think when you publish a research paper, you know, for the most part of the humanity, it's dry text.
For some, it's just Greek, right? They will not even understand it. They will never, they will never read it. And so, but they still might be curious, like, okay, how, you know, robots make decisions or something like that.
You know, so, how does my car, how does my car keep the lane keeps the lane? And actually today I was driving, I was driving to work and I was like, my car actually switched to the lane keeping mode. And it was telling me that I should not, you know, steer to the left that much.
So it was actually steering to the right. But the moment it noticed that I put my hands away from the steering wheel, it actually started alarming me and saying, hey, I'll sleep or something, you know.
So it's also like kind of caring for you, right? In a way, so it's not trying to do so much more work, in that sense.
Yeah, like, the idea of popular science, I mean, you know, I'm recording my podcast behind a bookshelf, like it makes me look smarter, but I only really, I only really read books like, you know, like the book of, I mean, the book of why is a bad example.
That's a really great book, like technical and I really really like that one. But most of these like popular science books, I'd have to be like on an airplane or something like I, or are in the same with the category of medium articles that are popular science.
Like, you know, I read research papers only, not to like be dismissive of anything else, but that's just like the question of what particularly do I study. And in my approach is very people-centric.
Like, you know, like when, say, Chelsea Finn publishes a new paper on Twitter, I'll go read that because I kind of have been following her thinking, like Jeff Cloon is another example with the AIGA's or François Shalide.
These kind of people like I, like Michael Bronson with the geometric deep learning is another great example. I hate doing these lists.
I never like to do these lists because it's so endless, like the vocabulary you need to kind of assess, like I've left off so many people, but you know, I like the people's centric focus and I try to get to know these people and understand like how they think of these things.
It's like the same thing as you go to the conference. Sometimes you don't go to that specific topic.
Maybe when you're a little bit more junior, you do, but later in your career, like academic or industrial, you actually go to listen to that person because they might not give you any novel idea, but they might give you so much experience that you daily, like really need, right?
Yeah, and just following the timeline of their work, it helped, like their newest work will help you realize, oh, that's their thinking in the past work too.
I kind of see how they're thinking about these things. And it's like, you know, everybody thinks so abstract. They have this idea, this vision, and it can be hard to communicate the vision in writing or videos.
So yeah, just like you said, I think just repeated exposure to the same person is like, hopefully that's Henry AI last thing. Yeah, absolutely. I'm pretty sure. I saw some really great comments underneath your videos, you know, some people were saying, I can't wait for the next one.
So you definitely doing great job there. So could as to you for doing that for so long actually. I don't know for how long you've been doing this, but you have a ton of videos. Yeah, and I really appreciate it.
You know, the people who keep commenting, I, you know, I recognize your profiles, and I do really, really appreciate it. So it helps me keep making the videos and staying convinced of that medium of YouTube being one of the ways to express these ideas.
I'd say like even, even more so than writing papers that you submit to these conferences. Sometimes I, you know, I think making a YouTube video can be a powerful way to share ideas.
I don't know if I want to completely put my flag on that idea because I, you know, these reviews, you do get some really good reviews. Like as I mentioned previously at the beginning of the video, I, you know, I literally got smashed on my ICLR reviews.
They were not good, but I got, I got really high quality feedback. So, yes. You know, you're learning from it. You're learning. Right. Yeah. Actually, one of my managers used to say feedback is gold.
So even if it feels painful, take it because because the problem is that sometimes, especially as you grow in your career, you know, at some point you will be the role model for some other people. Now, where do you get the feedback from nowhere? Because you're the person giving feedback.
But you still need to grow. You still have pains, you have doubts, you have ideas, you need validation. And maybe you're doing something wrong as well at some point. Maybe somebody is intimidated to tell you that because you are at the top. You are like the boss or whatever.
You know, like who gives you feedback at that point? They actually recommend to turn to, you know, professional coaches and kind of those people who can actually steer you in some direction. Right. Oh, maybe you can unload your thoughts.
Have you found yourself in that situation? Or what, what do you think? Yeah. Well, I mean, I'm in a lucky situation where I do have a formal PhD advisor that, as I mentioned, I speak on the phone with very often.
And, and you know, my PhD advisor and I had a relationship for so long that he like introduced machine learning to me. So it's like, I was a basketball player, you know, taking classes. And I, and so this was my introduction to machine learning.
I like, I hardly understood like, you know, like a tea test statistical regression analysis before this class. So it's like, so I'm, I've had the same advisor for a long time in that regard, like a formal academic advisor.
And then meeting people like Bob and, you know, you and I as we talk now, I, you know, trying to reach out and pick the brains of people and see what they think. I guess. Yeah. So basically they are like, they become like, you might have multiple role models.
And sometimes, you know, like they also say, you do not need a physical person with whom you talk, but it could be some kind of online person. Like for me, it used to be for a long time, Elon Musk, because I've been focusing on building startups.
And, and his approach to startups was not like, hey, you know, go unleash yourself, get rid of your doubt and just do it. No, he's so deep into what he does.
Like at some point, I want to record a podcast where I would like to talk to you or talk to somebody to actually explain and kind of does it resonate with you, like he's thinking, like, first, you need to try this before automating this.
You need to repeat it several times to learn new mistakes and blah, blah, blah. So it's like an amazing way.
And he like build this kind of, you know, a thought machinery that he applies to any problem, right? So any problem that lands in his hands, he's like, I can try it step by step like that and see what happens. And maybe at some point it just drops out and you're like, okay, I'm done here.
I'm moving to the next one, right? So I'm not going to waste my time. And he's a super productive guy, as we know. So I mean, sometimes it could be just an online person that you follow. And as you said, you do this on Twitter, like you said, like maniacally refreshing the tweeters.
So just stay stay safe as well there. But at the same time, I think the respiratory time in your life, when you're learning a ton. And later in your life, you will be kind of generating fruit out of it mostly. Or maybe you will be telling to other people and maybe inspiring them more and more.
And then leading some research groups and the work, you know, teams. And that's that's totally fine. But I also wanted to call out your idea that I think is quite instructive for many of us.
And hopefully to our listeners that yes, do go go and read papers because as Andrew Ang put it, he said, if you read a paper every weekend, let's say you have a full-time job, you don't have time to read it, you can read it on the weekend.
At some point, and he also recommended to start coding, you know, like actually you didn't find the code for it, just try to implement the idea, right?
At some point, after reading the papers, you will actually start generating ideas because you will find gaps in the thinking of the authors on all of these papers.
And nobody is doing perfect job there. They're doing the publishable work, right? And so I think that resonates with you as well. Yeah, definitely.
You definitely like switch gears where you become an idea machine like you say where you read a paper and you'll have like a billion ideas for how to extend it. And then you'll transition to this part, which is what I'm learning now.
And, you know, as I'm in my last year, I've been two years in my PhD and the transition for me is going from idea machine to, okay, can you really build the idea for real? Do you really know how to test this? And so, and that transition isn't super obvious.
And it's painful to be going back and forth between, you know, theoretical idea machine.
I'm reading these papers because like in terms of like that flow state of creativity that you get into when you're when you're working on things, for me, personally, reading papers is like the most satisfying thing. I feel very like productive when I'm reading papers.
I might, you know, I feel good. But when I'm engineering things, I feel more pain, man, because it's more painful, I'd say. Yes, yes.
And this is where, of course, you do want to have those oiled well, well, well, oiled software systems that you don't need to waste your time setting things up or running out of disco, whatever, you know, heaven so, so frequently.
So like even the innocuous things like before I had integrated Google Drive with Google collab, and it would crash. And I feel like I've just lost 10 hours of running this thing. So, and that is not good.
Like, this is I think what Joel Spolski said at some point, you know, the co-founder of Stack or Flow, you know, he said like, imagine that you want to print a piece of paper and you log into your computer and it says, please upgrade the driver.
So you upgrade the driver and then operating system says I need to reboot. So it reboots and it basically waits 10 minutes of your time. And then you, and then again, it says, hey, actually, I cannot print because you ran out of something now. Again, it installs them.
And you like, instead of solving the problem, you become the administrator of your computer, right?
And that's the same, the same thing can happen so much, so often in software, you know, development and research as well, because, because I think somebody will put on Twitter, we do not actually choose between big and small, like do a lot of things and do like small amount of things.
We usually choose between small and nothing. And so I guess when those things eating a lot of your small time, right, to nothing, you're like frustrated and you're like, okay, I'm just down the rabbit hole.
What am I doing?
And so I think tools like VEVIates save a ton of time and everybody who is innovating in this space from the direction of usability, you know, like and saving time, shaving those minutes off of, you know, your experience, I think that will save so much time for your thinking as well.
Yeah. And before VEVIate, I was doing a little bit of the sponsored content work, and which for me is great because I get to talk to these people and they teach me a lot. And so this is with the term in AI, which is now a part of you who have packered.
And so yeah, they're building the hyper-pram, like distributed training hyper-pram, reorganization, which what we're talking about, like the administer of the system, they're doing a lot of this work.
And you know, as anyone, I'm sure people listening to this have gotten smoked with the cost of one of these experiments too. So it's not just your time. It's not fun. Yeah, actually, you reminded me of on Google Cloud. It was a tutorial, like a workshop. It was a free one.
They even like gave us food. So you just show up, they video and then they tell you things. And it was a practical one. And I remember one of the instructors, he was not an employee of Google, but he was certified. And you know, like he said, hey, now we're gonna spin the Spanner cluster.
And Spanner is the my SQL planet scale with all the consistency and semantic guarantees using atomic clocks. And there is like a fantastic presentation by one of its engineers that I have in my recordings. I have not published yet because I don't know if Google will try to sue me.
But you know, the idea is that it's a fantastic system. And there is a paper as well. And then the guide, the teacher, he said, well, hold on. Don't spin too many of them because I get the bill. And last month, I got a bill of $4,000.
And Google could not reimburse it because they said, you're not an internal employee. So he was like, it's fun. But you know, to the point when you might. Yeah, it's funny. It's funny now, but it's not funny at all. Yeah, that determined AI calls it lunch and learn.
There are this kind of concept for deep learning, or like I'd say to science content, like even like, you know, with physics and they're going to be doing experiments where it's expensive. So we're not going to each be doing it.
We're going to watch one person do it and kind of gather around as a community. And yeah, I see that as being a huge part. Just like Uber eats coupons, I think is a brilliant interface for it. And then everyone attends the thing. But yeah, I love that kind of.
And then just quickly, so like one thing we're working on at Weve 8. And as people have seen with hugging face data sets and the Kaggle competitions, well, hugging face data is a little different, but it is hosting the demos cheaply. So that so in Weve 8, we're working on this.
The wiki data is going to be the next big release where we have the pie torch, big graph embeddings, which is the graph structure makes it different from say Wikipedia, because it's really good at entity embedding.
 As we mentioned London and Barcelona, if you construct a knowledge graph of Barcelona compared to London, that's going to have a better entity representation using learning techniques like deep walk or note to veck or maybe maybe like a graph convolutional network with an auto encoder loss, but probably deep walk or note to veck is what I would say is, I mean, I'm not completely caught up with that, but anyway, so having that kind of data set, the wiki data, and now it's cheaper.
That's the huge difference. That's the change in deep learning is hugging face is hosting all these data sets, so you don't have to host them yourself. You can just quickly access them.
 And with Weve 8, it's even more exciting, in my opinion, because they're hosting a vector search engine with model inference, I mean, hugging face is doing model inference too, as we talked about infinity where they've got inference time data like milliseconds for these massive models is, yeah, is you don't have to pay for the hosting of these things, which is obviously good.
Absolutely, absolutely. And also not like massive with hosting things, because that's also the cost of maintaining is the cost not to neglect. So absolutely. Yeah, yeah. Absolutely. Hey, it was such a packed conversation.
I think the show notes will be infinite, because you mentioned so many names, so many articles, and that's fantastic. Thanks so much for doing this. I wanted to just still kind of end on kind of a little bit like that philosophical stance, which I usually do.
And I think we touched a lot on that and thanks for doing this. But like in summary, what drives you? Why are you doing this? What you are doing? That's great question. I mean, I guess like, and I've heard, as you mentioned, Elon Musk, I've heard that he says, like, I want to be useful.
That's one thing he says. Yeah. And I guess in the same way, trying to do the useful thing.
And I guess like, obviously, I like these big grandiose visions of things like helping with health care and self-driving cars and helping with poverty and creating housing climate science, all these kind of things, obviously.
So obviously, there are these big grandiose goals that I think we all share truthfully.
But then it's more of a question of how do you stay in the grind of it? And how do you keep waking up and keep getting at it? And so I'd say that kind of heuristic of just trying to do useful things every day is actually a pretty good guide. And so we all share these big visions.
But we need the motivation to pick ourselves off the couch and achieve to do that. Yeah, absolutely.
And it also sounds like you mentioned you played basketball and you continue playing that, right? So that thing, when you do the sport, you need to be persistent, right? And your body sometimes doesn't want to do it, maybe. But you know in your mind that you do want to do it.
And so that persistence, I think, also translates into, you know, the research and keeping up with things, right? Yeah. Yeah.
 And to stay on that kind of analogy, I'd say like the physical pain of basketball is like, you might hurt your knee, you might have some tendonitis, is that kind of physical pain or the physical pain of when you're doing conditioning and you can't breathe, that you're going to have that same kind of analog with this kind of mental work.
And it'll manifest itself in like depression and burnout. And so you have to be like, as you do more training, you get better at the pain of the injuries. So to say like it's like injuries to your mind and the same kind of analog as physical injuries would be.
And I think understanding that and accepting it and dealing with it is important as well. And then it kind of translates into maybe some other region of your brain when you have this page from like, you know, reviews or like your experiment going, hey, why are you can make? Oh yeah. Oh yeah. Fine.
I got to get a cup of coffee and you know, in five minutes, I'm okay. Maybe. Yeah. The coffee is the key supplement. Absolutely. Corner, thanks so much. This was such a fantastic conversation. I'm pretty sure we can repeat it. Have another one.
And I can't wait to see what development you're doing with VIAVIAT and also in all your research projects. You know, stay active, stay hungry, stay foolish, as Steve Jobs used to say. And I think that's fantastic what you're doing. Thanks so much. Thank you so much for having me to meet me. Bye.