---
description: '<p>This episode on YouTube: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8">https://www.youtube.com/watch?v=TiwqVlDpsl8</a></p><p></p><p><a
  target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=0s">00:00</a>
  Intro</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=42s">00:42</a>
  Louis''s background</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=339s">05:39</a> From Facebook
  to Rockset</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=461s">07:41</a>
  Embeddings prior to deep learning / LLM era</p><p><a target="_blank" rel="noopener
  noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=755s">12:35</a>
  What''s Rockset as a product</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=927s">15:27</a> Use cases</p><p><a
  target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1084s">18:04</a>
  RocksDB as part of Rockset</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1233s">20:33</a> AI capabilities:
  ANN index, hybrid search</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1511s">25:11</a> Types of
  hybrid search</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1685s">28:05</a>
  Can one learn the alpha?</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1803s">30:03</a> Louis''s
  prediction of the future of vector search</p><p><a target="_blank" rel="noopener
  noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2035s">33:55</a>
  RAG and other AI capabilities</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2506s">41:46</a>
  Call out to the Vector Search community</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2776s">46:16</a>
  Vector Databases vs Databases</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2956s">49:16</a>
  Question of WHY</p>'
image_url: https://media.rss.com/vector-podcast/ep_cover_20240501_010549_d5b842295c8b59f78ff9fa1e488d2af8.png
pub_date: Wed, 01 May 2024 13:54:39 GMT
title: Louis Brandy - SQL meets Vector Search at Rockset
url: https://rss.com/podcasts/vector-podcast/1460893
whisper_segments: '[{"id": 0, "seek": 0, "start": 0.0, "end": 20.22, "text": " Hello
  there, vector podcast. Season three and this promised I''m trying to shoot for 30",
  "tokens": [50364, 2425, 456, 11, 8062, 7367, 13, 16465, 1045, 293, 341, 10768, 286,
  478, 1382, 281, 3076, 337, 2217, 51375], "temperature": 0.0, "avg_logprob": -0.2997669966324516,
  "compression_ratio": 1.303030303030303, "no_speech_prob": 0.18687711656093597},
  {"id": 1, "seek": 0, "start": 20.22, "end": 24.96, "text": " minute episodes. Let''s
  see how I''m going to do on this one. I''m super excited to have", "tokens": [51375,
  3456, 9313, 13, 961, 311, 536, 577, 286, 478, 516, 281, 360, 322, 341, 472, 13,
  286, 478, 1687, 2919, 281, 362, 51612], "temperature": 0.0, "avg_logprob": -0.2997669966324516,
  "compression_ratio": 1.303030303030303, "no_speech_prob": 0.18687711656093597},
  {"id": 2, "seek": 2496, "start": 24.96, "end": 31.200000000000003, "text": " Luis
  Brandy, vice president of engineering at Rockset. I know you guys are building database.",
  "tokens": [50364, 25133, 11119, 88, 11, 11964, 3868, 295, 7043, 412, 6922, 3854,
  13, 286, 458, 291, 1074, 366, 2390, 8149, 13, 50676], "temperature": 0.0, "avg_logprob":
  -0.1938008483575315, "compression_ratio": 1.5198412698412698, "no_speech_prob":
  0.36037302017211914}, {"id": 3, "seek": 2496, "start": 31.200000000000003, "end":
  36.24, "text": " Hey Luis, how are you doing? I''m doing great. So far so good.
  Thank you for having me today.", "tokens": [50676, 1911, 25133, 11, 577, 366, 291,
  884, 30, 286, 478, 884, 869, 13, 407, 1400, 370, 665, 13, 1044, 291, 337, 1419,
  385, 965, 13, 50928], "temperature": 0.0, "avg_logprob": -0.1938008483575315, "compression_ratio":
  1.5198412698412698, "no_speech_prob": 0.36037302017211914}, {"id": 4, "seek": 2496,
  "start": 36.24, "end": 44.0, "text": " Oh yeah, excited. Excited to learn about
  Rockset as well. But before that, it''s a tradition. Could", "tokens": [50928, 876,
  1338, 11, 2919, 13, 9368, 1226, 281, 1466, 466, 6922, 3854, 382, 731, 13, 583, 949,
  300, 11, 309, 311, 257, 6994, 13, 7497, 51316], "temperature": 0.0, "avg_logprob":
  -0.1938008483575315, "compression_ratio": 1.5198412698412698, "no_speech_prob":
  0.36037302017211914}, {"id": 5, "seek": 2496, "start": 44.0, "end": 50.480000000000004,
  "text": " you please introduce yourself a little bit about your background and how
  you got to your stage in", "tokens": [51316, 291, 1767, 5366, 1803, 257, 707, 857,
  466, 428, 3678, 293, 577, 291, 658, 281, 428, 3233, 294, 51640], "temperature":
  0.0, "avg_logprob": -0.1938008483575315, "compression_ratio": 1.5198412698412698,
  "no_speech_prob": 0.36037302017211914}, {"id": 6, "seek": 5048, "start": 50.48,
  "end": 57.36, "text": " your professional life? Sure. So I''ve been at Rockset for
  two years and change over two years.", "tokens": [50364, 428, 4843, 993, 30, 4894,
  13, 407, 286, 600, 668, 412, 6922, 3854, 337, 732, 924, 293, 1319, 670, 732, 924,
  13, 50708], "temperature": 0.0, "avg_logprob": -0.13005469062111594, "compression_ratio":
  1.623931623931624, "no_speech_prob": 0.0070395926013588905}, {"id": 7, "seek": 5048,
  "start": 58.64, "end": 65.84, "text": " VP of engineering. Before that, I was at
  Facebook for 11 years. So I did roughly three things at", "tokens": [50772, 35812,
  295, 7043, 13, 4546, 300, 11, 286, 390, 412, 4384, 337, 2975, 924, 13, 407, 286,
  630, 9810, 1045, 721, 412, 51132], "temperature": 0.0, "avg_logprob": -0.13005469062111594,
  "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0070395926013588905},
  {"id": 8, "seek": 5048, "start": 65.84, "end": 70.88, "text": " Facebook and it''s
  funny because even the ones that feel least relevant have become more relevant",
  "tokens": [51132, 4384, 293, 309, 311, 4074, 570, 754, 264, 2306, 300, 841, 1935,
  7340, 362, 1813, 544, 7340, 51384], "temperature": 0.0, "avg_logprob": -0.13005469062111594,
  "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0070395926013588905},
  {"id": 9, "seek": 5048, "start": 70.88, "end": 77.28, "text": " recently. I did
  spam fighting infrastructure for my first much of time at Facebook and that", "tokens":
  [51384, 3938, 13, 286, 630, 24028, 5237, 6896, 337, 452, 700, 709, 295, 565, 412,
  4384, 293, 300, 51704], "temperature": 0.0, "avg_logprob": -0.13005469062111594,
  "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0070395926013588905},
  {"id": 10, "seek": 7728, "start": 77.28, "end": 81.04, "text": " involved like two
  large systems. One was like a super real time system, which turns into the", "tokens":
  [50364, 3288, 411, 732, 2416, 3652, 13, 1485, 390, 411, 257, 1687, 957, 565, 1185,
  11, 597, 4523, 666, 264, 50552], "temperature": 0.0, "avg_logprob": -0.14345688606376078,
  "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.01672694832086563},
  {"id": 11, "seek": 7728, "start": 81.04, "end": 84.8, "text": " real time database
  we''re going to talk about today. And the other was we did a lot of vector", "tokens":
  [50552, 957, 565, 8149, 321, 434, 516, 281, 751, 466, 965, 13, 400, 264, 661, 390,
  321, 630, 257, 688, 295, 8062, 50740], "temperature": 0.0, "avg_logprob": -0.14345688606376078,
  "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.01672694832086563},
  {"id": 12, "seek": 7728, "start": 84.8, "end": 90.48, "text": " clustering. Like
  back I was doing vectors but way before they were cool. This time was like 2011,",
  "tokens": [50740, 596, 48673, 13, 1743, 646, 286, 390, 884, 18875, 457, 636, 949,
  436, 645, 1627, 13, 639, 565, 390, 411, 10154, 11, 51024], "temperature": 0.0, "avg_logprob":
  -0.14345688606376078, "compression_ratio": 1.8031746031746032, "no_speech_prob":
  0.01672694832086563}, {"id": 13, "seek": 7728, "start": 90.48, "end": 96.72, "text":
  " 2015 or so. And we used vectors a lot in in spam fighting and image classification.
  And this", "tokens": [51024, 7546, 420, 370, 13, 400, 321, 1143, 18875, 257, 688,
  294, 294, 24028, 5237, 293, 3256, 21538, 13, 400, 341, 51336], "temperature": 0.0,
  "avg_logprob": -0.14345688606376078, "compression_ratio": 1.8031746031746032, "no_speech_prob":
  0.01672694832086563}, {"id": 14, "seek": 7728, "start": 96.72, "end": 100.64, "text":
  " is like even before like the deep learning took over the world like this is right
  before deep", "tokens": [51336, 307, 411, 754, 949, 411, 264, 2452, 2539, 1890,
  670, 264, 1002, 411, 341, 307, 558, 949, 2452, 51532], "temperature": 0.0, "avg_logprob":
  -0.14345688606376078, "compression_ratio": 1.8031746031746032, "no_speech_prob":
  0.01672694832086563}, {"id": 15, "seek": 7728, "start": 100.64, "end": 104.48, "text":
  " learning changed everything in this in this space. But we were using vectors a
  lot. We built some", "tokens": [51532, 2539, 3105, 1203, 294, 341, 294, 341, 1901,
  13, 583, 321, 645, 1228, 18875, 257, 688, 13, 492, 3094, 512, 51724], "temperature":
  0.0, "avg_logprob": -0.14345688606376078, "compression_ratio": 1.8031746031746032,
  "no_speech_prob": 0.01672694832086563}, {"id": 16, "seek": 10448, "start": 104.48,
  "end": 109.2, "text": " pretty powerful systems actually built like large scale
  vector clustering. I don''t know before", "tokens": [50364, 1238, 4005, 3652, 767,
  3094, 411, 2416, 4373, 8062, 596, 48673, 13, 286, 500, 380, 458, 949, 50600], "temperature":
  0.0, "avg_logprob": -0.1368819399996921, "compression_ratio": 1.750915750915751,
  "no_speech_prob": 0.00035316290450282395}, {"id": 17, "seek": 10448, "start": 109.2,
  "end": 114.64, "text": " it was cool. Now everyone''s building large scale vector
  applications. And then I worked on a", "tokens": [50600, 309, 390, 1627, 13, 823,
  1518, 311, 2390, 2416, 4373, 8062, 5821, 13, 400, 550, 286, 2732, 322, 257, 50872],
  "temperature": 0.0, "avg_logprob": -0.1368819399996921, "compression_ratio": 1.750915750915751,
  "no_speech_prob": 0.00035316290450282395}, {"id": 18, "seek": 10448, "start": 114.64,
  "end": 119.92, "text": " lot of other stuff at my time at Facebook. So there was
  a lot of core C++ core libraries, a lot", "tokens": [50872, 688, 295, 661, 1507,
  412, 452, 565, 412, 4384, 13, 407, 456, 390, 257, 688, 295, 4965, 383, 25472, 4965,
  15148, 11, 257, 688, 51136], "temperature": 0.0, "avg_logprob": -0.1368819399996921,
  "compression_ratio": 1.750915750915751, "no_speech_prob": 0.00035316290450282395},
  {"id": 19, "seek": 10448, "start": 119.92, "end": 124.72, "text": " of infrastructure
  stuff. I worked on an open source stuff called folly and thrift. So these are",
  "tokens": [51136, 295, 6896, 1507, 13, 286, 2732, 322, 364, 1269, 4009, 1507, 1219,
  726, 13020, 293, 739, 2008, 13, 407, 613, 366, 51376], "temperature": 0.0, "avg_logprob":
  -0.1368819399996921, "compression_ratio": 1.750915750915751, "no_speech_prob": 0.00035316290450282395},
  {"id": 20, "seek": 10448, "start": 124.72, "end": 130.08, "text": " basically like
  core libraries that Facebook has released over the years. And the theme of all this",
  "tokens": [51376, 1936, 411, 4965, 15148, 300, 4384, 575, 4736, 670, 264, 924, 13,
  400, 264, 6314, 295, 439, 341, 51644], "temperature": 0.0, "avg_logprob": -0.1368819399996921,
  "compression_ratio": 1.750915750915751, "no_speech_prob": 0.00035316290450282395},
  {"id": 21, "seek": 13008, "start": 130.08, "end": 134.96, "text": " is like highly
  scalable infra. And then I did some real time and some vector stuff back in the",
  "tokens": [50364, 307, 411, 5405, 38481, 23654, 13, 400, 550, 286, 630, 512, 957,
  565, 293, 512, 8062, 1507, 646, 294, 264, 50608], "temperature": 0.0, "avg_logprob":
  -0.19945635347284824, "compression_ratio": 1.6632302405498283, "no_speech_prob":
  0.004424632992595434}, {"id": 22, "seek": 13008, "start": 134.96, "end": 139.60000000000002,
  "text": " spam fighting days. It''s not totally applicable necessarily to the modern
  world. But it''s still", "tokens": [50608, 24028, 5237, 1708, 13, 467, 311, 406,
  3879, 21142, 4725, 281, 264, 4363, 1002, 13, 583, 309, 311, 920, 50840], "temperature":
  0.0, "avg_logprob": -0.19945635347284824, "compression_ratio": 1.6632302405498283,
  "no_speech_prob": 0.004424632992595434}, {"id": 23, "seek": 13008, "start": 139.60000000000002,
  "end": 144.4, "text": " pretty interesting background. It a very interesting confluence
  of things that have brought me to", "tokens": [50840, 1238, 1880, 3678, 13, 467,
  257, 588, 1880, 1497, 40432, 295, 721, 300, 362, 3038, 385, 281, 51080], "temperature":
  0.0, "avg_logprob": -0.19945635347284824, "compression_ratio": 1.6632302405498283,
  "no_speech_prob": 0.004424632992595434}, {"id": 24, "seek": 13008, "start": 144.4,
  "end": 150.08, "text": " Roxette. So yeah, that''s my life story roughly and in
  nutshell, there''s more. But I think that", "tokens": [51080, 44427, 3007, 13, 407,
  1338, 11, 300, 311, 452, 993, 1657, 9810, 293, 294, 37711, 11, 456, 311, 544, 13,
  583, 286, 519, 300, 51364], "temperature": 0.0, "avg_logprob": -0.19945635347284824,
  "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.004424632992595434},
  {"id": 25, "seek": 13008, "start": 150.08, "end": 156.4, "text": " will do for the
  for the intro. Yeah, for sure. Very exciting, really exciting. I heard about thrift.",
  "tokens": [51364, 486, 360, 337, 264, 337, 264, 12897, 13, 865, 11, 337, 988, 13,
  4372, 4670, 11, 534, 4670, 13, 286, 2198, 466, 739, 2008, 13, 51680], "temperature":
  0.0, "avg_logprob": -0.19945635347284824, "compression_ratio": 1.6632302405498283,
  "no_speech_prob": 0.004424632992595434}, {"id": 26, "seek": 15640, "start": 156.4,
  "end": 162.56, "text": " And I also remember like early on many years ago, when
  some of you guys were on stage, you know,", "tokens": [50364, 400, 286, 611, 1604,
  411, 2440, 322, 867, 924, 2057, 11, 562, 512, 295, 291, 1074, 645, 322, 3233, 11,
  291, 458, 11, 50672], "temperature": 0.0, "avg_logprob": -0.1499397090223969, "compression_ratio":
  1.7272727272727273, "no_speech_prob": 0.008209636434912682}, {"id": 27, "seek":
  15640, "start": 162.56, "end": 167.36, "text": " from the engineering at Facebook,
  you would constantly, you know, hint to the point that yeah,", "tokens": [50672,
  490, 264, 7043, 412, 4384, 11, 291, 576, 6460, 11, 291, 458, 11, 12075, 281, 264,
  935, 300, 1338, 11, 50912], "temperature": 0.0, "avg_logprob": -0.1499397090223969,
  "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008209636434912682},
  {"id": 28, "seek": 15640, "start": 167.36, "end": 173.04000000000002, "text": "
  we ran out of the capabilities of this database. So we needed to scale up. We needed
  to build a new one", "tokens": [50912, 321, 5872, 484, 295, 264, 10862, 295, 341,
  8149, 13, 407, 321, 2978, 281, 4373, 493, 13, 492, 2978, 281, 1322, 257, 777, 472,
  51196], "temperature": 0.0, "avg_logprob": -0.1499397090223969, "compression_ratio":
  1.7272727272727273, "no_speech_prob": 0.008209636434912682}, {"id": 29, "seek":
  15640, "start": 173.04000000000002, "end": 179.04000000000002, "text": " sometimes.
  And that was really really interesting that it''s constantly like, you know, you''re
  always", "tokens": [51196, 2171, 13, 400, 300, 390, 534, 534, 1880, 300, 309, 311,
  6460, 411, 11, 291, 458, 11, 291, 434, 1009, 51496], "temperature": 0.0, "avg_logprob":
  -0.1499397090223969, "compression_ratio": 1.7272727272727273, "no_speech_prob":
  0.008209636434912682}, {"id": 30, "seek": 15640, "start": 179.04000000000002, "end":
  184.16, "text": " battle against too many images, too many videos and so on and
  so forth. Yeah, one thing that I''ve", "tokens": [51496, 4635, 1970, 886, 867, 5267,
  11, 886, 867, 2145, 293, 370, 322, 293, 370, 5220, 13, 865, 11, 472, 551, 300, 286,
  600, 51752], "temperature": 0.0, "avg_logprob": -0.1499397090223969, "compression_ratio":
  1.7272727272727273, "no_speech_prob": 0.008209636434912682}, {"id": 31, "seek":
  18416, "start": 184.16, "end": 190.8, "text": " always said was that like everything
  is broken at scale. Like like, there''s this idea that sometimes", "tokens": [50364,
  1009, 848, 390, 300, 411, 1203, 307, 5463, 412, 4373, 13, 1743, 411, 11, 456, 311,
  341, 1558, 300, 2171, 50696], "temperature": 0.0, "avg_logprob": -0.13620163654458933,
  "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.002339428523555398},
  {"id": 32, "seek": 18416, "start": 190.8, "end": 196.56, "text": " you reach for
  the right tool for the job, but the reality is like when when you push the even
  the", "tokens": [50696, 291, 2524, 337, 264, 558, 2290, 337, 264, 1691, 11, 457,
  264, 4103, 307, 411, 562, 562, 291, 2944, 264, 754, 264, 50984], "temperature":
  0.0, "avg_logprob": -0.13620163654458933, "compression_ratio": 1.7664233576642336,
  "no_speech_prob": 0.002339428523555398}, {"id": 33, "seek": 18416, "start": 196.56,
  "end": 201.12, "text": " right tool to the limit, it will fall over and you''ll
  find yourself doing things that other people,", "tokens": [50984, 558, 2290, 281,
  264, 4948, 11, 309, 486, 2100, 670, 293, 291, 603, 915, 1803, 884, 721, 300, 661,
  561, 11, 51212], "temperature": 0.0, "avg_logprob": -0.13620163654458933, "compression_ratio":
  1.7664233576642336, "no_speech_prob": 0.002339428523555398}, {"id": 34, "seek":
  18416, "start": 201.12, "end": 204.48, "text": " you know, rebuilding something
  that other people take for granted. Like my favorite example of this", "tokens":
  [51212, 291, 458, 11, 36717, 746, 300, 661, 561, 747, 337, 12344, 13, 1743, 452,
  2954, 1365, 295, 341, 51380], "temperature": 0.0, "avg_logprob": -0.13620163654458933,
  "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.002339428523555398},
  {"id": 35, "seek": 18416, "start": 204.48, "end": 210.32, "text": " is at Facebook,
  we had a team on on my core C++ group that was working on Malak. Like", "tokens":
  [51380, 307, 412, 4384, 11, 321, 632, 257, 1469, 322, 322, 452, 4965, 383, 25472,
  1594, 300, 390, 1364, 322, 5746, 514, 13, 1743, 51672], "temperature": 0.0, "avg_logprob":
  -0.13620163654458933, "compression_ratio": 1.7664233576642336, "no_speech_prob":
  0.002339428523555398}, {"id": 36, "seek": 21032, "start": 211.28, "end": 216.64,
  "text": " who who works on Malak? It turns out there are people that work at Malak.
  They''re most of them work at", "tokens": [50412, 567, 567, 1985, 322, 5746, 514,
  30, 467, 4523, 484, 456, 366, 561, 300, 589, 412, 5746, 514, 13, 814, 434, 881,
  295, 552, 589, 412, 50680], "temperature": 0.0, "avg_logprob": -0.18197216811003508,
  "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.012771518900990486},
  {"id": 37, "seek": 21032, "start": 216.64, "end": 221.12, "text": " like a place
  like Facebook or Google or places like that, but but that''s like the kind of thing
  where", "tokens": [50680, 411, 257, 1081, 411, 4384, 420, 3329, 420, 3190, 411,
  300, 11, 457, 457, 300, 311, 411, 264, 733, 295, 551, 689, 50904], "temperature":
  0.0, "avg_logprob": -0.18197216811003508, "compression_ratio": 1.6322314049586777,
  "no_speech_prob": 0.012771518900990486}, {"id": 38, "seek": 21032, "start": 221.12,
  "end": 226.0, "text": " you can save a lot of money by making tiny improvements
  to Malak. So it''s worth doing.", "tokens": [50904, 291, 393, 3155, 257, 688, 295,
  1460, 538, 1455, 5870, 13797, 281, 5746, 514, 13, 407, 309, 311, 3163, 884, 13,
  51148], "temperature": 0.0, "avg_logprob": -0.18197216811003508, "compression_ratio":
  1.6322314049586777, "no_speech_prob": 0.012771518900990486}, {"id": 39, "seek":
  21032, "start": 226.0, "end": 233.35999999999999, "text": " It''s amazing. I remember
  I did a bit of a C++ as well. I guess like you could say two and a half years.",
  "tokens": [51148, 467, 311, 2243, 13, 286, 1604, 286, 630, 257, 857, 295, 257, 383,
  25472, 382, 731, 13, 286, 2041, 411, 291, 727, 584, 732, 293, 257, 1922, 924, 13,
  51516], "temperature": 0.0, "avg_logprob": -0.18197216811003508, "compression_ratio":
  1.6322314049586777, "no_speech_prob": 0.012771518900990486}, {"id": 40, "seek":
  23336, "start": 234.32000000000002, "end": 242.0, "text": " And at some point in
  the 90 virus company here in Finland, I had to choose which Malak will it be,",
  "tokens": [50412, 400, 412, 512, 935, 294, 264, 4289, 5752, 2237, 510, 294, 24869,
  11, 286, 632, 281, 2826, 597, 5746, 514, 486, 309, 312, 11, 50796], "temperature":
  0.0, "avg_logprob": -0.15402721891216203, "compression_ratio": 1.58, "no_speech_prob":
  0.03078543022274971}, {"id": 41, "seek": 23336, "start": 242.0, "end": 247.12, "text":
  " right? And I had to sort of discuss with my team and I was like, struck really,
  is that really the", "tokens": [50796, 558, 30, 400, 286, 632, 281, 1333, 295, 2248,
  365, 452, 1469, 293, 286, 390, 411, 11, 13159, 534, 11, 307, 300, 534, 264, 51052],
  "temperature": 0.0, "avg_logprob": -0.15402721891216203, "compression_ratio": 1.58,
  "no_speech_prob": 0.03078543022274971}, {"id": 42, "seek": 23336, "start": 247.12,
  "end": 252.4, "text": " thing we need to discuss? And they said, yeah, actually
  you won''t believe because we are running on", "tokens": [51052, 551, 321, 643,
  281, 2248, 30, 400, 436, 848, 11, 1338, 11, 767, 291, 1582, 380, 1697, 570, 321,
  366, 2614, 322, 51316], "temperature": 0.0, "avg_logprob": -0.15402721891216203,
  "compression_ratio": 1.58, "no_speech_prob": 0.03078543022274971}, {"id": 43, "seek":
  23336, "start": 252.4, "end": 258.96000000000004, "text": " a mobile phone back
  then it was this Microsoft''s Windows mobile, I guess it was called, right? So",
  "tokens": [51316, 257, 6013, 2593, 646, 550, 309, 390, 341, 8116, 311, 8591, 6013,
  11, 286, 2041, 309, 390, 1219, 11, 558, 30, 407, 51644], "temperature": 0.0, "avg_logprob":
  -0.15402721891216203, "compression_ratio": 1.58, "no_speech_prob": 0.03078543022274971},
  {"id": 44, "seek": 25896, "start": 259.03999999999996, "end": 264.47999999999996,
  "text": " you have to be really careful to the round. Yeah, I mean, there''s only
  here for Malak''s in the", "tokens": [50368, 291, 362, 281, 312, 534, 5026, 281,
  264, 3098, 13, 865, 11, 286, 914, 11, 456, 311, 787, 510, 337, 5746, 514, 311, 294,
  264, 50640], "temperature": 0.0, "avg_logprob": -0.16987393596979578, "compression_ratio":
  1.6526315789473685, "no_speech_prob": 0.021107446402311325}, {"id": 45, "seek":
  25896, "start": 264.47999999999996, "end": 269.2, "text": " world. So you might
  have chosen ours. Who knows? Amazing. All these say is that you''ve been really,",
  "tokens": [50640, 1002, 13, 407, 291, 1062, 362, 8614, 11896, 13, 2102, 3255, 30,
  14165, 13, 1057, 613, 584, 307, 300, 291, 600, 668, 534, 11, 50876], "temperature":
  0.0, "avg_logprob": -0.16987393596979578, "compression_ratio": 1.6526315789473685,
  "no_speech_prob": 0.021107446402311325}, {"id": 46, "seek": 25896, "start": 269.2,
  "end": 275.03999999999996, "text": " really deep and low level. And so I think you
  you doubled in coding obviously, right?", "tokens": [50876, 534, 2452, 293, 2295,
  1496, 13, 400, 370, 286, 519, 291, 291, 24405, 294, 17720, 2745, 11, 558, 30, 51168],
  "temperature": 0.0, "avg_logprob": -0.16987393596979578, "compression_ratio": 1.6526315789473685,
  "no_speech_prob": 0.021107446402311325}, {"id": 47, "seek": 25896, "start": 276.0,
  "end": 280.15999999999997, "text": " Yeah. So I was a fairly technical. I''ve been
  a manager for relatively long time. I don''t know,", "tokens": [51216, 865, 13,
  407, 286, 390, 257, 6457, 6191, 13, 286, 600, 668, 257, 6598, 337, 7226, 938, 565,
  13, 286, 500, 380, 458, 11, 51424], "temperature": 0.0, "avg_logprob": -0.16987393596979578,
  "compression_ratio": 1.6526315789473685, "no_speech_prob": 0.021107446402311325},
  {"id": 48, "seek": 25896, "start": 280.15999999999997, "end": 285.84, "text": "
  12 years or so, but I''ve always been a fairly technical manager in my path. And
  so for example,", "tokens": [51424, 2272, 924, 420, 370, 11, 457, 286, 600, 1009,
  668, 257, 6457, 6191, 6598, 294, 452, 3100, 13, 400, 370, 337, 1365, 11, 51708],
  "temperature": 0.0, "avg_logprob": -0.16987393596979578, "compression_ratio": 1.6526315789473685,
  "no_speech_prob": 0.021107446402311325}, {"id": 49, "seek": 28584, "start": 286.0,
  "end": 289.84, "text": " for years I worked in the course, SQL''s plus libraries
  at Facebook, even while I was a manager,", "tokens": [50372, 337, 924, 286, 2732,
  294, 264, 1164, 11, 19200, 311, 1804, 15148, 412, 4384, 11, 754, 1339, 286, 390,
  257, 6598, 11, 50564], "temperature": 0.0, "avg_logprob": -0.20760056229888416,
  "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.004974909592419863},
  {"id": 50, "seek": 28584, "start": 289.84, "end": 297.2, "text": " even a director.
  I was on the SQL standards committee for a while and doing things like that.", "tokens":
  [50564, 754, 257, 5391, 13, 286, 390, 322, 264, 19200, 7787, 7482, 337, 257, 1339,
  293, 884, 721, 411, 300, 13, 50932], "temperature": 0.0, "avg_logprob": -0.20760056229888416,
  "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.004974909592419863},
  {"id": 51, "seek": 28584, "start": 298.96, "end": 306.15999999999997, "text": "
  Sorry, I got paged. Everything''s fine. So yeah, I''ve definitely worked in the
  code. I''ve tried", "tokens": [51020, 4919, 11, 286, 658, 280, 2980, 13, 5471, 311,
  2489, 13, 407, 1338, 11, 286, 600, 2138, 2732, 294, 264, 3089, 13, 286, 600, 3031,
  51380], "temperature": 0.0, "avg_logprob": -0.20760056229888416, "compression_ratio":
  1.6643356643356644, "no_speech_prob": 0.004974909592419863}, {"id": 52, "seek":
  28584, "start": 306.15999999999997, "end": 309.67999999999995, "text": " to stay
  as hands on as possible. In most recent years, it''s become increasingly difficult.",
  "tokens": [51380, 281, 1754, 382, 2377, 322, 382, 1944, 13, 682, 881, 5162, 924,
  11, 309, 311, 1813, 12980, 2252, 13, 51556], "temperature": 0.0, "avg_logprob":
  -0.20760056229888416, "compression_ratio": 1.6643356643356644, "no_speech_prob":
  0.004974909592419863}, {"id": 53, "seek": 28584, "start": 310.4, "end": 315.12,
  "text": " I just I don''t know, it''s sort of the dark side of management. You slowly
  slide into more managerial", "tokens": [51592, 286, 445, 286, 500, 380, 458, 11,
  309, 311, 1333, 295, 264, 2877, 1252, 295, 4592, 13, 509, 5692, 4137, 666, 544,
  6598, 831, 51828], "temperature": 0.0, "avg_logprob": -0.20760056229888416, "compression_ratio":
  1.6643356643356644, "no_speech_prob": 0.004974909592419863}, {"id": 54, "seek":
  31512, "start": 315.12, "end": 320.4, "text": " things. But I still try to stay
  about as hands on as I possibly can. Oh, tell me about,", "tokens": [50364, 721,
  13, 583, 286, 920, 853, 281, 1754, 466, 382, 2377, 322, 382, 286, 6264, 393, 13,
  876, 11, 980, 385, 466, 11, 50628], "temperature": 0.0, "avg_logprob": -0.18076297429602917,
  "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.013700243085622787},
  {"id": 55, "seek": 31512, "start": 320.4, "end": 326.24, "text": " tell me about
  me about that. I mean, I''m also on the product management side today and", "tokens":
  [50628, 980, 385, 466, 385, 466, 300, 13, 286, 914, 11, 286, 478, 611, 322, 264,
  1674, 4592, 1252, 965, 293, 50920], "temperature": 0.0, "avg_logprob": -0.18076297429602917,
  "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.013700243085622787},
  {"id": 56, "seek": 31512, "start": 326.24, "end": 331.04, "text": " previously a
  manager of people as well. And I''m like, am I sliding backwards? Do I need to?",
  "tokens": [50920, 8046, 257, 6598, 295, 561, 382, 731, 13, 400, 286, 478, 411, 11,
  669, 286, 21169, 12204, 30, 1144, 286, 643, 281, 30, 51160], "temperature": 0.0,
  "avg_logprob": -0.18076297429602917, "compression_ratio": 1.6559139784946237, "no_speech_prob":
  0.013700243085622787}, {"id": 57, "seek": 31512, "start": 331.76, "end": 338.0,
  "text": " Sometimes I do, but it''s not on the same level as it used to be for sure.
  But it makes sense to", "tokens": [51196, 4803, 286, 360, 11, 457, 309, 311, 406,
  322, 264, 912, 1496, 382, 309, 1143, 281, 312, 337, 988, 13, 583, 309, 1669, 2020,
  281, 51508], "temperature": 0.0, "avg_logprob": -0.18076297429602917, "compression_ratio":
  1.6559139784946237, "no_speech_prob": 0.013700243085622787}, {"id": 58, "seek":
  31512, "start": 338.0, "end": 343.92, "text": " stay on these topics. And and then
  after all these years, you decided to move to Roxette. I''ve read", "tokens": [51508,
  1754, 322, 613, 8378, 13, 400, 293, 550, 934, 439, 613, 924, 11, 291, 3047, 281,
  1286, 281, 44427, 3007, 13, 286, 600, 1401, 51804], "temperature": 0.0, "avg_logprob":
  -0.18076297429602917, "compression_ratio": 1.6559139784946237, "no_speech_prob":
  0.013700243085622787}, {"id": 59, "seek": 34392, "start": 344.64000000000004, "end":
  351.04, "text": " a blog post that I think you''ve written for the company where
  you give the reasons why you did so", "tokens": [50400, 257, 6968, 2183, 300, 286,
  519, 291, 600, 3720, 337, 264, 2237, 689, 291, 976, 264, 4112, 983, 291, 630, 370,
  50720], "temperature": 0.0, "avg_logprob": -0.15379995169098845, "compression_ratio":
  1.6141078838174274, "no_speech_prob": 0.020054491236805916}, {"id": 60, "seek":
  34392, "start": 351.04, "end": 356.48, "text": " and you explain about the team
  strengths and so on support. Some of them are from Facebook as well.", "tokens":
  [50720, 293, 291, 2903, 466, 264, 1469, 16986, 293, 370, 322, 1406, 13, 2188, 295,
  552, 366, 490, 4384, 382, 731, 13, 50992], "temperature": 0.0, "avg_logprob": -0.15379995169098845,
  "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.020054491236805916},
  {"id": 61, "seek": 34392, "start": 356.48, "end": 365.52000000000004, "text": "
  Today matter, right? Can you sort of repeat that story a little bit like why you
  moved from a big", "tokens": [50992, 2692, 1871, 11, 558, 30, 1664, 291, 1333, 295,
  7149, 300, 1657, 257, 707, 857, 411, 983, 291, 4259, 490, 257, 955, 51444], "temperature":
  0.0, "avg_logprob": -0.15379995169098845, "compression_ratio": 1.6141078838174274,
  "no_speech_prob": 0.020054491236805916}, {"id": 62, "seek": 34392, "start": 365.52000000000004,
  "end": 372.08000000000004, "text": " company you could say, right? To a startup.
  So the answer is in short is the people. The core", "tokens": [51444, 2237, 291,
  727, 584, 11, 558, 30, 1407, 257, 18578, 13, 407, 264, 1867, 307, 294, 2099, 307,
  264, 561, 13, 440, 4965, 51772], "temperature": 0.0, "avg_logprob": -0.15379995169098845,
  "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.020054491236805916},
  {"id": 63, "seek": 37208, "start": 372.08, "end": 376.64, "text": " group at Roxette
  is a bunch of, I shouldn''t say the core group now. The core group now has grown
  a", "tokens": [50364, 1594, 412, 44427, 3007, 307, 257, 3840, 295, 11, 286, 4659,
  380, 584, 264, 4965, 1594, 586, 13, 440, 4965, 1594, 586, 575, 7709, 257, 50592],
  "temperature": 0.0, "avg_logprob": -0.18809340610977046, "compression_ratio": 1.8065693430656935,
  "no_speech_prob": 0.0033300681971013546}, {"id": 64, "seek": 37208, "start": 376.64,
  "end": 382.88, "text": " lot, but the original founding or was a bunch of extremely
  strong Facebook people that I knew from", "tokens": [50592, 688, 11, 457, 264, 3380,
  22223, 420, 390, 257, 3840, 295, 4664, 2068, 4384, 561, 300, 286, 2586, 490, 50904],
  "temperature": 0.0, "avg_logprob": -0.18809340610977046, "compression_ratio": 1.8065693430656935,
  "no_speech_prob": 0.0033300681971013546}, {"id": 65, "seek": 37208, "start": 382.88,
  "end": 388.15999999999997, "text": " Facebook and from. And so you know, you mentioned
  rebuilding databases. For example, like two of the", "tokens": [50904, 4384, 293,
  490, 13, 400, 370, 291, 458, 11, 291, 2835, 36717, 22380, 13, 1171, 1365, 11, 411,
  732, 295, 264, 51168], "temperature": 0.0, "avg_logprob": -0.18809340610977046,
  "compression_ratio": 1.8065693430656935, "no_speech_prob": 0.0033300681971013546},
  {"id": 66, "seek": 37208, "start": 388.15999999999997, "end": 391.76, "text": "
  main people were probably three of the main people responsible for rebuilding databases
  at Facebook", "tokens": [51168, 2135, 561, 645, 1391, 1045, 295, 264, 2135, 561,
  6250, 337, 36717, 22380, 412, 4384, 51348], "temperature": 0.0, "avg_logprob": -0.18809340610977046,
  "compression_ratio": 1.8065693430656935, "no_speech_prob": 0.0033300681971013546},
  {"id": 67, "seek": 37208, "start": 391.76, "end": 398.08, "text": " are at Roxette.
  So Drupal, who''s who''s our CTO was built RoxDB at Facebook. And that was part
  of", "tokens": [51348, 366, 412, 44427, 3007, 13, 407, 413, 11976, 304, 11, 567,
  311, 567, 311, 527, 383, 15427, 390, 3094, 44427, 27735, 412, 4384, 13, 400, 300,
  390, 644, 295, 51664], "temperature": 0.0, "avg_logprob": -0.18809340610977046,
  "compression_ratio": 1.8065693430656935, "no_speech_prob": 0.0033300681971013546},
  {"id": 68, "seek": 39808, "start": 398.56, "end": 404.24, "text": " replacing the
  storage plan of my sequel and a highly scalable way at Facebook. And then of course,",
  "tokens": [50388, 19139, 264, 6725, 1393, 295, 452, 20622, 293, 257, 5405, 38481,
  636, 412, 4384, 13, 400, 550, 295, 1164, 11, 50672], "temperature": 0.0, "avg_logprob":
  -0.21484406415153953, "compression_ratio": 1.6724890829694323, "no_speech_prob":
  0.0004236118693370372}, {"id": 69, "seek": 39808, "start": 404.24, "end": 408.47999999999996,
  "text": " the graph database that powers literally all of Facebook like Facebook
  is a graph and it is", "tokens": [50672, 264, 4295, 8149, 300, 8674, 3736, 439,
  295, 4384, 411, 4384, 307, 257, 4295, 293, 309, 307, 50884], "temperature": 0.0,
  "avg_logprob": -0.21484406415153953, "compression_ratio": 1.6724890829694323, "no_speech_prob":
  0.0004236118693370372}, {"id": 70, "seek": 39808, "start": 408.47999999999996, "end":
  413.36, "text": " primarily powered by a graph database called Tau. Nathan and Vencat
  are two people who worked", "tokens": [50884, 10029, 17786, 538, 257, 4295, 8149,
  1219, 314, 1459, 13, 20634, 293, 11182, 18035, 366, 732, 561, 567, 2732, 51128],
  "temperature": 0.0, "avg_logprob": -0.21484406415153953, "compression_ratio": 1.6724890829694323,
  "no_speech_prob": 0.0004236118693370372}, {"id": 71, "seek": 39808, "start": 413.36,
  "end": 420.15999999999997, "text": " who worked on that at at extensively at like
  tech leads and founders in some sense of that project", "tokens": [51128, 567, 2732,
  322, 300, 412, 412, 32636, 412, 411, 7553, 6689, 293, 25608, 294, 512, 2020, 295,
  300, 1716, 51468], "temperature": 0.0, "avg_logprob": -0.21484406415153953, "compression_ratio":
  1.6724890829694323, "no_speech_prob": 0.0004236118693370372}, {"id": 72, "seek":
  42016, "start": 420.8, "end": 429.52000000000004, "text": " Facebook. So this is
  like extremely pedigree group. So to me, I don''t care so much about it,", "tokens":
  [50396, 4384, 13, 407, 341, 307, 411, 4664, 5670, 328, 701, 1594, 13, 407, 281,
  385, 11, 286, 500, 380, 1127, 370, 709, 466, 309, 11, 50832], "temperature": 0.0,
  "avg_logprob": -0.1625074109723491, "compression_ratio": 1.7814814814814814, "no_speech_prob":
  0.020830150693655014}, {"id": 73, "seek": 42016, "start": 429.52000000000004, "end":
  433.76000000000005, "text": " they''re also like genuinely amazing people to work
  with and work around. And so this is kind of", "tokens": [50832, 436, 434, 611,
  411, 17839, 2243, 561, 281, 589, 365, 293, 589, 926, 13, 400, 370, 341, 307, 733,
  295, 51044], "temperature": 0.0, "avg_logprob": -0.1625074109723491, "compression_ratio":
  1.7814814814814814, "no_speech_prob": 0.020830150693655014}, {"id": 74, "seek":
  42016, "start": 433.76000000000005, "end": 439.12, "text": " this idea of like,
  hey, you want to join us startup with a bunch of the smartest people you''ve ever",
  "tokens": [51044, 341, 1558, 295, 411, 11, 4177, 11, 291, 528, 281, 3917, 505, 18578,
  365, 257, 3840, 295, 264, 41491, 561, 291, 600, 1562, 51312], "temperature": 0.0,
  "avg_logprob": -0.1625074109723491, "compression_ratio": 1.7814814814814814, "no_speech_prob":
  0.020830150693655014}, {"id": 75, "seek": 42016, "start": 439.12, "end": 444.72,
  "text": " worked with and like try to do something and worst case scenario, you
  know, it all goes, you know,", "tokens": [51312, 2732, 365, 293, 411, 853, 281,
  360, 746, 293, 5855, 1389, 9005, 11, 291, 458, 11, 309, 439, 1709, 11, 291, 458,
  11, 51592], "temperature": 0.0, "avg_logprob": -0.1625074109723491, "compression_ratio":
  1.7814814814814814, "no_speech_prob": 0.020830150693655014}, {"id": 76, "seek":
  42016, "start": 444.72, "end": 448.48, "text": " kaput or whatever, but you have
  like you worked with like some of the best people on a really", "tokens": [51592,
  13816, 325, 420, 2035, 11, 457, 291, 362, 411, 291, 2732, 365, 411, 512, 295, 264,
  1151, 561, 322, 257, 534, 51780], "temperature": 0.0, "avg_logprob": -0.1625074109723491,
  "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.020830150693655014},
  {"id": 77, "seek": 44848, "start": 448.48, "end": 451.76, "text": " interesting
  problem for a couple years. And I was like, yeah, I''m in for that. There''s a",
  "tokens": [50364, 1880, 1154, 337, 257, 1916, 924, 13, 400, 286, 390, 411, 11, 1338,
  11, 286, 478, 294, 337, 300, 13, 821, 311, 257, 50528], "temperature": 0.0, "avg_logprob":
  -0.16544021478220194, "compression_ratio": 1.6736842105263159, "no_speech_prob":
  0.0017827838892117143}, {"id": 78, "seek": 44848, "start": 451.76, "end": 455.84000000000003,
  "text": " longer version of that story, but that''s that is really the central reason
  of why I ended up", "tokens": [50528, 2854, 3037, 295, 300, 1657, 11, 457, 300,
  311, 300, 307, 534, 264, 5777, 1778, 295, 983, 286, 4590, 493, 50732], "temperature":
  0.0, "avg_logprob": -0.16544021478220194, "compression_ratio": 1.6736842105263159,
  "no_speech_prob": 0.0017827838892117143}, {"id": 79, "seek": 44848, "start": 455.84000000000003,
  "end": 462.48, "text": " I ended up switching. Yeah, I mean, it sounds like a brilliant
  reason too. But I''m also interested", "tokens": [50732, 286, 4590, 493, 16493,
  13, 865, 11, 286, 914, 11, 309, 3263, 411, 257, 10248, 1778, 886, 13, 583, 286,
  478, 611, 3102, 51064], "temperature": 0.0, "avg_logprob": -0.16544021478220194,
  "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.0017827838892117143},
  {"id": 80, "seek": 44848, "start": 462.48, "end": 468.16, "text": " you said you''ve
  been using embeddings before like Facebook and on vectors and you said that prior
  to", "tokens": [51064, 291, 848, 291, 600, 668, 1228, 12240, 29432, 949, 411, 4384,
  293, 322, 18875, 293, 291, 848, 300, 4059, 281, 51348], "temperature": 0.0, "avg_logprob":
  -0.16544021478220194, "compression_ratio": 1.6736842105263159, "no_speech_prob":
  0.0017827838892117143}, {"id": 81, "seek": 44848, "start": 469.04, "end": 475.92,
  "text": " deep learning era. So can you explain a bit like how these vectors were
  sort of created if it''s", "tokens": [51392, 2452, 2539, 4249, 13, 407, 393, 291,
  2903, 257, 857, 411, 577, 613, 18875, 645, 1333, 295, 2942, 498, 309, 311, 51736],
  "temperature": 0.0, "avg_logprob": -0.16544021478220194, "compression_ratio": 1.6736842105263159,
  "no_speech_prob": 0.0017827838892117143}, {"id": 82, "seek": 47592, "start": 475.92,
  "end": 481.52000000000004, "text": " possible? So there is some sensitivity here,
  but it''s not maybe for the reason you think it''s not", "tokens": [50364, 1944,
  30, 407, 456, 307, 512, 19392, 510, 11, 457, 309, 311, 406, 1310, 337, 264, 1778,
  291, 519, 309, 311, 406, 50644], "temperature": 0.0, "avg_logprob": -0.16989439277238744,
  "compression_ratio": 1.72, "no_speech_prob": 0.0009300808887928724}, {"id": 83,
  "seek": 47592, "start": 481.52000000000004, "end": 487.52000000000004, "text": "
  a trade sensitivity. The sensitivity with abuse abuse use cases. What we were doing
  was image", "tokens": [50644, 257, 4923, 19392, 13, 440, 19392, 365, 9852, 9852,
  764, 3331, 13, 708, 321, 645, 884, 390, 3256, 50944], "temperature": 0.0, "avg_logprob":
  -0.16989439277238744, "compression_ratio": 1.72, "no_speech_prob": 0.0009300808887928724},
  {"id": 84, "seek": 47592, "start": 487.52000000000004, "end": 494.88, "text": "
  classification. And and most of this is I''m not going to go into too much detail
  for maybe obvious", "tokens": [50944, 21538, 13, 400, 293, 881, 295, 341, 307, 286,
  478, 406, 516, 281, 352, 666, 886, 709, 2607, 337, 1310, 6322, 51312], "temperature":
  0.0, "avg_logprob": -0.16989439277238744, "compression_ratio": 1.72, "no_speech_prob":
  0.0009300808887928724}, {"id": 85, "seek": 47592, "start": 494.88, "end": 502.08000000000004,
  "text": " reasons, but there are there are images that you are not allowed to to
  to use or put up and they", "tokens": [51312, 4112, 11, 457, 456, 366, 456, 366,
  5267, 300, 291, 366, 406, 4350, 281, 281, 281, 764, 420, 829, 493, 293, 436, 51672],
  "temperature": 0.0, "avg_logprob": -0.16989439277238744, "compression_ratio": 1.72,
  "no_speech_prob": 0.0009300808887928724}, {"id": 86, "seek": 50208, "start": 502.08,
  "end": 506.88, "text": " and and obviously what they don''t want to do is hand all
  these companies like the images and say", "tokens": [50364, 293, 293, 2745, 437,
  436, 500, 380, 528, 281, 360, 307, 1011, 439, 613, 3431, 411, 264, 5267, 293, 584,
  50604], "temperature": 0.0, "avg_logprob": -0.13278803011266196, "compression_ratio":
  1.7661870503597121, "no_speech_prob": 0.00045941834105178714}, {"id": 87, "seek":
  50208, "start": 506.88, "end": 513.4399999999999, "text": " if you see this illegal
  image, tell us. So oftentimes they give you hashes. And but these aren''t actual",
  "tokens": [50604, 498, 291, 536, 341, 11905, 3256, 11, 980, 505, 13, 407, 18349,
  436, 976, 291, 575, 8076, 13, 400, 457, 613, 3212, 380, 3539, 50932], "temperature":
  0.0, "avg_logprob": -0.13278803011266196, "compression_ratio": 1.7661870503597121,
  "no_speech_prob": 0.00045941834105178714}, {"id": 88, "seek": 50208, "start": 513.4399999999999,
  "end": 517.52, "text": " hashes. They are not a hash of the illegal image. They
  are a locality sensitive hash and they''re", "tokens": [50932, 575, 8076, 13, 814,
  366, 406, 257, 22019, 295, 264, 11905, 3256, 13, 814, 366, 257, 1628, 1860, 9477,
  22019, 293, 436, 434, 51136], "temperature": 0.0, "avg_logprob": -0.13278803011266196,
  "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.00045941834105178714},
  {"id": 89, "seek": 50208, "start": 517.52, "end": 523.92, "text": " a vector. What
  they are is literally a vector. And Euclidean distance is the measurement of so
  you", "tokens": [51136, 257, 8062, 13, 708, 436, 366, 307, 3736, 257, 8062, 13,
  400, 462, 1311, 31264, 282, 4560, 307, 264, 13160, 295, 370, 291, 51456], "temperature":
  0.0, "avg_logprob": -0.13278803011266196, "compression_ratio": 1.7661870503597121,
  "no_speech_prob": 0.00045941834105178714}, {"id": 90, "seek": 50208, "start": 523.92,
  "end": 529.6, "text": " basically have a a classic vector search problem. You''re
  given a pile of vectors. If there''s a", "tokens": [51456, 1936, 362, 257, 257,
  7230, 8062, 3164, 1154, 13, 509, 434, 2212, 257, 14375, 295, 18875, 13, 759, 456,
  311, 257, 51740], "temperature": 0.0, "avg_logprob": -0.13278803011266196, "compression_ratio":
  1.7661870503597121, "no_speech_prob": 0.00045941834105178714}, {"id": 91, "seek":
  52960, "start": 529.6, "end": 534.4, "text": " technology known as photo DNA that
  you can look up. It''s it''s not as far as I know it''s not like an", "tokens":
  [50364, 2899, 2570, 382, 5052, 8272, 300, 291, 393, 574, 493, 13, 467, 311, 309,
  311, 406, 382, 1400, 382, 286, 458, 309, 311, 406, 411, 364, 50604], "temperature":
  0.0, "avg_logprob": -0.15064579678564957, "compression_ratio": 1.6382113821138211,
  "no_speech_prob": 0.00031559172202832997}, {"id": 92, "seek": 52960, "start": 534.4,
  "end": 539.6800000000001, "text": " open standard. So you don''t actually it''s
  not actually in the public domain. What it actually is,", "tokens": [50604, 1269,
  3832, 13, 407, 291, 500, 380, 767, 309, 311, 406, 767, 294, 264, 1908, 9274, 13,
  708, 309, 767, 307, 11, 50868], "temperature": 0.0, "avg_logprob": -0.15064579678564957,
  "compression_ratio": 1.6382113821138211, "no_speech_prob": 0.00031559172202832997},
  {"id": 93, "seek": 52960, "start": 539.6800000000001, "end": 545.6, "text": " but
  it''s effectively a mechanism for turning images into vectors that''s used as this
  hashing mechanism.", "tokens": [50868, 457, 309, 311, 8659, 257, 7513, 337, 6246,
  5267, 666, 18875, 300, 311, 1143, 382, 341, 575, 571, 7513, 13, 51164], "temperature":
  0.0, "avg_logprob": -0.15064579678564957, "compression_ratio": 1.6382113821138211,
  "no_speech_prob": 0.00031559172202832997}, {"id": 94, "seek": 52960, "start": 546.16,
  "end": 555.36, "text": " And and so Facebook built a bunch of infrastructure to
  flag hashes that came through for reasons that", "tokens": [51192, 400, 293, 370,
  4384, 3094, 257, 3840, 295, 6896, 281, 7166, 575, 8076, 300, 1361, 807, 337, 4112,
  300, 51652], "temperature": 0.0, "avg_logprob": -0.15064579678564957, "compression_ratio":
  1.6382113821138211, "no_speech_prob": 0.00031559172202832997}, {"id": 95, "seek":
  55536, "start": 556.32, "end": 561.12, "text": " are not fun to talk about. Let''s
  put it that way. Like they''re there. There''s like again, I don''t want", "tokens":
  [50412, 366, 406, 1019, 281, 751, 466, 13, 961, 311, 829, 309, 300, 636, 13, 1743,
  436, 434, 456, 13, 821, 311, 411, 797, 11, 286, 500, 380, 528, 50652], "temperature":
  0.0, "avg_logprob": -0.15344659062742277, "compression_ratio": 1.745583038869258,
  "no_speech_prob": 0.003532773582264781}, {"id": 96, "seek": 55536, "start": 561.12,
  "end": 566.16, "text": " to get into it. It''s kind of it''s awful, right? But at
  the end of the day, like you have you have", "tokens": [50652, 281, 483, 666, 309,
  13, 467, 311, 733, 295, 309, 311, 11232, 11, 558, 30, 583, 412, 264, 917, 295, 264,
  786, 11, 411, 291, 362, 291, 362, 50904], "temperature": 0.0, "avg_logprob": -0.15344659062742277,
  "compression_ratio": 1.745583038869258, "no_speech_prob": 0.003532773582264781},
  {"id": 97, "seek": 55536, "start": 566.16, "end": 573.52, "text": " vectors flowing
  into the system. And what you''re doing every single upload is is doing essentially
  a", "tokens": [50904, 18875, 13974, 666, 264, 1185, 13, 400, 437, 291, 434, 884,
  633, 2167, 6580, 307, 307, 884, 4476, 257, 51272], "temperature": 0.0, "avg_logprob":
  -0.15344659062742277, "compression_ratio": 1.745583038869258, "no_speech_prob":
  0.003532773582264781}, {"id": 98, "seek": 55536, "start": 573.52, "end": 578.32,
  "text": " vector search. You''re saying, Hey, given this corpus of vectors is this
  vector that fly that''s", "tokens": [51272, 8062, 3164, 13, 509, 434, 1566, 11,
  1911, 11, 2212, 341, 1181, 31624, 295, 18875, 307, 341, 8062, 300, 3603, 300, 311,
  51512], "temperature": 0.0, "avg_logprob": -0.15344659062742277, "compression_ratio":
  1.745583038869258, "no_speech_prob": 0.003532773582264781}, {"id": 99, "seek": 55536,
  "start": 578.32, "end": 584.88, "text": " coming in match any use. That was the
  basic core of the system. But once you have this like these", "tokens": [51512,
  1348, 294, 2995, 604, 764, 13, 663, 390, 264, 3875, 4965, 295, 264, 1185, 13, 583,
  1564, 291, 362, 341, 411, 613, 51840], "temperature": 0.0, "avg_logprob": -0.15344659062742277,
  "compression_ratio": 1.745583038869258, "no_speech_prob": 0.003532773582264781},
  {"id": 100, "seek": 58488, "start": 584.88, "end": 588.72, "text": " vectors, you
  can start to do other abuse things. So for example, you can start clustering vectors.",
  "tokens": [50364, 18875, 11, 291, 393, 722, 281, 360, 661, 9852, 721, 13, 407, 337,
  1365, 11, 291, 393, 722, 596, 48673, 18875, 13, 50556], "temperature": 0.0, "avg_logprob":
  -0.1964050654707284, "compression_ratio": 1.835820895522388, "no_speech_prob": 0.00021399892284534872},
  {"id": 101, "seek": 58488, "start": 588.72, "end": 593.52, "text": " You can build
  vector clusters. And that way you can find like neighborhoods of images, like similar",
  "tokens": [50556, 509, 393, 1322, 8062, 23313, 13, 400, 300, 636, 291, 393, 915,
  411, 20052, 295, 5267, 11, 411, 2531, 50796], "temperature": 0.0, "avg_logprob":
  -0.1964050654707284, "compression_ratio": 1.835820895522388, "no_speech_prob": 0.00021399892284534872},
  {"id": 102, "seek": 58488, "start": 593.52, "end": 601.76, "text": " images. Now
  here similar is here similar means something quite different. Because these were
  not", "tokens": [50796, 5267, 13, 823, 510, 2531, 307, 510, 2531, 1355, 746, 1596,
  819, 13, 1436, 613, 645, 406, 51208], "temperature": 0.0, "avg_logprob": -0.1964050654707284,
  "compression_ratio": 1.835820895522388, "no_speech_prob": 0.00021399892284534872},
  {"id": 103, "seek": 58488, "start": 601.76, "end": 606.48, "text": " like semantic
  similarity. So this is not like what you would get from an embedding today from
  like", "tokens": [51208, 411, 47982, 32194, 13, 407, 341, 307, 406, 411, 437, 291,
  576, 483, 490, 364, 12240, 3584, 965, 490, 411, 51444], "temperature": 0.0, "avg_logprob":
  -0.1964050654707284, "compression_ratio": 1.835820895522388, "no_speech_prob": 0.00021399892284534872},
  {"id": 104, "seek": 58488, "start": 606.48, "end": 612.64, "text": " say, you know,
  any of the modern. Yeah, I heard clip. Yeah, whatever. Yeah. These were these were",
  "tokens": [51444, 584, 11, 291, 458, 11, 604, 295, 264, 4363, 13, 865, 11, 286,
  2198, 7353, 13, 865, 11, 2035, 13, 865, 13, 1981, 645, 613, 645, 51752], "temperature":
  0.0, "avg_logprob": -0.1964050654707284, "compression_ratio": 1.835820895522388,
  "no_speech_prob": 0.00021399892284534872}, {"id": 105, "seek": 61264, "start": 612.64,
  "end": 619.84, "text": " these were much more like text textual. I mean, texture.
  People familiar with like image processing", "tokens": [50364, 613, 645, 709, 544,
  411, 2487, 2487, 901, 13, 286, 914, 11, 8091, 13, 3432, 4963, 365, 411, 3256, 9007,
  50724], "temperature": 0.0, "avg_logprob": -0.1727774852030986, "compression_ratio":
  1.7158273381294964, "no_speech_prob": 0.0003227063571102917}, {"id": 106, "seek":
  61264, "start": 619.84, "end": 625.76, "text": " techniques. This is these are vectors
  based on things like local pixel gradients or wavelet", "tokens": [50724, 7512,
  13, 639, 307, 613, 366, 18875, 2361, 322, 721, 411, 2654, 19261, 2771, 2448, 420,
  22144, 302, 51020], "temperature": 0.0, "avg_logprob": -0.1727774852030986, "compression_ratio":
  1.7158273381294964, "no_speech_prob": 0.0003227063571102917}, {"id": 107, "seek":
  61264, "start": 625.76, "end": 630.96, "text": " transforms things like that. So
  when we say images were similar, we mean to things like, you know,", "tokens": [51020,
  35592, 721, 411, 300, 13, 407, 562, 321, 584, 5267, 645, 2531, 11, 321, 914, 281,
  721, 411, 11, 291, 458, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1727774852030986,
  "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.0003227063571102917},
  {"id": 108, "seek": 61264, "start": 630.96, "end": 637.84, "text": " like rebalancing
  the white scale or or changing the hue and saturation like like those kinds of",
  "tokens": [51280, 411, 319, 2645, 8779, 264, 2418, 4373, 420, 420, 4473, 264, 24967,
  293, 27090, 411, 411, 729, 3685, 295, 51624], "temperature": 0.0, "avg_logprob":
  -0.1727774852030986, "compression_ratio": 1.7158273381294964, "no_speech_prob":
  0.0003227063571102917}, {"id": 109, "seek": 61264, "start": 637.84, "end": 641.92,
  "text": " image manipulation or re encoding it right from a different JPEG, different
  JPEG encoding.", "tokens": [51624, 3256, 26475, 420, 319, 43430, 309, 558, 490,
  257, 819, 508, 5208, 38, 11, 819, 508, 5208, 38, 43430, 13, 51828], "temperature":
  0.0, "avg_logprob": -0.1727774852030986, "compression_ratio": 1.7158273381294964,
  "no_speech_prob": 0.0003227063571102917}, {"id": 110, "seek": 64192, "start": 641.92,
  "end": 647.36, "text": " Like it was tolerant to that kind of manipulation, not
  like it wasn''t like finding images of elephants,", "tokens": [50364, 1743, 309,
  390, 45525, 281, 300, 733, 295, 26475, 11, 406, 411, 309, 2067, 380, 411, 5006,
  5267, 295, 33015, 11, 50636], "temperature": 0.0, "avg_logprob": -0.21305700302124023,
  "compression_ratio": 1.640495867768595, "no_speech_prob": 0.001825169543735683},
  {"id": 111, "seek": 64192, "start": 647.36, "end": 652.4799999999999, "text": "
  like that''s that''s not what it was doing. Yeah, yeah, I remember I took a course.
  Actually, I studied", "tokens": [50636, 411, 300, 311, 300, 311, 406, 437, 309,
  390, 884, 13, 865, 11, 1338, 11, 286, 1604, 286, 1890, 257, 1164, 13, 5135, 11,
  286, 9454, 50892], "temperature": 0.0, "avg_logprob": -0.21305700302124023, "compression_ratio":
  1.640495867768595, "no_speech_prob": 0.001825169543735683}, {"id": 112, "seek":
  64192, "start": 652.4799999999999, "end": 659.28, "text": " master degree in Finland
  here dedicated to data security. And one of the courses was about,", "tokens": [50892,
  4505, 4314, 294, 24869, 510, 8374, 281, 1412, 3825, 13, 400, 472, 295, 264, 7712,
  390, 466, 11, 51232], "temperature": 0.0, "avg_logprob": -0.21305700302124023, "compression_ratio":
  1.640495867768595, "no_speech_prob": 0.001825169543735683}, {"id": 113, "seek":
  64192, "start": 659.28, "end": 667.4399999999999, "text": " you know, how you can
  temper with images that had watermarks, right? So like, yeah, and then how do",
  "tokens": [51232, 291, 458, 11, 577, 291, 393, 3393, 365, 5267, 300, 632, 1281,
  37307, 11, 558, 30, 407, 411, 11, 1338, 11, 293, 550, 577, 360, 51640], "temperature":
  0.0, "avg_logprob": -0.21305700302124023, "compression_ratio": 1.640495867768595,
  "no_speech_prob": 0.001825169543735683}, {"id": 114, "seek": 66744, "start": 667.44,
  "end": 673.2, "text": " you make that watermark resilient to any tempering that
  might happen on the image level, right?", "tokens": [50364, 291, 652, 300, 1281,
  5638, 23699, 281, 604, 3393, 278, 300, 1062, 1051, 322, 264, 3256, 1496, 11, 558,
  30, 50652], "temperature": 0.0, "avg_logprob": -0.15820659838224713, "compression_ratio":
  1.6192468619246863, "no_speech_prob": 0.0037283434066921473}, {"id": 115, "seek":
  66744, "start": 673.2, "end": 679.6800000000001, "text": " On any of the bands and
  stuff. And as you explained, he was in stuff. So that''s basically they digital",
  "tokens": [50652, 1282, 604, 295, 264, 13543, 293, 1507, 13, 400, 382, 291, 8825,
  11, 415, 390, 294, 1507, 13, 407, 300, 311, 1936, 436, 4562, 50976], "temperature":
  0.0, "avg_logprob": -0.15820659838224713, "compression_ratio": 1.6192468619246863,
  "no_speech_prob": 0.0037283434066921473}, {"id": 116, "seek": 66744, "start": 679.6800000000001,
  "end": 684.8000000000001, "text": " image processing is the word to Google if someone
  wants to. And then it''s like a big, big topic.", "tokens": [50976, 3256, 9007,
  307, 264, 1349, 281, 3329, 498, 1580, 2738, 281, 13, 400, 550, 309, 311, 411, 257,
  955, 11, 955, 4829, 13, 51232], "temperature": 0.0, "avg_logprob": -0.15820659838224713,
  "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0037283434066921473},
  {"id": 117, "seek": 66744, "start": 686.24, "end": 691.36, "text": " But what struck
  me and what you explained is that every image upload had to go through that", "tokens":
  [51304, 583, 437, 13159, 385, 293, 437, 291, 8825, 307, 300, 633, 3256, 6580, 632,
  281, 352, 807, 300, 51560], "temperature": 0.0, "avg_logprob": -0.15820659838224713,
  "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0037283434066921473},
  {"id": 118, "seek": 69136, "start": 692.08, "end": 699.2, "text": " process, which
  means it had to be super scalable. And also your database of vectors would", "tokens":
  [50400, 1399, 11, 597, 1355, 309, 632, 281, 312, 1687, 38481, 13, 400, 611, 428,
  8149, 295, 18875, 576, 50756], "temperature": 0.0, "avg_logprob": -0.14114008144456514,
  "compression_ratio": 1.602510460251046, "no_speech_prob": 0.012525550089776516},
  {"id": 119, "seek": 69136, "start": 699.2, "end": 704.32, "text": " be ever growing
  all the time as the image passes through or doesn''t, you would need to add it",
  "tokens": [50756, 312, 1562, 4194, 439, 264, 565, 382, 264, 3256, 11335, 807, 420,
  1177, 380, 11, 291, 576, 643, 281, 909, 309, 51012], "temperature": 0.0, "avg_logprob":
  -0.14114008144456514, "compression_ratio": 1.602510460251046, "no_speech_prob":
  0.012525550089776516}, {"id": 120, "seek": 69136, "start": 704.32, "end": 709.84,
  "text": " somewhere to your vector space. So in this case, no, this is the one advantage
  we had, because we", "tokens": [51012, 4079, 281, 428, 8062, 1901, 13, 407, 294,
  341, 1389, 11, 572, 11, 341, 307, 264, 472, 5002, 321, 632, 11, 570, 321, 51288],
  "temperature": 0.0, "avg_logprob": -0.14114008144456514, "compression_ratio": 1.602510460251046,
  "no_speech_prob": 0.012525550089776516}, {"id": 121, "seek": 69136, "start": 709.84,
  "end": 717.6, "text": " only care about matches to a specific relatively small set.
  Oh, I see, I see. So it''s like a set that", "tokens": [51288, 787, 1127, 466, 10676,
  281, 257, 2685, 7226, 1359, 992, 13, 876, 11, 286, 536, 11, 286, 536, 13, 407, 309,
  311, 411, 257, 992, 300, 51676], "temperature": 0.0, "avg_logprob": -0.14114008144456514,
  "compression_ratio": 1.602510460251046, "no_speech_prob": 0.012525550089776516},
  {"id": 122, "seek": 71760, "start": 717.6800000000001, "end": 724.24, "text": "
  shouldn''t grow ideally, right? Yeah, or very, very nominal. I see. Yeah. And so
  this is, so it''s", "tokens": [50368, 4659, 380, 1852, 22915, 11, 558, 30, 865,
  11, 420, 588, 11, 588, 41641, 13, 286, 536, 13, 865, 13, 400, 370, 341, 307, 11,
  370, 309, 311, 50696], "temperature": 0.0, "avg_logprob": -0.2112926079974911, "compression_ratio":
  1.6563573883161513, "no_speech_prob": 0.003292010398581624}, {"id": 123, "seek":
  71760, "start": 724.24, "end": 730.8000000000001, "text": " funny because that that''s
  a big difference that that makes it easy in that era. Today, you''d have", "tokens":
  [50696, 4074, 570, 300, 300, 311, 257, 955, 2649, 300, 300, 1669, 309, 1858, 294,
  300, 4249, 13, 2692, 11, 291, 1116, 362, 51024], "temperature": 0.0, "avg_logprob":
  -0.2112926079974911, "compression_ratio": 1.6563573883161513, "no_speech_prob":
  0.003292010398581624}, {"id": 124, "seek": 71760, "start": 730.8000000000001, "end":
  734.88, "text": " to bust out all the A and N stuff and maybe stuff we''ll get into
  to really be able to do a really", "tokens": [51024, 281, 19432, 484, 439, 264,
  316, 293, 426, 1507, 293, 1310, 1507, 321, 603, 483, 666, 281, 534, 312, 1075, 281,
  360, 257, 534, 51228], "temperature": 0.0, "avg_logprob": -0.2112926079974911, "compression_ratio":
  1.6563573883161513, "no_speech_prob": 0.003292010398581624}, {"id": 125, "seek":
  71760, "start": 734.88, "end": 740.08, "text": " much more scalable vector search.
  So this was really more about evaluating a relatively fixed", "tokens": [51228,
  709, 544, 38481, 8062, 3164, 13, 407, 341, 390, 534, 544, 466, 27479, 257, 7226,
  6806, 51488], "temperature": 0.0, "avg_logprob": -0.2112926079974911, "compression_ratio":
  1.6563573883161513, "no_speech_prob": 0.003292010398581624}, {"id": 126, "seek":
  71760, "start": 740.88, "end": 747.28, "text": " set of vectors. So you can hyper
  optimize how that was organized in like a, and, but evaluating", "tokens": [51528,
  992, 295, 18875, 13, 407, 291, 393, 9848, 19719, 577, 300, 390, 9983, 294, 411,
  257, 11, 293, 11, 457, 27479, 51848], "temperature": 0.0, "avg_logprob": -0.2112926079974911,
  "compression_ratio": 1.6563573883161513, "no_speech_prob": 0.003292010398581624},
  {"id": 127, "seek": 74728, "start": 747.28, "end": 752.0, "text": " it at an insane
  scale. So the update problem wasn''t very hard, but the evaluation problem was",
  "tokens": [50364, 309, 412, 364, 10838, 4373, 13, 407, 264, 5623, 1154, 2067, 380,
  588, 1152, 11, 457, 264, 13344, 1154, 390, 50600], "temperature": 0.0, "avg_logprob":
  -0.19094404923288447, "compression_ratio": 1.5833333333333333, "no_speech_prob":
  0.001189122791402042}, {"id": 128, "seek": 74728, "start": 752.0, "end": 758.0799999999999,
  "text": " like it needed to be extremely high scale. Yeah, a bunch of questions
  in my mind, but let''s move", "tokens": [50600, 411, 309, 2978, 281, 312, 4664,
  1090, 4373, 13, 865, 11, 257, 3840, 295, 1651, 294, 452, 1575, 11, 457, 718, 311,
  1286, 50904], "temperature": 0.0, "avg_logprob": -0.19094404923288447, "compression_ratio":
  1.5833333333333333, "no_speech_prob": 0.001189122791402042}, {"id": 129, "seek":
  74728, "start": 758.0799999999999, "end": 764.16, "text": " move on to Roxette.
  Tell me more about the what part, you know, what it is as the product.", "tokens":
  [50904, 1286, 322, 281, 44427, 3007, 13, 5115, 385, 544, 466, 264, 437, 644, 11,
  291, 458, 11, 437, 309, 307, 382, 264, 1674, 13, 51208], "temperature": 0.0, "avg_logprob":
  -0.19094404923288447, "compression_ratio": 1.5833333333333333, "no_speech_prob":
  0.001189122791402042}, {"id": 130, "seek": 74728, "start": 764.48, "end": 770.72,
  "text": " And then slowly, let''s go deeper into the technology side. Yeah. So my
  standard", "tokens": [51224, 400, 550, 5692, 11, 718, 311, 352, 7731, 666, 264,
  2899, 1252, 13, 865, 13, 407, 452, 3832, 51536], "temperature": 0.0, "avg_logprob":
  -0.19094404923288447, "compression_ratio": 1.5833333333333333, "no_speech_prob":
  0.001189122791402042}, {"id": 131, "seek": 77072, "start": 771.6800000000001, "end":
  777.6, "text": " statement of what Roxette is is Roxette is a search and analytics
  database built for the cloud.", "tokens": [50412, 5629, 295, 437, 44427, 3007, 307,
  307, 44427, 3007, 307, 257, 3164, 293, 15370, 8149, 3094, 337, 264, 4588, 13, 50708],
  "temperature": 0.0, "avg_logprob": -0.1229516967894539, "compression_ratio": 1.8850574712643677,
  "no_speech_prob": 0.0064694019965827465}, {"id": 132, "seek": 77072, "start": 779.6,
  "end": 785.52, "text": " And that''s a bunch of, I forgot one, it''s a real time
  search and analytics database for the cloud.", "tokens": [50808, 400, 300, 311,
  257, 3840, 295, 11, 286, 5298, 472, 11, 309, 311, 257, 957, 565, 3164, 293, 15370,
  8149, 337, 264, 4588, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1229516967894539,
  "compression_ratio": 1.8850574712643677, "no_speech_prob": 0.0064694019965827465},
  {"id": 133, "seek": 77072, "start": 785.52, "end": 788.88, "text": " Now that''s
  a bunch of little buzz worries that, you know, it''s very easy to get lost in the
  kind", "tokens": [51104, 823, 300, 311, 257, 3840, 295, 707, 13036, 16340, 300,
  11, 291, 458, 11, 309, 311, 588, 1858, 281, 483, 2731, 294, 264, 733, 51272], "temperature":
  0.0, "avg_logprob": -0.1229516967894539, "compression_ratio": 1.8850574712643677,
  "no_speech_prob": 0.0064694019965827465}, {"id": 134, "seek": 77072, "start": 788.88,
  "end": 794.64, "text": " of marketing feel of that, but each of those words does
  like non trivial amounts of work and what", "tokens": [51272, 295, 6370, 841, 295,
  300, 11, 457, 1184, 295, 729, 2283, 775, 411, 2107, 26703, 11663, 295, 589, 293,
  437, 51560], "temperature": 0.0, "avg_logprob": -0.1229516967894539, "compression_ratio":
  1.8850574712643677, "no_speech_prob": 0.0064694019965827465}, {"id": 135, "seek":
  77072, "start": 794.64, "end": 798.64, "text": " it is I''m really trying to build
  here. So first of all, it''s a search and analytics database. So here,", "tokens":
  [51560, 309, 307, 286, 478, 534, 1382, 281, 1322, 510, 13, 407, 700, 295, 439, 11,
  309, 311, 257, 3164, 293, 15370, 8149, 13, 407, 510, 11, 51760], "temperature":
  0.0, "avg_logprob": -0.1229516967894539, "compression_ratio": 1.8850574712643677,
  "no_speech_prob": 0.0064694019965827465}, {"id": 136, "seek": 79864, "start": 798.64,
  "end": 803.68, "text": " what we mean is like a like an OLAP style analytics database
  is like it''s it''s like that''s where", "tokens": [50364, 437, 321, 914, 307, 411,
  257, 411, 364, 39191, 4715, 3758, 15370, 8149, 307, 411, 309, 311, 309, 311, 411,
  300, 311, 689, 50616], "temperature": 0.0, "avg_logprob": -0.13680712930087385,
  "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0001771239476511255},
  {"id": 137, "seek": 79864, "start": 803.68, "end": 808.08, "text": " we''re starting.
  We want to run an analytics type queries and this I won''t get into all of this,",
  "tokens": [50616, 321, 434, 2891, 13, 492, 528, 281, 1190, 364, 15370, 2010, 24109,
  293, 341, 286, 1582, 380, 483, 666, 439, 295, 341, 11, 50836], "temperature": 0.0,
  "avg_logprob": -0.13680712930087385, "compression_ratio": 1.8136882129277567, "no_speech_prob":
  0.0001771239476511255}, {"id": 138, "seek": 79864, "start": 808.08, "end": 813.4399999999999,
  "text": " but this is like separate from your OLTP style databases. So this is not
  my sequel, not a large", "tokens": [50836, 457, 341, 307, 411, 4994, 490, 428, 39191,
  16804, 3758, 22380, 13, 407, 341, 307, 406, 452, 20622, 11, 406, 257, 2416, 51104],
  "temperature": 0.0, "avg_logprob": -0.13680712930087385, "compression_ratio": 1.8136882129277567,
  "no_speech_prob": 0.0001771239476511255}, {"id": 139, "seek": 79864, "start": 813.4399999999999,
  "end": 819.84, "text": " transactional thing. It is a but is it OLAP style database.
  And search and analytics is a very", "tokens": [51104, 46688, 1966, 551, 13, 467,
  307, 257, 457, 307, 309, 39191, 4715, 3758, 8149, 13, 400, 3164, 293, 15370, 307,
  257, 588, 51424], "temperature": 0.0, "avg_logprob": -0.13680712930087385, "compression_ratio":
  1.8136882129277567, "no_speech_prob": 0.0001771239476511255}, {"id": 140, "seek":
  79864, "start": 819.84, "end": 825.04, "text": " interesting pairing in this world
  because systems like elastic search or very search oriented", "tokens": [51424,
  1880, 32735, 294, 341, 1002, 570, 3652, 411, 17115, 3164, 420, 588, 3164, 21841,
  51684], "temperature": 0.0, "avg_logprob": -0.13680712930087385, "compression_ratio":
  1.8136882129277567, "no_speech_prob": 0.0001771239476511255}, {"id": 141, "seek":
  82504, "start": 825.04, "end": 829.12, "text": " system systems like rocks that
  have analytics styles, but these are actually not that different", "tokens": [50364,
  1185, 3652, 411, 10989, 300, 362, 15370, 13273, 11, 457, 613, 366, 767, 406, 300,
  819, 50568], "temperature": 0.0, "avg_logprob": -0.14332838276870377, "compression_ratio":
  1.8580645161290323, "no_speech_prob": 0.0005571605870500207}, {"id": 142, "seek":
  82504, "start": 829.12, "end": 833.76, "text": " architecturally. They''re very
  the way you use them may feel different. The primitives you''re", "tokens": [50568,
  6331, 6512, 13, 814, 434, 588, 264, 636, 291, 764, 552, 815, 841, 819, 13, 440,
  2886, 38970, 291, 434, 50800], "temperature": 0.0, "avg_logprob": -0.14332838276870377,
  "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0005571605870500207},
  {"id": 143, "seek": 82504, "start": 833.76, "end": 838.7199999999999, "text": "
  using feel different, but all that sits fairly shallowly in the technology. The
  underlying", "tokens": [50800, 1228, 841, 819, 11, 457, 439, 300, 12696, 6457, 20488,
  356, 294, 264, 2899, 13, 440, 14217, 51048], "temperature": 0.0, "avg_logprob":
  -0.14332838276870377, "compression_ratio": 1.8580645161290323, "no_speech_prob":
  0.0005571605870500207}, {"id": 144, "seek": 82504, "start": 838.7199999999999, "end":
  842.0799999999999, "text": " architecture of these systems ends up looking quite
  similar. So search and analytics actually go", "tokens": [51048, 9482, 295, 613,
  3652, 5314, 493, 1237, 1596, 2531, 13, 407, 3164, 293, 15370, 767, 352, 51216],
  "temperature": 0.0, "avg_logprob": -0.14332838276870377, "compression_ratio": 1.8580645161290323,
  "no_speech_prob": 0.0005571605870500207}, {"id": 145, "seek": 82504, "start": 842.0799999999999,
  "end": 847.04, "text": " together quite nicely from like a I can do both. Maybe
  I don''t do both well, but that will mostly", "tokens": [51216, 1214, 1596, 9594,
  490, 411, 257, 286, 393, 360, 1293, 13, 2704, 286, 500, 380, 360, 1293, 731, 11,
  457, 300, 486, 5240, 51464], "temperature": 0.0, "avg_logprob": -0.14332838276870377,
  "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0005571605870500207},
  {"id": 146, "seek": 82504, "start": 847.04, "end": 852.9599999999999, "text": "
  exist at the top, not not in the not in the infrastructure. It''s in the cloud.
  So the whole system is", "tokens": [51464, 2514, 412, 264, 1192, 11, 406, 406, 294,
  264, 406, 294, 264, 6896, 13, 467, 311, 294, 264, 4588, 13, 407, 264, 1379, 1185,
  307, 51760], "temperature": 0.0, "avg_logprob": -0.14332838276870377, "compression_ratio":
  1.8580645161290323, "no_speech_prob": 0.0005571605870500207}, {"id": 147, "seek":
  85296, "start": 852.96, "end": 857.76, "text": " built to be elastic from the beginning.
  So if you send me twice as much data, I can scale you out", "tokens": [50364, 3094,
  281, 312, 17115, 490, 264, 2863, 13, 407, 498, 291, 2845, 385, 6091, 382, 709, 1412,
  11, 286, 393, 4373, 291, 484, 50604], "temperature": 0.0, "avg_logprob": -0.1125994548201561,
  "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.0008639035513624549},
  {"id": 148, "seek": 85296, "start": 857.76, "end": 862.32, "text": " in a way that
  you know, like it just works. You don''t have to worry. You''re not reprovisioning
  more", "tokens": [50604, 294, 257, 636, 300, 291, 458, 11, 411, 309, 445, 1985,
  13, 509, 500, 380, 362, 281, 3292, 13, 509, 434, 406, 1085, 340, 6763, 278, 544,
  50832], "temperature": 0.0, "avg_logprob": -0.1125994548201561, "compression_ratio":
  1.7310344827586206, "no_speech_prob": 0.0008639035513624549}, {"id": 149, "seek":
  85296, "start": 862.32, "end": 867.84, "text": " machines to double your cluster
  size or anything like that. And then real time. So our focus has", "tokens": [50832,
  8379, 281, 3834, 428, 13630, 2744, 420, 1340, 411, 300, 13, 400, 550, 957, 565,
  13, 407, 527, 1879, 575, 51108], "temperature": 0.0, "avg_logprob": -0.1125994548201561,
  "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.0008639035513624549},
  {"id": 150, "seek": 85296, "start": 867.84, "end": 872.96, "text": " always been
  real time, which is to say specifically most people when they think of real time
  they want", "tokens": [51108, 1009, 668, 957, 565, 11, 597, 307, 281, 584, 4682,
  881, 561, 562, 436, 519, 295, 957, 565, 436, 528, 51364], "temperature": 0.0, "avg_logprob":
  -0.1125994548201561, "compression_ratio": 1.7310344827586206, "no_speech_prob":
  0.0008639035513624549}, {"id": 151, "seek": 85296, "start": 872.96, "end": 878.48,
  "text": " their queries to be fast, but the real heart of real time is ingest latency.
  So if you send me new data,", "tokens": [51364, 641, 24109, 281, 312, 2370, 11,
  457, 264, 957, 1917, 295, 957, 565, 307, 3957, 377, 27043, 13, 407, 498, 291, 2845,
  385, 777, 1412, 11, 51640], "temperature": 0.0, "avg_logprob": -0.1125994548201561,
  "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.0008639035513624549},
  {"id": 152, "seek": 87848, "start": 878.48, "end": 883.2, "text": " how quickly
  does that data get manifested in the queries? If it''s tomorrow, if it shows up
  in", "tokens": [50364, 577, 2661, 775, 300, 1412, 483, 42775, 294, 264, 24109, 30,
  759, 309, 311, 4153, 11, 498, 309, 3110, 493, 294, 50600], "temperature": 0.0, "avg_logprob":
  -0.16038077218191965, "compression_ratio": 1.7314487632508835, "no_speech_prob":
  0.001409567310474813}, {"id": 153, "seek": 87848, "start": 883.2, "end": 887.52,
  "text": " tomorrow''s queries, you''re not that''s not a real time system. And there''s
  a lot of systems like this,", "tokens": [50600, 4153, 311, 24109, 11, 291, 434,
  406, 300, 311, 406, 257, 957, 565, 1185, 13, 400, 456, 311, 257, 688, 295, 3652,
  411, 341, 11, 50816], "temperature": 0.0, "avg_logprob": -0.16038077218191965, "compression_ratio":
  1.7314487632508835, "no_speech_prob": 0.001409567310474813}, {"id": 154, "seek":
  87848, "start": 887.52, "end": 894.88, "text": " these very big batch style, like
  mega exabyte type of like doob clusters that you you can query", "tokens": [50816,
  613, 588, 955, 15245, 3758, 11, 411, 17986, 454, 34529, 2010, 295, 411, 360, 996,
  23313, 300, 291, 291, 393, 14581, 51184], "temperature": 0.0, "avg_logprob": -0.16038077218191965,
  "compression_ratio": 1.7314487632508835, "no_speech_prob": 0.001409567310474813},
  {"id": 155, "seek": 87848, "start": 894.88, "end": 900.24, "text": " yesterday''s
  data, right? And get and get like genuinely enormous amounts of data. That is not",
  "tokens": [51184, 5186, 311, 1412, 11, 558, 30, 400, 483, 293, 483, 411, 17839,
  11322, 11663, 295, 1412, 13, 663, 307, 406, 51452], "temperature": 0.0, "avg_logprob":
  -0.16038077218191965, "compression_ratio": 1.7314487632508835, "no_speech_prob":
  0.001409567310474813}, {"id": 156, "seek": 87848, "start": 900.24, "end": 905.6,
  "text": " rock set like as that''s not rock sets problem. But for us, it''s like,
  hey, if you want like last minutes", "tokens": [51452, 3727, 992, 411, 382, 300,
  311, 406, 3727, 6352, 1154, 13, 583, 337, 505, 11, 309, 311, 411, 11, 4177, 11,
  498, 291, 528, 411, 1036, 2077, 51720], "temperature": 0.0, "avg_logprob": -0.16038077218191965,
  "compression_ratio": 1.7314487632508835, "no_speech_prob": 0.001409567310474813},
  {"id": 157, "seek": 90560, "start": 905.6, "end": 910.88, "text": " data and it''s
  ideally several zero smaller of a working set, then that''s where rock set is meant",
  "tokens": [50364, 1412, 293, 309, 311, 22915, 2940, 4018, 4356, 295, 257, 1364,
  992, 11, 550, 300, 311, 689, 3727, 992, 307, 4140, 50628], "temperature": 0.0, "avg_logprob":
  -0.14660627824546646, "compression_ratio": 1.7689530685920578, "no_speech_prob":
  0.010947044007480145}, {"id": 158, "seek": 90560, "start": 910.88, "end": 915.6800000000001,
  "text": " is meant to work really well. And so this is like the heart of this is
  what we''ve set out to build", "tokens": [50628, 307, 4140, 281, 589, 534, 731,
  13, 400, 370, 341, 307, 411, 264, 1917, 295, 341, 307, 437, 321, 600, 992, 484,
  281, 1322, 50868], "temperature": 0.0, "avg_logprob": -0.14660627824546646, "compression_ratio":
  1.7689530685920578, "no_speech_prob": 0.010947044007480145}, {"id": 159, "seek":
  90560, "start": 916.48, "end": 923.76, "text": " at a high level. And I don''t know
  if you want to do want me to keep going. I don''t know. I feel like", "tokens":
  [50908, 412, 257, 1090, 1496, 13, 400, 286, 500, 380, 458, 498, 291, 528, 281, 360,
  528, 385, 281, 1066, 516, 13, 286, 500, 380, 458, 13, 286, 841, 411, 51272], "temperature":
  0.0, "avg_logprob": -0.14660627824546646, "compression_ratio": 1.7689530685920578,
  "no_speech_prob": 0.010947044007480145}, {"id": 160, "seek": 90560, "start": 923.76,
  "end": 929.52, "text": " I''ve already said too much. I want I want no, it''s amazing.
  It''s a good start. I wanted to stay", "tokens": [51272, 286, 600, 1217, 848, 886,
  709, 13, 286, 528, 286, 528, 572, 11, 309, 311, 2243, 13, 467, 311, 257, 665, 722,
  13, 286, 1415, 281, 1754, 51560], "temperature": 0.0, "avg_logprob": -0.14660627824546646,
  "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.010947044007480145},
  {"id": 161, "seek": 90560, "start": 929.52, "end": 935.12, "text": " a little bit
  on the product side. If you go now and flip over to the use cases for the moment.
  So", "tokens": [51560, 257, 707, 857, 322, 264, 1674, 1252, 13, 759, 291, 352, 586,
  293, 7929, 670, 281, 264, 764, 3331, 337, 264, 1623, 13, 407, 51840], "temperature":
  0.0, "avg_logprob": -0.14660627824546646, "compression_ratio": 1.7689530685920578,
  "no_speech_prob": 0.010947044007480145}, {"id": 162, "seek": 93512, "start": 935.44,
  "end": 941.6, "text": " what are the typical use cases and sort of can you zoom
  out as much as possible, maybe even giving,", "tokens": [50380, 437, 366, 264, 7476,
  764, 3331, 293, 1333, 295, 393, 291, 8863, 484, 382, 709, 382, 1944, 11, 1310, 754,
  2902, 11, 50688], "temperature": 0.0, "avg_logprob": -0.1525605773925781, "compression_ratio":
  1.7859778597785978, "no_speech_prob": 0.0006826731842011213}, {"id": 163, "seek":
  93512, "start": 941.6, "end": 946.08, "text": " you know, even if hypothetical,
  it''s fine. For example, so products that use your product.", "tokens": [50688,
  291, 458, 11, 754, 498, 33053, 11, 309, 311, 2489, 13, 1171, 1365, 11, 370, 3383,
  300, 764, 428, 1674, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1525605773925781,
  "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.0006826731842011213},
  {"id": 164, "seek": 93512, "start": 946.72, "end": 952.96, "text": " Yeah. So we
  we have a bunch of customers in a bunch of different domains and it''s we can even
  go.", "tokens": [50944, 865, 13, 407, 321, 321, 362, 257, 3840, 295, 4581, 294,
  257, 3840, 295, 819, 25514, 293, 309, 311, 321, 393, 754, 352, 13, 51256], "temperature":
  0.0, "avg_logprob": -0.1525605773925781, "compression_ratio": 1.7859778597785978,
  "no_speech_prob": 0.0006826731842011213}, {"id": 165, "seek": 93512, "start": 952.96,
  "end": 956.32, "text": " So so one way to think about this is just like who''s using
  it and why like what domains are they", "tokens": [51256, 407, 370, 472, 636, 281,
  519, 466, 341, 307, 445, 411, 567, 311, 1228, 309, 293, 983, 411, 437, 25514, 366,
  436, 51424], "temperature": 0.0, "avg_logprob": -0.1525605773925781, "compression_ratio":
  1.7859778597785978, "no_speech_prob": 0.0006826731842011213}, {"id": 166, "seek":
  93512, "start": 956.32, "end": 961.52, "text": " using it in? And so for example,
  we have a bunch of gaming customers. So this is like there''s real", "tokens": [51424,
  1228, 309, 294, 30, 400, 370, 337, 1365, 11, 321, 362, 257, 3840, 295, 9703, 4581,
  13, 407, 341, 307, 411, 456, 311, 957, 51684], "temperature": 0.0, "avg_logprob":
  -0.1525605773925781, "compression_ratio": 1.7859778597785978, "no_speech_prob":
  0.0006826731842011213}, {"id": 167, "seek": 96152, "start": 961.52, "end": 967.12,
  "text": " time events occurring in games. Imagine an online an online game of some
  sort and", "tokens": [50364, 565, 3931, 18386, 294, 2813, 13, 11739, 364, 2950,
  364, 2950, 1216, 295, 512, 1333, 293, 50644], "temperature": 0.0, "avg_logprob":
  -0.15728677037250566, "compression_ratio": 1.6355555555555557, "no_speech_prob":
  0.004070555791258812}, {"id": 168, "seek": 96152, "start": 970.96, "end": 976.3199999999999,
  "text": " they''re collating that information constantly and having it be real uptime
  say leader boards or", "tokens": [50836, 436, 434, 1263, 990, 300, 1589, 6460, 293,
  1419, 309, 312, 957, 493, 3766, 584, 5263, 13293, 420, 51104], "temperature": 0.0,
  "avg_logprob": -0.15728677037250566, "compression_ratio": 1.6355555555555557, "no_speech_prob":
  0.004070555791258812}, {"id": 169, "seek": 96152, "start": 976.3199999999999, "end":
  981.76, "text": " things like that are happening. There''s a lot there''s several
  actually like logistics and supply", "tokens": [51104, 721, 411, 300, 366, 2737,
  13, 821, 311, 257, 688, 456, 311, 2940, 767, 411, 27420, 293, 5847, 51376], "temperature":
  0.0, "avg_logprob": -0.15728677037250566, "compression_ratio": 1.6355555555555557,
  "no_speech_prob": 0.004070555791258812}, {"id": 170, "seek": 96152, "start": 981.76,
  "end": 988.56, "text": " chain type people using it. So like where is my package
  right now or where is the boat in the", "tokens": [51376, 5021, 2010, 561, 1228,
  309, 13, 407, 411, 689, 307, 452, 7372, 558, 586, 420, 689, 307, 264, 6582, 294,
  264, 51716], "temperature": 0.0, "avg_logprob": -0.15728677037250566, "compression_ratio":
  1.6355555555555557, "no_speech_prob": 0.004070555791258812}, {"id": 171, "seek":
  98856, "start": 988.56, "end": 994.88, "text": " ocean like these kinds of queries
  are like very commonly done, you know, like where is the where", "tokens": [50364,
  7810, 411, 613, 3685, 295, 24109, 366, 411, 588, 12719, 1096, 11, 291, 458, 11,
  411, 689, 307, 264, 689, 50680], "temperature": 0.0, "avg_logprob": -0.1868603689628735,
  "compression_ratio": 1.7963636363636364, "no_speech_prob": 0.0016653829952701926},
  {"id": 172, "seek": 98856, "start": 994.88, "end": 998.16, "text": " they''re basically
  tracking their entire supply chain trying to find shortages and what''s going to",
  "tokens": [50680, 436, 434, 1936, 11603, 641, 2302, 5847, 5021, 1382, 281, 915,
  46765, 293, 437, 311, 516, 281, 50844], "temperature": 0.0, "avg_logprob": -0.1868603689628735,
  "compression_ratio": 1.7963636363636364, "no_speech_prob": 0.0016653829952701926},
  {"id": 173, "seek": 98856, "start": 998.16, "end": 1003.5999999999999, "text": "
  create problems down the line in like a logistic type settings. There''s a lot of
  FinTech. There''s", "tokens": [50844, 1884, 2740, 760, 264, 1622, 294, 411, 257,
  3565, 3142, 2010, 6257, 13, 821, 311, 257, 688, 295, 3773, 36050, 13, 821, 311,
  51116], "temperature": 0.0, "avg_logprob": -0.1868603689628735, "compression_ratio":
  1.7963636363636364, "no_speech_prob": 0.0016653829952701926}, {"id": 174, "seek":
  98856, "start": 1003.5999999999999, "end": 1009.04, "text": " a lot of financial
  financial firms use it a lot of fraud detection. So again fraud and spam these",
  "tokens": [51116, 257, 688, 295, 4669, 4669, 18055, 764, 309, 257, 688, 295, 14560,
  17784, 13, 407, 797, 14560, 293, 24028, 613, 51388], "temperature": 0.0, "avg_logprob":
  -0.1868603689628735, "compression_ratio": 1.7963636363636364, "no_speech_prob":
  0.0016653829952701926}, {"id": 175, "seek": 98856, "start": 1009.04, "end": 1014.16,
  "text": " are very real time problems. You can''t like detect yesterday spam or
  fraud. That''s like really harmful.", "tokens": [51388, 366, 588, 957, 565, 2740,
  13, 509, 393, 380, 411, 5531, 5186, 24028, 420, 14560, 13, 663, 311, 411, 534, 19727,
  13, 51644], "temperature": 0.0, "avg_logprob": -0.1868603689628735, "compression_ratio":
  1.7963636363636364, "no_speech_prob": 0.0016653829952701926}, {"id": 176, "seek":
  101416, "start": 1014.16, "end": 1021.8399999999999, "text": " You got to you need
  to know now right. And then a lot of like recommendation and like product", "tokens":
  [50364, 509, 658, 281, 291, 643, 281, 458, 586, 558, 13, 400, 550, 257, 688, 295,
  411, 11879, 293, 411, 1674, 50748], "temperature": 0.0, "avg_logprob": -0.20070678904905156,
  "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0022025706712156534},
  {"id": 177, "seek": 101416, "start": 1021.8399999999999, "end": 1026.48, "text":
  " experience. So anytime that like you want to power a user facing experience, you
  almost always", "tokens": [50748, 1752, 13, 407, 13038, 300, 411, 291, 528, 281,
  1347, 257, 4195, 7170, 1752, 11, 291, 1920, 1009, 50980], "temperature": 0.0, "avg_logprob":
  -0.20070678904905156, "compression_ratio": 1.7259259259259259, "no_speech_prob":
  0.0022025706712156534}, {"id": 178, "seek": 101416, "start": 1026.48, "end": 1031.2,
  "text": " need that to be real time. So you know example I like to use is there''s
  a there''s a there''s a place", "tokens": [50980, 643, 300, 281, 312, 957, 565,
  13, 407, 291, 458, 1365, 286, 411, 281, 764, 307, 456, 311, 257, 456, 311, 257,
  456, 311, 257, 1081, 51216], "temperature": 0.0, "avg_logprob": -0.20070678904905156,
  "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0022025706712156534},
  {"id": 179, "seek": 101416, "start": 1031.2, "end": 1036.0, "text": " called what
  not if you go to what not.com if you''ve never heard of it. What not is basically
  a", "tokens": [51216, 1219, 437, 406, 498, 291, 352, 281, 437, 406, 13, 1112, 498,
  291, 600, 1128, 2198, 295, 309, 13, 708, 406, 307, 1936, 257, 51456], "temperature":
  0.0, "avg_logprob": -0.20070678904905156, "compression_ratio": 1.7259259259259259,
  "no_speech_prob": 0.0022025706712156534}, {"id": 180, "seek": 101416, "start": 1036.0,
  "end": 1041.6, "text": " streaming site for buying and selling. So it''s sort of
  eBay meets Twitch kind of a", "tokens": [51456, 11791, 3621, 337, 6382, 293, 6511,
  13, 407, 309, 311, 1333, 295, 33803, 13961, 22222, 733, 295, 257, 51736], "temperature":
  0.0, "avg_logprob": -0.20070678904905156, "compression_ratio": 1.7259259259259259,
  "no_speech_prob": 0.0022025706712156534}, {"id": 181, "seek": 104160, "start": 1042.1599999999999,
  "end": 1045.4399999999998, "text": " easiest way I could describe it. But what''s
  really cool about that is you have a recommendation", "tokens": [50392, 12889, 636,
  286, 727, 6786, 309, 13, 583, 437, 311, 534, 1627, 466, 300, 307, 291, 362, 257,
  11879, 50556], "temperature": 0.0, "avg_logprob": -0.15352546746003712, "compression_ratio":
  1.9233333333333333, "no_speech_prob": 0.020020080730319023}, {"id": 182, "seek":
  104160, "start": 1045.4399999999998, "end": 1049.76, "text": " problem like I want
  to buy something or people selling it. So I it''s really in the sites.", "tokens":
  [50556, 1154, 411, 286, 528, 281, 2256, 746, 420, 561, 6511, 309, 13, 407, 286,
  309, 311, 534, 294, 264, 7533, 13, 50772], "temperature": 0.0, "avg_logprob": -0.15352546746003712,
  "compression_ratio": 1.9233333333333333, "no_speech_prob": 0.020020080730319023},
  {"id": 183, "seek": 104160, "start": 1049.76, "end": 1053.9199999999998, "text":
  " And my interest were you to show me like you might want to check these things
  out. That''s like a", "tokens": [50772, 400, 452, 1179, 645, 291, 281, 855, 385,
  411, 291, 1062, 528, 281, 1520, 613, 721, 484, 13, 663, 311, 411, 257, 50980], "temperature":
  0.0, "avg_logprob": -0.15352546746003712, "compression_ratio": 1.9233333333333333,
  "no_speech_prob": 0.020020080730319023}, {"id": 184, "seek": 104160, "start": 1053.9199999999998,
  "end": 1059.76, "text": " recommendation problem. But it''s like really real time
  right. It has to match me to online sellers", "tokens": [50980, 11879, 1154, 13,
  583, 309, 311, 411, 534, 957, 565, 558, 13, 467, 575, 281, 2995, 385, 281, 2950,
  31276, 51272], "temperature": 0.0, "avg_logprob": -0.15352546746003712, "compression_ratio":
  1.9233333333333333, "no_speech_prob": 0.020020080730319023}, {"id": 185, "seek":
  104160, "start": 1059.76, "end": 1064.48, "text": " at any given moment. And so
  it''s a recommendation system that has to get built needs decent amount", "tokens":
  [51272, 412, 604, 2212, 1623, 13, 400, 370, 309, 311, 257, 11879, 1185, 300, 575,
  281, 483, 3094, 2203, 8681, 2372, 51508], "temperature": 0.0, "avg_logprob": -0.15352546746003712,
  "compression_ratio": 1.9233333333333333, "no_speech_prob": 0.020020080730319023},
  {"id": 186, "seek": 104160, "start": 1064.48, "end": 1069.52, "text": " of needs
  high scale. And it also needs to be real time. It needs to use a lot of real time
  data.", "tokens": [51508, 295, 2203, 1090, 4373, 13, 400, 309, 611, 2203, 281, 312,
  957, 565, 13, 467, 2203, 281, 764, 257, 688, 295, 957, 565, 1412, 13, 51760], "temperature":
  0.0, "avg_logprob": -0.15352546746003712, "compression_ratio": 1.9233333333333333,
  "no_speech_prob": 0.020020080730319023}, {"id": 187, "seek": 106952, "start": 1069.52,
  "end": 1074.72, "text": " So these are all use cases for Rockset. These are every
  one of these is real customers", "tokens": [50364, 407, 613, 366, 439, 764, 3331,
  337, 6922, 3854, 13, 1981, 366, 633, 472, 295, 613, 307, 957, 4581, 50624], "temperature":
  0.0, "avg_logprob": -0.23288567860921225, "compression_ratio": 1.6852791878172588,
  "no_speech_prob": 0.0013946861727163196}, {"id": 188, "seek": 106952, "start": 1075.44,
  "end": 1082.16, "text": " using Rockset to do something. Yeah, for sure. Now I want
  to go back to jump back to tech side.", "tokens": [50660, 1228, 6922, 3854, 281,
  360, 746, 13, 865, 11, 337, 988, 13, 823, 286, 528, 281, 352, 646, 281, 3012, 646,
  281, 7553, 1252, 13, 50996], "temperature": 0.0, "avg_logprob": -0.23288567860921225,
  "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.0013946861727163196},
  {"id": 189, "seek": 106952, "start": 1082.72, "end": 1087.76, "text": " So Rockset
  and inside it are you using RocksDB or something else?", "tokens": [51024, 407,
  6922, 3854, 293, 1854, 309, 366, 291, 1228, 6922, 82, 27735, 420, 746, 1646, 30,
  51276], "temperature": 0.0, "avg_logprob": -0.23288567860921225, "compression_ratio":
  1.6852791878172588, "no_speech_prob": 0.0013946861727163196}, {"id": 190, "seek":
  106952, "start": 1087.76, "end": 1095.12, "text": " So okay. So okay. Are we using
  RocksDB? So first of all do we know what RocksDB is?", "tokens": [51276, 407, 1392,
  13, 407, 1392, 13, 2014, 321, 1228, 6922, 82, 27735, 30, 407, 700, 295, 439, 360,
  321, 458, 437, 6922, 82, 27735, 307, 30, 51644], "temperature": 0.0, "avg_logprob":
  -0.23288567860921225, "compression_ratio": 1.6852791878172588, "no_speech_prob":
  0.0013946861727163196}, {"id": 191, "seek": 109512, "start": 1095.12, "end": 1100.2399999999998,
  "text": " Just everyone''s on the same page. RocksDB is an engine that was built
  by Drew Bat Facebook.", "tokens": [50364, 1449, 1518, 311, 322, 264, 912, 3028,
  13, 6922, 82, 27735, 307, 364, 2848, 300, 390, 3094, 538, 25550, 10066, 4384, 13,
  50620], "temperature": 0.0, "avg_logprob": -0.17456136211272208, "compression_ratio":
  1.6702898550724639, "no_speech_prob": 0.0019574747420847416}, {"id": 192, "seek":
  109512, "start": 1100.8799999999999, "end": 1104.3999999999999, "text": " And I
  shouldn''t say by Drew, but by a team that Drew was a part of. Like he was one of
  the", "tokens": [50652, 400, 286, 4659, 380, 584, 538, 25550, 11, 457, 538, 257,
  1469, 300, 25550, 390, 257, 644, 295, 13, 1743, 415, 390, 472, 295, 264, 50828],
  "temperature": 0.0, "avg_logprob": -0.17456136211272208, "compression_ratio": 1.6702898550724639,
  "no_speech_prob": 0.0019574747420847416}, {"id": 193, "seek": 109512, "start": 1104.3999999999999,
  "end": 1107.84, "text": " original founders of that team. There''s certainly a lot
  of people involved in RocksDB.", "tokens": [50828, 3380, 25608, 295, 300, 1469,
  13, 821, 311, 3297, 257, 688, 295, 561, 3288, 294, 6922, 82, 27735, 13, 51000],
  "temperature": 0.0, "avg_logprob": -0.17456136211272208, "compression_ratio": 1.6702898550724639,
  "no_speech_prob": 0.0019574747420847416}, {"id": 194, "seek": 109512, "start": 1107.84,
  "end": 1113.76, "text": " It''s a key value store right. It''s built sort of to
  scale very well and sort of do log structure", "tokens": [51000, 467, 311, 257,
  2141, 2158, 3531, 558, 13, 467, 311, 3094, 1333, 295, 281, 4373, 588, 731, 293,
  1333, 295, 360, 3565, 3877, 51296], "temperature": 0.0, "avg_logprob": -0.17456136211272208,
  "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0019574747420847416},
  {"id": 195, "seek": 109512, "start": 1113.76, "end": 1122.0, "text": " merge over
  time. Rockset absolutely uses RocksDB as its storage plane. And so there''s a lot
  of", "tokens": [51296, 22183, 670, 565, 13, 6922, 3854, 3122, 4960, 6922, 82, 27735,
  382, 1080, 6725, 5720, 13, 400, 370, 456, 311, 257, 688, 295, 51708], "temperature":
  0.0, "avg_logprob": -0.17456136211272208, "compression_ratio": 1.6702898550724639,
  "no_speech_prob": 0.0019574747420847416}, {"id": 196, "seek": 112200, "start": 1122.0,
  "end": 1127.84, "text": " Rockset built on top of RocksDB. So Rockset is not RocksDB
  as a service. That is not what Rockset is.", "tokens": [50364, 6922, 3854, 3094,
  322, 1192, 295, 6922, 82, 27735, 13, 407, 6922, 3854, 307, 406, 6922, 82, 27735,
  382, 257, 2643, 13, 663, 307, 406, 437, 6922, 3854, 307, 13, 50656], "temperature":
  0.0, "avg_logprob": -0.12445149539915984, "compression_ratio": 1.7649253731343284,
  "no_speech_prob": 0.00041014549788087606}, {"id": 197, "seek": 112200, "start":
  1127.84, "end": 1136.64, "text": " We do use it as the storage plane of Rockset.
  And we do take heavy advantage of, again,", "tokens": [50656, 492, 360, 764, 309,
  382, 264, 6725, 5720, 295, 6922, 3854, 13, 400, 321, 360, 747, 4676, 5002, 295,
  11, 797, 11, 51096], "temperature": 0.0, "avg_logprob": -0.12445149539915984, "compression_ratio":
  1.7649253731343284, "no_speech_prob": 0.00041014549788087606}, {"id": 198, "seek":
  112200, "start": 1136.64, "end": 1140.72, "text": " to get into the technical weeds
  a little bit like log structured merges to keep our indexes", "tokens": [51096,
  281, 483, 666, 264, 6191, 26370, 257, 707, 857, 411, 3565, 18519, 3551, 2880, 281,
  1066, 527, 8186, 279, 51300], "temperature": 0.0, "avg_logprob": -0.12445149539915984,
  "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.00041014549788087606},
  {"id": 199, "seek": 112200, "start": 1141.28, "end": 1146.56, "text": " sort of
  up to date continuously. And that is a big part of like the real timeness of Rockset.",
  "tokens": [51328, 1333, 295, 493, 281, 4002, 15684, 13, 400, 300, 307, 257, 955,
  644, 295, 411, 264, 957, 524, 15264, 295, 6922, 3854, 13, 51592], "temperature":
  0.0, "avg_logprob": -0.12445149539915984, "compression_ratio": 1.7649253731343284,
  "no_speech_prob": 0.00041014549788087606}, {"id": 200, "seek": 112200, "start":
  1146.56, "end": 1151.2, "text": " Like being able to update the index continuously
  and having this like heavy weight infrastructure", "tokens": [51592, 1743, 885,
  1075, 281, 5623, 264, 8186, 15684, 293, 1419, 341, 411, 4676, 3364, 6896, 51824],
  "temperature": 0.0, "avg_logprob": -0.12445149539915984, "compression_ratio": 1.7649253731343284,
  "no_speech_prob": 0.00041014549788087606}, {"id": 201, "seek": 115120, "start":
  1151.2, "end": 1155.52, "text": " to merge these indexes and then the kind of the
  appendonly log structured way that you do.", "tokens": [50364, 281, 22183, 613,
  8186, 279, 293, 550, 264, 733, 295, 264, 724, 521, 25202, 3565, 18519, 636, 300,
  291, 360, 13, 50580], "temperature": 0.0, "avg_logprob": -0.21169595795918286, "compression_ratio":
  1.711111111111111, "no_speech_prob": 0.0015068243956193328}, {"id": 202, "seek":
  115120, "start": 1156.4, "end": 1161.2, "text": " And the LSM world is part of the
  secret sauce. It''s not that secret, but it''s part of the secret", "tokens": [50624,
  400, 264, 441, 26693, 1002, 307, 644, 295, 264, 4054, 4880, 13, 467, 311, 406, 300,
  4054, 11, 457, 309, 311, 644, 295, 264, 4054, 50864], "temperature": 0.0, "avg_logprob":
  -0.21169595795918286, "compression_ratio": 1.711111111111111, "no_speech_prob":
  0.0015068243956193328}, {"id": 203, "seek": 115120, "start": 1161.2, "end": 1167.44,
  "text": " sauce of Rockset. Yeah, for sure. But then also all these things like
  vector search, you know,", "tokens": [50864, 4880, 295, 6922, 3854, 13, 865, 11,
  337, 988, 13, 583, 550, 611, 439, 613, 721, 411, 8062, 3164, 11, 291, 458, 11, 51176],
  "temperature": 0.0, "avg_logprob": -0.21169595795918286, "compression_ratio": 1.711111111111111,
  "no_speech_prob": 0.0015068243956193328}, {"id": 204, "seek": 115120, "start": 1168.16,
  "end": 1173.76, "text": " storing the embeddings. Is that also happening outside
  of RocksDB? Basically, in the layer you explained.", "tokens": [51212, 26085, 264,
  12240, 29432, 13, 1119, 300, 611, 2737, 2380, 295, 6922, 82, 27735, 30, 8537, 11,
  294, 264, 4583, 291, 8825, 13, 51492], "temperature": 0.0, "avg_logprob": -0.21169595795918286,
  "compression_ratio": 1.711111111111111, "no_speech_prob": 0.0015068243956193328},
  {"id": 205, "seek": 115120, "start": 1175.1200000000001, "end": 1180.56, "text":
  " So hold on, you asked about vector, what were the things? Oh, embeddings.", "tokens":
  [51560, 407, 1797, 322, 11, 291, 2351, 466, 8062, 11, 437, 645, 264, 721, 30, 876,
  11, 12240, 29432, 13, 51832], "temperature": 0.0, "avg_logprob": -0.21169595795918286,
  "compression_ratio": 1.711111111111111, "no_speech_prob": 0.0015068243956193328},
  {"id": 206, "seek": 118056, "start": 1180.56, "end": 1184.6399999999999, "text":
  " And embeddings and vector search itself and the sort of a and n indexes presumably.",
  "tokens": [50364, 400, 12240, 29432, 293, 8062, 3164, 2564, 293, 264, 1333, 295,
  257, 293, 297, 8186, 279, 26742, 13, 50568], "temperature": 0.0, "avg_logprob":
  -0.1622507226376133, "compression_ratio": 1.7638376383763839, "no_speech_prob":
  0.0004625711590051651}, {"id": 207, "seek": 118056, "start": 1184.6399999999999,
  "end": 1190.8, "text": " Yeah. So the a and n index, so we''ve added, we''ve extended
  RocksDB a little bit to kind of have", "tokens": [50568, 865, 13, 407, 264, 257,
  293, 297, 8186, 11, 370, 321, 600, 3869, 11, 321, 600, 10913, 6922, 82, 27735, 257,
  707, 857, 281, 733, 295, 362, 50876], "temperature": 0.0, "avg_logprob": -0.1622507226376133,
  "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0004625711590051651},
  {"id": 208, "seek": 118056, "start": 1190.8, "end": 1195.84, "text": " this notion
  of a blob of memory that you attach to a particular thing. It''s what''s going to
  be the", "tokens": [50876, 341, 10710, 295, 257, 46115, 295, 4675, 300, 291, 5085,
  281, 257, 1729, 551, 13, 467, 311, 437, 311, 516, 281, 312, 264, 51128], "temperature":
  0.0, "avg_logprob": -0.1622507226376133, "compression_ratio": 1.7638376383763839,
  "no_speech_prob": 0.0004625711590051651}, {"id": 209, "seek": 118056, "start": 1195.84,
  "end": 1202.0, "text": " a and n index. And then you can build custom operators
  to merge them, for example. And so that we do,", "tokens": [51128, 257, 293, 297,
  8186, 13, 400, 550, 291, 393, 1322, 2375, 19077, 281, 22183, 552, 11, 337, 1365,
  13, 400, 370, 300, 321, 360, 11, 51436], "temperature": 0.0, "avg_logprob": -0.1622507226376133,
  "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0004625711590051651},
  {"id": 210, "seek": 118056, "start": 1202.0, "end": 1208.0, "text": " we do essentially
  shove the a and n index into this. And so it gets into RocksDB. RocksDB doesn''t",
  "tokens": [51436, 321, 360, 4476, 35648, 264, 257, 293, 297, 8186, 666, 341, 13,
  400, 370, 309, 2170, 666, 6922, 82, 27735, 13, 6922, 82, 27735, 1177, 380, 51736],
  "temperature": 0.0, "avg_logprob": -0.1622507226376133, "compression_ratio": 1.7638376383763839,
  "no_speech_prob": 0.0004625711590051651}, {"id": 211, "seek": 120800, "start": 1208.0,
  "end": 1212.48, "text": " know about a and n indexes. It just knows there''s a blob
  of memory that it has to log structure merge", "tokens": [50364, 458, 466, 257,
  293, 297, 8186, 279, 13, 467, 445, 3255, 456, 311, 257, 46115, 295, 4675, 300, 309,
  575, 281, 3565, 3877, 22183, 50588], "temperature": 0.0, "avg_logprob": -0.1709749548284857,
  "compression_ratio": 1.676595744680851, "no_speech_prob": 0.0006812462816014886},
  {"id": 212, "seek": 120800, "start": 1212.48, "end": 1219.6, "text": " down the
  road. As far as embeddings, for us, that''s just arrays. So for us, an embedding
  is just a", "tokens": [50588, 760, 264, 3060, 13, 1018, 1400, 382, 12240, 29432,
  11, 337, 505, 11, 300, 311, 445, 41011, 13, 407, 337, 505, 11, 364, 12240, 3584,
  307, 445, 257, 50944], "temperature": 0.0, "avg_logprob": -0.1709749548284857, "compression_ratio":
  1.676595744680851, "no_speech_prob": 0.0006812462816014886}, {"id": 213, "seek":
  120800, "start": 1219.6, "end": 1225.04, "text": " vector. And for us, a vector
  is just an array. There''s no real difference in the way these things", "tokens":
  [50944, 8062, 13, 400, 337, 505, 11, 257, 8062, 307, 445, 364, 10225, 13, 821, 311,
  572, 957, 2649, 294, 264, 636, 613, 721, 51216], "temperature": 0.0, "avg_logprob":
  -0.1709749548284857, "compression_ratio": 1.676595744680851, "no_speech_prob": 0.0006812462816014886},
  {"id": 214, "seek": 120800, "start": 1225.04, "end": 1233.92, "text": " are stored.
  And those are stored in RocksDB. Yeah, got it. And so, and basically, what other
  AI", "tokens": [51216, 366, 12187, 13, 400, 729, 366, 12187, 294, 6922, 82, 27735,
  13, 865, 11, 658, 309, 13, 400, 370, 11, 293, 1936, 11, 437, 661, 7318, 51660],
  "temperature": 0.0, "avg_logprob": -0.1709749548284857, "compression_ratio": 1.676595744680851,
  "no_speech_prob": 0.0006812462816014886}, {"id": 215, "seek": 123392, "start": 1233.92,
  "end": 1239.6000000000001, "text": " capabilities does RocksDB offer, you know,
  basically everything? What''s the secret source of that", "tokens": [50364, 10862,
  775, 6922, 82, 27735, 2626, 11, 291, 458, 11, 1936, 1203, 30, 708, 311, 264, 4054,
  4009, 295, 300, 50648], "temperature": 0.0, "avg_logprob": -0.16754087854604252,
  "compression_ratio": 1.8081180811808117, "no_speech_prob": 0.018749956041574478},
  {"id": 216, "seek": 123392, "start": 1239.6000000000001, "end": 1247.3600000000001,
  "text": " thing? So they''re facing, right? But still. So I have two, there''s a
  few things to talk about here.", "tokens": [50648, 551, 30, 407, 436, 434, 7170,
  11, 558, 30, 583, 920, 13, 407, 286, 362, 732, 11, 456, 311, 257, 1326, 721, 281,
  751, 466, 510, 13, 51036], "temperature": 0.0, "avg_logprob": -0.16754087854604252,
  "compression_ratio": 1.8081180811808117, "no_speech_prob": 0.018749956041574478},
  {"id": 217, "seek": 123392, "start": 1247.3600000000001, "end": 1251.6000000000001,
  "text": " We talk about secret sauce. So one thing we skipped over about one thing
  that''s worth touching on", "tokens": [51036, 492, 751, 466, 4054, 4880, 13, 407,
  472, 551, 321, 30193, 670, 466, 472, 551, 300, 311, 3163, 11175, 322, 51248], "temperature":
  0.0, "avg_logprob": -0.16754087854604252, "compression_ratio": 1.8081180811808117,
  "no_speech_prob": 0.018749956041574478}, {"id": 218, "seek": 123392, "start": 1251.6000000000001,
  "end": 1258.64, "text": " in terms of RocksDB or architecture is RocksDB has two
  things that you hope every database has,", "tokens": [51248, 294, 2115, 295, 6922,
  82, 27735, 420, 9482, 307, 6922, 82, 27735, 575, 732, 721, 300, 291, 1454, 633,
  8149, 575, 11, 51600], "temperature": 0.0, "avg_logprob": -0.16754087854604252,
  "compression_ratio": 1.8081180811808117, "no_speech_prob": 0.018749956041574478},
  {"id": 219, "seek": 123392, "start": 1258.64, "end": 1263.3600000000001, "text":
  " but not every database has one is we have disaggregated storage, like fully disaggregated
  storage.", "tokens": [51600, 457, 406, 633, 8149, 575, 472, 307, 321, 362, 10414,
  11027, 770, 6725, 11, 411, 4498, 10414, 11027, 770, 6725, 13, 51836], "temperature":
  0.0, "avg_logprob": -0.16754087854604252, "compression_ratio": 1.8081180811808117,
  "no_speech_prob": 0.018749956041574478}, {"id": 220, "seek": 126336, "start": 1263.36,
  "end": 1267.52, "text": " So if you double your storage, you can, you can, basically,
  you can double your storage,", "tokens": [50364, 407, 498, 291, 3834, 428, 6725,
  11, 291, 393, 11, 291, 393, 11, 1936, 11, 291, 393, 3834, 428, 6725, 11, 50572],
  "temperature": 0.0, "avg_logprob": -0.14591153462727866, "compression_ratio": 2.089605734767025,
  "no_speech_prob": 0.0007795862038619816}, {"id": 221, "seek": 126336, "start": 1267.52,
  "end": 1272.0, "text": " you can double your compute, you can do either. You don''t
  have to do both, right? You can, they", "tokens": [50572, 291, 393, 3834, 428, 14722,
  11, 291, 393, 360, 2139, 13, 509, 500, 380, 362, 281, 360, 1293, 11, 558, 30, 509,
  393, 11, 436, 50796], "temperature": 0.0, "avg_logprob": -0.14591153462727866, "compression_ratio":
  2.089605734767025, "no_speech_prob": 0.0007795862038619816}, {"id": 222, "seek":
  126336, "start": 1272.0, "end": 1275.9199999999998, "text": " are stable. They,
  there''s compute optimized machines and storage optimized machines, and you can",
  "tokens": [50796, 366, 8351, 13, 814, 11, 456, 311, 14722, 26941, 8379, 293, 6725,
  26941, 8379, 11, 293, 291, 393, 50992], "temperature": 0.0, "avg_logprob": -0.14591153462727866,
  "compression_ratio": 2.089605734767025, "no_speech_prob": 0.0007795862038619816},
  {"id": 223, "seek": 126336, "start": 1275.9199999999998, "end": 1282.08, "text":
  " add to either group independently. We also have compute and compute isolation.
  So you can set aside", "tokens": [50992, 909, 281, 2139, 1594, 21761, 13, 492, 611,
  362, 14722, 293, 14722, 16001, 13, 407, 291, 393, 992, 7359, 51300], "temperature":
  0.0, "avg_logprob": -0.14591153462727866, "compression_ratio": 2.089605734767025,
  "no_speech_prob": 0.0007795862038619816}, {"id": 224, "seek": 126336, "start": 1282.08,
  "end": 1287.6799999999998, "text": " a set of machines, for example, just to do
  ingest and a different set of machines, just to do queries.", "tokens": [51300,
  257, 992, 295, 8379, 11, 337, 1365, 11, 445, 281, 360, 3957, 377, 293, 257, 819,
  992, 295, 8379, 11, 445, 281, 360, 24109, 13, 51580], "temperature": 0.0, "avg_logprob":
  -0.14591153462727866, "compression_ratio": 2.089605734767025, "no_speech_prob":
  0.0007795862038619816}, {"id": 225, "seek": 126336, "start": 1287.6799999999998,
  "end": 1291.84, "text": " And they both operate on the same backend, for example.
  You can go farther than that. You can have", "tokens": [51580, 400, 436, 1293, 9651,
  322, 264, 912, 38087, 11, 337, 1365, 13, 509, 393, 352, 20344, 813, 300, 13, 509,
  393, 362, 51788], "temperature": 0.0, "avg_logprob": -0.14591153462727866, "compression_ratio":
  2.089605734767025, "no_speech_prob": 0.0007795862038619816}, {"id": 226, "seek":
  129184, "start": 1292.32, "end": 1296.1599999999999, "text": " different groups
  of machines for different sets of queries or by 10 in or whatever you can go", "tokens":
  [50388, 819, 3935, 295, 8379, 337, 819, 6352, 295, 24109, 420, 538, 1266, 294, 420,
  2035, 291, 393, 352, 50580], "temperature": 0.0, "avg_logprob": -0.14488281637935316,
  "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0013978761853650212},
  {"id": 227, "seek": 129184, "start": 1296.1599999999999, "end": 1301.6, "text":
  " wild with this idea, isolating compute from it''s from each other, right? Once
  you have disaggregated", "tokens": [50580, 4868, 365, 341, 1558, 11, 48912, 14722,
  490, 309, 311, 490, 1184, 661, 11, 558, 30, 3443, 291, 362, 10414, 11027, 770, 50852],
  "temperature": 0.0, "avg_logprob": -0.14488281637935316, "compression_ratio": 1.6363636363636365,
  "no_speech_prob": 0.0013978761853650212}, {"id": 228, "seek": 129184, "start": 1301.6,
  "end": 1308.3999999999999, "text": " storage, this is an idea you can do. This is
  already really powerful for AI use cases, like in a way", "tokens": [50852, 6725,
  11, 341, 307, 364, 1558, 291, 393, 360, 13, 639, 307, 1217, 534, 4005, 337, 7318,
  764, 3331, 11, 411, 294, 257, 636, 51192], "temperature": 0.0, "avg_logprob": -0.14488281637935316,
  "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0013978761853650212},
  {"id": 229, "seek": 129184, "start": 1308.3999999999999, "end": 1313.36, "text":
  " you don''t necessarily appreciate, because what it means is I have a way to do
  my index rebuilds,", "tokens": [51192, 291, 500, 380, 4725, 4449, 11, 570, 437,
  309, 1355, 307, 286, 362, 257, 636, 281, 360, 452, 8186, 16877, 82, 11, 51440],
  "temperature": 0.0, "avg_logprob": -0.14488281637935316, "compression_ratio": 1.6363636363636365,
  "no_speech_prob": 0.0013978761853650212}, {"id": 230, "seek": 129184, "start": 1313.36,
  "end": 1319.28, "text": " which are expensive in a vector world, away from the machines
  handling queries. Like I''m not,", "tokens": [51440, 597, 366, 5124, 294, 257, 8062,
  1002, 11, 1314, 490, 264, 8379, 13175, 24109, 13, 1743, 286, 478, 406, 11, 51736],
  "temperature": 0.0, "avg_logprob": -0.14488281637935316, "compression_ratio": 1.6363636363636365,
  "no_speech_prob": 0.0013978761853650212}, {"id": 231, "seek": 131928, "start": 1319.28,
  "end": 1323.76, "text": " like what''s not going to happen is the machine, the database
  is going to bog itself down doing", "tokens": [50364, 411, 437, 311, 406, 516, 281,
  1051, 307, 264, 3479, 11, 264, 8149, 307, 516, 281, 26132, 2564, 760, 884, 50588],
  "temperature": 0.0, "avg_logprob": -0.14676791223986396, "compression_ratio": 1.6810035842293907,
  "no_speech_prob": 0.0016930574784055352}, {"id": 232, "seek": 131928, "start": 1323.76,
  "end": 1328.24, "text": " an index updates of some sort while queries are trying
  to be served and you''re going to get time", "tokens": [50588, 364, 8186, 9205,
  295, 512, 1333, 1339, 24109, 366, 1382, 281, 312, 7584, 293, 291, 434, 516, 281,
  483, 565, 50812], "temperature": 0.0, "avg_logprob": -0.14676791223986396, "compression_ratio":
  1.6810035842293907, "no_speech_prob": 0.0016930574784055352}, {"id": 233, "seek":
  131928, "start": 1328.24, "end": 1334.0, "text": " out. So being able to actually
  separate out compute is very powerful in these AI settings.", "tokens": [50812,
  484, 13, 407, 885, 1075, 281, 767, 4994, 484, 14722, 307, 588, 4005, 294, 613, 7318,
  6257, 13, 51100], "temperature": 0.0, "avg_logprob": -0.14676791223986396, "compression_ratio":
  1.6810035842293907, "no_speech_prob": 0.0016930574784055352}, {"id": 234, "seek":
  131928, "start": 1334.0, "end": 1338.96, "text": " Again, another example, no one''s
  done this like in total anger yet, but it''s going to come,", "tokens": [51100,
  3764, 11, 1071, 1365, 11, 572, 472, 311, 1096, 341, 411, 294, 3217, 10240, 1939,
  11, 457, 309, 311, 516, 281, 808, 11, 51348], "temperature": 0.0, "avg_logprob":
  -0.14676791223986396, "compression_ratio": 1.6810035842293907, "no_speech_prob":
  0.0016930574784055352}, {"id": 235, "seek": 131928, "start": 1338.96, "end": 1344.8,
  "text": " which is like the hey, I have a god awful amount of vectors. I want to
  update them to the next", "tokens": [51348, 597, 307, 411, 264, 4177, 11, 286, 362,
  257, 3044, 11232, 2372, 295, 18875, 13, 286, 528, 281, 5623, 552, 281, 264, 958,
  51640], "temperature": 0.0, "avg_logprob": -0.14676791223986396, "compression_ratio":
  1.6810035842293907, "no_speech_prob": 0.0016930574784055352}, {"id": 236, "seek":
  134480, "start": 1344.8, "end": 1349.52, "text": " generation of my the new open
  AI model has come out. I want to rerun the entire data set.", "tokens": [50364,
  5125, 295, 452, 264, 777, 1269, 7318, 2316, 575, 808, 484, 13, 286, 528, 281, 43819,
  409, 264, 2302, 1412, 992, 13, 50600], "temperature": 0.0, "avg_logprob": -0.16023313698648406,
  "compression_ratio": 1.6725352112676057, "no_speech_prob": 0.0026966959703713655},
  {"id": 237, "seek": 134480, "start": 1350.56, "end": 1355.68, "text": " We can do
  that in this kind of like off on the side fashion in a way that just reduz it all
  in", "tokens": [50652, 492, 393, 360, 300, 294, 341, 733, 295, 411, 766, 322, 264,
  1252, 6700, 294, 257, 636, 300, 445, 2182, 3334, 309, 439, 294, 50908], "temperature":
  0.0, "avg_logprob": -0.16023313698648406, "compression_ratio": 1.6725352112676057,
  "no_speech_prob": 0.0026966959703713655}, {"id": 238, "seek": 134480, "start": 1355.68,
  "end": 1360.48, "text": " place without affecting the running application as an
  example. So that''s one like kind of very", "tokens": [50908, 1081, 1553, 17476,
  264, 2614, 3861, 382, 364, 1365, 13, 407, 300, 311, 472, 411, 733, 295, 588, 51148],
  "temperature": 0.0, "avg_logprob": -0.16023313698648406, "compression_ratio": 1.6725352112676057,
  "no_speech_prob": 0.0026966959703713655}, {"id": 239, "seek": 134480, "start": 1360.48,
  "end": 1366.24, "text": " architectural found is a very database type of a feature
  that you you will miss it if you don''t", "tokens": [51148, 26621, 1352, 307, 257,
  588, 8149, 2010, 295, 257, 4111, 300, 291, 291, 486, 1713, 309, 498, 291, 500, 380,
  51436], "temperature": 0.0, "avg_logprob": -0.16023313698648406, "compression_ratio":
  1.6725352112676057, "no_speech_prob": 0.0026966959703713655}, {"id": 240, "seek":
  134480, "start": 1366.24, "end": 1372.56, "text": " have it when the day comes.
  Moving up to kind of more AI level things, the other thing that we have", "tokens":
  [51436, 362, 309, 562, 264, 786, 1487, 13, 14242, 493, 281, 733, 295, 544, 7318,
  1496, 721, 11, 264, 661, 551, 300, 321, 362, 51752], "temperature": 0.0, "avg_logprob":
  -0.16023313698648406, "compression_ratio": 1.6725352112676057, "no_speech_prob":
  0.0026966959703713655}, {"id": 241, "seek": 137256, "start": 1372.56, "end": 1379.76,
  "text": " is like we have a huge pile of infrastructure of like doing SQL and relational
  queries, right?", "tokens": [50364, 307, 411, 321, 362, 257, 2603, 14375, 295, 6896,
  295, 411, 884, 19200, 293, 38444, 24109, 11, 558, 30, 50724], "temperature": 0.0,
  "avg_logprob": -0.1363154867421026, "compression_ratio": 1.7482014388489209, "no_speech_prob":
  0.0016974152531474829}, {"id": 242, "seek": 137256, "start": 1380.3999999999999,
  "end": 1386.3999999999999, "text": " In this system that''s separate from the vector
  stuff. So when the vector stuff gets mixed with that", "tokens": [50756, 682, 341,
  1185, 300, 311, 4994, 490, 264, 8062, 1507, 13, 407, 562, 264, 8062, 1507, 2170,
  7467, 365, 300, 51056], "temperature": 0.0, "avg_logprob": -0.1363154867421026,
  "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0016974152531474829},
  {"id": 243, "seek": 137256, "start": 1386.3999999999999, "end": 1391.9199999999998,
  "text": " stuff, the things get very powerful and very magical. And so this gets
  you into so there''s it''s", "tokens": [51056, 1507, 11, 264, 721, 483, 588, 4005,
  293, 588, 12066, 13, 400, 370, 341, 2170, 291, 666, 370, 456, 311, 309, 311, 51332],
  "temperature": 0.0, "avg_logprob": -0.1363154867421026, "compression_ratio": 1.7482014388489209,
  "no_speech_prob": 0.0016974152531474829}, {"id": 244, "seek": 137256, "start": 1391.9199999999998,
  "end": 1396.1599999999999, "text": " funny because database people talk a certain
  way and AI people talk a certain way and a lot of", "tokens": [51332, 4074, 570,
  8149, 561, 751, 257, 1629, 636, 293, 7318, 561, 751, 257, 1629, 636, 293, 257, 688,
  295, 51544], "temperature": 0.0, "avg_logprob": -0.1363154867421026, "compression_ratio":
  1.7482014388489209, "no_speech_prob": 0.0016974152531474829}, {"id": 245, "seek":
  137256, "start": 1396.1599999999999, "end": 1399.36, "text": " times they''re actually
  saying the same thing, but they use none of the same words. And so they don''t",
  "tokens": [51544, 1413, 436, 434, 767, 1566, 264, 912, 551, 11, 457, 436, 764, 6022,
  295, 264, 912, 2283, 13, 400, 370, 436, 500, 380, 51704], "temperature": 0.0, "avg_logprob":
  -0.1363154867421026, "compression_ratio": 1.7482014388489209, "no_speech_prob":
  0.0016974152531474829}, {"id": 246, "seek": 139936, "start": 1399.36, "end": 1403.84,
  "text": " know they''re talking about the same thing, but as an example, like so
  in an AI context, things like", "tokens": [50364, 458, 436, 434, 1417, 466, 264,
  912, 551, 11, 457, 382, 364, 1365, 11, 411, 370, 294, 364, 7318, 4319, 11, 721,
  411, 50588], "temperature": 0.0, "avg_logprob": -0.19275750404547068, "compression_ratio":
  1.8972332015810276, "no_speech_prob": 0.0008676409488543868}, {"id": 247, "seek":
  139936, "start": 1403.84, "end": 1409.76, "text": " metadata filtering or hybrid
  search, these are all things Rockset does out of the box. Like", "tokens": [50588,
  26603, 30822, 420, 13051, 3164, 11, 613, 366, 439, 721, 6922, 3854, 775, 484, 295,
  264, 2424, 13, 1743, 50884], "temperature": 0.0, "avg_logprob": -0.19275750404547068,
  "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.0008676409488543868},
  {"id": 248, "seek": 139936, "start": 1409.76, "end": 1415.28, "text": " metadata
  filtering in an AI context or a vector context, that''s just like the wear clause
  of a", "tokens": [50884, 26603, 30822, 294, 364, 7318, 4319, 420, 257, 8062, 4319,
  11, 300, 311, 445, 411, 264, 3728, 25925, 295, 257, 51160], "temperature": 0.0,
  "avg_logprob": -0.19275750404547068, "compression_ratio": 1.8972332015810276, "no_speech_prob":
  0.0008676409488543868}, {"id": 249, "seek": 139936, "start": 1415.28, "end": 1419.76,
  "text": " SQL query. Like that''s all that is like where X is created and this time
  is created and that.", "tokens": [51160, 19200, 14581, 13, 1743, 300, 311, 439,
  300, 307, 411, 689, 1783, 307, 2942, 293, 341, 565, 307, 2942, 293, 300, 13, 51384],
  "temperature": 0.0, "avg_logprob": -0.19275750404547068, "compression_ratio": 1.8972332015810276,
  "no_speech_prob": 0.0008676409488543868}, {"id": 250, "seek": 139936, "start": 1419.76,
  "end": 1425.04, "text": " Like so for us, it''s that''s all done. Like metadata
  filtering is easy. That''s not a hard problem at", "tokens": [51384, 1743, 370,
  337, 505, 11, 309, 311, 300, 311, 439, 1096, 13, 1743, 26603, 30822, 307, 1858,
  13, 663, 311, 406, 257, 1152, 1154, 412, 51648], "temperature": 0.0, "avg_logprob":
  -0.19275750404547068, "compression_ratio": 1.8972332015810276, "no_speech_prob":
  0.0008676409488543868}, {"id": 251, "seek": 142504, "start": 1425.04, "end": 1430.1599999999999,
  "text": " all. All you have to do is you know, I have a super powerful query language.
  I''m query optimizer.", "tokens": [50364, 439, 13, 1057, 291, 362, 281, 360, 307,
  291, 458, 11, 286, 362, 257, 1687, 4005, 14581, 2856, 13, 286, 478, 14581, 5028,
  6545, 13, 50620], "temperature": 0.0, "avg_logprob": -0.14817818556681717, "compression_ratio":
  1.6753246753246753, "no_speech_prob": 7.794262637617067e-05}, {"id": 252, "seek":
  142504, "start": 1430.1599999999999, "end": 1434.8799999999999, "text": " All you
  have to do is kind of merge that with the a and n kind of vector search and I get
  like", "tokens": [50620, 1057, 291, 362, 281, 360, 307, 733, 295, 22183, 300, 365,
  264, 257, 293, 297, 733, 295, 8062, 3164, 293, 286, 483, 411, 50856], "temperature":
  0.0, "avg_logprob": -0.14817818556681717, "compression_ratio": 1.6753246753246753,
  "no_speech_prob": 7.794262637617067e-05}, {"id": 253, "seek": 142504, "start": 1434.8799999999999,
  "end": 1439.6, "text": " metadata filtering is like a not that''s not a hard problem
  for us to solve. Like it would be for", "tokens": [50856, 26603, 30822, 307, 411,
  257, 406, 300, 311, 406, 257, 1152, 1154, 337, 505, 281, 5039, 13, 1743, 309, 576,
  312, 337, 51092], "temperature": 0.0, "avg_logprob": -0.14817818556681717, "compression_ratio":
  1.6753246753246753, "no_speech_prob": 7.794262637617067e-05}, {"id": 254, "seek":
  142504, "start": 1439.6, "end": 1446.72, "text": " others to solve. And so I do
  think we really shine in situations where a you care about real time", "tokens":
  [51092, 2357, 281, 5039, 13, 400, 370, 286, 360, 519, 321, 534, 12207, 294, 6851,
  689, 257, 291, 1127, 466, 957, 565, 51448], "temperature": 0.0, "avg_logprob": -0.14817818556681717,
  "compression_ratio": 1.6753246753246753, "no_speech_prob": 7.794262637617067e-05},
  {"id": 255, "seek": 144672, "start": 1446.72, "end": 1456.72, "text": " ingest,
  be you care about any kind of hybrid or metadata filtering. Rockset''s really good
  as well", "tokens": [50364, 3957, 377, 11, 312, 291, 1127, 466, 604, 733, 295, 13051,
  420, 26603, 30822, 13, 6922, 3854, 311, 534, 665, 382, 731, 50864], "temperature":
  0.0, "avg_logprob": -0.16194987297058105, "compression_ratio": 1.6485355648535565,
  "no_speech_prob": 0.000734504486899823}, {"id": 256, "seek": 144672, "start": 1456.72,
  "end": 1464.32, "text": " for for kind of raw vector power, but I wouldn''t say
  we''re like the best database in the world for like,", "tokens": [50864, 337, 337,
  733, 295, 8936, 8062, 1347, 11, 457, 286, 2759, 380, 584, 321, 434, 411, 264, 1151,
  8149, 294, 264, 1002, 337, 411, 11, 51244], "temperature": 0.0, "avg_logprob": -0.16194987297058105,
  "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.000734504486899823},
  {"id": 257, "seek": 144672, "start": 1465.28, "end": 1468.96, "text": " I don''t
  know, I view it more like we kind of going where our customers are taking us. Like
  if", "tokens": [51292, 286, 500, 380, 458, 11, 286, 1910, 309, 544, 411, 321, 733,
  295, 516, 689, 527, 4581, 366, 1940, 505, 13, 1743, 498, 51476], "temperature":
  0.0, "avg_logprob": -0.16194987297058105, "compression_ratio": 1.6485355648535565,
  "no_speech_prob": 0.000734504486899823}, {"id": 258, "seek": 144672, "start": 1468.96,
  "end": 1473.04, "text": " the customers came to me as like, Hey, if you if you if
  I can have 10 times more vectors and like", "tokens": [51476, 264, 4581, 1361, 281,
  385, 382, 411, 11, 1911, 11, 498, 291, 498, 291, 498, 286, 393, 362, 1266, 1413,
  544, 18875, 293, 411, 51680], "temperature": 0.0, "avg_logprob": -0.16194987297058105,
  "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.000734504486899823},
  {"id": 259, "seek": 147304, "start": 1473.6, "end": 1477.92, "text": " 4% more precision
  and recall, if you implemented this slightly better algorithm with these parameters,",
  "tokens": [50392, 1017, 4, 544, 18356, 293, 9901, 11, 498, 291, 12270, 341, 4748,
  1101, 9284, 365, 613, 9834, 11, 50608], "temperature": 0.0, "avg_logprob": -0.12673638774230417,
  "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002413652604445815},
  {"id": 260, "seek": 147304, "start": 1477.92, "end": 1485.04, "text": " we would
  do it. But almost always it''s like they want we want that like hybrid search seems
  to be", "tokens": [50608, 321, 576, 360, 309, 13, 583, 1920, 1009, 309, 311, 411,
  436, 528, 321, 528, 300, 411, 13051, 3164, 2544, 281, 312, 50964], "temperature":
  0.0, "avg_logprob": -0.12673638774230417, "compression_ratio": 1.7132867132867133,
  "no_speech_prob": 0.002413652604445815}, {"id": 261, "seek": 147304, "start": 1485.04,
  "end": 1490.32, "text": " the king. Like it''s it''s it''s merging these things.
  And that''s where like a lot of our effort has", "tokens": [50964, 264, 4867, 13,
  1743, 309, 311, 309, 311, 309, 311, 44559, 613, 721, 13, 400, 300, 311, 689, 411,
  257, 688, 295, 527, 4630, 575, 51228], "temperature": 0.0, "avg_logprob": -0.12673638774230417,
  "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002413652604445815},
  {"id": 262, "seek": 147304, "start": 1490.32, "end": 1495.28, "text": " gone is
  into making the hybrid search story like making these two worlds work together like",
  "tokens": [51228, 2780, 307, 666, 1455, 264, 13051, 3164, 1657, 411, 1455, 613,
  732, 13401, 589, 1214, 411, 51476], "temperature": 0.0, "avg_logprob": -0.12673638774230417,
  "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002413652604445815},
  {"id": 263, "seek": 147304, "start": 1495.28, "end": 1500.6399999999999, "text":
  " fairly seamlessly. Like be able to say like show me the closest 10 vectors that
  were updated in the", "tokens": [51476, 6457, 38083, 13, 1743, 312, 1075, 281, 584,
  411, 855, 385, 264, 13699, 1266, 18875, 300, 645, 10588, 294, 264, 51744], "temperature":
  0.0, "avg_logprob": -0.12673638774230417, "compression_ratio": 1.7132867132867133,
  "no_speech_prob": 0.002413652604445815}, {"id": 264, "seek": 150064, "start": 1500.64,
  "end": 1507.6000000000001, "text": " last 10 minutes. Like that that kind of query
  is really powerful. And that''s kind of what we''ve", "tokens": [50364, 1036, 1266,
  2077, 13, 1743, 300, 300, 733, 295, 14581, 307, 534, 4005, 13, 400, 300, 311, 733,
  295, 437, 321, 600, 50712], "temperature": 0.0, "avg_logprob": -0.20999789441752637,
  "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.00041285910992883146},
  {"id": 265, "seek": 150064, "start": 1507.6000000000001, "end": 1513.1200000000001,
  "text": " been focused on in terms of in terms of. But I guess the timestamp example
  you gave it''s also", "tokens": [50712, 668, 5178, 322, 294, 2115, 295, 294, 2115,
  295, 13, 583, 286, 2041, 264, 49108, 1215, 1365, 291, 2729, 309, 311, 611, 50988],
  "temperature": 0.0, "avg_logprob": -0.20999789441752637, "compression_ratio": 1.7388059701492538,
  "no_speech_prob": 0.00041285910992883146}, {"id": 266, "seek": 150064, "start":
  1513.1200000000001, "end": 1518.16, "text": " like metadata check right. It''s kind
  of like way close where you say between a and b timestamps.", "tokens": [50988,
  411, 26603, 1520, 558, 13, 467, 311, 733, 295, 411, 636, 1998, 689, 291, 584, 1296,
  257, 293, 272, 49108, 23150, 13, 51240], "temperature": 0.0, "avg_logprob": -0.20999789441752637,
  "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.00041285910992883146},
  {"id": 267, "seek": 150064, "start": 1518.16, "end": 1523.68, "text": " Yes. Yes.
  But like hybrid search at least the way I''m hearing people do this is that", "tokens":
  [51240, 1079, 13, 1079, 13, 583, 411, 13051, 3164, 412, 1935, 264, 636, 286, 478,
  4763, 561, 360, 341, 307, 300, 51516], "temperature": 0.0, "avg_logprob": -0.20999789441752637,
  "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.00041285910992883146},
  {"id": 268, "seek": 150064, "start": 1524.24, "end": 1530.0, "text": " let''s say
  take the search domains example. You might have a keyword search right which is
  your", "tokens": [51544, 718, 311, 584, 747, 264, 3164, 25514, 1365, 13, 509, 1062,
  362, 257, 20428, 3164, 558, 597, 307, 428, 51832], "temperature": 0.0, "avg_logprob":
  -0.20999789441752637, "compression_ratio": 1.7388059701492538, "no_speech_prob":
  0.00041285910992883146}, {"id": 269, "seek": 153000, "start": 1530.0, "end": 1536.96,
  "text": " sparse index and then you have your then syntax vector search. And you
  want to combine the two in", "tokens": [50364, 637, 11668, 8186, 293, 550, 291,
  362, 428, 550, 28431, 8062, 3164, 13, 400, 291, 528, 281, 10432, 264, 732, 294,
  50712], "temperature": 0.0, "avg_logprob": -0.19386354569465883, "compression_ratio":
  1.7536764705882353, "no_speech_prob": 0.0020784453954547644}, {"id": 270, "seek":
  153000, "start": 1536.96, "end": 1543.2, "text": " some way. For example, you could
  say I still trust keyword search. So let''s give it 75% of weight", "tokens": [50712,
  512, 636, 13, 1171, 1365, 11, 291, 727, 584, 286, 920, 3361, 20428, 3164, 13, 407,
  718, 311, 976, 309, 9562, 4, 295, 3364, 51024], "temperature": 0.0, "avg_logprob":
  -0.19386354569465883, "compression_ratio": 1.7536764705882353, "no_speech_prob":
  0.0020784453954547644}, {"id": 271, "seek": 153000, "start": 1543.2, "end": 1548.96,
  "text": " and then 25% goes to vector. And then you combine them into leave them
  in some merging strategy.", "tokens": [51024, 293, 550, 3552, 4, 1709, 281, 8062,
  13, 400, 550, 291, 10432, 552, 666, 1856, 552, 294, 512, 44559, 5206, 13, 51312],
  "temperature": 0.0, "avg_logprob": -0.19386354569465883, "compression_ratio": 1.7536764705882353,
  "no_speech_prob": 0.0020784453954547644}, {"id": 272, "seek": 153000, "start": 1548.96,
  "end": 1553.2, "text": " And then you return back to the user. Is this how you see
  hybrid search or do you see?", "tokens": [51312, 400, 550, 291, 2736, 646, 281,
  264, 4195, 13, 1119, 341, 577, 291, 536, 13051, 3164, 420, 360, 291, 536, 30, 51524],
  "temperature": 0.0, "avg_logprob": -0.19386354569465883, "compression_ratio": 1.7536764705882353,
  "no_speech_prob": 0.0020784453954547644}, {"id": 273, "seek": 153000, "start": 1554.0,
  "end": 1558.4, "text": " So I have a whole ran here. You might you might have yes
  you''ve unlocked my ran here. So let''s go", "tokens": [51564, 407, 286, 362, 257,
  1379, 5872, 510, 13, 509, 1062, 291, 1062, 362, 2086, 291, 600, 30180, 452, 5872,
  510, 13, 407, 718, 311, 352, 51784], "temperature": 0.0, "avg_logprob": -0.19386354569465883,
  "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.0020784453954547644},
  {"id": 274, "seek": 155840, "start": 1558.88, "end": 1563.52, "text": " so hybrid
  search is one of these very overloaded terms exactly as you have kind of this is
  kind", "tokens": [50388, 370, 13051, 3164, 307, 472, 295, 613, 588, 28777, 292,
  2115, 2293, 382, 291, 362, 733, 295, 341, 307, 733, 50620], "temperature": 0.0,
  "avg_logprob": -0.13490611051036194, "compression_ratio": 1.888030888030888, "no_speech_prob":
  0.0010457593016326427}, {"id": 275, "seek": 155840, "start": 1563.52, "end": 1568.4,
  "text": " of sometimes what people mean. Sometimes people do they they smuggle metadata
  filtering as a hybrid", "tokens": [50620, 295, 2171, 437, 561, 914, 13, 4803, 561,
  360, 436, 436, 899, 31726, 26603, 30822, 382, 257, 13051, 50864], "temperature":
  0.0, "avg_logprob": -0.13490611051036194, "compression_ratio": 1.888030888030888,
  "no_speech_prob": 0.0010457593016326427}, {"id": 276, "seek": 155840, "start": 1568.4,
  "end": 1573.6000000000001, "text": " search. Strictly speaking under my definition,
  metadata filtering is a kind of hybrid search. It", "tokens": [50864, 3164, 13,
  745, 3740, 356, 4124, 833, 452, 7123, 11, 26603, 30822, 307, 257, 733, 295, 13051,
  3164, 13, 467, 51124], "temperature": 0.0, "avg_logprob": -0.13490611051036194,
  "compression_ratio": 1.888030888030888, "no_speech_prob": 0.0010457593016326427},
  {"id": 277, "seek": 155840, "start": 1573.6000000000001, "end": 1579.0400000000002,
  "text": " just sort of has extreme weights right like it''s weight one if it matches
  and zero if it doesn''t.", "tokens": [51124, 445, 1333, 295, 575, 8084, 17443, 558,
  411, 309, 311, 3364, 472, 498, 309, 10676, 293, 4018, 498, 309, 1177, 380, 13, 51396],
  "temperature": 0.0, "avg_logprob": -0.13490611051036194, "compression_ratio": 1.888030888030888,
  "no_speech_prob": 0.0010457593016326427}, {"id": 278, "seek": 155840, "start": 1579.0400000000002,
  "end": 1586.0, "text": " And so it''s kind of like a weighted hybrid search. You
  can also do this kind of linear combination", "tokens": [51396, 400, 370, 309, 311,
  733, 295, 411, 257, 32807, 13051, 3164, 13, 509, 393, 611, 360, 341, 733, 295, 8213,
  6562, 51744], "temperature": 0.0, "avg_logprob": -0.13490611051036194, "compression_ratio":
  1.888030888030888, "no_speech_prob": 0.0010457593016326427}, {"id": 279, "seek":
  158600, "start": 1586.0, "end": 1591.04, "text": " hybrid search right like I have
  a BM 25 keyword type a ranker which by the way, rockset can do like", "tokens":
  [50364, 13051, 3164, 558, 411, 286, 362, 257, 15901, 3552, 20428, 2010, 257, 6181,
  260, 597, 538, 264, 636, 11, 10989, 302, 393, 360, 411, 50616], "temperature": 0.0,
  "avg_logprob": -0.18300769774894404, "compression_ratio": 1.7870036101083033, "no_speech_prob":
  0.003641925984993577}, {"id": 280, "seek": 158600, "start": 1591.04, "end": 1596.24,
  "text": " rockset has this rockset you can build you can do this order by keyword
  ranking limit 10 like you", "tokens": [50616, 10989, 302, 575, 341, 10989, 302,
  291, 393, 1322, 291, 393, 360, 341, 1668, 538, 20428, 17833, 4948, 1266, 411, 291,
  50876], "temperature": 0.0, "avg_logprob": -0.18300769774894404, "compression_ratio":
  1.7870036101083033, "no_speech_prob": 0.003641925984993577}, {"id": 281, "seek":
  158600, "start": 1596.24, "end": 1601.52, "text": " could write that. And then you
  can also then do the vector limit 10 like show me the 10 closest", "tokens": [50876,
  727, 2464, 300, 13, 400, 550, 291, 393, 611, 550, 360, 264, 8062, 4948, 1266, 411,
  855, 385, 264, 1266, 13699, 51140], "temperature": 0.0, "avg_logprob": -0.18300769774894404,
  "compression_ratio": 1.7870036101083033, "no_speech_prob": 0.003641925984993577},
  {"id": 282, "seek": 158600, "start": 1601.52, "end": 1609.84, "text": " vectors.
  There''s nothing stopping you from saying or you know order by 0.25 of that plus
  0.75 of that", "tokens": [51140, 18875, 13, 821, 311, 1825, 12767, 291, 490, 1566,
  420, 291, 458, 1668, 538, 1958, 13, 6074, 295, 300, 1804, 1958, 13, 11901, 295,
  300, 51556], "temperature": 0.0, "avg_logprob": -0.18300769774894404, "compression_ratio":
  1.7870036101083033, "no_speech_prob": 0.003641925984993577}, {"id": 283, "seek":
  158600, "start": 1609.84, "end": 1615.52, "text": " for example, in your in your
  example. So that kind of linear combination hybrid search is is doable", "tokens":
  [51556, 337, 1365, 11, 294, 428, 294, 428, 1365, 13, 407, 300, 733, 295, 8213, 6562,
  13051, 3164, 307, 307, 41183, 51840], "temperature": 0.0, "avg_logprob": -0.18300769774894404,
  "compression_ratio": 1.7870036101083033, "no_speech_prob": 0.003641925984993577},
  {"id": 284, "seek": 161552, "start": 1615.52, "end": 1619.04, "text": " like that
  that''s how that''s how you could do rockset. Sorry, that''s how you can do that
  kind of", "tokens": [50364, 411, 300, 300, 311, 577, 300, 311, 577, 291, 727, 360,
  10989, 302, 13, 4919, 11, 300, 311, 577, 291, 393, 360, 300, 733, 295, 50540], "temperature":
  0.0, "avg_logprob": -0.11747104030544475, "compression_ratio": 1.8365019011406845,
  "no_speech_prob": 0.0003555835864972323}, {"id": 285, "seek": 161552, "start": 1619.04,
  "end": 1624.4, "text": " hybrid search on rockset today. Now you people do do slightly
  more advanced things than this by", "tokens": [50540, 13051, 3164, 322, 10989, 302,
  965, 13, 823, 291, 561, 360, 360, 4748, 544, 7339, 721, 813, 341, 538, 50808], "temperature":
  0.0, "avg_logprob": -0.11747104030544475, "compression_ratio": 1.8365019011406845,
  "no_speech_prob": 0.0003555835864972323}, {"id": 286, "seek": 161552, "start": 1624.4,
  "end": 1628.72, "text": " the way there are like you can go beyond that in hybrid
  search and get into things like by encoding", "tokens": [50808, 264, 636, 456, 366,
  411, 291, 393, 352, 4399, 300, 294, 13051, 3164, 293, 483, 666, 721, 411, 538, 43430,
  51024], "temperature": 0.0, "avg_logprob": -0.11747104030544475, "compression_ratio":
  1.8365019011406845, "no_speech_prob": 0.0003555835864972323}, {"id": 287, "seek":
  161552, "start": 1628.72, "end": 1635.68, "text": " and crossing coding where you
  really do try to take the the expanded vector space and treat it", "tokens": [51024,
  293, 14712, 17720, 689, 291, 534, 360, 853, 281, 747, 264, 264, 14342, 8062, 1901,
  293, 2387, 309, 51372], "temperature": 0.0, "avg_logprob": -0.11747104030544475,
  "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0003555835864972323},
  {"id": 288, "seek": 161552, "start": 1635.68, "end": 1641.76, "text": " non-linearly
  so it''s no longer a linear combination of the two halves. And we''ve this is this
  is", "tokens": [51372, 2107, 12, 28263, 356, 370, 309, 311, 572, 2854, 257, 8213,
  6562, 295, 264, 732, 38490, 13, 400, 321, 600, 341, 307, 341, 307, 51676], "temperature":
  0.0, "avg_logprob": -0.11747104030544475, "compression_ratio": 1.8365019011406845,
  "no_speech_prob": 0.0003555835864972323}, {"id": 289, "seek": 164176, "start": 1641.76,
  "end": 1648.96, "text": " something we are actively looking at. I don''t so it''s
  I don''t think it''s hard to add like it''s", "tokens": [50364, 746, 321, 366, 13022,
  1237, 412, 13, 286, 500, 380, 370, 309, 311, 286, 500, 380, 519, 309, 311, 1152,
  281, 909, 411, 309, 311, 50724], "temperature": 0.0, "avg_logprob": -0.10175528064850838,
  "compression_ratio": 1.9516129032258065, "no_speech_prob": 0.0010528104612603784},
  {"id": 290, "seek": 164176, "start": 1648.96, "end": 1653.76, "text": " easy extension
  onto onto onto the current system but it''s more of like a science question like",
  "tokens": [50724, 1858, 10320, 3911, 3911, 3911, 264, 2190, 1185, 457, 309, 311,
  544, 295, 411, 257, 3497, 1168, 411, 50964], "temperature": 0.0, "avg_logprob":
  -0.10175528064850838, "compression_ratio": 1.9516129032258065, "no_speech_prob":
  0.0010528104612603784}, {"id": 291, "seek": 164176, "start": 1653.76, "end": 1658.96,
  "text": " it''s more of like if you tell me what to add I''ll add it sure that''s
  easy but it''s like what do we", "tokens": [50964, 309, 311, 544, 295, 411, 498,
  291, 980, 385, 437, 281, 909, 286, 603, 909, 309, 988, 300, 311, 1858, 457, 309,
  311, 411, 437, 360, 321, 51224], "temperature": 0.0, "avg_logprob": -0.10175528064850838,
  "compression_ratio": 1.9516129032258065, "no_speech_prob": 0.0010528104612603784},
  {"id": 292, "seek": 164176, "start": 1658.96, "end": 1662.32, "text": " add like
  what''s the right crossing code I don''t know that''s a much harder problem that''s
  like much", "tokens": [51224, 909, 411, 437, 311, 264, 558, 14712, 3089, 286, 500,
  380, 458, 300, 311, 257, 709, 6081, 1154, 300, 311, 411, 709, 51392], "temperature":
  0.0, "avg_logprob": -0.10175528064850838, "compression_ratio": 1.9516129032258065,
  "no_speech_prob": 0.0010528104612603784}, {"id": 293, "seek": 164176, "start": 1662.32,
  "end": 1667.52, "text": " more of a scientific question in terms of like do I need
  to train an encoder for your particular", "tokens": [51392, 544, 295, 257, 8134,
  1168, 294, 2115, 295, 411, 360, 286, 643, 281, 3847, 364, 2058, 19866, 337, 428,
  1729, 51652], "temperature": 0.0, "avg_logprob": -0.10175528064850838, "compression_ratio":
  1.9516129032258065, "no_speech_prob": 0.0010528104612603784}, {"id": 294, "seek":
  166752, "start": 1667.68, "end": 1671.36, "text": " use case is there such a thing
  as a good off the shelf one right so that''s that''s kind of where", "tokens": [50372,
  764, 1389, 307, 456, 1270, 257, 551, 382, 257, 665, 766, 264, 15222, 472, 558, 370,
  300, 311, 300, 311, 733, 295, 689, 50556], "temperature": 0.0, "avg_logprob": -0.15393006088387254,
  "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.004065278917551041},
  {"id": 295, "seek": 166752, "start": 1671.36, "end": 1675.12, "text": " we''re at
  with this but but in terms of adding that functionality that is like an active you''ve",
  "tokens": [50556, 321, 434, 412, 365, 341, 457, 457, 294, 2115, 295, 5127, 300,
  14980, 300, 307, 411, 364, 4967, 291, 600, 50744], "temperature": 0.0, "avg_logprob":
  -0.15393006088387254, "compression_ratio": 1.8795180722891567, "no_speech_prob":
  0.004065278917551041}, {"id": 296, "seek": 166752, "start": 1675.12, "end": 1678.8799999999999,
  "text": " you''ve this is the this is the frontier right now for us that''s for
  those people that they''re", "tokens": [50744, 291, 600, 341, 307, 264, 341, 307,
  264, 35853, 558, 586, 337, 505, 300, 311, 337, 729, 561, 300, 436, 434, 50932],
  "temperature": 0.0, "avg_logprob": -0.15393006088387254, "compression_ratio": 1.8795180722891567,
  "no_speech_prob": 0.004065278917551041}, {"id": 297, "seek": 166752, "start": 1678.8799999999999,
  "end": 1687.92, "text": " trying to go beyond the kind of bilinear yeah wait yeah
  another thing yeah bilinear is it''s", "tokens": [50932, 1382, 281, 352, 4399, 264,
  733, 295, 8588, 533, 289, 1338, 1699, 1338, 1071, 551, 1338, 8588, 533, 289, 307,
  309, 311, 51384], "temperature": 0.0, "avg_logprob": -0.15393006088387254, "compression_ratio":
  1.8795180722891567, "no_speech_prob": 0.004065278917551041}, {"id": 298, "seek":
  166752, "start": 1687.92, "end": 1692.24, "text": " it''s amazing maybe you can
  share some resources as well for for me and the audience to read", "tokens": [51384,
  309, 311, 2243, 1310, 291, 393, 2073, 512, 3593, 382, 731, 337, 337, 385, 293, 264,
  4034, 281, 1401, 51600], "temperature": 0.0, "avg_logprob": -0.15393006088387254,
  "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.004065278917551041},
  {"id": 299, "seek": 169224, "start": 1692.56, "end": 1699.36, "text": " but also
  I thought you know when hybrid search sort of topic emerged right in in the vector",
  "tokens": [50380, 457, 611, 286, 1194, 291, 458, 562, 13051, 3164, 1333, 295, 4829,
  20178, 558, 294, 294, 264, 8062, 50720], "temperature": 0.0, "avg_logprob": -0.24188362373100533,
  "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003579241456463933},
  {"id": 300, "seek": 169224, "start": 1699.36, "end": 1707.84, "text": " database
  world you know bb8 pine cone milbus what you''re like and so on I think one thing
  that was", "tokens": [50720, 8149, 1002, 291, 458, 272, 65, 23, 15113, 19749, 1962,
  21441, 437, 291, 434, 411, 293, 370, 322, 286, 519, 472, 551, 300, 390, 51144],
  "temperature": 0.0, "avg_logprob": -0.24188362373100533, "compression_ratio": 1.6666666666666667,
  "no_speech_prob": 0.003579241456463933}, {"id": 301, "seek": 169224, "start": 1707.84,
  "end": 1715.1200000000001, "text": " overlooked and I really wanted to tap into
  that at some point is to learn the alpha rise because", "tokens": [51144, 32269,
  293, 286, 534, 1415, 281, 5119, 666, 300, 412, 512, 935, 307, 281, 1466, 264, 8961,
  6272, 570, 51508], "temperature": 0.0, "avg_logprob": -0.24188362373100533, "compression_ratio":
  1.6666666666666667, "no_speech_prob": 0.003579241456463933}, {"id": 302, "seek":
  169224, "start": 1715.1200000000001, "end": 1720.24, "text": " it''s not given like
  how should you come if you go with linear combination you know what should be",
  "tokens": [51508, 309, 311, 406, 2212, 411, 577, 820, 291, 808, 498, 291, 352, 365,
  8213, 6562, 291, 458, 437, 820, 312, 51764], "temperature": 0.0, "avg_logprob":
  -0.24188362373100533, "compression_ratio": 1.6666666666666667, "no_speech_prob":
  0.003579241456463933}, {"id": 303, "seek": 172024, "start": 1720.24, "end": 1728.88,
  "text": " the alpha for your data yeah it''s fun yeah this is what''s certain like
  the search community has", "tokens": [50364, 264, 8961, 337, 428, 1412, 1338, 309,
  311, 1019, 1338, 341, 307, 437, 311, 1629, 411, 264, 3164, 1768, 575, 50796], "temperature":
  0.0, "avg_logprob": -0.14784541220035194, "compression_ratio": 1.9173553719008265,
  "no_speech_prob": 0.0009606542298570275}, {"id": 304, "seek": 172024, "start": 1728.88,
  "end": 1733.68, "text": " been doing things like this for a long time like search
  people are quite familiar with this idea of", "tokens": [50796, 668, 884, 721, 411,
  341, 337, 257, 938, 565, 411, 3164, 561, 366, 1596, 4963, 365, 341, 1558, 295, 51036],
  "temperature": 0.0, "avg_logprob": -0.14784541220035194, "compression_ratio": 1.9173553719008265,
  "no_speech_prob": 0.0009606542298570275}, {"id": 305, "seek": 172024, "start": 1734.4,
  "end": 1738.72, "text": " I have a semantic search system I have a keyword ranking
  system I have an alpha", "tokens": [51072, 286, 362, 257, 47982, 3164, 1185, 286,
  362, 257, 20428, 17833, 1185, 286, 362, 364, 8961, 51288], "temperature": 0.0, "avg_logprob":
  -0.14784541220035194, "compression_ratio": 1.9173553719008265, "no_speech_prob":
  0.0009606542298570275}, {"id": 306, "seek": 172024, "start": 1739.36, "end": 1743.6,
  "text": " and I''ve learned I learned that alpha and I inject it into my system
  and then they''ve even", "tokens": [51320, 293, 286, 600, 3264, 286, 3264, 300,
  8961, 293, 286, 10711, 309, 666, 452, 1185, 293, 550, 436, 600, 754, 51532], "temperature":
  0.0, "avg_logprob": -0.14784541220035194, "compression_ratio": 1.9173553719008265,
  "no_speech_prob": 0.0009606542298570275}, {"id": 307, "seek": 172024, "start": 1743.6,
  "end": 1747.2, "text": " gone farther like search has this whole like wand idea
  people I don''t know if people are familiar", "tokens": [51532, 2780, 20344, 411,
  3164, 575, 341, 1379, 411, 14304, 1558, 561, 286, 500, 380, 458, 498, 561, 366,
  4963, 51712], "temperature": 0.0, "avg_logprob": -0.14784541220035194, "compression_ratio":
  1.9173553719008265, "no_speech_prob": 0.0009606542298570275}, {"id": 308, "seek":
  174720, "start": 1747.2, "end": 1753.04, "text": " so again we have to have all
  these community like weekend weekend exactly right joe bersham listening to", "tokens":
  [50364, 370, 797, 321, 362, 281, 362, 439, 613, 1768, 411, 6711, 6711, 2293, 558,
  1488, 68, 272, 433, 4822, 4764, 281, 50656], "temperature": 0.0, "avg_logprob":
  -0.194007044253142, "compression_ratio": 1.9094488188976377, "no_speech_prob": 0.005349722225219011},
  {"id": 309, "seek": 174720, "start": 1753.04, "end": 1757.92, "text": " this podcast
  will probably say yeah I know what you''re talking about yeah yeah yeah so it''s
  funny", "tokens": [50656, 341, 7367, 486, 1391, 584, 1338, 286, 458, 437, 291, 434,
  1417, 466, 1338, 1338, 1338, 370, 309, 311, 4074, 50900], "temperature": 0.0, "avg_logprob":
  -0.194007044253142, "compression_ratio": 1.9094488188976377, "no_speech_prob": 0.005349722225219011},
  {"id": 310, "seek": 174720, "start": 1757.92, "end": 1763.8400000000001, "text":
  " because like the vector community is sort of like I mean it''s not it''s not rehashing
  it''s not", "tokens": [50900, 570, 411, 264, 8062, 1768, 307, 1333, 295, 411, 286,
  914, 309, 311, 406, 309, 311, 406, 22355, 11077, 309, 311, 406, 51196], "temperature":
  0.0, "avg_logprob": -0.194007044253142, "compression_ratio": 1.9094488188976377,
  "no_speech_prob": 0.005349722225219011}, {"id": 311, "seek": 174720, "start": 1763.8400000000001,
  "end": 1767.76, "text": " relearning because it''s got this new thing this a and
  n things what''s got to like drag a and", "tokens": [51196, 2951, 2341, 570, 309,
  311, 658, 341, 777, 551, 341, 257, 293, 297, 721, 437, 311, 658, 281, 411, 5286,
  257, 293, 51392], "temperature": 0.0, "avg_logprob": -0.194007044253142, "compression_ratio":
  1.9094488188976377, "no_speech_prob": 0.005349722225219011}, {"id": 312, "seek":
  174720, "start": 1767.76, "end": 1773.2, "text": " through the search history of
  like things these other kinds of things so yes so so learning the", "tokens": [51392,
  807, 264, 3164, 2503, 295, 411, 721, 613, 661, 3685, 295, 721, 370, 2086, 370, 370,
  2539, 264, 51664], "temperature": 0.0, "avg_logprob": -0.194007044253142, "compression_ratio":
  1.9094488188976377, "no_speech_prob": 0.005349722225219011}, {"id": 313, "seek":
  177320, "start": 1773.2, "end": 1779.92, "text": " ant parameter um this is not
  a particularly hard thing to do using rock set but it''s not a thing we", "tokens":
  [50364, 2511, 13075, 1105, 341, 307, 406, 257, 4098, 1152, 551, 281, 360, 1228,
  3727, 992, 457, 309, 311, 406, 257, 551, 321, 50700], "temperature": 0.0, "avg_logprob":
  -0.14020461710090312, "compression_ratio": 2.0041152263374484, "no_speech_prob":
  0.002518066205084324}, {"id": 314, "seek": 177320, "start": 1780.56, "end": 1786.8,
  "text": " we don''t we don''t help you like I don''t have a button you push to to
  automatically learn your", "tokens": [50732, 321, 500, 380, 321, 500, 380, 854,
  291, 411, 286, 500, 380, 362, 257, 2960, 291, 2944, 281, 281, 6772, 1466, 428, 51044],
  "temperature": 0.0, "avg_logprob": -0.14020461710090312, "compression_ratio": 2.0041152263374484,
  "no_speech_prob": 0.002518066205084324}, {"id": 315, "seek": 177320, "start": 1786.8,
  "end": 1791.1200000000001, "text": " your alpha like you can send me whatever query
  you want it can have whatever alpha in it you want", "tokens": [51044, 428, 8961,
  411, 291, 393, 2845, 385, 2035, 14581, 291, 528, 309, 393, 362, 2035, 8961, 294,
  309, 291, 528, 51260], "temperature": 0.0, "avg_logprob": -0.14020461710090312,
  "compression_ratio": 2.0041152263374484, "no_speech_prob": 0.002518066205084324},
  {"id": 316, "seek": 177320, "start": 1791.1200000000001, "end": 1796.32, "text":
  " you can build whatever system you can query us arbitrarily to generate an alpha
  however you''d like", "tokens": [51260, 291, 393, 1322, 2035, 1185, 291, 393, 14581,
  505, 19071, 3289, 281, 8460, 364, 8961, 4461, 291, 1116, 411, 51520], "temperature":
  0.0, "avg_logprob": -0.14020461710090312, "compression_ratio": 2.0041152263374484,
  "no_speech_prob": 0.002518066205084324}, {"id": 317, "seek": 177320, "start": 1796.32,
  "end": 1800.56, "text": " and and then send me the queries with the alpha you you
  you you you dreaded and ready but that''s", "tokens": [51520, 293, 293, 550, 2845,
  385, 264, 24109, 365, 264, 8961, 291, 291, 291, 291, 291, 22236, 292, 293, 1919,
  457, 300, 311, 51732], "temperature": 0.0, "avg_logprob": -0.14020461710090312,
  "compression_ratio": 2.0041152263374484, "no_speech_prob": 0.002518066205084324},
  {"id": 318, "seek": 180056, "start": 1800.56, "end": 1805.44, "text": " that''s
  roughly how that''s going to look today for us yeah do you think at all maybe picking
  a", "tokens": [50364, 300, 311, 9810, 577, 300, 311, 516, 281, 574, 965, 337, 505,
  1338, 360, 291, 519, 412, 439, 1310, 8867, 257, 50608], "temperature": 0.0, "avg_logprob":
  -0.15571122030610018, "compression_ratio": 1.836, "no_speech_prob": 0.002275618491694331},
  {"id": 319, "seek": 180056, "start": 1805.44, "end": 1811.52, "text": " little bit
  into the future and sort of inspiration do you think at all that the industry you
  iin", "tokens": [50608, 707, 857, 666, 264, 2027, 293, 1333, 295, 10249, 360, 291,
  519, 412, 439, 300, 264, 3518, 291, 741, 259, 50912], "temperature": 0.0, "avg_logprob":
  -0.15571122030610018, "compression_ratio": 1.836, "no_speech_prob": 0.002275618491694331},
  {"id": 320, "seek": 180056, "start": 1812.1599999999999, "end": 1817.44, "text":
  " one day will end up suggesting these values to their users you know learning from
  the data and", "tokens": [50944, 472, 786, 486, 917, 493, 18094, 613, 4190, 281,
  641, 5022, 291, 458, 2539, 490, 264, 1412, 293, 51208], "temperature": 0.0, "avg_logprob":
  -0.15571122030610018, "compression_ratio": 1.836, "no_speech_prob": 0.002275618491694331},
  {"id": 321, "seek": 180056, "start": 1817.44, "end": 1822.24, "text": " sort of
  maybe even like you know looking at how things behave you know introduction", "tokens":
  [51208, 1333, 295, 1310, 754, 411, 291, 458, 1237, 412, 577, 721, 15158, 291, 458,
  9339, 51448], "temperature": 0.0, "avg_logprob": -0.15571122030610018, "compression_ratio":
  1.836, "no_speech_prob": 0.002275618491694331}, {"id": 322, "seek": 180056, "start":
  1822.72, "end": 1827.6799999999998, "text": " what do people click although yeah
  there is a risk of going too much into the application", "tokens": [51472, 437,
  360, 561, 2052, 4878, 1338, 456, 307, 257, 3148, 295, 516, 886, 709, 666, 264, 3861,
  51720], "temperature": 0.0, "avg_logprob": -0.15571122030610018, "compression_ratio":
  1.836, "no_speech_prob": 0.002275618491694331}, {"id": 323, "seek": 182768, "start":
  1828.24, "end": 1835.76, "text": " logic which you probably do not want to do but
  I know I my view is kind of like", "tokens": [50392, 9952, 597, 291, 1391, 360,
  406, 528, 281, 360, 457, 286, 458, 286, 452, 1910, 307, 733, 295, 411, 50768], "temperature":
  0.0, "avg_logprob": -0.10111207740251409, "compression_ratio": 1.7788461538461537,
  "no_speech_prob": 0.0014382046647369862}, {"id": 324, "seek": 182768, "start": 1836.5600000000002,
  "end": 1842.16, "text": " so once upon a time I had a similar feeling this reminds
  me of a similar discussion that didn''t", "tokens": [50808, 370, 1564, 3564, 257,
  565, 286, 632, 257, 2531, 2633, 341, 12025, 385, 295, 257, 2531, 5017, 300, 994,
  380, 51088], "temperature": 0.0, "avg_logprob": -0.10111207740251409, "compression_ratio":
  1.7788461538461537, "no_speech_prob": 0.0014382046647369862}, {"id": 325, "seek":
  182768, "start": 1842.16, "end": 1848.0800000000002, "text": " happen that long
  ago which was like around feature stores like database people looked at feature",
  "tokens": [51088, 1051, 300, 938, 2057, 597, 390, 411, 926, 4111, 9512, 411, 8149,
  561, 2956, 412, 4111, 51384], "temperature": 0.0, "avg_logprob": -0.10111207740251409,
  "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.0014382046647369862},
  {"id": 326, "seek": 182768, "start": 1848.0800000000002, "end": 1852.16, "text":
  " stores and we''re like what do you need a feature store for like you just use
  a database store for", "tokens": [51384, 9512, 293, 321, 434, 411, 437, 360, 291,
  643, 257, 4111, 3531, 337, 411, 291, 445, 764, 257, 8149, 3531, 337, 51588], "temperature":
  0.0, "avg_logprob": -0.10111207740251409, "compression_ratio": 1.7788461538461537,
  "no_speech_prob": 0.0014382046647369862}, {"id": 327, "seek": 185216, "start": 1852.16,
  "end": 1858.64, "text": " features and the reality is most feature stores that''s
  what they are they are databases that on top", "tokens": [50364, 4122, 293, 264,
  4103, 307, 881, 4111, 9512, 300, 311, 437, 436, 366, 436, 366, 22380, 300, 322,
  1192, 50688], "temperature": 0.0, "avg_logprob": -0.22868998297329607, "compression_ratio":
  1.9367588932806323, "no_speech_prob": 0.0004790632228832692}, {"id": 328, "seek":
  185216, "start": 1858.64, "end": 1862.8000000000002, "text": " of them put a lot
  of things to help manage as a first class citizen the lifetime of a feature", "tokens":
  [50688, 295, 552, 829, 257, 688, 295, 721, 281, 854, 3067, 382, 257, 700, 1508,
  13326, 264, 11364, 295, 257, 4111, 50896], "temperature": 0.0, "avg_logprob": -0.22868998297329607,
  "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0004790632228832692},
  {"id": 329, "seek": 185216, "start": 1864.16, "end": 1869.76, "text": " like orchestration
  platforms like like techton and he''s like orc orc orcust and that orchestration
  systems", "tokens": [50964, 411, 14161, 2405, 9473, 411, 411, 7553, 1756, 293, 415,
  311, 411, 420, 66, 420, 66, 420, 66, 381, 293, 300, 14161, 2405, 3652, 51244], "temperature":
  0.0, "avg_logprob": -0.22868998297329607, "compression_ratio": 1.9367588932806323,
  "no_speech_prob": 0.0004790632228832692}, {"id": 330, "seek": 185216, "start": 1869.76,
  "end": 1875.3600000000001, "text": " that''s that''s what you''re I think it no
  matter what there''ll always be a database in there", "tokens": [51244, 300, 311,
  300, 311, 437, 291, 434, 286, 519, 309, 572, 1871, 437, 456, 603, 1009, 312, 257,
  8149, 294, 456, 51524], "temperature": 0.0, "avg_logprob": -0.22868998297329607,
  "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0004790632228832692},
  {"id": 331, "seek": 185216, "start": 1875.3600000000001, "end": 1879.28, "text":
  " and something like rockset will be in there and the question of whether or not
  rockset the company", "tokens": [51524, 293, 746, 411, 10989, 302, 486, 312, 294,
  456, 293, 264, 1168, 295, 1968, 420, 406, 10989, 302, 264, 2237, 51720], "temperature":
  0.0, "avg_logprob": -0.22868998297329607, "compression_ratio": 1.9367588932806323,
  "no_speech_prob": 0.0004790632228832692}, {"id": 332, "seek": 187928, "start": 1879.36,
  "end": 1883.68, "text": " is like a larger piece of software that has rockset the
  database and some orchestration layers", "tokens": [50368, 307, 411, 257, 4833,
  2522, 295, 4722, 300, 575, 10989, 302, 264, 8149, 293, 512, 14161, 2405, 7914, 50584],
  "temperature": 0.0, "avg_logprob": -0.0850755724796029, "compression_ratio": 1.6919642857142858,
  "no_speech_prob": 0.0013353492831811309}, {"id": 333, "seek": 187928, "start": 1883.68,
  "end": 1887.84, "text": " above it to help you do these kinds of things that''s
  a harder question I think that", "tokens": [50584, 3673, 309, 281, 854, 291, 360,
  613, 3685, 295, 721, 300, 311, 257, 6081, 1168, 286, 519, 300, 50792], "temperature":
  0.0, "avg_logprob": -0.0850755724796029, "compression_ratio": 1.6919642857142858,
  "no_speech_prob": 0.0013353492831811309}, {"id": 334, "seek": 187928, "start": 1888.72,
  "end": 1894.08, "text": " if you ask me to make a prediction about where things
  are going my guess is that for the foreseeable", "tokens": [50836, 498, 291, 1029,
  385, 281, 652, 257, 17630, 466, 689, 721, 366, 516, 452, 2041, 307, 300, 337, 264,
  38736, 712, 51104], "temperature": 0.0, "avg_logprob": -0.0850755724796029, "compression_ratio":
  1.6919642857142858, "no_speech_prob": 0.0013353492831811309}, {"id": 335, "seek":
  187928, "start": 1894.08, "end": 1902.56, "text": " future hybrid searches king
  of some kind so very few problems will be purely vector search I that''s", "tokens":
  [51104, 2027, 13051, 26701, 4867, 295, 512, 733, 370, 588, 1326, 2740, 486, 312,
  17491, 8062, 3164, 286, 300, 311, 51528], "temperature": 0.0, "avg_logprob": -0.0850755724796029,
  "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.0013353492831811309},
  {"id": 336, "seek": 190256, "start": 1902.56, "end": 1909.76, "text": " my guess
  almost all will be will we greatly benefited by some form of hybridization even
  if it''s", "tokens": [50364, 452, 2041, 1920, 439, 486, 312, 486, 321, 14147, 33605,
  538, 512, 1254, 295, 13051, 2144, 754, 498, 309, 311, 50724], "temperature": 0.0,
  "avg_logprob": -0.11390698674213455, "compression_ratio": 1.668103448275862, "no_speech_prob":
  0.00033994796103797853}, {"id": 337, "seek": 190256, "start": 1909.76, "end": 1918.3999999999999,
  "text": " just metadata filtering um and then that means that the more advanced
  search techniques that will", "tokens": [50724, 445, 26603, 30822, 1105, 293, 550,
  300, 1355, 300, 264, 544, 7339, 3164, 7512, 300, 486, 51156], "temperature": 0.0,
  "avg_logprob": -0.11390698674213455, "compression_ratio": 1.668103448275862, "no_speech_prob":
  0.00033994796103797853}, {"id": 338, "seek": 190256, "start": 1918.3999999999999,
  "end": 1923.2, "text": " slowly migrate over which means things like alpha learning
  and weak and and all these other kinds", "tokens": [51156, 5692, 31821, 670, 597,
  1355, 721, 411, 8961, 2539, 293, 5336, 293, 293, 439, 613, 661, 3685, 51396], "temperature":
  0.0, "avg_logprob": -0.11390698674213455, "compression_ratio": 1.668103448275862,
  "no_speech_prob": 0.00033994796103797853}, {"id": 339, "seek": 190256, "start":
  1923.2, "end": 1929.6, "text": " of higher level two-stage retrieval type ideas
  that that come from the search world I do think", "tokens": [51396, 295, 2946, 1496,
  732, 12, 17882, 19817, 3337, 2010, 3487, 300, 300, 808, 490, 264, 3164, 1002, 286,
  360, 519, 51716], "temperature": 0.0, "avg_logprob": -0.11390698674213455, "compression_ratio":
  1.668103448275862, "no_speech_prob": 0.00033994796103797853}, {"id": 340, "seek":
  192960, "start": 1929.6, "end": 1935.04, "text": " will come over and more and more
  influence the vector search world because the vector search", "tokens": [50364,
  486, 808, 670, 293, 544, 293, 544, 6503, 264, 8062, 3164, 1002, 570, 264, 8062,
  3164, 50636], "temperature": 0.0, "avg_logprob": -0.1513976331027049, "compression_ratio":
  1.687719298245614, "no_speech_prob": 0.004446651786565781}, {"id": 341, "seek":
  192960, "start": 1935.04, "end": 1939.76, "text": " ultimately is a form of search
  so it shouldn''t be surprising that most of these same ideas are still", "tokens":
  [50636, 6284, 307, 257, 1254, 295, 3164, 370, 309, 4659, 380, 312, 8830, 300, 881,
  295, 613, 912, 3487, 366, 920, 50872], "temperature": 0.0, "avg_logprob": -0.1513976331027049,
  "compression_ratio": 1.687719298245614, "no_speech_prob": 0.004446651786565781},
  {"id": 342, "seek": 192960, "start": 1939.76, "end": 1946.7199999999998, "text":
  " still apply yeah for sure I mean there is this extreme example from Mark Cuban
  the episode on", "tokens": [50872, 920, 3079, 1338, 337, 988, 286, 914, 456, 307,
  341, 8084, 1365, 490, 3934, 31547, 264, 3500, 322, 51220], "temperature": 0.0, "avg_logprob":
  -0.1513976331027049, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.004446651786565781},
  {"id": 343, "seek": 192960, "start": 1946.7199999999998, "end": 1953.04, "text":
  " Lex Friedman podcast that they just finished listening to he says that probably
  in the future all", "tokens": [51220, 24086, 17605, 1601, 7367, 300, 436, 445, 4335,
  4764, 281, 415, 1619, 300, 1391, 294, 264, 2027, 439, 51536], "temperature": 0.0,
  "avg_logprob": -0.1513976331027049, "compression_ratio": 1.687719298245614, "no_speech_prob":
  0.004446651786565781}, {"id": 344, "seek": 192960, "start": 1953.04, "end": 1958.7199999999998,
  "text": " of us will have their own LLAMs trained for whatever reason you know for
  example you want to do", "tokens": [51536, 295, 505, 486, 362, 641, 1065, 441, 43,
  2865, 82, 8895, 337, 2035, 1778, 291, 458, 337, 1365, 291, 528, 281, 360, 51820],
  "temperature": 0.0, "avg_logprob": -0.1513976331027049, "compression_ratio": 1.687719298245614,
  "no_speech_prob": 0.004446651786565781}, {"id": 345, "seek": 195872, "start": 1958.72,
  "end": 1964.56, "text": " stock trading and so you start you know draining your
  model maybe on specific subset of stocks or", "tokens": [50364, 4127, 9529, 293,
  370, 291, 722, 291, 458, 42916, 428, 2316, 1310, 322, 2685, 25993, 295, 12966, 420,
  50656], "temperature": 0.0, "avg_logprob": -0.14325469605466154, "compression_ratio":
  1.7863636363636364, "no_speech_prob": 0.010126732289791107}, {"id": 346, "seek":
  195872, "start": 1964.56, "end": 1972.16, "text": " whatever and then it will help
  you it will augment augment you as they say yeah as an entity yeah I", "tokens":
  [50656, 2035, 293, 550, 309, 486, 854, 291, 309, 486, 29919, 29919, 291, 382, 436,
  584, 1338, 382, 364, 13977, 1338, 286, 51036], "temperature": 0.0, "avg_logprob":
  -0.14325469605466154, "compression_ratio": 1.7863636363636364, "no_speech_prob":
  0.010126732289791107}, {"id": 347, "seek": 195872, "start": 1972.16, "end": 1978.72,
  "text": " would love I would love for a chat GPT that could like put in making an
  email sketch me a skeleton", "tokens": [51036, 576, 959, 286, 576, 959, 337, 257,
  5081, 26039, 51, 300, 727, 411, 829, 294, 1455, 364, 3796, 12325, 385, 257, 25204,
  51364], "temperature": 0.0, "avg_logprob": -0.14325469605466154, "compression_ratio":
  1.7863636363636364, "no_speech_prob": 0.010126732289791107}, {"id": 348, "seek":
  195872, "start": 1978.72, "end": 1983.84, "text": " email in my voice like the chat
  GPT voice if I say hey write me an email to say this to somebody", "tokens": [51364,
  3796, 294, 452, 3177, 411, 264, 5081, 26039, 51, 3177, 498, 286, 584, 4177, 2464,
  385, 364, 3796, 281, 584, 341, 281, 2618, 51620], "temperature": 0.0, "avg_logprob":
  -0.14325469605466154, "compression_ratio": 1.7863636363636364, "no_speech_prob":
  0.010126732289791107}, {"id": 349, "seek": 198384, "start": 1983.84, "end": 1988.1599999999999,
  "text": " it''s not my voice right it''s a I don''t know it''s a little too corporate
  my voice is a little bit more", "tokens": [50364, 309, 311, 406, 452, 3177, 558,
  309, 311, 257, 286, 500, 380, 458, 309, 311, 257, 707, 886, 10896, 452, 3177, 307,
  257, 707, 857, 544, 50580], "temperature": 0.0, "avg_logprob": -0.13255721803695436,
  "compression_ratio": 1.996031746031746, "no_speech_prob": 0.01226211991161108},
  {"id": 350, "seek": 198384, "start": 1988.1599999999999, "end": 1994.48, "text":
  " yeah so it''d be cool to have it like learn my voice and be able to you know write
  me a skeleton that", "tokens": [50580, 1338, 370, 309, 1116, 312, 1627, 281, 362,
  309, 411, 1466, 452, 3177, 293, 312, 1075, 281, 291, 458, 2464, 385, 257, 25204,
  300, 50896], "temperature": 0.0, "avg_logprob": -0.13255721803695436, "compression_ratio":
  1.996031746031746, "no_speech_prob": 0.01226211991161108}, {"id": 351, "seek": 198384,
  "start": 1994.48, "end": 1999.52, "text": " of something that was like sounded like
  me that would be that would be awesome I''ll be I''m there for", "tokens": [50896,
  295, 746, 300, 390, 411, 17714, 411, 385, 300, 576, 312, 300, 576, 312, 3476, 286,
  603, 312, 286, 478, 456, 337, 51148], "temperature": 0.0, "avg_logprob": -0.13255721803695436,
  "compression_ratio": 1.996031746031746, "no_speech_prob": 0.01226211991161108},
  {"id": 352, "seek": 198384, "start": 1999.52, "end": 2005.9199999999998, "text":
  " that yeah what I would like that some model or whatever it is would remind me
  that I forgot to drink", "tokens": [51148, 300, 1338, 437, 286, 576, 411, 300, 512,
  2316, 420, 2035, 309, 307, 576, 4160, 385, 300, 286, 5298, 281, 2822, 51468], "temperature":
  0.0, "avg_logprob": -0.13255721803695436, "compression_ratio": 1.996031746031746,
  "no_speech_prob": 0.01226211991161108}, {"id": 353, "seek": 198384, "start": 2005.9199999999998,
  "end": 2010.3999999999999, "text": " water you know something like that so it learns
  my habits and it knows that it''s bad for my health", "tokens": [51468, 1281, 291,
  458, 746, 411, 300, 370, 309, 27152, 452, 14100, 293, 309, 3255, 300, 309, 311,
  1578, 337, 452, 1585, 51692], "temperature": 0.0, "avg_logprob": -0.13255721803695436,
  "compression_ratio": 1.996031746031746, "no_speech_prob": 0.01226211991161108},
  {"id": 354, "seek": 201040, "start": 2010.96, "end": 2015.52, "text": " you know
  remember to do these remember to stand out remember to walk things like this you
  know", "tokens": [50392, 291, 458, 1604, 281, 360, 613, 1604, 281, 1463, 484, 1604,
  281, 1792, 721, 411, 341, 291, 458, 50620], "temperature": 0.0, "avg_logprob": -0.20290459034054778,
  "compression_ratio": 1.8019323671497585, "no_speech_prob": 0.0164946336299181},
  {"id": 355, "seek": 201040, "start": 2016.88, "end": 2023.52, "text": " I drank
  some water that''s good everyone drinks water yes yeah please do because it''s very
  healthy", "tokens": [50688, 286, 21011, 512, 1281, 300, 311, 665, 1518, 12142, 1281,
  2086, 1338, 1767, 360, 570, 309, 311, 588, 4627, 51020], "temperature": 0.0, "avg_logprob":
  -0.20290459034054778, "compression_ratio": 1.8019323671497585, "no_speech_prob":
  0.0164946336299181}, {"id": 356, "seek": 201040, "start": 2023.52, "end": 2028.4,
  "text": " you need to drink I guess two liters a day whatever some people do forget
  this and then they say have", "tokens": [51020, 291, 643, 281, 2822, 286, 2041,
  732, 32323, 257, 786, 2035, 512, 561, 360, 2870, 341, 293, 550, 436, 584, 362, 51264],
  "temperature": 0.0, "avg_logprob": -0.20290459034054778, "compression_ratio": 1.8019323671497585,
  "no_speech_prob": 0.0164946336299181}, {"id": 357, "seek": 201040, "start": 2028.88,
  "end": 2033.0400000000002, "text": " you know I have to take pink here or so whatever
  no you don''t just drink water", "tokens": [51288, 291, 458, 286, 362, 281, 747,
  7022, 510, 420, 370, 2035, 572, 291, 500, 380, 445, 2822, 1281, 51496], "temperature":
  0.0, "avg_logprob": -0.20290459034054778, "compression_ratio": 1.8019323671497585,
  "no_speech_prob": 0.0164946336299181}, {"id": 358, "seek": 203304, "start": 2033.2,
  "end": 2043.12, "text": " but so what else do you want to share about Rockset you
  know as an offering as a AI", "tokens": [50372, 457, 370, 437, 1646, 360, 291, 528,
  281, 2073, 466, 6922, 3854, 291, 458, 382, 364, 8745, 382, 257, 7318, 50868], "temperature":
  0.0, "avg_logprob": -0.23303544180733818, "compression_ratio": 1.6790123456790123,
  "no_speech_prob": 0.00903274118900299}, {"id": 359, "seek": 203304, "start": 2044.08,
  "end": 2050.32, "text": " enabler you know maybe do you guys plan to support rag
  or do you think rag is sort of like", "tokens": [50916, 465, 455, 1918, 291, 458,
  1310, 360, 291, 1074, 1393, 281, 1406, 17539, 420, 360, 291, 519, 17539, 307, 1333,
  295, 411, 51228], "temperature": 0.0, "avg_logprob": -0.23303544180733818, "compression_ratio":
  1.6790123456790123, "no_speech_prob": 0.00903274118900299}, {"id": 360, "seek":
  203304, "start": 2050.32, "end": 2055.52, "text": " client side you know thing as
  well that people can do you know using your tap things like that no", "tokens":
  [51228, 6423, 1252, 291, 458, 551, 382, 731, 300, 561, 393, 360, 291, 458, 1228,
  428, 5119, 721, 411, 300, 572, 51488], "temperature": 0.0, "avg_logprob": -0.23303544180733818,
  "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.00903274118900299},
  {"id": 361, "seek": 205552, "start": 2056.16, "end": 2062.56, "text": " no we we
  um we actually have a bunch of rag type style use cases on Rockset today and I do",
  "tokens": [50396, 572, 321, 321, 1105, 321, 767, 362, 257, 3840, 295, 17539, 2010,
  3758, 764, 3331, 322, 6922, 3854, 965, 293, 286, 360, 50716], "temperature": 0.0,
  "avg_logprob": -0.13970440312435753, "compression_ratio": 1.7522522522522523, "no_speech_prob":
  0.000697075854986906}, {"id": 362, "seek": 205552, "start": 2062.56, "end": 2068.0,
  "text": " I do think Rockset naturally supports rag but it''s interesting so like
  I guess one of the my kind", "tokens": [50716, 286, 360, 519, 6922, 3854, 8195,
  9346, 17539, 457, 309, 311, 1880, 370, 411, 286, 2041, 472, 295, 264, 452, 733,
  50988], "temperature": 0.0, "avg_logprob": -0.13970440312435753, "compression_ratio":
  1.7522522522522523, "no_speech_prob": 0.000697075854986906}, {"id": 363, "seek":
  205552, "start": 2068.0, "end": 2074.72, "text": " of open questions is pure rag
  and I''m making up a term here but but but it is actually one of the very", "tokens":
  [50988, 295, 1269, 1651, 307, 6075, 17539, 293, 286, 478, 1455, 493, 257, 1433,
  510, 457, 457, 457, 309, 307, 767, 472, 295, 264, 588, 51324], "temperature": 0.0,
  "avg_logprob": -0.13970440312435753, "compression_ratio": 1.7522522522522523, "no_speech_prob":
  0.000697075854986906}, {"id": 364, "seek": 205552, "start": 2074.72, "end": 2081.28,
  "text": " few like almost perfect vector use cases in its pure vector search but
  I''m actually not convinced", "tokens": [51324, 1326, 411, 1920, 2176, 8062, 764,
  3331, 294, 1080, 6075, 8062, 3164, 457, 286, 478, 767, 406, 12561, 51652], "temperature":
  0.0, "avg_logprob": -0.13970440312435753, "compression_ratio": 1.7522522522522523,
  "no_speech_prob": 0.000697075854986906}, {"id": 365, "seek": 208128, "start": 2081.36,
  "end": 2087.28, "text": " because even most of the people that we''re we know that
  are doing like rag style things want", "tokens": [50368, 570, 754, 881, 295, 264,
  561, 300, 321, 434, 321, 458, 300, 366, 884, 411, 17539, 3758, 721, 528, 50664],
  "temperature": 0.0, "avg_logprob": -0.09950314946921475, "compression_ratio": 1.7971698113207548,
  "no_speech_prob": 0.0014873042237013578}, {"id": 366, "seek": 208128, "start": 2087.84,
  "end": 2094.2400000000002, "text": " are also doing some amount of boosting and
  or metadata filtering to like further augment like", "tokens": [50692, 366, 611,
  884, 512, 2372, 295, 43117, 293, 420, 26603, 30822, 281, 411, 3052, 29919, 411,
  51012], "temperature": 0.0, "avg_logprob": -0.09950314946921475, "compression_ratio":
  1.7971698113207548, "no_speech_prob": 0.0014873042237013578}, {"id": 367, "seek":
  208128, "start": 2094.2400000000002, "end": 2101.6800000000003, "text": " hybrid
  augmented the retrieval that augments the generation um uh and so so for example
  like hey", "tokens": [51012, 13051, 36155, 264, 19817, 3337, 300, 14501, 1117, 264,
  5125, 1105, 2232, 293, 370, 370, 337, 1365, 411, 4177, 51384], "temperature": 0.0,
  "avg_logprob": -0.09950314946921475, "compression_ratio": 1.7971698113207548, "no_speech_prob":
  0.0014873042237013578}, {"id": 368, "seek": 208128, "start": 2101.6800000000003,
  "end": 2108.2400000000002, "text": " if the user asks about a certain thing when
  you search for blurbs to augment the generation boost", "tokens": [51384, 498, 264,
  4195, 8962, 466, 257, 1629, 551, 562, 291, 3164, 337, 14257, 929, 281, 29919, 264,
  5125, 9194, 51712], "temperature": 0.0, "avg_logprob": -0.09950314946921475, "compression_ratio":
  1.7971698113207548, "no_speech_prob": 0.0014873042237013578}, {"id": 369, "seek":
  210824, "start": 2108.24, "end": 2112.4799999999996, "text": " the more recent ones
  kind of a kind of a thing like there''s this kind of thing that gets injected",
  "tokens": [50364, 264, 544, 5162, 2306, 733, 295, 257, 733, 295, 257, 551, 411,
  456, 311, 341, 733, 295, 551, 300, 2170, 36967, 50576], "temperature": 0.0, "avg_logprob":
  -0.056673914194107056, "compression_ratio": 1.7853881278538812, "no_speech_prob":
  0.00019456676091067493}, {"id": 370, "seek": 210824, "start": 2112.4799999999996,
  "end": 2120.3999999999996, "text": " into these systems um yeah so I''m I''m we
  you can build this with Rockset today and I''m quite keen", "tokens": [50576, 666,
  613, 3652, 1105, 1338, 370, 286, 478, 286, 478, 321, 291, 393, 1322, 341, 365, 6922,
  3854, 965, 293, 286, 478, 1596, 20297, 50972], "temperature": 0.0, "avg_logprob":
  -0.056673914194107056, "compression_ratio": 1.7853881278538812, "no_speech_prob":
  0.00019456676091067493}, {"id": 371, "seek": 210824, "start": 2120.3999999999996,
  "end": 2126.9599999999996, "text": " on on these kinds of use cases I would say
  that like like looking forward I''m I am quite interested", "tokens": [50972, 322,
  322, 613, 3685, 295, 764, 3331, 286, 576, 584, 300, 411, 411, 1237, 2128, 286, 478,
  286, 669, 1596, 3102, 51300], "temperature": 0.0, "avg_logprob": -0.056673914194107056,
  "compression_ratio": 1.7853881278538812, "no_speech_prob": 0.00019456676091067493},
  {"id": 372, "seek": 210824, "start": 2126.9599999999996, "end": 2134.08, "text":
  " in this kind of emerging dynamic of like where the real value is from here they''re
  sort of like", "tokens": [51300, 294, 341, 733, 295, 14989, 8546, 295, 411, 689,
  264, 957, 2158, 307, 490, 510, 436, 434, 1333, 295, 411, 51656], "temperature":
  0.0, "avg_logprob": -0.056673914194107056, "compression_ratio": 1.7853881278538812,
  "no_speech_prob": 0.00019456676091067493}, {"id": 373, "seek": 213408, "start":
  2134.08, "end": 2140.72, "text": " at least three dimensions things could go one
  is like better and better an an algorithms that", "tokens": [50364, 412, 1935, 1045,
  12819, 721, 727, 352, 472, 307, 411, 1101, 293, 1101, 364, 364, 14642, 300, 50696],
  "temperature": 0.0, "avg_logprob": -0.13713808946831282, "compression_ratio": 1.8037383177570094,
  "no_speech_prob": 0.00011774120503105223}, {"id": 374, "seek": 213408, "start":
  2140.72, "end": 2148.3199999999997, "text": " squeeze more performance and more
  scale and more whatever recall out of out of everything out of", "tokens": [50696,
  13578, 544, 3389, 293, 544, 4373, 293, 544, 2035, 9901, 484, 295, 484, 295, 1203,
  484, 295, 51076], "temperature": 0.0, "avg_logprob": -0.13713808946831282, "compression_ratio":
  1.8037383177570094, "no_speech_prob": 0.00011774120503105223}, {"id": 375, "seek":
  213408, "start": 2148.3199999999997, "end": 2153.84, "text": " every bite of RAM
  and so forth and so on another direction is incrementability so a lot of these",
  "tokens": [51076, 633, 7988, 295, 14561, 293, 370, 5220, 293, 370, 322, 1071, 3513,
  307, 26200, 2310, 370, 257, 688, 295, 613, 51352], "temperature": 0.0, "avg_logprob":
  -0.13713808946831282, "compression_ratio": 1.8037383177570094, "no_speech_prob":
  0.00011774120503105223}, {"id": 376, "seek": 213408, "start": 2153.84, "end": 2160.0,
  "text": " there''s a lot of a lot of these like really advanced really strong systems
  sorry a n n indexes are", "tokens": [51352, 456, 311, 257, 688, 295, 257, 688, 295,
  613, 411, 534, 7339, 534, 2068, 3652, 2597, 257, 297, 297, 8186, 279, 366, 51660],
  "temperature": 0.0, "avg_logprob": -0.13713808946831282, "compression_ratio": 1.8037383177570094,
  "no_speech_prob": 0.00011774120503105223}, {"id": 377, "seek": 216000, "start":
  2160.0, "end": 2166.96, "text": " not updateable easily so the sort of updateability
  destroys a lot of what you just worked really hard", "tokens": [50364, 406, 5623,
  712, 3612, 370, 264, 1333, 295, 5623, 2310, 36714, 257, 688, 295, 437, 291, 445,
  2732, 534, 1152, 50712], "temperature": 0.0, "avg_logprob": -0.10931411411451257,
  "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.0004392066621221602},
  {"id": 378, "seek": 216000, "start": 2166.96, "end": 2172.72, "text": " to build
  or you spend way too much CPU to do it so which is better like which which in on
  in real", "tokens": [50712, 281, 1322, 420, 291, 3496, 636, 886, 709, 13199, 281,
  360, 309, 370, 597, 307, 1101, 411, 597, 597, 294, 322, 294, 957, 51000], "temperature":
  0.0, "avg_logprob": -0.10931411411451257, "compression_ratio": 1.8021978021978022,
  "no_speech_prob": 0.0004392066621221602}, {"id": 379, "seek": 216000, "start": 2172.72,
  "end": 2177.84, "text": " life which are the what I rather update twice as fast
  or twice as painlessly or what I rather get", "tokens": [51000, 993, 597, 366, 264,
  437, 286, 2831, 5623, 6091, 382, 2370, 420, 6091, 382, 1822, 12048, 420, 437, 286,
  2831, 483, 51256], "temperature": 0.0, "avg_logprob": -0.10931411411451257, "compression_ratio":
  1.8021978021978022, "no_speech_prob": 0.0004392066621221602}, {"id": 380, "seek":
  216000, "start": 2177.84, "end": 2182.32, "text": " three and a half percent more
  you know on my precision recall and then the third dimension is how", "tokens":
  [51256, 1045, 293, 257, 1922, 3043, 544, 291, 458, 322, 452, 18356, 9901, 293, 550,
  264, 2636, 10139, 307, 577, 51480], "temperature": 0.0, "avg_logprob": -0.10931411411451257,
  "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.0004392066621221602},
  {"id": 381, "seek": 216000, "start": 2182.32, "end": 2188.4, "text": " do these
  things integrate with other indexes right so certain a and n indexes are much better
  at", "tokens": [51480, 360, 613, 721, 13365, 365, 661, 8186, 279, 558, 370, 1629,
  257, 293, 297, 8186, 279, 366, 709, 1101, 412, 51784], "temperature": 0.0, "avg_logprob":
  -0.10931411411451257, "compression_ratio": 1.8021978021978022, "no_speech_prob":
  0.0004392066621221602}, {"id": 382, "seek": 218840, "start": 2188.4, "end": 2193.92,
  "text": " doing meditative filter at scale than other ones are and so you know if
  there''s more value in that", "tokens": [50364, 884, 1205, 14275, 6608, 412, 4373,
  813, 661, 2306, 366, 293, 370, 291, 458, 498, 456, 311, 544, 2158, 294, 300, 50640],
  "temperature": 0.0, "avg_logprob": -0.13066453519074814, "compression_ratio": 1.866412213740458,
  "no_speech_prob": 0.00030513416277244687}, {"id": 383, "seek": 218840, "start":
  2193.92, "end": 2200.2400000000002, "text": " than the 3% I got over here then I
  so it''s not all together clear we are pretty heavily betting on", "tokens": [50640,
  813, 264, 805, 4, 286, 658, 670, 510, 550, 286, 370, 309, 311, 406, 439, 1214, 1850,
  321, 366, 1238, 10950, 34246, 322, 50956], "temperature": 0.0, "avg_logprob": -0.13066453519074814,
  "compression_ratio": 1.866412213740458, "no_speech_prob": 0.00030513416277244687},
  {"id": 384, "seek": 218840, "start": 2200.2400000000002, "end": 2206.1600000000003,
  "text": " the I shouldn''t say we''re betting on it like right now we we got the
  hybrid stuff relatively easily", "tokens": [50956, 264, 286, 4659, 380, 584, 321,
  434, 34246, 322, 309, 411, 558, 586, 321, 321, 658, 264, 13051, 1507, 7226, 3612,
  51252], "temperature": 0.0, "avg_logprob": -0.13066453519074814, "compression_ratio":
  1.866412213740458, "no_speech_prob": 0.00030513416277244687}, {"id": 385, "seek":
  218840, "start": 2206.1600000000003, "end": 2210.08, "text": " so that''s the thing
  that we''re building heavily because all the all the hybridization has been", "tokens":
  [51252, 370, 300, 311, 264, 551, 300, 321, 434, 2390, 10950, 570, 439, 264, 439,
  264, 13051, 2144, 575, 668, 51448], "temperature": 0.0, "avg_logprob": -0.13066453519074814,
  "compression_ratio": 1.866412213740458, "no_speech_prob": 0.00030513416277244687},
  {"id": 386, "seek": 218840, "start": 2210.08, "end": 2216.0, "text": " and the the
  incrementability because that''s core like so for us the incrementability is like
  not", "tokens": [51448, 293, 264, 264, 26200, 2310, 570, 300, 311, 4965, 411, 370,
  337, 505, 264, 26200, 2310, 307, 411, 406, 51744], "temperature": 0.0, "avg_logprob":
  -0.13066453519074814, "compression_ratio": 1.866412213740458, "no_speech_prob":
  0.00030513416277244687}, {"id": 387, "seek": 221600, "start": 2216.32, "end": 2220.24,
  "text": " you have to have that I can''t use an an index that requires like overnight
  training like that''s", "tokens": [50380, 291, 362, 281, 362, 300, 286, 393, 380,
  764, 364, 364, 8186, 300, 7029, 411, 13935, 3097, 411, 300, 311, 50576], "temperature":
  0.0, "avg_logprob": -0.12285808865114939, "compression_ratio": 2.0385964912280703,
  "no_speech_prob": 0.00858211424201727}, {"id": 388, "seek": 221600, "start": 2220.24,
  "end": 2224.88, "text": " not a thing that that rock that doesn''t work with rocks
  x we were trying to be real time and then I", "tokens": [50576, 406, 257, 551, 300,
  300, 3727, 300, 1177, 380, 589, 365, 10989, 2031, 321, 645, 1382, 281, 312, 957,
  565, 293, 550, 286, 50808], "temperature": 0.0, "avg_logprob": -0.12285808865114939,
  "compression_ratio": 2.0385964912280703, "no_speech_prob": 0.00858211424201727},
  {"id": 389, "seek": 221600, "start": 2224.88, "end": 2228.64, "text": " guess there''s
  like one fourth dimension that could blow all this up which is that somehow the",
  "tokens": [50808, 2041, 456, 311, 411, 472, 6409, 10139, 300, 727, 6327, 439, 341,
  493, 597, 307, 300, 6063, 264, 50996], "temperature": 0.0, "avg_logprob": -0.12285808865114939,
  "compression_ratio": 2.0385964912280703, "no_speech_prob": 0.00858211424201727},
  {"id": 390, "seek": 221600, "start": 2228.64, "end": 2233.84, "text": " vectors
  get so good that none of the rest of this matters like maybe there is maybe there
  is no rag", "tokens": [50996, 18875, 483, 370, 665, 300, 6022, 295, 264, 1472, 295,
  341, 7001, 411, 1310, 456, 307, 1310, 456, 307, 572, 17539, 51256], "temperature":
  0.0, "avg_logprob": -0.12285808865114939, "compression_ratio": 2.0385964912280703,
  "no_speech_prob": 0.00858211424201727}, {"id": 391, "seek": 221600, "start": 2233.84,
  "end": 2238.48, "text": " maybe there is no like maybe the vectors just good enough
  maybe the machine is smart enough that", "tokens": [51256, 1310, 456, 307, 572,
  411, 1310, 264, 18875, 445, 665, 1547, 1310, 264, 3479, 307, 4069, 1547, 300, 51488],
  "temperature": 0.0, "avg_logprob": -0.12285808865114939, "compression_ratio": 2.0385964912280703,
  "no_speech_prob": 0.00858211424201727}, {"id": 392, "seek": 221600, "start": 2238.48,
  "end": 2242.32, "text": " we don''t need any of the rest of this we don''t need
  any hybrids I think that''s unlikely in the", "tokens": [51488, 321, 500, 380, 643,
  604, 295, 264, 1472, 295, 341, 321, 500, 380, 643, 604, 2477, 1443, 3742, 286, 519,
  300, 311, 17518, 294, 264, 51680], "temperature": 0.0, "avg_logprob": -0.12285808865114939,
  "compression_ratio": 2.0385964912280703, "no_speech_prob": 0.00858211424201727},
  {"id": 393, "seek": 224232, "start": 2242.32, "end": 2246.8, "text": " short and
  medium term but who knows in the in the long that''s probably require some kind
  of", "tokens": [50364, 2099, 293, 6399, 1433, 457, 567, 3255, 294, 264, 294, 264,
  938, 300, 311, 1391, 3651, 512, 733, 295, 50588], "temperature": 0.0, "avg_logprob":
  -0.16735186857335707, "compression_ratio": 1.7130044843049328, "no_speech_prob":
  0.011528562754392624}, {"id": 394, "seek": 224232, "start": 2246.8, "end": 2254.0800000000004,
  "text": " singularity yes it is jump right because that means that you do not need
  foundational models from", "tokens": [50588, 20010, 507, 2086, 309, 307, 3012, 558,
  570, 300, 1355, 300, 291, 360, 406, 643, 32195, 5245, 490, 50952], "temperature":
  0.0, "avg_logprob": -0.16735186857335707, "compression_ratio": 1.7130044843049328,
  "no_speech_prob": 0.011528562754392624}, {"id": 395, "seek": 224232, "start": 2254.0800000000004,
  "end": 2260.1600000000003, "text": " metal whoever right you could train it from
  scratch and if you can do it within a couple minutes", "tokens": [50952, 5760, 11387,
  558, 291, 727, 3847, 309, 490, 8459, 293, 498, 291, 393, 360, 309, 1951, 257, 1916,
  2077, 51256], "temperature": 0.0, "avg_logprob": -0.16735186857335707, "compression_ratio":
  1.7130044843049328, "no_speech_prob": 0.011528562754392624}, {"id": 396, "seek":
  224232, "start": 2260.1600000000003, "end": 2267.84, "text": " then why would you
  bother taking those models right that''s very interesting it''s my that that''s",
  "tokens": [51256, 550, 983, 576, 291, 8677, 1940, 729, 5245, 558, 300, 311, 588,
  1880, 309, 311, 452, 300, 300, 311, 51640], "temperature": 0.0, "avg_logprob": -0.16735186857335707,
  "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.011528562754392624},
  {"id": 397, "seek": 226784, "start": 2267.92, "end": 2273.44, "text": " that''s
  why I said there''s three and then I threw the fourth one in because I it''s it''s
  not impossible", "tokens": [50368, 300, 311, 983, 286, 848, 456, 311, 1045, 293,
  550, 286, 11918, 264, 6409, 472, 294, 570, 286, 309, 311, 309, 311, 406, 6243, 50644],
  "temperature": 0.0, "avg_logprob": -0.1486361821492513, "compression_ratio": 1.7207207207207207,
  "no_speech_prob": 0.005666608456522226}, {"id": 398, "seek": 226784, "start": 2273.44,
  "end": 2280.2400000000002, "text": " but I think it''s not likely not anytime exactly
  I mean it''s probably if this is about to happen", "tokens": [50644, 457, 286, 519,
  309, 311, 406, 3700, 406, 13038, 2293, 286, 914, 309, 311, 1391, 498, 341, 307,
  466, 281, 1051, 50984], "temperature": 0.0, "avg_logprob": -0.1486361821492513,
  "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.005666608456522226},
  {"id": 399, "seek": 226784, "start": 2280.96, "end": 2286.32, "text": " then probably
  we would already see the room like you know the signals of that but today", "tokens":
  [51020, 550, 1391, 321, 576, 1217, 536, 264, 1808, 411, 291, 458, 264, 12354, 295,
  300, 457, 965, 51288], "temperature": 0.0, "avg_logprob": -0.1486361821492513, "compression_ratio":
  1.7207207207207207, "no_speech_prob": 0.005666608456522226}, {"id": 400, "seek":
  226784, "start": 2287.2000000000003, "end": 2292.8, "text": " still we can see how
  these giants keep training the models and they keep open sourcing sometimes", "tokens":
  [51332, 920, 321, 393, 536, 577, 613, 31894, 1066, 3097, 264, 5245, 293, 436, 1066,
  1269, 11006, 2175, 2171, 51612], "temperature": 0.0, "avg_logprob": -0.1486361821492513,
  "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.005666608456522226},
  {"id": 401, "seek": 229280, "start": 2292.96, "end": 2299.76, "text": " encodes
  sometimes for real but yeah it''s it''s another topic to cover I have a very practical",
  "tokens": [50372, 2058, 4789, 2171, 337, 957, 457, 1338, 309, 311, 309, 311, 1071,
  4829, 281, 2060, 286, 362, 257, 588, 8496, 50712], "temperature": 0.0, "avg_logprob":
  -0.19653683739739494, "compression_ratio": 1.5628415300546448, "no_speech_prob":
  0.0026188548654317856}, {"id": 402, "seek": 229280, "start": 2299.76, "end": 2305.76,
  "text": " question as well so for example if I do have a model and that model could
  be from Higging Face for", "tokens": [50712, 1168, 382, 731, 370, 337, 1365, 498,
  286, 360, 362, 257, 2316, 293, 300, 2316, 727, 312, 490, 389, 328, 3249, 4047, 337,
  51012], "temperature": 0.0, "avg_logprob": -0.19653683739739494, "compression_ratio":
  1.5628415300546448, "no_speech_prob": 0.0026188548654317856}, {"id": 403, "seek":
  229280, "start": 2305.76, "end": 2314.4, "text": " example so it''s not mine how
  do I bring the embeddings to Rockset can I leverage the Rockset''s", "tokens": [51012,
  1365, 370, 309, 311, 406, 3892, 577, 360, 286, 1565, 264, 12240, 29432, 281, 6922,
  3854, 393, 286, 13982, 264, 6922, 3854, 311, 51444], "temperature": 0.0, "avg_logprob":
  -0.19653683739739494, "compression_ratio": 1.5628415300546448, "no_speech_prob":
  0.0026188548654317856}, {"id": 404, "seek": 231440, "start": 2314.4, "end": 2323.6,
  "text": " infrastructure to compute the embeddings themselves so this the answer
  in short is no today and it is", "tokens": [50364, 6896, 281, 14722, 264, 12240,
  29432, 2969, 370, 341, 264, 1867, 294, 2099, 307, 572, 965, 293, 309, 307, 50824],
  "temperature": 0.0, "avg_logprob": -0.09754545792289403, "compression_ratio": 1.8389513108614233,
  "no_speech_prob": 0.0016795805422589183}, {"id": 405, "seek": 231440, "start": 2323.6,
  "end": 2329.04, "text": " on my list super high on my list so there is a customer
  who came to me tomorrow and was like hey", "tokens": [50824, 322, 452, 1329, 1687,
  1090, 322, 452, 1329, 370, 456, 307, 257, 5474, 567, 1361, 281, 385, 4153, 293,
  390, 411, 4177, 51096], "temperature": 0.0, "avg_logprob": -0.09754545792289403,
  "compression_ratio": 1.8389513108614233, "no_speech_prob": 0.0016795805422589183},
  {"id": 406, "seek": 231440, "start": 2330.08, "end": 2335.52, "text": " I want to
  run this model using your infrastructure over my data I''d probably find a way to
  make", "tokens": [51148, 286, 528, 281, 1190, 341, 2316, 1228, 428, 6896, 670, 452,
  1412, 286, 1116, 1391, 915, 257, 636, 281, 652, 51420], "temperature": 0.0, "avg_logprob":
  -0.09754545792289403, "compression_ratio": 1.8389513108614233, "no_speech_prob":
  0.0016795805422589183}, {"id": 407, "seek": 231440, "start": 2335.52, "end": 2339.36,
  "text": " that work for that like an existing customer like I would like because
  that''s a feature I want to", "tokens": [51420, 300, 589, 337, 300, 411, 364, 6741,
  5474, 411, 286, 576, 411, 570, 300, 311, 257, 4111, 286, 528, 281, 51612], "temperature":
  0.0, "avg_logprob": -0.09754545792289403, "compression_ratio": 1.8389513108614233,
  "no_speech_prob": 0.0016795805422589183}, {"id": 408, "seek": 231440, "start": 2339.36,
  "end": 2343.36, "text": " build I''m like waiting for the excuse to build that the
  problem for me is it''s just really hard to", "tokens": [51612, 1322, 286, 478,
  411, 3806, 337, 264, 8960, 281, 1322, 300, 264, 1154, 337, 385, 307, 309, 311, 445,
  534, 1152, 281, 51812], "temperature": 0.0, "avg_logprob": -0.09754545792289403,
  "compression_ratio": 1.8389513108614233, "no_speech_prob": 0.0016795805422589183},
  {"id": 409, "seek": 234336, "start": 2343.36, "end": 2351.52, "text": " build generally
  like if it was like call this API or support these exact kind of models it''s not",
  "tokens": [50364, 1322, 5101, 411, 498, 309, 390, 411, 818, 341, 9362, 420, 1406,
  613, 1900, 733, 295, 5245, 309, 311, 406, 50772], "temperature": 0.0, "avg_logprob":
  -0.044462160269419355, "compression_ratio": 1.7765567765567765, "no_speech_prob":
  0.0018911833176389337}, {"id": 410, "seek": 234336, "start": 2351.52, "end": 2355.6,
  "text": " so hard but to do it in general without having like a specific customer
  demand it''s a little bit", "tokens": [50772, 370, 1152, 457, 281, 360, 309, 294,
  2674, 1553, 1419, 411, 257, 2685, 5474, 4733, 309, 311, 257, 707, 857, 50976], "temperature":
  0.0, "avg_logprob": -0.044462160269419355, "compression_ratio": 1.7765567765567765,
  "no_speech_prob": 0.0018911833176389337}, {"id": 411, "seek": 234336, "start": 2355.6,
  "end": 2360.48, "text": " trickier so we can kind of wait until that take a little
  bit more shape but we have the pieces in", "tokens": [50976, 4282, 811, 370, 321,
  393, 733, 295, 1699, 1826, 300, 747, 257, 707, 857, 544, 3909, 457, 321, 362, 264,
  3755, 294, 51220], "temperature": 0.0, "avg_logprob": -0.044462160269419355, "compression_ratio":
  1.7765567765567765, "no_speech_prob": 0.0018911833176389337}, {"id": 412, "seek":
  234336, "start": 2360.48, "end": 2364.2400000000002, "text": " place like it''s
  not hard for me to spin up a bunch of machines that run on your data and write",
  "tokens": [51220, 1081, 411, 309, 311, 406, 1152, 337, 385, 281, 6060, 493, 257,
  3840, 295, 8379, 300, 1190, 322, 428, 1412, 293, 2464, 51408], "temperature": 0.0,
  "avg_logprob": -0.044462160269419355, "compression_ratio": 1.7765567765567765, "no_speech_prob":
  0.0018911833176389337}, {"id": 413, "seek": 234336, "start": 2364.2400000000002,
  "end": 2371.04, "text": " to your database I just it''s the actual like last mile
  of wire of like what code do I run how do I", "tokens": [51408, 281, 428, 8149,
  286, 445, 309, 311, 264, 3539, 411, 1036, 12620, 295, 6234, 295, 411, 437, 3089,
  360, 286, 1190, 577, 360, 286, 51748], "temperature": 0.0, "avg_logprob": -0.044462160269419355,
  "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0018911833176389337},
  {"id": 414, "seek": 237104, "start": 2371.04, "end": 2375.52, "text": " secure that
  code you know like that kind of stuff that''s like what''s missing from us so today",
  "tokens": [50364, 7144, 300, 3089, 291, 458, 411, 300, 733, 295, 1507, 300, 311,
  411, 437, 311, 5361, 490, 505, 370, 965, 50588], "temperature": 0.0, "avg_logprob":
  -0.12991098846708024, "compression_ratio": 1.8098859315589353, "no_speech_prob":
  0.0019807470962405205}, {"id": 415, "seek": 237104, "start": 2375.52, "end": 2378.72,
  "text": " and today you have to give me the embedding you''re gonna have to run
  them and put them in a", "tokens": [50588, 293, 965, 291, 362, 281, 976, 385, 264,
  12240, 3584, 291, 434, 799, 362, 281, 1190, 552, 293, 829, 552, 294, 257, 50748],
  "temperature": 0.0, "avg_logprob": -0.12991098846708024, "compression_ratio": 1.8098859315589353,
  "no_speech_prob": 0.0019807470962405205}, {"id": 416, "seek": 237104, "start": 2378.72,
  "end": 2386.0, "text": " rock set but this is at the top of my list of sort of features
  I want to build yeah I mean it", "tokens": [50748, 3727, 992, 457, 341, 307, 412,
  264, 1192, 295, 452, 1329, 295, 1333, 295, 4122, 286, 528, 281, 1322, 1338, 286,
  914, 309, 51112], "temperature": 0.0, "avg_logprob": -0.12991098846708024, "compression_ratio":
  1.8098859315589353, "no_speech_prob": 0.0019807470962405205}, {"id": 417, "seek":
  237104, "start": 2386.0, "end": 2393.04, "text": " just sounds and by the way you
  know if you take database today probably you could divide them into", "tokens":
  [51112, 445, 3263, 293, 538, 264, 636, 291, 458, 498, 291, 747, 8149, 965, 1391,
  291, 727, 9845, 552, 666, 51464], "temperature": 0.0, "avg_logprob": -0.12991098846708024,
  "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0019807470962405205},
  {"id": 418, "seek": 237104, "start": 2393.04, "end": 2397.7599999999998, "text":
  " two groups you know using these dimensions specifically whether or not you can
  compute embeddings", "tokens": [51464, 732, 3935, 291, 458, 1228, 613, 12819, 4682,
  1968, 420, 406, 291, 393, 14722, 12240, 29432, 51700], "temperature": 0.0, "avg_logprob":
  -0.12991098846708024, "compression_ratio": 1.8098859315589353, "no_speech_prob":
  0.0019807470962405205}, {"id": 419, "seek": 239776, "start": 2397.76, "end": 2405.28,
  "text": " inside and sometimes you do not want that because you want to like fine
  tune the model and obviously", "tokens": [50364, 1854, 293, 2171, 291, 360, 406,
  528, 300, 570, 291, 528, 281, 411, 2489, 10864, 264, 2316, 293, 2745, 50740], "temperature":
  0.0, "avg_logprob": -0.08197278766841679, "compression_ratio": 1.7739130434782608,
  "no_speech_prob": 0.0028080677147954702}, {"id": 420, "seek": 239776, "start": 2405.28,
  "end": 2410.48, "text": " the database wouldn''t have access to it unless there
  is a very easy way to plug it in which I haven''t", "tokens": [50740, 264, 8149,
  2759, 380, 362, 2105, 281, 309, 5969, 456, 307, 257, 588, 1858, 636, 281, 5452,
  309, 294, 597, 286, 2378, 380, 51000], "temperature": 0.0, "avg_logprob": -0.08197278766841679,
  "compression_ratio": 1.7739130434782608, "no_speech_prob": 0.0028080677147954702},
  {"id": 421, "seek": 239776, "start": 2410.48, "end": 2417.28, "text": " seen by
  the way probably I''m missing something but I haven''t seen it and everyone today
  has some sort", "tokens": [51000, 1612, 538, 264, 636, 1391, 286, 478, 5361, 746,
  457, 286, 2378, 380, 1612, 309, 293, 1518, 965, 575, 512, 1333, 51340], "temperature":
  0.0, "avg_logprob": -0.08197278766841679, "compression_ratio": 1.7739130434782608,
  "no_speech_prob": 0.0028080677147954702}, {"id": 422, "seek": 239776, "start": 2417.28,
  "end": 2424.6400000000003, "text": " of vector support you know both the traditional
  databases as well as this new breed of vector databases", "tokens": [51340, 295,
  8062, 1406, 291, 458, 1293, 264, 5164, 22380, 382, 731, 382, 341, 777, 18971, 295,
  8062, 22380, 51708], "temperature": 0.0, "avg_logprob": -0.08197278766841679, "compression_ratio":
  1.7739130434782608, "no_speech_prob": 0.0028080677147954702}, {"id": 423, "seek":
  242464, "start": 2425.6, "end": 2429.2799999999997, "text": " but yeah that''s interesting
  that''s interesting that you guys are looking in that direction", "tokens": [50412,
  457, 1338, 300, 311, 1880, 300, 311, 1880, 300, 291, 1074, 366, 1237, 294, 300,
  3513, 50596], "temperature": 0.0, "avg_logprob": -0.15169025551189075, "compression_ratio":
  1.9790575916230366, "no_speech_prob": 0.008275533095002174}, {"id": 424, "seek":
  242464, "start": 2431.2799999999997, "end": 2438.48, "text": " what else you know
  like if if someone wants in the audience wants to try rock set today you know",
  "tokens": [50696, 437, 1646, 291, 458, 411, 498, 498, 1580, 2738, 294, 264, 4034,
  2738, 281, 853, 3727, 992, 965, 291, 458, 51056], "temperature": 0.0, "avg_logprob":
  -0.15169025551189075, "compression_ratio": 1.9790575916230366, "no_speech_prob":
  0.008275533095002174}, {"id": 425, "seek": 242464, "start": 2439.12, "end": 2444.08,
  "text": " do they need to pay it right away well can they have some free tier to
  play around oh there''s", "tokens": [51088, 360, 436, 643, 281, 1689, 309, 558,
  1314, 731, 393, 436, 362, 512, 1737, 12362, 281, 862, 926, 1954, 456, 311, 51336],
  "temperature": 0.0, "avg_logprob": -0.15169025551189075, "compression_ratio": 1.9790575916230366,
  "no_speech_prob": 0.008275533095002174}, {"id": 426, "seek": 242464, "start": 2444.08,
  "end": 2450.0, "text": " free there''s free tiers yeah so you can play around you
  can play around for free in rock set and", "tokens": [51336, 1737, 456, 311, 1737,
  40563, 1338, 370, 291, 393, 862, 926, 291, 393, 862, 926, 337, 1737, 294, 3727,
  992, 293, 51632], "temperature": 0.0, "avg_logprob": -0.15169025551189075, "compression_ratio":
  1.9790575916230366, "no_speech_prob": 0.008275533095002174}, {"id": 427, "seek":
  245000, "start": 2450.96, "end": 2455.92, "text": " uh if anybody is like super
  interested and they have something interesting and they they they", "tokens": [50412,
  2232, 498, 4472, 307, 411, 1687, 3102, 293, 436, 362, 746, 1880, 293, 436, 436,
  436, 50660], "temperature": 0.0, "avg_logprob": -0.14585168738114207, "compression_ratio":
  1.8237547892720307, "no_speech_prob": 0.00036798944347538054}, {"id": 428, "seek":
  245000, "start": 2455.92, "end": 2460.88, "text": " can always email us too um we
  we will try to find a way to make make make that stuff work as much as", "tokens":
  [50660, 393, 1009, 3796, 505, 886, 1105, 321, 321, 486, 853, 281, 915, 257, 636,
  281, 652, 652, 652, 300, 1507, 589, 382, 709, 382, 50908], "temperature": 0.0, "avg_logprob":
  -0.14585168738114207, "compression_ratio": 1.8237547892720307, "no_speech_prob":
  0.00036798944347538054}, {"id": 429, "seek": 245000, "start": 2460.88, "end": 2465.52,
  "text": " possible but yes there is a free tier you can go back around with it yeah
  um and um", "tokens": [50908, 1944, 457, 2086, 456, 307, 257, 1737, 12362, 291,
  393, 352, 646, 926, 365, 309, 1338, 1105, 293, 1105, 51140], "temperature": 0.0,
  "avg_logprob": -0.14585168738114207, "compression_ratio": 1.8237547892720307, "no_speech_prob":
  0.00036798944347538054}, {"id": 430, "seek": 245000, "start": 2467.84, "end": 2471.76,
  "text": " it is managed so that the one thing you have to understand about rock
  set is the managed service", "tokens": [51256, 309, 307, 6453, 370, 300, 264, 472,
  551, 291, 362, 281, 1223, 466, 3727, 992, 307, 264, 6453, 2643, 51452], "temperature":
  0.0, "avg_logprob": -0.14585168738114207, "compression_ratio": 1.8237547892720307,
  "no_speech_prob": 0.00036798944347538054}, {"id": 431, "seek": 245000, "start":
  2471.76, "end": 2475.6, "text": " right so you''re not going to download it and
  run it or whatever it''s not that''s not the way it works", "tokens": [51452, 558,
  370, 291, 434, 406, 516, 281, 5484, 309, 293, 1190, 309, 420, 2035, 309, 311, 406,
  300, 311, 406, 264, 636, 309, 1985, 51644], "temperature": 0.0, "avg_logprob": -0.14585168738114207,
  "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.00036798944347538054},
  {"id": 432, "seek": 247560, "start": 2475.6, "end": 2481.2799999999997, "text":
  " no and and by the way that''s exactly the advantage for businesses right and that''s
  why we do have", "tokens": [50364, 572, 293, 293, 538, 264, 636, 300, 311, 2293,
  264, 5002, 337, 6011, 558, 293, 300, 311, 983, 321, 360, 362, 50648], "temperature":
  0.0, "avg_logprob": -0.1159331202507019, "compression_ratio": 1.8106060606060606,
  "no_speech_prob": 0.0008684160420671105}, {"id": 433, "seek": 247560, "start": 2481.2799999999997,
  "end": 2486.72, "text": " different business models you know because in the end
  of the day you''re not doing this only", "tokens": [50648, 819, 1606, 5245, 291,
  458, 570, 294, 264, 917, 295, 264, 786, 291, 434, 406, 884, 341, 787, 50920], "temperature":
  0.0, "avg_logprob": -0.1159331202507019, "compression_ratio": 1.8106060606060606,
  "no_speech_prob": 0.0008684160420671105}, {"id": 434, "seek": 247560, "start": 2486.72,
  "end": 2492.48, "text": " for fun you you really need to run money too for the company
  to grow and and build more things", "tokens": [50920, 337, 1019, 291, 291, 534,
  643, 281, 1190, 1460, 886, 337, 264, 2237, 281, 1852, 293, 293, 1322, 544, 721,
  51208], "temperature": 0.0, "avg_logprob": -0.1159331202507019, "compression_ratio":
  1.8106060606060606, "no_speech_prob": 0.0008684160420671105}, {"id": 435, "seek":
  247560, "start": 2492.48, "end": 2499.68, "text": " for your users and so that''s
  absolutely legit uh approach not everything needs to be open source", "tokens":
  [51208, 337, 428, 5022, 293, 370, 300, 311, 3122, 10275, 2232, 3109, 406, 1203,
  2203, 281, 312, 1269, 4009, 51568], "temperature": 0.0, "avg_logprob": -0.1159331202507019,
  "compression_ratio": 1.8106060606060606, "no_speech_prob": 0.0008684160420671105},
  {"id": 436, "seek": 247560, "start": 2499.68, "end": 2505.36, "text": " you chose
  it that way but it''s great that you have free tier and we can also link it in the
  show", "tokens": [51568, 291, 5111, 309, 300, 636, 457, 309, 311, 869, 300, 291,
  362, 1737, 12362, 293, 321, 393, 611, 2113, 309, 294, 264, 855, 51852], "temperature":
  0.0, "avg_logprob": -0.1159331202507019, "compression_ratio": 1.8106060606060606,
  "no_speech_prob": 0.0008684160420671105}, {"id": 437, "seek": 250536, "start": 2505.44,
  "end": 2512.7200000000003, "text": " notes sure um what are you looking at you know
  do you need some you said you have already so", "tokens": [50368, 5570, 988, 1105,
  437, 366, 291, 1237, 412, 291, 458, 360, 291, 643, 512, 291, 848, 291, 362, 1217,
  370, 50732], "temperature": 0.0, "avg_logprob": -0.14704912049429758, "compression_ratio":
  1.6741071428571428, "no_speech_prob": 0.0011592706432566047}, {"id": 438, "seek":
  250536, "start": 2512.7200000000003, "end": 2520.88, "text": " many clients in different
  nations different verticals what else would you benefit from by sharing", "tokens":
  [50732, 867, 6982, 294, 819, 11035, 819, 9429, 82, 437, 1646, 576, 291, 5121, 490,
  538, 5414, 51140], "temperature": 0.0, "avg_logprob": -0.14704912049429758, "compression_ratio":
  1.6741071428571428, "no_speech_prob": 0.0011592706432566047}, {"id": 439, "seek":
  250536, "start": 2521.44, "end": 2528.4, "text": " rock set into a wider community
  you know through these podcasts all right so there''s a lot of", "tokens": [51168,
  3727, 992, 666, 257, 11842, 1768, 291, 458, 807, 613, 24045, 439, 558, 370, 456,
  311, 257, 688, 295, 51516], "temperature": 0.0, "avg_logprob": -0.14704912049429758,
  "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0011592706432566047},
  {"id": 440, "seek": 250536, "start": 2528.4, "end": 2533.52, "text": " ways to answer
  this question but but this is the vector group right so selfishly I kind of", "tokens":
  [51516, 2098, 281, 1867, 341, 1168, 457, 457, 341, 307, 264, 8062, 1594, 558, 370,
  19074, 356, 286, 733, 295, 51772], "temperature": 0.0, "avg_logprob": -0.14704912049429758,
  "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0011592706432566047},
  {"id": 441, "seek": 253352, "start": 2533.52, "end": 2540.0, "text": " already hinted
  at this is I''m trying to get a clearer sense by where the value is going to come",
  "tokens": [50364, 1217, 12075, 292, 412, 341, 307, 286, 478, 1382, 281, 483, 257,
  26131, 2020, 538, 689, 264, 2158, 307, 516, 281, 808, 50688], "temperature": 0.0,
  "avg_logprob": -0.07006655890366127, "compression_ratio": 1.8358778625954197, "no_speech_prob":
  0.0005382033996284008}, {"id": 442, "seek": 253352, "start": 2540.0, "end": 2545.12,
  "text": " from in for vectors in the in the short and medium term for people like
  there''s a lot of people", "tokens": [50688, 490, 294, 337, 18875, 294, 264, 294,
  264, 2099, 293, 6399, 1433, 337, 561, 411, 456, 311, 257, 688, 295, 561, 50944],
  "temperature": 0.0, "avg_logprob": -0.07006655890366127, "compression_ratio": 1.8358778625954197,
  "no_speech_prob": 0.0005382033996284008}, {"id": 443, "seek": 253352, "start": 2545.12,
  "end": 2550.0, "text": " out there and we saw this there''s a million people trying
  to oh my god vectors are happening how", "tokens": [50944, 484, 456, 293, 321, 1866,
  341, 456, 311, 257, 2459, 561, 1382, 281, 1954, 452, 3044, 18875, 366, 2737, 577,
  51188], "temperature": 0.0, "avg_logprob": -0.07006655890366127, "compression_ratio":
  1.8358778625954197, "no_speech_prob": 0.0005382033996284008}, {"id": 444, "seek":
  253352, "start": 2550.0, "end": 2556.24, "text": " do I plug this into my business
  like is there it''s can I use this and we''ve seen a bunch of", "tokens": [51188,
  360, 286, 5452, 341, 666, 452, 1606, 411, 307, 456, 309, 311, 393, 286, 764, 341,
  293, 321, 600, 1612, 257, 3840, 295, 51500], "temperature": 0.0, "avg_logprob":
  -0.07006655890366127, "compression_ratio": 1.8358778625954197, "no_speech_prob":
  0.0005382033996284008}, {"id": 445, "seek": 253352, "start": 2556.24, "end": 2560.96,
  "text": " interesting super novel use cases like things you would not expect and
  you know there''s an insurance", "tokens": [51500, 1880, 1687, 7613, 764, 3331,
  411, 721, 291, 576, 406, 2066, 293, 291, 458, 456, 311, 364, 7214, 51736], "temperature":
  0.0, "avg_logprob": -0.07006655890366127, "compression_ratio": 1.8358778625954197,
  "no_speech_prob": 0.0005382033996284008}, {"id": 446, "seek": 256096, "start": 2560.96,
  "end": 2566.08, "text": " company that want to that wants to like scan internal
  documents you know do they want to do search", "tokens": [50364, 2237, 300, 528,
  281, 300, 2738, 281, 411, 11049, 6920, 8512, 291, 458, 360, 436, 528, 281, 360,
  3164, 50620], "temperature": 0.0, "avg_logprob": -0.1157717008269235, "compression_ratio":
  1.9186602870813396, "no_speech_prob": 0.0012765832943841815}, {"id": 447, "seek":
  256096, "start": 2566.08, "end": 2574.4, "text": " they want to do like internal
  search semantic search um and so for me my my most selfish interest here", "tokens":
  [50620, 436, 528, 281, 360, 411, 6920, 3164, 47982, 3164, 1105, 293, 370, 337, 385,
  452, 452, 881, 19074, 1179, 510, 51036], "temperature": 0.0, "avg_logprob": -0.1157717008269235,
  "compression_ratio": 1.9186602870813396, "no_speech_prob": 0.0012765832943841815},
  {"id": 448, "seek": 256096, "start": 2574.4, "end": 2580.88, "text": " is to really
  get a clear picture of like which of these like little subdomains is actually really",
  "tokens": [51036, 307, 281, 534, 483, 257, 1850, 3036, 295, 411, 597, 295, 613,
  411, 707, 1422, 4121, 2315, 307, 767, 534, 51360], "temperature": 0.0, "avg_logprob":
  -0.1157717008269235, "compression_ratio": 1.9186602870813396, "no_speech_prob":
  0.0012765832943841815}, {"id": 449, "seek": 256096, "start": 2581.2, "end": 2586.4,
  "text": " providing like real value like what is really what is really like taking
  off it''s hard it''s sometimes", "tokens": [51376, 6530, 411, 957, 2158, 411, 437,
  307, 534, 437, 307, 534, 411, 1940, 766, 309, 311, 1152, 309, 311, 2171, 51636],
  "temperature": 0.0, "avg_logprob": -0.1157717008269235, "compression_ratio": 1.9186602870813396,
  "no_speech_prob": 0.0012765832943841815}, {"id": 450, "seek": 258640, "start": 2586.56,
  "end": 2590.56, "text": " it''s hard to tell like who''s just messing around because
  everyone''s messing around literally everyone", "tokens": [50372, 309, 311, 1152,
  281, 980, 411, 567, 311, 445, 23258, 926, 570, 1518, 311, 23258, 926, 3736, 1518,
  50572], "temperature": 0.0, "avg_logprob": -0.11061093596374097, "compression_ratio":
  2.079310344827586, "no_speech_prob": 0.008515751920640469}, {"id": 451, "seek":
  258640, "start": 2590.56, "end": 2595.28, "text": " is messing around and who''s
  like actually latch on to something that''s got some real legs and every", "tokens":
  [50572, 307, 23258, 926, 293, 567, 311, 411, 767, 31837, 322, 281, 746, 300, 311,
  658, 512, 957, 5668, 293, 633, 50808], "temperature": 0.0, "avg_logprob": -0.11061093596374097,
  "compression_ratio": 2.079310344827586, "no_speech_prob": 0.008515751920640469},
  {"id": 452, "seek": 258640, "start": 2595.28, "end": 2599.52, "text": " time we
  find a customer that''s got like real legs we dig in we''re like all in we''re like
  all right how", "tokens": [50808, 565, 321, 915, 257, 5474, 300, 311, 658, 411,
  957, 5668, 321, 2528, 294, 321, 434, 411, 439, 294, 321, 434, 411, 439, 558, 577,
  51020], "temperature": 0.0, "avg_logprob": -0.11061093596374097, "compression_ratio":
  2.079310344827586, "no_speech_prob": 0.008515751920640469}, {"id": 453, "seek":
  258640, "start": 2599.52, "end": 2604.96, "text": " can we help you like let me
  let''s you know again like the the I''m waiting for one of these people to", "tokens":
  [51020, 393, 321, 854, 291, 411, 718, 385, 718, 311, 291, 458, 797, 411, 264, 264,
  286, 478, 3806, 337, 472, 295, 613, 561, 281, 51292], "temperature": 0.0, "avg_logprob":
  -0.11061093596374097, "compression_ratio": 2.079310344827586, "no_speech_prob":
  0.008515751920640469}, {"id": 454, "seek": 258640, "start": 2604.96, "end": 2608.4,
  "text": " come back and be like can we retrain our embedding so like all right yeah
  let''s go build it right so", "tokens": [51292, 808, 646, 293, 312, 411, 393, 321,
  1533, 7146, 527, 12240, 3584, 370, 411, 439, 558, 1338, 718, 311, 352, 1322, 309,
  558, 370, 51464], "temperature": 0.0, "avg_logprob": -0.11061093596374097, "compression_ratio":
  2.079310344827586, "no_speech_prob": 0.008515751920640469}, {"id": 455, "seek":
  258640, "start": 2608.4, "end": 2613.76, "text": " that''s kind of my yeah I I want
  people to keep messing around with this stuff I I want to figure", "tokens": [51464,
  300, 311, 733, 295, 452, 1338, 286, 286, 528, 561, 281, 1066, 23258, 926, 365, 341,
  1507, 286, 286, 528, 281, 2573, 51732], "temperature": 0.0, "avg_logprob": -0.11061093596374097,
  "compression_ratio": 2.079310344827586, "no_speech_prob": 0.008515751920640469},
  {"id": 456, "seek": 261376, "start": 2613.84, "end": 2617.84, "text": " like all
  of us messing around it is going to find where it gets traction like where we can
  get our", "tokens": [50368, 411, 439, 295, 505, 23258, 926, 309, 307, 516, 281,
  915, 689, 309, 2170, 23558, 411, 689, 321, 393, 483, 527, 50568], "temperature":
  0.0, "avg_logprob": -0.10648101010768533, "compression_ratio": 1.9387096774193548,
  "no_speech_prob": 0.0008747426327317953}, {"id": 457, "seek": 261376, "start": 2617.84,
  "end": 2621.76, "text": " hooks in and where things start to start to really make
  progress and then I just want to hear", "tokens": [50568, 26485, 294, 293, 689,
  721, 722, 281, 722, 281, 534, 652, 4205, 293, 550, 286, 445, 528, 281, 1568, 50764],
  "temperature": 0.0, "avg_logprob": -0.10648101010768533, "compression_ratio": 1.9387096774193548,
  "no_speech_prob": 0.0008747426327317953}, {"id": 458, "seek": 261376, "start": 2621.76,
  "end": 2626.8, "text": " from those people like I want to know what what you need
  every time we talk to someone it''s something new", "tokens": [50764, 490, 729,
  561, 411, 286, 528, 281, 458, 437, 437, 291, 643, 633, 565, 321, 751, 281, 1580,
  309, 311, 746, 777, 51016], "temperature": 0.0, "avg_logprob": -0.10648101010768533,
  "compression_ratio": 1.9387096774193548, "no_speech_prob": 0.0008747426327317953},
  {"id": 459, "seek": 261376, "start": 2626.8, "end": 2633.36, "text": " and surprising
  right um and that''s kind of though yeah when the real world intersects with all
  this like", "tokens": [51016, 293, 8830, 558, 1105, 293, 300, 311, 733, 295, 1673,
  1338, 562, 264, 957, 1002, 27815, 82, 365, 439, 341, 411, 51344], "temperature":
  0.0, "avg_logprob": -0.10648101010768533, "compression_ratio": 1.9387096774193548,
  "no_speech_prob": 0.0008747426327317953}, {"id": 460, "seek": 261376, "start": 2633.36,
  "end": 2639.1200000000003, "text": " you know uh in my head it''s all an indexes
  and graph theory or whatever but but uh when the real", "tokens": [51344, 291, 458,
  2232, 294, 452, 1378, 309, 311, 439, 364, 8186, 279, 293, 4295, 5261, 420, 2035,
  457, 457, 2232, 562, 264, 957, 51632], "temperature": 0.0, "avg_logprob": -0.10648101010768533,
  "compression_ratio": 1.9387096774193548, "no_speech_prob": 0.0008747426327317953},
  {"id": 461, "seek": 261376, "start": 2639.1200000000003, "end": 2643.0400000000004,
  "text": " word intersects is always something like simple that you need that would
  make your life a lot easier", "tokens": [51632, 1349, 27815, 82, 307, 1009, 746,
  411, 2199, 300, 291, 643, 300, 576, 652, 428, 993, 257, 688, 3571, 51828], "temperature":
  0.0, "avg_logprob": -0.10648101010768533, "compression_ratio": 1.9387096774193548,
  "no_speech_prob": 0.0008747426327317953}, {"id": 462, "seek": 264304, "start": 2643.04,
  "end": 2648.96, "text": " and that''s the kind of stuff that I''m eager to hear
  yeah I think uh I could share with you without", "tokens": [50364, 293, 300, 311,
  264, 733, 295, 1507, 300, 286, 478, 18259, 281, 1568, 1338, 286, 519, 2232, 286,
  727, 2073, 365, 291, 1553, 50660], "temperature": 0.0, "avg_logprob": -0.23126888275146484,
  "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.001815369469113648},
  {"id": 463, "seek": 264304, "start": 2648.96, "end": 2654.48, "text": " saying what
  would be okay uh one uh member of my team said hey we''re we''re we''re", "tokens":
  [50660, 1566, 437, 576, 312, 1392, 2232, 472, 2232, 4006, 295, 452, 1469, 848, 4177,
  321, 434, 321, 434, 321, 434, 50936], "temperature": 0.0, "avg_logprob": -0.23126888275146484,
  "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.001815369469113648},
  {"id": 464, "seek": 264304, "start": 2654.48, "end": 2662.32, "text": " using one
  one um search engine today which also has you know beyond the um sparse indexals
  that", "tokens": [50936, 1228, 472, 472, 1105, 3164, 2848, 965, 597, 611, 575, 291,
  458, 4399, 264, 1105, 637, 11668, 8186, 1124, 300, 51328], "temperature": 0.0, "avg_logprob":
  -0.23126888275146484, "compression_ratio": 1.7123287671232876, "no_speech_prob":
  0.001815369469113648}, {"id": 465, "seek": 264304, "start": 2662.32, "end": 2668.48,
  "text": " vector search support and so he was saying okay they''re using hnsw algorithm
  but I cannot tweak the", "tokens": [51328, 8062, 3164, 1406, 293, 370, 415, 390,
  1566, 1392, 436, 434, 1228, 276, 3695, 86, 9284, 457, 286, 2644, 29879, 264, 51636],
  "temperature": 0.0, "avg_logprob": -0.23126888275146484, "compression_ratio": 1.7123287671232876,
  "no_speech_prob": 0.001815369469113648}, {"id": 466, "seek": 266848, "start": 2668.48,
  "end": 2675.6, "text": " amp parameter and I forgot what was the second parameter
  and look because I cannot do that recall", "tokens": [50364, 18648, 13075, 293,
  286, 5298, 437, 390, 264, 1150, 13075, 293, 574, 570, 286, 2644, 360, 300, 9901,
  50720], "temperature": 0.0, "avg_logprob": -0.13528889279032863, "compression_ratio":
  1.6981981981981982, "no_speech_prob": 0.004841654561460018}, {"id": 467, "seek":
  266848, "start": 2675.6, "end": 2682.48, "text": " is really below what it needs
  to be it just doesn''t work and then he went online it''s an open source", "tokens":
  [50720, 307, 534, 2507, 437, 309, 2203, 281, 312, 309, 445, 1177, 380, 589, 293,
  550, 415, 1437, 2950, 309, 311, 364, 1269, 4009, 51064], "temperature": 0.0, "avg_logprob":
  -0.13528889279032863, "compression_ratio": 1.6981981981981982, "no_speech_prob":
  0.004841654561460018}, {"id": 468, "seek": 266848, "start": 2682.48, "end": 2690.2400000000002,
  "text": " database he typed you know the issue on github and they realized oh we
  missed really important", "tokens": [51064, 8149, 415, 33941, 291, 458, 264, 2734,
  322, 290, 355, 836, 293, 436, 5334, 1954, 321, 6721, 534, 1021, 51452], "temperature":
  0.0, "avg_logprob": -0.13528889279032863, "compression_ratio": 1.6981981981981982,
  "no_speech_prob": 0.004841654561460018}, {"id": 469, "seek": 266848, "start": 2690.2400000000002,
  "end": 2698.0, "text": " thing so they quickly uh expose the parameters and so he
  now can tune them right so", "tokens": [51452, 551, 370, 436, 2661, 2232, 19219,
  264, 9834, 293, 370, 415, 586, 393, 10864, 552, 558, 370, 51840], "temperature":
  0.0, "avg_logprob": -0.13528889279032863, "compression_ratio": 1.6981981981981982,
  "no_speech_prob": 0.004841654561460018}, {"id": 470, "seek": 269848, "start": 2698.96,
  "end": 2704.96, "text": " so yeah the tuning of the index is another this is a good
  one right so a lot of these systems have", "tokens": [50388, 370, 1338, 264, 15164,
  295, 264, 8186, 307, 1071, 341, 307, 257, 665, 472, 558, 370, 257, 688, 295, 613,
  3652, 362, 50688], "temperature": 0.0, "avg_logprob": -0.09588472304805633, "compression_ratio":
  1.8435114503816794, "no_speech_prob": 0.0006601736531592906}, {"id": 471, "seek":
  269848, "start": 2704.96, "end": 2710.16, "text": " like a tier there''s like a
  coarse grain and a fine grain so you have hnsw over IVF or hnsw over", "tokens":
  [50688, 411, 257, 12362, 456, 311, 411, 257, 39312, 12837, 293, 257, 2489, 12837,
  370, 291, 362, 276, 3695, 86, 670, 15967, 37, 420, 276, 3695, 86, 670, 50948], "temperature":
  0.0, "avg_logprob": -0.09588472304805633, "compression_ratio": 1.8435114503816794,
  "no_speech_prob": 0.0006601736531592906}, {"id": 472, "seek": 269848, "start": 2710.16,
  "end": 2715.12, "text": " or IVF or IVF and then each of these has parameters and
  so you get these like massive config strings", "tokens": [50948, 420, 15967, 37,
  420, 15967, 37, 293, 550, 1184, 295, 613, 575, 9834, 293, 370, 291, 483, 613, 411,
  5994, 6662, 13985, 51196], "temperature": 0.0, "avg_logprob": -0.09588472304805633,
  "compression_ratio": 1.8435114503816794, "no_speech_prob": 0.0006601736531592906},
  {"id": 473, "seek": 269848, "start": 2715.12, "end": 2723.04, "text": " that set
  that say how these are built um and we we expose this so you can do all this stuff
  but", "tokens": [51196, 300, 992, 300, 584, 577, 613, 366, 3094, 1105, 293, 321,
  321, 19219, 341, 370, 291, 393, 360, 439, 341, 1507, 457, 51592], "temperature":
  0.0, "avg_logprob": -0.09588472304805633, "compression_ratio": 1.8435114503816794,
  "no_speech_prob": 0.0006601736531592906}, {"id": 474, "seek": 269848, "start": 2723.92,
  "end": 2728.0, "text": " in real life if you''re building like what what number
  do you even pick like how do you know", "tokens": [51636, 294, 957, 993, 498, 291,
  434, 2390, 411, 437, 437, 1230, 360, 291, 754, 1888, 411, 577, 360, 291, 458, 51840],
  "temperature": 0.0, "avg_logprob": -0.09588472304805633, "compression_ratio": 1.8435114503816794,
  "no_speech_prob": 0.0006601736531592906}, {"id": 475, "seek": 272848, "start": 2728.48,
  "end": 2731.84, "text": " I don''t know that person must have gone through a lot
  to decide they needed to change that", "tokens": [50364, 286, 500, 380, 458, 300,
  954, 1633, 362, 2780, 807, 257, 688, 281, 4536, 436, 2978, 281, 1319, 300, 50532],
  "temperature": 0.0, "avg_logprob": -0.11468374832816745, "compression_ratio": 1.8396946564885497,
  "no_speech_prob": 0.0002649218949954957}, {"id": 476, "seek": 272848, "start": 2731.84,
  "end": 2735.68, "text": " ever because it''s not obvious it''s not like oh yeah
  you it''s like you look at the data like 16s", "tokens": [50532, 1562, 570, 309,
  311, 406, 6322, 309, 311, 406, 411, 1954, 1338, 291, 309, 311, 411, 291, 574, 412,
  264, 1412, 411, 3165, 82, 50724], "temperature": 0.0, "avg_logprob": -0.11468374832816745,
  "compression_ratio": 1.8396946564885497, "no_speech_prob": 0.0002649218949954957},
  {"id": 477, "seek": 272848, "start": 2735.68, "end": 2742.72, "text": " wrong like
  the infrastructure to like optimize this system is not trivial and then even if
  you do", "tokens": [50724, 2085, 411, 264, 6896, 281, 411, 19719, 341, 1185, 307,
  406, 26703, 293, 550, 754, 498, 291, 360, 51076], "temperature": 0.0, "avg_logprob":
  -0.11468374832816745, "compression_ratio": 1.8396946564885497, "no_speech_prob":
  0.0002649218949954957}, {"id": 478, "seek": 272848, "start": 2742.72, "end": 2746.8,
  "text": " optimize it you have to rerun everything you have to rebuild that index
  right once you kind of", "tokens": [51076, 19719, 309, 291, 362, 281, 43819, 409,
  1203, 291, 362, 281, 16877, 300, 8186, 558, 1564, 291, 733, 295, 51280], "temperature":
  0.0, "avg_logprob": -0.11468374832816745, "compression_ratio": 1.8396946564885497,
  "no_speech_prob": 0.0002649218949954957}, {"id": 479, "seek": 272848, "start": 2746.8,
  "end": 2753.28, "text": " trained it so to speak so yeah I think that''s a that''s
  a huge area where our our infrastructure is not", "tokens": [51280, 8895, 309, 370,
  281, 1710, 370, 1338, 286, 519, 300, 311, 257, 300, 311, 257, 2603, 1859, 689, 527,
  527, 6896, 307, 406, 51604], "temperature": 0.0, "avg_logprob": -0.11468374832816745,
  "compression_ratio": 1.8396946564885497, "no_speech_prob": 0.0002649218949954957},
  {"id": 480, "seek": 275328, "start": 2753.36, "end": 2761.6000000000004, "text":
  " helpful at the moment yeah but I''m sure you will learn in general excited like
  Luis look you have", "tokens": [50368, 4961, 412, 264, 1623, 1338, 457, 286, 478,
  988, 291, 486, 1466, 294, 2674, 2919, 411, 25133, 574, 291, 362, 50780], "temperature":
  0.0, "avg_logprob": -0.1946825632234899, "compression_ratio": 1.6593886462882097,
  "no_speech_prob": 0.002556996885687113}, {"id": 481, "seek": 275328, "start": 2761.6000000000004,
  "end": 2768.32, "text": " so much information that I think we should record another
  episode as well down the road as you guys", "tokens": [50780, 370, 709, 1589, 300,
  286, 519, 321, 820, 2136, 1071, 3500, 382, 731, 760, 264, 3060, 382, 291, 1074,
  51116], "temperature": 0.0, "avg_logprob": -0.1946825632234899, "compression_ratio":
  1.6593886462882097, "no_speech_prob": 0.002556996885687113}, {"id": 482, "seek":
  275328, "start": 2768.32, "end": 2775.1200000000003, "text": " progressing on the
  database and you add all this interesting you know tweaks that and not", "tokens":
  [51116, 36305, 322, 264, 8149, 293, 291, 909, 439, 341, 1880, 291, 458, 46664, 300,
  293, 406, 51456], "temperature": 0.0, "avg_logprob": -0.1946825632234899, "compression_ratio":
  1.6593886462882097, "no_speech_prob": 0.002556996885687113}, {"id": 483, "seek":
  275328, "start": 2775.1200000000003, "end": 2780.8, "text": " to the database as
  well but I''m also super excited about the direction because basically you", "tokens":
  [51456, 281, 264, 8149, 382, 731, 457, 286, 478, 611, 1687, 2919, 466, 264, 3513,
  570, 1936, 291, 51740], "temperature": 0.0, "avg_logprob": -0.1946825632234899,
  "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.002556996885687113},
  {"id": 484, "seek": 278080, "start": 2781.28, "end": 2789.1200000000003, "text":
  " offer like if you take pure vector databases you know they do not implement SQL
  support right", "tokens": [50388, 2626, 411, 498, 291, 747, 6075, 8062, 22380, 291,
  458, 436, 360, 406, 4445, 19200, 1406, 558, 50780], "temperature": 0.0, "avg_logprob":
  -0.1702940434585383, "compression_ratio": 1.6741071428571428, "no_speech_prob":
  0.003910748288035393}, {"id": 485, "seek": 278080, "start": 2789.52, "end": 2794.0,
  "text": " right they like the purpose of what what the existence is something else
  right they''ve been", "tokens": [50800, 558, 436, 411, 264, 4334, 295, 437, 437,
  264, 9123, 307, 746, 1646, 558, 436, 600, 668, 51024], "temperature": 0.0, "avg_logprob":
  -0.1702940434585383, "compression_ratio": 1.6741071428571428, "no_speech_prob":
  0.003910748288035393}, {"id": 486, "seek": 278080, "start": 2794.6400000000003,
  "end": 2802.88, "text": " designed to have vectors as the first class citizens and
  so they they make it super easy to", "tokens": [51056, 4761, 281, 362, 18875, 382,
  264, 700, 1508, 7180, 293, 370, 436, 436, 652, 309, 1687, 1858, 281, 51468], "temperature":
  0.0, "avg_logprob": -0.1702940434585383, "compression_ratio": 1.6741071428571428,
  "no_speech_prob": 0.003910748288035393}, {"id": 487, "seek": 278080, "start": 2802.88,
  "end": 2809.28, "text": " plug in a model or actually have the model you know almost
  pulled from hugging face or some other", "tokens": [51468, 5452, 294, 257, 2316,
  420, 767, 362, 264, 2316, 291, 458, 1920, 7373, 490, 41706, 1851, 420, 512, 661,
  51788], "temperature": 0.0, "avg_logprob": -0.1702940434585383, "compression_ratio":
  1.6741071428571428, "no_speech_prob": 0.003910748288035393}, {"id": 488, "seek":
  280928, "start": 2809.28, "end": 2817.1200000000003, "text": " model storage model
  model hub but then when you want to do some facets or whatever you want to", "tokens":
  [50364, 2316, 6725, 2316, 2316, 11838, 457, 550, 562, 291, 528, 281, 360, 512, 49752,
  420, 2035, 291, 528, 281, 50756], "temperature": 0.0, "avg_logprob": -0.11756068087638692,
  "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.004267509561032057},
  {"id": 489, "seek": 280928, "start": 2817.1200000000003, "end": 2822.2400000000002,
  "text": " call them aggregations right that''s not as easy depends on database probably
  as well but I''ve seen", "tokens": [50756, 818, 552, 16743, 763, 558, 300, 311,
  406, 382, 1858, 5946, 322, 8149, 1391, 382, 731, 457, 286, 600, 1612, 51012], "temperature":
  0.0, "avg_logprob": -0.11756068087638692, "compression_ratio": 1.7935779816513762,
  "no_speech_prob": 0.004267509561032057}, {"id": 490, "seek": 280928, "start": 2822.2400000000002,
  "end": 2827.76, "text": " some I don''t want to name them but in any case they know
  it''s it''s a weak point and it''s probably", "tokens": [51012, 512, 286, 500, 380,
  528, 281, 1315, 552, 457, 294, 604, 1389, 436, 458, 309, 311, 309, 311, 257, 5336,
  935, 293, 309, 311, 1391, 51288], "temperature": 0.0, "avg_logprob": -0.11756068087638692,
  "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.004267509561032057},
  {"id": 491, "seek": 280928, "start": 2827.76, "end": 2834.6400000000003, "text":
  " because they do not want to serve that segment of the market maybe they do it''s
  partially right but", "tokens": [51288, 570, 436, 360, 406, 528, 281, 4596, 300,
  9469, 295, 264, 2142, 1310, 436, 360, 309, 311, 18886, 558, 457, 51632], "temperature":
  0.0, "avg_logprob": -0.11756068087638692, "compression_ratio": 1.7935779816513762,
  "no_speech_prob": 0.004267509561032057}, {"id": 492, "seek": 283464, "start": 2834.64,
  "end": 2842.08, "text": " it''s so hard yeah exactly yeah I mean I think that the
  really good vector databases who succeed", "tokens": [50364, 309, 311, 370, 1152,
  1338, 2293, 1338, 286, 914, 286, 519, 300, 264, 534, 665, 8062, 22380, 567, 7754,
  50736], "temperature": 0.0, "avg_logprob": -0.07968366371010835, "compression_ratio":
  1.849056603773585, "no_speech_prob": 0.0001273619564017281}, {"id": 493, "seek":
  283464, "start": 2842.08, "end": 2847.92, "text": " will slowly turn into databases
  and databases will turn into like these things are merging they''re", "tokens":
  [50736, 486, 5692, 1261, 666, 22380, 293, 22380, 486, 1261, 666, 411, 613, 721,
  366, 44559, 436, 434, 51028], "temperature": 0.0, "avg_logprob": -0.07968366371010835,
  "compression_ratio": 1.849056603773585, "no_speech_prob": 0.0001273619564017281},
  {"id": 494, "seek": 283464, "start": 2847.92, "end": 2852.16, "text": " just coming
  at each other for different directions like like if you''re at a vector database
  if you''re", "tokens": [51028, 445, 1348, 412, 1184, 661, 337, 819, 11095, 411,
  411, 498, 291, 434, 412, 257, 8062, 8149, 498, 291, 434, 51240], "temperature":
  0.0, "avg_logprob": -0.07968366371010835, "compression_ratio": 1.849056603773585,
  "no_speech_prob": 0.0001273619564017281}, {"id": 495, "seek": 283464, "start": 2852.16,
  "end": 2855.8399999999997, "text": " building a vector database and you''re looking
  at your metadata filtering support you''re like I", "tokens": [51240, 2390, 257,
  8062, 8149, 293, 291, 434, 1237, 412, 428, 26603, 30822, 1406, 291, 434, 411, 286,
  51424], "temperature": 0.0, "avg_logprob": -0.07968366371010835, "compression_ratio":
  1.849056603773585, "no_speech_prob": 0.0001273619564017281}, {"id": 496, "seek":
  283464, "start": 2855.8399999999997, "end": 2859.6, "text": " can''t make this more
  powerful without just reinventing SQL like at some point I''m going to have to",
  "tokens": [51424, 393, 380, 652, 341, 544, 4005, 1553, 445, 33477, 278, 19200, 411,
  412, 512, 935, 286, 478, 516, 281, 362, 281, 51612], "temperature": 0.0, "avg_logprob":
  -0.07968366371010835, "compression_ratio": 1.849056603773585, "no_speech_prob":
  0.0001273619564017281}, {"id": 497, "seek": 285960, "start": 2859.6, "end": 2864.72,
  "text": " just build SQL and so one day they''re going to bite the bullet and we''ll
  I mean maybe not SQL but", "tokens": [50364, 445, 1322, 19200, 293, 370, 472, 786,
  436, 434, 516, 281, 7988, 264, 11632, 293, 321, 603, 286, 914, 1310, 406, 19200,
  457, 50620], "temperature": 0.0, "avg_logprob": -0.09612897924474768, "compression_ratio":
  1.8576923076923078, "no_speech_prob": 0.00153682054951787}, {"id": 498, "seek":
  285960, "start": 2864.72, "end": 2869.6, "text": " something you know SQL complete
  if you will right because you just need all that stuff and then", "tokens": [50620,
  746, 291, 458, 19200, 3566, 498, 291, 486, 558, 570, 291, 445, 643, 439, 300, 1507,
  293, 550, 50864], "temperature": 0.0, "avg_logprob": -0.09612897924474768, "compression_ratio":
  1.8576923076923078, "no_speech_prob": 0.00153682054951787}, {"id": 499, "seek":
  285960, "start": 2869.6, "end": 2874.96, "text": " pretty soon you get into the
  problem of like hey my metadata filter is the slow part of this", "tokens": [50864,
  1238, 2321, 291, 483, 666, 264, 1154, 295, 411, 4177, 452, 26603, 6608, 307, 264,
  2964, 644, 295, 341, 51132], "temperature": 0.0, "avg_logprob": -0.09612897924474768,
  "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.00153682054951787},
  {"id": 500, "seek": 285960, "start": 2874.96, "end": 2880.72, "text": " of my thing
  so now what like oh now I''m doing query optimization like SQL query optimization
  like", "tokens": [51132, 295, 452, 551, 370, 586, 437, 411, 1954, 586, 286, 478,
  884, 14581, 19618, 411, 19200, 14581, 19618, 411, 51420], "temperature": 0.0, "avg_logprob":
  -0.09612897924474768, "compression_ratio": 1.8576923076923078, "no_speech_prob":
  0.00153682054951787}, {"id": 501, "seek": 285960, "start": 2880.72, "end": 2886.08,
  "text": " now I''m building query optimizers like metadata filter optimizers and
  you know so we have all that", "tokens": [51420, 586, 286, 478, 2390, 14581, 5028,
  22525, 411, 26603, 6608, 5028, 22525, 293, 291, 458, 370, 321, 362, 439, 300, 51688],
  "temperature": 0.0, "avg_logprob": -0.09612897924474768, "compression_ratio": 1.8576923076923078,
  "no_speech_prob": 0.00153682054951787}, {"id": 502, "seek": 288608, "start": 2886.08,
  "end": 2890.16, "text": " like we brought all that to the party right like I have
  a I have a cost based optimizer for my", "tokens": [50364, 411, 321, 3038, 439,
  300, 281, 264, 3595, 558, 411, 286, 362, 257, 286, 362, 257, 2063, 2361, 5028, 6545,
  337, 452, 50568], "temperature": 0.0, "avg_logprob": -0.10259328925091288, "compression_ratio":
  1.8089887640449438, "no_speech_prob": 0.00031465725624002516}, {"id": 503, "seek":
  288608, "start": 2890.16, "end": 2895.36, "text": " SQL query so if your metadata
  filter does crazy stuff I can like do you know all kinds of SQL", "tokens": [50568,
  19200, 14581, 370, 498, 428, 26603, 6608, 775, 3219, 1507, 286, 393, 411, 360, 291,
  458, 439, 3685, 295, 19200, 50828], "temperature": 0.0, "avg_logprob": -0.10259328925091288,
  "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.00031465725624002516},
  {"id": 504, "seek": 288608, "start": 2895.36, "end": 2901.7599999999998, "text":
  " magic to like to optimize this query but on the flip side like yeah like so everybody''s
  everybody", "tokens": [50828, 5585, 281, 411, 281, 19719, 341, 14581, 457, 322,
  264, 7929, 1252, 411, 1338, 411, 370, 2201, 311, 2201, 51148], "temperature": 0.0,
  "avg_logprob": -0.10259328925091288, "compression_ratio": 1.8089887640449438, "no_speech_prob":
  0.00031465725624002516}, {"id": 505, "seek": 288608, "start": 2903.2799999999997,
  "end": 2907.92, "text": " I think the good systems need all this stuff it so it''s
  just we took a hard problem we took two hard", "tokens": [51224, 286, 519, 264,
  665, 3652, 643, 439, 341, 1507, 309, 370, 309, 311, 445, 321, 1890, 257, 1152, 1154,
  321, 1890, 732, 1152, 51456], "temperature": 0.0, "avg_logprob": -0.10259328925091288,
  "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.00031465725624002516},
  {"id": 506, "seek": 288608, "start": 2907.92, "end": 2912.08, "text": " problems
  and we say congratulations this now one hard problem and it''s like okay well okay
  it''s", "tokens": [51456, 2740, 293, 321, 584, 13568, 341, 586, 472, 1152, 1154,
  293, 309, 311, 411, 1392, 731, 1392, 309, 311, 51664], "temperature": 0.0, "avg_logprob":
  -0.10259328925091288, "compression_ratio": 1.8089887640449438, "no_speech_prob":
  0.00031465725624002516}, {"id": 507, "seek": 291208, "start": 2912.08, "end": 2918.4,
  "text": " a big hard problem yeah I love how you you model it that this database
  is and non-data", "tokens": [50364, 257, 955, 1152, 1154, 1338, 286, 959, 577, 291,
  291, 2316, 309, 300, 341, 8149, 307, 293, 2107, 12, 67, 3274, 50680], "temperature":
  0.0, "avg_logprob": -0.14094980372938998, "compression_ratio": 1.76036866359447,
  "no_speech_prob": 0.0022365718614310026}, {"id": 508, "seek": 291208, "start": 2918.4,
  "end": 2922.56, "text": " bases sort of will converge eventually even though everyone
  I think at this point calls themselves", "tokens": [50680, 17949, 1333, 295, 486,
  41881, 4728, 754, 1673, 1518, 286, 519, 412, 341, 935, 5498, 2969, 50888], "temperature":
  0.0, "avg_logprob": -0.14094980372938998, "compression_ratio": 1.76036866359447,
  "no_speech_prob": 0.0022365718614310026}, {"id": 509, "seek": 291208, "start": 2922.56,
  "end": 2930.48, "text": " a database yeah probably minor exceptions but still you
  are spot on on whether or not first of all", "tokens": [50888, 257, 8149, 1338,
  1391, 6696, 22847, 457, 920, 291, 366, 4008, 322, 322, 1968, 420, 406, 700, 295,
  439, 51284], "temperature": 0.0, "avg_logprob": -0.14094980372938998, "compression_ratio":
  1.76036866359447, "no_speech_prob": 0.0022365718614310026}, {"id": 510, "seek":
  291208, "start": 2930.48, "end": 2934.64, "text": " what is a database right and
  then whether or not you have all these features that that need to be", "tokens":
  [51284, 437, 307, 257, 8149, 558, 293, 550, 1968, 420, 406, 291, 362, 439, 613,
  4122, 300, 300, 643, 281, 312, 51492], "temperature": 0.0, "avg_logprob": -0.14094980372938998,
  "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0022365718614310026},
  {"id": 511, "seek": 293464, "start": 2934.64, "end": 2942.8799999999997, "text":
  " supported and and also like really importantly the world is used to having SQL
  databases right so", "tokens": [50364, 8104, 293, 293, 611, 411, 534, 8906, 264,
  1002, 307, 1143, 281, 1419, 19200, 22380, 558, 370, 50776], "temperature": 0.0,
  "avg_logprob": -0.14325880200675364, "compression_ratio": 1.684873949579832, "no_speech_prob":
  0.0021565337665379047}, {"id": 512, "seek": 293464, "start": 2942.8799999999997,
  "end": 2949.12, "text": " like if you sort of I don''t have a better analogy but
  basically if you develop something and you say", "tokens": [50776, 411, 498, 291,
  1333, 295, 286, 500, 380, 362, 257, 1101, 21663, 457, 1936, 498, 291, 1499, 746,
  293, 291, 584, 51088], "temperature": 0.0, "avg_logprob": -0.14325880200675364,
  "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0021565337665379047},
  {"id": 513, "seek": 293464, "start": 2949.12, "end": 2956.08, "text": " it can run
  but cannot walk and you''re like okay but sometimes you need to walk right that''s
  amazing", "tokens": [51088, 309, 393, 1190, 457, 2644, 1792, 293, 291, 434, 411,
  1392, 457, 2171, 291, 643, 281, 1792, 558, 300, 311, 2243, 51436], "temperature":
  0.0, "avg_logprob": -0.14325880200675364, "compression_ratio": 1.684873949579832,
  "no_speech_prob": 0.0021565337665379047}, {"id": 514, "seek": 293464, "start": 2956.08,
  "end": 2961.52, "text": " before we close I really like to ask this question with
  some people find it a little awkward to answer", "tokens": [51436, 949, 321, 1998,
  286, 534, 411, 281, 1029, 341, 1168, 365, 512, 561, 915, 309, 257, 707, 11411, 281,
  1867, 51708], "temperature": 0.0, "avg_logprob": -0.14325880200675364, "compression_ratio":
  1.684873949579832, "no_speech_prob": 0.0021565337665379047}, {"id": 515, "seek":
  296152, "start": 2962.16, "end": 2968.88, "text": " but I do feel it''s important
  it''s a little bit philosophical and I ask what drives you it used to be", "tokens":
  [50396, 457, 286, 360, 841, 309, 311, 1021, 309, 311, 257, 707, 857, 25066, 293,
  286, 1029, 437, 11754, 291, 309, 1143, 281, 312, 50732], "temperature": 0.0, "avg_logprob":
  -0.1462329047066825, "compression_ratio": 1.6201117318435754, "no_speech_prob":
  0.008417884819209576}, {"id": 516, "seek": 296152, "start": 2968.88, "end": 2976.24,
  "text": " why you do this but basically when you wake up you know you are driven
  to continue but what''s", "tokens": [50732, 983, 291, 360, 341, 457, 1936, 562,
  291, 6634, 493, 291, 458, 291, 366, 9555, 281, 2354, 457, 437, 311, 51100], "temperature":
  0.0, "avg_logprob": -0.1462329047066825, "compression_ratio": 1.6201117318435754,
  "no_speech_prob": 0.008417884819209576}, {"id": 517, "seek": 296152, "start": 2976.24,
  "end": 2981.92, "text": " inside that spinning you''ve been through it right you''ve
  been doing this for so many years also", "tokens": [51100, 1854, 300, 15640, 291,
  600, 668, 807, 309, 558, 291, 600, 668, 884, 341, 337, 370, 867, 924, 611, 51384],
  "temperature": 0.0, "avg_logprob": -0.1462329047066825, "compression_ratio": 1.6201117318435754,
  "no_speech_prob": 0.008417884819209576}, {"id": 518, "seek": 298192, "start": 2982.0,
  "end": 2991.76, "text": " Facebook at scale but you want to continue to do that
  so I am the way I think about this is there''s", "tokens": [50368, 4384, 412, 4373,
  457, 291, 528, 281, 2354, 281, 360, 300, 370, 286, 669, 264, 636, 286, 519, 466,
  341, 307, 456, 311, 50856], "temperature": 0.0, "avg_logprob": -0.08384686787923178,
  "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.003769760252907872},
  {"id": 519, "seek": 298192, "start": 2993.6, "end": 2999.44, "text": " there''s
  like a shiny problem at the heart of all this that I love and if you if you let
  me", "tokens": [50948, 456, 311, 411, 257, 16997, 1154, 412, 264, 1917, 295, 439,
  341, 300, 286, 959, 293, 498, 291, 498, 291, 718, 385, 51240], "temperature": 0.0,
  "avg_logprob": -0.08384686787923178, "compression_ratio": 1.6627906976744187, "no_speech_prob":
  0.003769760252907872}, {"id": 520, "seek": 298192, "start": 3000.2400000000002,
  "end": 3008.08, "text": " I will sit there and like I will be happy if like I just
  come into work every day and like look", "tokens": [51280, 286, 486, 1394, 456,
  293, 411, 286, 486, 312, 2055, 498, 411, 286, 445, 808, 666, 589, 633, 786, 293,
  411, 574, 51672], "temperature": 0.0, "avg_logprob": -0.08384686787923178, "compression_ratio":
  1.6627906976744187, "no_speech_prob": 0.003769760252907872}, {"id": 521, "seek":
  300808, "start": 3008.08, "end": 3013.04, "text": " through the corridors and and
  fix bugs anything that''s crashing then look through the profiles and", "tokens":
  [50364, 807, 264, 46920, 293, 293, 3191, 15120, 1340, 300, 311, 26900, 550, 574,
  807, 264, 23693, 293, 50612], "temperature": 0.0, "avg_logprob": -0.11945095768681278,
  "compression_ratio": 1.9918367346938775, "no_speech_prob": 0.004618676844984293},
  {"id": 522, "seek": 300808, "start": 3013.04, "end": 3019.52, "text": " like optimize
  code I can just do this this just makes me happy and so like building like reliable",
  "tokens": [50612, 411, 19719, 3089, 286, 393, 445, 360, 341, 341, 445, 1669, 385,
  2055, 293, 370, 411, 2390, 411, 12924, 50936], "temperature": 0.0, "avg_logprob":
  -0.11945095768681278, "compression_ratio": 1.9918367346938775, "no_speech_prob":
  0.004618676844984293}, {"id": 523, "seek": 300808, "start": 3019.52, "end": 3025.36,
  "text": " scalable systems make me happy so there''s like this shiny problem in
  the middle of all this and", "tokens": [50936, 38481, 3652, 652, 385, 2055, 370,
  456, 311, 411, 341, 16997, 1154, 294, 264, 2808, 295, 439, 341, 293, 51228], "temperature":
  0.0, "avg_logprob": -0.11945095768681278, "compression_ratio": 1.9918367346938775,
  "no_speech_prob": 0.004618676844984293}, {"id": 524, "seek": 300808, "start": 3025.36,
  "end": 3030.72, "text": " it''s like the common thread through everything that I
  could just do and be happy and it it''s rewarded", "tokens": [51228, 309, 311, 411,
  264, 2689, 7207, 807, 1203, 300, 286, 727, 445, 360, 293, 312, 2055, 293, 309, 309,
  311, 29105, 51496], "temperature": 0.0, "avg_logprob": -0.11945095768681278, "compression_ratio":
  1.9918367346938775, "no_speech_prob": 0.004618676844984293}, {"id": 525, "seek":
  300808, "start": 3030.72, "end": 3036.4, "text": " and rewarding right and so that
  like the basis of like it''s really easy to like this stuff so", "tokens": [51496,
  293, 20063, 558, 293, 370, 300, 411, 264, 5143, 295, 411, 309, 311, 534, 1858, 281,
  411, 341, 1507, 370, 51780], "temperature": 0.0, "avg_logprob": -0.11945095768681278,
  "compression_ratio": 1.9918367346938775, "no_speech_prob": 0.004618676844984293},
  {"id": 526, "seek": 303640, "start": 3036.4, "end": 3040.88, "text": " then obviously
  you have to extend upon that like the way that you get driven beyond the shiny",
  "tokens": [50364, 550, 2745, 291, 362, 281, 10101, 3564, 300, 411, 264, 636, 300,
  291, 483, 9555, 4399, 264, 16997, 50588], "temperature": 0.0, "avg_logprob": -0.07752901012614621,
  "compression_ratio": 1.9254901960784314, "no_speech_prob": 0.00015686126425862312},
  {"id": 527, "seek": 303640, "start": 3040.88, "end": 3045.28, "text": " thing because
  you know I could go do that for like Minecraft mods I don''t have to do that for
  databases", "tokens": [50588, 551, 570, 291, 458, 286, 727, 352, 360, 300, 337,
  411, 21029, 30899, 286, 500, 380, 362, 281, 360, 300, 337, 22380, 50808], "temperature":
  0.0, "avg_logprob": -0.07752901012614621, "compression_ratio": 1.9254901960784314,
  "no_speech_prob": 0.00015686126425862312}, {"id": 528, "seek": 303640, "start":
  3046.32, "end": 3054.8, "text": " is like in some larger mission that like you feel
  connected to so for me the the mission here was", "tokens": [50860, 307, 411, 294,
  512, 4833, 4447, 300, 411, 291, 841, 4582, 281, 370, 337, 385, 264, 264, 4447, 510,
  390, 51284], "temperature": 0.0, "avg_logprob": -0.07752901012614621, "compression_ratio":
  1.9254901960784314, "no_speech_prob": 0.00015686126425862312}, {"id": 529, "seek":
  303640, "start": 3054.8, "end": 3059.92, "text": " a little bit too old the people
  was actually kind of the original driving force like this is the", "tokens": [51284,
  257, 707, 857, 886, 1331, 264, 561, 390, 767, 733, 295, 264, 3380, 4840, 3464, 411,
  341, 307, 264, 51540], "temperature": 0.0, "avg_logprob": -0.07752901012614621,
  "compression_ratio": 1.9254901960784314, "no_speech_prob": 0.00015686126425862312},
  {"id": 530, "seek": 303640, "start": 3059.92, "end": 3063.76, "text": " people I
  don''t even care what we''re I don''t care what we''re doing like let''s go do it
  like us as a", "tokens": [51540, 561, 286, 500, 380, 754, 1127, 437, 321, 434, 286,
  500, 380, 1127, 437, 321, 434, 884, 411, 718, 311, 352, 360, 309, 411, 505, 382,
  257, 51732], "temperature": 0.0, "avg_logprob": -0.07752901012614621, "compression_ratio":
  1.9254901960784314, "no_speech_prob": 0.00015686126425862312}, {"id": 531, "seek":
  306376, "start": 3063.76, "end": 3068.8, "text": " group that''s gonna be fun but
  then the whole AI thing I mean look I we can get philosophical you", "tokens": [50364,
  1594, 300, 311, 799, 312, 1019, 457, 550, 264, 1379, 7318, 551, 286, 914, 574, 286,
  321, 393, 483, 25066, 291, 50616], "temperature": 0.0, "avg_logprob": -0.06892404040774784,
  "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0020170139614492655},
  {"id": 532, "seek": 306376, "start": 3068.8, "end": 3074.8, "text": " want to get
  philosophical do it real quick there''s like two or three nominations for technologies",
  "tokens": [50616, 528, 281, 483, 25066, 360, 309, 957, 1702, 456, 311, 411, 732,
  420, 1045, 46331, 337, 7943, 50916], "temperature": 0.0, "avg_logprob": -0.06892404040774784,
  "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0020170139614492655},
  {"id": 533, "seek": 306376, "start": 3074.8, "end": 3081.6800000000003, "text":
  " that will change the 21st century like and I you got to work pretty hard to not
  put AI at the top", "tokens": [50916, 300, 486, 1319, 264, 5080, 372, 4901, 411,
  293, 286, 291, 658, 281, 589, 1238, 1152, 281, 406, 829, 7318, 412, 264, 1192, 51260],
  "temperature": 0.0, "avg_logprob": -0.06892404040774784, "compression_ratio": 1.7636363636363637,
  "no_speech_prob": 0.0020170139614492655}, {"id": 534, "seek": 306376, "start": 3081.6800000000003,
  "end": 3086.96, "text": " of that list maybe there''s some other ones you could
  argue like maybe nuclear fusion is a 21st", "tokens": [51260, 295, 300, 1329, 1310,
  456, 311, 512, 661, 2306, 291, 727, 9695, 411, 1310, 8179, 23100, 307, 257, 5080,
  372, 51524], "temperature": 0.0, "avg_logprob": -0.06892404040774784, "compression_ratio":
  1.7636363636363637, "no_speech_prob": 0.0020170139614492655}, {"id": 535, "seek":
  306376, "start": 3086.96, "end": 3092.0, "text": " century revolution maybe gene
  editing like I don''t know you could come up with something but like", "tokens":
  [51524, 4901, 8894, 1310, 12186, 10000, 411, 286, 500, 380, 458, 291, 727, 808,
  493, 365, 746, 457, 411, 51776], "temperature": 0.0, "avg_logprob": -0.06892404040774784,
  "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0020170139614492655},
  {"id": 536, "seek": 309200, "start": 3092.0, "end": 3099.12, "text": " chances are
  that AI is gonna be like a defining 21st century technology so you''re gonna let
  me play", "tokens": [50364, 10486, 366, 300, 7318, 307, 799, 312, 411, 257, 17827,
  5080, 372, 4901, 2899, 370, 291, 434, 799, 718, 385, 862, 50720], "temperature":
  0.0, "avg_logprob": -0.17327480316162108, "compression_ratio": 1.726027397260274,
  "no_speech_prob": 0.0004677653778344393}, {"id": 537, "seek": 309200, "start": 3099.12,
  "end": 3105.76, "text": " with my shiny toys in that yeah that''s okay I''m out
  of bed now right I''ll get out of bed I''ll come", "tokens": [50720, 365, 452, 16997,
  13753, 294, 300, 1338, 300, 311, 1392, 286, 478, 484, 295, 2901, 586, 558, 286,
  603, 483, 484, 295, 2901, 286, 603, 808, 51052], "temperature": 0.0, "avg_logprob":
  -0.17327480316162108, "compression_ratio": 1.726027397260274, "no_speech_prob":
  0.0004677653778344393}, {"id": 538, "seek": 309200, "start": 3105.76, "end": 3110.72,
  "text": " I''ll come get out of bed and I will let''s go let''s go build something
  so that''s I think that''s", "tokens": [51052, 286, 603, 808, 483, 484, 295, 2901,
  293, 286, 486, 718, 311, 352, 718, 311, 352, 1322, 746, 370, 300, 311, 286, 519,
  300, 311, 51300], "temperature": 0.0, "avg_logprob": -0.17327480316162108, "compression_ratio":
  1.726027397260274, "no_speech_prob": 0.0004677653778344393}, {"id": 539, "seek":
  309200, "start": 3110.72, "end": 3116.4, "text": " my answer to your question amazing
  and I think you got it on from here to really and", "tokens": [51300, 452, 1867,
  281, 428, 1168, 2243, 293, 286, 519, 291, 658, 309, 322, 490, 510, 281, 534, 293,
  51584], "temperature": 0.0, "avg_logprob": -0.17327480316162108, "compression_ratio":
  1.726027397260274, "no_speech_prob": 0.0004677653778344393}, {"id": 540, "seek":
  311640, "start": 3116.4, "end": 3124.7200000000003, "text": " and they saw passion
  knowledge so you did see the movements so I''m really excited to see what", "tokens":
  [50364, 293, 436, 1866, 5418, 3601, 370, 291, 630, 536, 264, 9981, 370, 286, 478,
  534, 2919, 281, 536, 437, 50780], "temperature": 0.0, "avg_logprob": -0.2578787857227111,
  "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.007722989656031132},
  {"id": 541, "seek": 311640, "start": 3124.7200000000003, "end": 3131.52, "text":
  " you guys got a built thank you so much for joining me today to discuss yes we
  didn''t go to the", "tokens": [50780, 291, 1074, 658, 257, 3094, 1309, 291, 370,
  709, 337, 5549, 385, 965, 281, 2248, 2086, 321, 994, 380, 352, 281, 264, 51120],
  "temperature": 0.0, "avg_logprob": -0.2578787857227111, "compression_ratio": 1.6741071428571428,
  "no_speech_prob": 0.007722989656031132}, {"id": 542, "seek": 311640, "start": 3131.52,
  "end": 3138.08, "text": " NM tuning this algo and this is how the algorithm goes
  but hey I really enjoyed the product level", "tokens": [51120, 426, 44, 15164, 341,
  8655, 293, 341, 307, 577, 264, 9284, 1709, 457, 4177, 286, 534, 4626, 264, 1674,
  1496, 51448], "temperature": 0.0, "avg_logprob": -0.2578787857227111, "compression_ratio":
  1.6741071428571428, "no_speech_prob": 0.007722989656031132}, {"id": 543, "seek":
  311640, "start": 3138.08, "end": 3146.0, "text": " this is what this is on the money
  some during my company say yeah fantastic thank you so", "tokens": [51448, 341,
  307, 437, 341, 307, 322, 264, 1460, 512, 1830, 452, 2237, 584, 1338, 5456, 1309,
  291, 370, 51844], "temperature": 0.0, "avg_logprob": -0.2578787857227111, "compression_ratio":
  1.6741071428571428, "no_speech_prob": 0.007722989656031132}, {"id": 544, "seek":
  314600, "start": 3146.0, "end": 3153.28, "text": " much Luis you know enjoy your
  day and let''s talk soon awesome thank you for having me and yeah happy", "tokens":
  [50364, 709, 25133, 291, 458, 2103, 428, 786, 293, 718, 311, 751, 2321, 3476, 1309,
  291, 337, 1419, 385, 293, 1338, 2055, 50728], "temperature": 0.0, "avg_logprob":
  -0.2339029592626235, "compression_ratio": 1.275229357798165, "no_speech_prob": 0.02100030519068241},
  {"id": 545, "seek": 314600, "start": 3153.28, "end": 3156.0, "text": " to chat again
  all right cheers bye bye", "tokens": [50728, 281, 5081, 797, 439, 558, 15301, 6543,
  6543, 50864], "temperature": 0.0, "avg_logprob": -0.2339029592626235, "compression_ratio":
  1.275229357798165, "no_speech_prob": 0.02100030519068241}]'
---

Hello there, vector podcast. Season three and this promised I'm trying to shoot for 30 minute episodes. Let's see how I'm going to do on this one. I'm super excited to have Luis Brandy, vice president of engineering at Rockset. I know you guys are building database.
Hey Luis, how are you doing? I'm doing great. So far so good. Thank you for having me today. Oh yeah, excited. Excited to learn about Rockset as well. But before that, it's a tradition.
Could you please introduce yourself a little bit about your background and how you got to your stage in your professional life? Sure. So I've been at Rockset for two years and change over two years. VP of engineering. Before that, I was at Facebook for 11 years.
So I did roughly three things at Facebook and it's funny because even the ones that feel least relevant have become more relevant recently. I did spam fighting infrastructure for my first much of time at Facebook and that involved like two large systems.
One was like a super real time system, which turns into the real time database we're going to talk about today. And the other was we did a lot of vector clustering. Like back I was doing vectors but way before they were cool. This time was like 2011, 2015 or so.
And we used vectors a lot in in spam fighting and image classification. And this is like even before like the deep learning took over the world like this is right before deep learning changed everything in this in this space. But we were using vectors a lot.
We built some pretty powerful systems actually built like large scale vector clustering. I don't know before it was cool. Now everyone's building large scale vector applications. And then I worked on a lot of other stuff at my time at Facebook.
So there was a lot of core C++ core libraries, a lot of infrastructure stuff. I worked on an open source stuff called folly and thrift. So these are basically like core libraries that Facebook has released over the years. And the theme of all this is like highly scalable infra.
And then I did some real time and some vector stuff back in the spam fighting days. It's not totally applicable necessarily to the modern world. But it's still pretty interesting background. It a very interesting confluence of things that have brought me to Roxette.
So yeah, that's my life story roughly and in nutshell, there's more. But I think that will do for the for the intro. Yeah, for sure. Very exciting, really exciting. I heard about thrift.
And I also remember like early on many years ago, when some of you guys were on stage, you know, from the engineering at Facebook, you would constantly, you know, hint to the point that yeah, we ran out of the capabilities of this database. So we needed to scale up.
We needed to build a new one sometimes. And that was really really interesting that it's constantly like, you know, you're always battle against too many images, too many videos and so on and so forth. Yeah, one thing that I've always said was that like everything is broken at scale.
 Like like, there's this idea that sometimes you reach for the right tool for the job, but the reality is like when when you push the even the right tool to the limit, it will fall over and you'll find yourself doing things that other people, you know, rebuilding something that other people take for granted.
Like my favorite example of this is at Facebook, we had a team on on my core C++ group that was working on Malak. Like who who works on Malak? It turns out there are people that work at Malak.
They're most of them work at like a place like Facebook or Google or places like that, but but that's like the kind of thing where you can save a lot of money by making tiny improvements to Malak. So it's worth doing. It's amazing. I remember I did a bit of a C++ as well.
I guess like you could say two and a half years.
And at some point in the 90 virus company here in Finland, I had to choose which Malak will it be, right? And I had to sort of discuss with my team and I was like, struck really, is that really the thing we need to discuss?
And they said, yeah, actually you won't believe because we are running on a mobile phone back then it was this Microsoft's Windows mobile, I guess it was called, right? So you have to be really careful to the round.
Yeah, I mean, there's only here for Malak's in the world. So you might have chosen ours. Who knows? Amazing. All these say is that you've been really, really deep and low level. And so I think you you doubled in coding obviously, right? Yeah. So I was a fairly technical.
I've been a manager for relatively long time. I don't know, 12 years or so, but I've always been a fairly technical manager in my path. And so for example, for years I worked in the course, SQL's plus libraries at Facebook, even while I was a manager, even a director.
I was on the SQL standards committee for a while and doing things like that. Sorry, I got paged. Everything's fine. So yeah, I've definitely worked in the code. I've tried to stay as hands on as possible. In most recent years, it's become increasingly difficult.
I just I don't know, it's sort of the dark side of management. You slowly slide into more managerial things. But I still try to stay about as hands on as I possibly can. Oh, tell me about, tell me about me about that.
I mean, I'm also on the product management side today and previously a manager of people as well. And I'm like, am I sliding backwards? Do I need to? Sometimes I do, but it's not on the same level as it used to be for sure. But it makes sense to stay on these topics.
And and then after all these years, you decided to move to Roxette. I've read a blog post that I think you've written for the company where you give the reasons why you did so and you explain about the team strengths and so on support. Some of them are from Facebook as well.
Today matter, right? Can you sort of repeat that story a little bit like why you moved from a big company you could say, right? To a startup. So the answer is in short is the people. The core group at Roxette is a bunch of, I shouldn't say the core group now.
The core group now has grown a lot, but the original founding or was a bunch of extremely strong Facebook people that I knew from Facebook and from. And so you know, you mentioned rebuilding databases.
For example, like two of the main people were probably three of the main people responsible for rebuilding databases at Facebook are at Roxette. So Drupal, who's who's our CTO was built RoxDB at Facebook.
And that was part of replacing the storage plan of my sequel and a highly scalable way at Facebook. And then of course, the graph database that powers literally all of Facebook like Facebook is a graph and it is primarily powered by a graph database called Tau.
Nathan and Vencat are two people who worked who worked on that at at extensively at like tech leads and founders in some sense of that project Facebook. So this is like extremely pedigree group.
So to me, I don't care so much about it, they're also like genuinely amazing people to work with and work around.
 And so this is kind of this idea of like, hey, you want to join us startup with a bunch of the smartest people you've ever worked with and like try to do something and worst case scenario, you know, it all goes, you know, kaput or whatever, but you have like you worked with like some of the best people on a really interesting problem for a couple years.
And I was like, yeah, I'm in for that. There's a longer version of that story, but that's that is really the central reason of why I ended up I ended up switching. Yeah, I mean, it sounds like a brilliant reason too.
But I'm also interested you said you've been using embeddings before like Facebook and on vectors and you said that prior to deep learning era.
So can you explain a bit like how these vectors were sort of created if it's possible? So there is some sensitivity here, but it's not maybe for the reason you think it's not a trade sensitivity. The sensitivity with abuse abuse use cases. What we were doing was image classification.
 And and most of this is I'm not going to go into too much detail for maybe obvious reasons, but there are there are images that you are not allowed to to to use or put up and they and and obviously what they don't want to do is hand all these companies like the images and say if you see this illegal image, tell us.
So oftentimes they give you hashes. And but these aren't actual hashes. They are not a hash of the illegal image. They are a locality sensitive hash and they're a vector. What they are is literally a vector.
And Euclidean distance is the measurement of so you basically have a a classic vector search problem. You're given a pile of vectors. If there's a technology known as photo DNA that you can look up. It's it's not as far as I know it's not like an open standard.
So you don't actually it's not actually in the public domain. What it actually is, but it's effectively a mechanism for turning images into vectors that's used as this hashing mechanism.
And and so Facebook built a bunch of infrastructure to flag hashes that came through for reasons that are not fun to talk about. Let's put it that way. Like they're there. There's like again, I don't want to get into it.
It's kind of it's awful, right? But at the end of the day, like you have you have vectors flowing into the system. And what you're doing every single upload is is doing essentially a vector search.
You're saying, Hey, given this corpus of vectors is this vector that fly that's coming in match any use. That was the basic core of the system. But once you have this like these vectors, you can start to do other abuse things. So for example, you can start clustering vectors.
You can build vector clusters. And that way you can find like neighborhoods of images, like similar images. Now here similar is here similar means something quite different. Because these were not like semantic similarity.
So this is not like what you would get from an embedding today from like say, you know, any of the modern. Yeah, I heard clip. Yeah, whatever. Yeah. These were these were these were much more like text textual. I mean, texture. People familiar with like image processing techniques.
This is these are vectors based on things like local pixel gradients or wavelet transforms things like that.
So when we say images were similar, we mean to things like, you know, like rebalancing the white scale or or changing the hue and saturation like like those kinds of image manipulation or re encoding it right from a different JPEG, different JPEG encoding.
Like it was tolerant to that kind of manipulation, not like it wasn't like finding images of elephants, like that's that's not what it was doing. Yeah, yeah, I remember I took a course. Actually, I studied master degree in Finland here dedicated to data security.
And one of the courses was about, you know, how you can temper with images that had watermarks, right? So like, yeah, and then how do you make that watermark resilient to any tempering that might happen on the image level, right? On any of the bands and stuff. And as you explained, he was in stuff.
So that's basically they digital image processing is the word to Google if someone wants to. And then it's like a big, big topic. But what struck me and what you explained is that every image upload had to go through that process, which means it had to be super scalable.
And also your database of vectors would be ever growing all the time as the image passes through or doesn't, you would need to add it somewhere to your vector space. So in this case, no, this is the one advantage we had, because we only care about matches to a specific relatively small set.
Oh, I see, I see. So it's like a set that shouldn't grow ideally, right? Yeah, or very, very nominal. I see. Yeah. And so this is, so it's funny because that that's a big difference that that makes it easy in that era.
Today, you'd have to bust out all the A and N stuff and maybe stuff we'll get into to really be able to do a really much more scalable vector search. So this was really more about evaluating a relatively fixed set of vectors.
So you can hyper optimize how that was organized in like a, and, but evaluating it at an insane scale. So the update problem wasn't very hard, but the evaluation problem was like it needed to be extremely high scale. Yeah, a bunch of questions in my mind, but let's move move on to Roxette.
Tell me more about the what part, you know, what it is as the product. And then slowly, let's go deeper into the technology side. Yeah. So my standard statement of what Roxette is is Roxette is a search and analytics database built for the cloud.
And that's a bunch of, I forgot one, it's a real time search and analytics database for the cloud.
Now that's a bunch of little buzz worries that, you know, it's very easy to get lost in the kind of marketing feel of that, but each of those words does like non trivial amounts of work and what it is I'm really trying to build here. So first of all, it's a search and analytics database.
So here, what we mean is like a like an OLAP style analytics database is like it's it's like that's where we're starting. We want to run an analytics type queries and this I won't get into all of this, but this is like separate from your OLTP style databases.
So this is not my sequel, not a large transactional thing. It is a but is it OLAP style database.
And search and analytics is a very interesting pairing in this world because systems like elastic search or very search oriented system systems like rocks that have analytics styles, but these are actually not that different architecturally. They're very the way you use them may feel different.
The primitives you're using feel different, but all that sits fairly shallowly in the technology. The underlying architecture of these systems ends up looking quite similar. So search and analytics actually go together quite nicely from like a I can do both.
Maybe I don't do both well, but that will mostly exist at the top, not not in the not in the infrastructure. It's in the cloud. So the whole system is built to be elastic from the beginning. So if you send me twice as much data, I can scale you out in a way that you know, like it just works.
You don't have to worry. You're not reprovisioning more machines to double your cluster size or anything like that. And then real time.
So our focus has always been real time, which is to say specifically most people when they think of real time they want their queries to be fast, but the real heart of real time is ingest latency.
So if you send me new data, how quickly does that data get manifested in the queries? If it's tomorrow, if it shows up in tomorrow's queries, you're not that's not a real time system.
And there's a lot of systems like this, these very big batch style, like mega exabyte type of like doob clusters that you you can query yesterday's data, right? And get and get like genuinely enormous amounts of data. That is not rock set like as that's not rock sets problem.
But for us, it's like, hey, if you want like last minutes data and it's ideally several zero smaller of a working set, then that's where rock set is meant is meant to work really well. And so this is like the heart of this is what we've set out to build at a high level.
And I don't know if you want to do want me to keep going. I don't know. I feel like I've already said too much. I want I want no, it's amazing. It's a good start. I wanted to stay a little bit on the product side. If you go now and flip over to the use cases for the moment.
So what are the typical use cases and sort of can you zoom out as much as possible, maybe even giving, you know, even if hypothetical, it's fine. For example, so products that use your product. Yeah. So we we have a bunch of customers in a bunch of different domains and it's we can even go.
So so one way to think about this is just like who's using it and why like what domains are they using it in? And so for example, we have a bunch of gaming customers. So this is like there's real time events occurring in games.
Imagine an online an online game of some sort and they're collating that information constantly and having it be real uptime say leader boards or things like that are happening. There's a lot there's several actually like logistics and supply chain type people using it.
 So like where is my package right now or where is the boat in the ocean like these kinds of queries are like very commonly done, you know, like where is the where they're basically tracking their entire supply chain trying to find shortages and what's going to create problems down the line in like a logistic type settings.
There's a lot of FinTech. There's a lot of financial financial firms use it a lot of fraud detection. So again fraud and spam these are very real time problems. You can't like detect yesterday spam or fraud. That's like really harmful. You got to you need to know now right.
And then a lot of like recommendation and like product experience. So anytime that like you want to power a user facing experience, you almost always need that to be real time. So you know example I like to use is there's a there's a there's a place called what not if you go to what not.
com if you've never heard of it. What not is basically a streaming site for buying and selling. So it's sort of eBay meets Twitch kind of a easiest way I could describe it. But what's really cool about that is you have a recommendation problem like I want to buy something or people selling it.
So I it's really in the sites. And my interest were you to show me like you might want to check these things out. That's like a recommendation problem. But it's like really real time right. It has to match me to online sellers at any given moment.
And so it's a recommendation system that has to get built needs decent amount of needs high scale. And it also needs to be real time. It needs to use a lot of real time data. So these are all use cases for Rockset. These are every one of these is real customers using Rockset to do something.
Yeah, for sure. Now I want to go back to jump back to tech side. So Rockset and inside it are you using RocksDB or something else? So okay. So okay. Are we using RocksDB? So first of all do we know what RocksDB is? Just everyone's on the same page.
RocksDB is an engine that was built by Drew Bat Facebook. And I shouldn't say by Drew, but by a team that Drew was a part of. Like he was one of the original founders of that team. There's certainly a lot of people involved in RocksDB. It's a key value store right.
It's built sort of to scale very well and sort of do log structure merge over time. Rockset absolutely uses RocksDB as its storage plane. And so there's a lot of Rockset built on top of RocksDB. So Rockset is not RocksDB as a service. That is not what Rockset is.
We do use it as the storage plane of Rockset. And we do take heavy advantage of, again, to get into the technical weeds a little bit like log structured merges to keep our indexes sort of up to date continuously. And that is a big part of like the real timeness of Rockset.
Like being able to update the index continuously and having this like heavy weight infrastructure to merge these indexes and then the kind of the appendonly log structured way that you do. And the LSM world is part of the secret sauce.
It's not that secret, but it's part of the secret sauce of Rockset. Yeah, for sure. But then also all these things like vector search, you know, storing the embeddings. Is that also happening outside of RocksDB? Basically, in the layer you explained.
So hold on, you asked about vector, what were the things? Oh, embeddings. And embeddings and vector search itself and the sort of a and n indexes presumably. Yeah.
So the a and n index, so we've added, we've extended RocksDB a little bit to kind of have this notion of a blob of memory that you attach to a particular thing. It's what's going to be the a and n index. And then you can build custom operators to merge them, for example.
And so that we do, we do essentially shove the a and n index into this. And so it gets into RocksDB. RocksDB doesn't know about a and n indexes. It just knows there's a blob of memory that it has to log structure merge down the road. As far as embeddings, for us, that's just arrays.
So for us, an embedding is just a vector. And for us, a vector is just an array. There's no real difference in the way these things are stored. And those are stored in RocksDB. Yeah, got it.
And so, and basically, what other AI capabilities does RocksDB offer, you know, basically everything? What's the secret source of that thing? So they're facing, right? But still. So I have two, there's a few things to talk about here. We talk about secret sauce.
So one thing we skipped over about one thing that's worth touching on in terms of RocksDB or architecture is RocksDB has two things that you hope every database has, but not every database has one is we have disaggregated storage, like fully disaggregated storage.
So if you double your storage, you can, you can, basically, you can double your storage, you can double your compute, you can do either. You don't have to do both, right? You can, they are stable.
They, there's compute optimized machines and storage optimized machines, and you can add to either group independently. We also have compute and compute isolation. So you can set aside a set of machines, for example, just to do ingest and a different set of machines, just to do queries.
And they both operate on the same backend, for example. You can go farther than that.
You can have different groups of machines for different sets of queries or by 10 in or whatever you can go wild with this idea, isolating compute from it's from each other, right? Once you have disaggregated storage, this is an idea you can do.
This is already really powerful for AI use cases, like in a way you don't necessarily appreciate, because what it means is I have a way to do my index rebuilds, which are expensive in a vector world, away from the machines handling queries.
Like I'm not, like what's not going to happen is the machine, the database is going to bog itself down doing an index updates of some sort while queries are trying to be served and you're going to get time out. So being able to actually separate out compute is very powerful in these AI settings.
Again, another example, no one's done this like in total anger yet, but it's going to come, which is like the hey, I have a god awful amount of vectors. I want to update them to the next generation of my the new open AI model has come out. I want to rerun the entire data set.
We can do that in this kind of like off on the side fashion in a way that just reduz it all in place without affecting the running application as an example.
So that's one like kind of very architectural found is a very database type of a feature that you you will miss it if you don't have it when the day comes.
Moving up to kind of more AI level things, the other thing that we have is like we have a huge pile of infrastructure of like doing SQL and relational queries, right? In this system that's separate from the vector stuff.
So when the vector stuff gets mixed with that stuff, the things get very powerful and very magical.
And so this gets you into so there's it's funny because database people talk a certain way and AI people talk a certain way and a lot of times they're actually saying the same thing, but they use none of the same words.
And so they don't know they're talking about the same thing, but as an example, like so in an AI context, things like metadata filtering or hybrid search, these are all things Rockset does out of the box.
Like metadata filtering in an AI context or a vector context, that's just like the wear clause of a SQL query. Like that's all that is like where X is created and this time is created and that. Like so for us, it's that's all done. Like metadata filtering is easy. That's not a hard problem at all.
All you have to do is you know, I have a super powerful query language. I'm query optimizer. All you have to do is kind of merge that with the a and n kind of vector search and I get like metadata filtering is like a not that's not a hard problem for us to solve.
Like it would be for others to solve. And so I do think we really shine in situations where a you care about real time ingest, be you care about any kind of hybrid or metadata filtering.
Rockset's really good as well for for kind of raw vector power, but I wouldn't say we're like the best database in the world for like, I don't know, I view it more like we kind of going where our customers are taking us.
Like if the customers came to me as like, Hey, if you if you if I can have 10 times more vectors and like 4% more precision and recall, if you implemented this slightly better algorithm with these parameters, we would do it.
But almost always it's like they want we want that like hybrid search seems to be the king. Like it's it's it's merging these things. And that's where like a lot of our effort has gone is into making the hybrid search story like making these two worlds work together like fairly seamlessly.
Like be able to say like show me the closest 10 vectors that were updated in the last 10 minutes. Like that that kind of query is really powerful. And that's kind of what we've been focused on in terms of in terms of. But I guess the timestamp example you gave it's also like metadata check right.
It's kind of like way close where you say between a and b timestamps. Yes. Yes. But like hybrid search at least the way I'm hearing people do this is that let's say take the search domains example.
You might have a keyword search right which is your sparse index and then you have your then syntax vector search. And you want to combine the two in some way. For example, you could say I still trust keyword search. So let's give it 75% of weight and then 25% goes to vector.
And then you combine them into leave them in some merging strategy. And then you return back to the user. Is this how you see hybrid search or do you see? So I have a whole ran here. You might you might have yes you've unlocked my ran here.
So let's go so hybrid search is one of these very overloaded terms exactly as you have kind of this is kind of sometimes what people mean. Sometimes people do they they smuggle metadata filtering as a hybrid search.
Strictly speaking under my definition, metadata filtering is a kind of hybrid search. It just sort of has extreme weights right like it's weight one if it matches and zero if it doesn't. And so it's kind of like a weighted hybrid search.
You can also do this kind of linear combination hybrid search right like I have a BM 25 keyword type a ranker which by the way, rockset can do like rockset has this rockset you can build you can do this order by keyword ranking limit 10 like you could write that.
And then you can also then do the vector limit 10 like show me the 10 closest vectors. There's nothing stopping you from saying or you know order by 0.25 of that plus 0.75 of that for example, in your in your example.
So that kind of linear combination hybrid search is is doable like that that's how that's how you could do rockset. Sorry, that's how you can do that kind of hybrid search on rockset today.
 Now you people do do slightly more advanced things than this by the way there are like you can go beyond that in hybrid search and get into things like by encoding and crossing coding where you really do try to take the the expanded vector space and treat it non-linearly so it's no longer a linear combination of the two halves.
And we've this is this is something we are actively looking at.
 I don't so it's I don't think it's hard to add like it's easy extension onto onto onto the current system but it's more of like a science question like it's more of like if you tell me what to add I'll add it sure that's easy but it's like what do we add like what's the right crossing code I don't know that's a much harder problem that's like much more of a scientific question in terms of like do I need to train an encoder for your particular use case is there such a thing as a good off the shelf one right so that's that's kind of where we're at with this but but in terms of adding that functionality that is like an active you've you've this is the this is the frontier right now for us that's for those people that they're trying to go beyond the kind of bilinear yeah wait yeah another thing yeah bilinear is it's it's amazing maybe you can share some resources as well for for me and the audience to read but also I thought you know when hybrid search sort of topic emerged right in in the vector database world you know bb8 pine cone milbus what you're like and so on I think one thing that was overlooked and I really wanted to tap into that at some point is to learn the alpha rise because it's not given like how should you come if you go with linear combination you know what should be the alpha for your data yeah it's fun yeah this is what's certain like the search community has been doing things like this for a long time like search people are quite familiar with this idea of I have a semantic search system I have a keyword ranking system I have an alpha and I've learned I learned that alpha and I inject it into my system and then they've even gone farther like search has this whole like wand idea people I don't know if people are familiar so again we have to have all these community like weekend weekend exactly right joe bersham listening to this podcast will probably say yeah I know what you're talking about yeah yeah yeah so it's funny because like the vector community is sort of like I mean it's not it's not rehashing it's not relearning because it's got this new thing this a and n things what's got to like drag a and through the search history of like things these other kinds of things so yes so so learning the ant parameter um this is not a particularly hard thing to do using rock set but it's not a thing we we don't we don't help you like I don't have a button you push to to automatically learn your your alpha like you can send me whatever query you want it can have whatever alpha in it you want you can build whatever system you can query us arbitrarily to generate an alpha however you'd like and and then send me the queries with the alpha you you you you you dreaded and ready but that's that's roughly how that's going to look today for us yeah do you think at all maybe picking a little bit into the future and sort of inspiration do you think at all that the industry you iin one day will end up suggesting these values to their users you know learning from the data and sort of maybe even like you know looking at how things behave you know introduction what do people click although yeah there is a risk of going too much into the application logic which you probably do not want to do but I know I my view is kind of like so once upon a time I had a similar feeling this reminds me of a similar discussion that didn't happen that long ago which was like around feature stores like database people looked at feature stores and we're like what do you need a feature store for like you just use a database store for features and the reality is most feature stores that's what they are they are databases that on top of them put a lot of things to help manage as a first class citizen the lifetime of a feature like orchestration platforms like like techton and he's like orc orc orcust and that orchestration systems that's that's what you're I think it no matter what there'll always be a database in there and something like rockset will be in there and the question of whether or not rockset the company is like a larger piece of software that has rockset the database and some orchestration layers above it to help you do these kinds of things that's a harder question I think that if you ask me to make a prediction about where things are going my guess is that for the foreseeable future hybrid searches king of some kind so very few problems will be purely vector search I that's my guess almost all will be will we greatly benefited by some form of hybridization even if it's just metadata filtering um and then that means that the more advanced search techniques that will slowly migrate over which means things like alpha learning and weak and and all these other kinds of higher level two-stage retrieval type ideas that that come from the search world I do think will come over and more and more influence the vector search world because the vector search ultimately is a form of search so it shouldn't be surprising that most of these same ideas are still still apply yeah for sure I mean there is this extreme example from Mark Cuban the episode on Lex Friedman podcast that they just finished listening to he says that probably in the future all of us will have their own LLAMs trained for whatever reason you know for example you want to do stock trading and so you start you know draining your model maybe on specific subset of stocks or whatever and then it will help you it will augment augment you as they say yeah as an entity yeah I would love I would love for a chat GPT that could like put in making an email sketch me a skeleton email in my voice like the chat GPT voice if I say hey write me an email to say this to somebody it's not my voice right it's a I don't know it's a little too corporate my voice is a little bit more yeah so it'd be cool to have it like learn my voice and be able to you know write me a skeleton that of something that was like sounded like me that would be that would be awesome I'll be I'm there for that yeah what I would like that some model or whatever it is would remind me that I forgot to drink water you know something like that so it learns my habits and it knows that it's bad for my health you know remember to do these remember to stand out remember to walk things like this you know I drank some water that's good everyone drinks water yes yeah please do because it's very healthy you need to drink I guess two liters a day whatever some people do forget this and then they say have you know I have to take pink here or so whatever no you don't just drink water but so what else do you want to share about Rockset you know as an offering as a AI enabler you know maybe do you guys plan to support rag or do you think rag is sort of like client side you know thing as well that people can do you know using your tap things like that no no we we um we actually have a bunch of rag type style use cases on Rockset today and I do I do think Rockset naturally supports rag but it's interesting so like I guess one of the my kind of open questions is pure rag and I'm making up a term here but but but it is actually one of the very few like almost perfect vector use cases in its pure vector search but I'm actually not convinced because even most of the people that we're we know that are doing like rag style things want are also doing some amount of boosting and or metadata filtering to like further augment like hybrid augmented the retrieval that augments the generation um uh and so so for example like hey if the user asks about a certain thing when you search for blurbs to augment the generation boost the more recent ones kind of a kind of a thing like there's this kind of thing that gets injected into these systems um yeah so I'm I'm we you can build this with Rockset today and I'm quite keen on on these kinds of use cases I would say that like like looking forward I'm I am quite interested in this kind of emerging dynamic of like where the real value is from here they're sort of like at least three dimensions things could go one is like better and better an an algorithms that squeeze more performance and more scale and more whatever recall out of out of everything out of every bite of RAM and so forth and so on another direction is incrementability so a lot of these there's a lot of a lot of these like really advanced really strong systems sorry a n n indexes are not updateable easily so the sort of updateability destroys a lot of what you just worked really hard to build or you spend way too much CPU to do it so which is better like which which in on in real life which are the what I rather update twice as fast or twice as painlessly or what I rather get three and a half percent more you know on my precision recall and then the third dimension is how do these things integrate with other indexes right so certain a and n indexes are much better at doing meditative filter at scale than other ones are and so you know if there's more value in that than the 3% I got over here then I so it's not all together clear we are pretty heavily betting on the I shouldn't say we're betting on it like right now we we got the hybrid stuff relatively easily so that's the thing that we're building heavily because all the all the hybridization has been and the the incrementability because that's core like so for us the incrementability is like not you have to have that I can't use an an index that requires like overnight training like that's not a thing that that rock that doesn't work with rocks x we were trying to be real time and then I guess there's like one fourth dimension that could blow all this up which is that somehow the vectors get so good that none of the rest of this matters like maybe there is maybe there is no rag maybe there is no like maybe the vectors just good enough maybe the machine is smart enough that we don't need any of the rest of this we don't need any hybrids I think that's unlikely in the short and medium term but who knows in the in the long that's probably require some kind of singularity yes it is jump right because that means that you do not need foundational models from metal whoever right you could train it from scratch and if you can do it within a couple minutes then why would you bother taking those models right that's very interesting it's my that that's that's why I said there's three and then I threw the fourth one in because I it's it's not impossible but I think it's not likely not anytime exactly I mean it's probably if this is about to happen then probably we would already see the room like you know the signals of that but today still we can see how these giants keep training the models and they keep open sourcing sometimes encodes sometimes for real but yeah it's it's another topic to cover I have a very practical question as well so for example if I do have a model and that model could be from Higging Face for example so it's not mine how do I bring the embeddings to Rockset can I leverage the Rockset's infrastructure to compute the embeddings themselves so this the answer in short is no today and it is on my list super high on my list so there is a customer who came to me tomorrow and was like hey I want to run this model using your infrastructure over my data I'd probably find a way to make that work for that like an existing customer like I would like because that's a feature I want to build I'm like waiting for the excuse to build that the problem for me is it's just really hard to build generally like if it was like call this API or support these exact kind of models it's not so hard but to do it in general without having like a specific customer demand it's a little bit trickier so we can kind of wait until that take a little bit more shape but we have the pieces in place like it's not hard for me to spin up a bunch of machines that run on your data and write to your database I just it's the actual like last mile of wire of like what code do I run how do I secure that code you know like that kind of stuff that's like what's missing from us so today and today you have to give me the embedding you're gonna have to run them and put them in a rock set but this is at the top of my list of sort of features I want to build yeah I mean it just sounds and by the way you know if you take database today probably you could divide them into two groups you know using these dimensions specifically whether or not you can compute embeddings inside and sometimes you do not want that because you want to like fine tune the model and obviously the database wouldn't have access to it unless there is a very easy way to plug it in which I haven't seen by the way probably I'm missing something but I haven't seen it and everyone today has some sort of vector support you know both the traditional databases as well as this new breed of vector databases but yeah that's interesting that's interesting that you guys are looking in that direction what else you know like if if someone wants in the audience wants to try rock set today you know do they need to pay it right away well can they have some free tier to play around oh there's free there's free tiers yeah so you can play around you can play around for free in rock set and uh if anybody is like super interested and they have something interesting and they they they can always email us too um we we will try to find a way to make make make that stuff work as much as possible but yes there is a free tier you can go back around with it yeah um and um it is managed so that the one thing you have to understand about rock set is the managed service right so you're not going to download it and run it or whatever it's not that's not the way it works no and and by the way that's exactly the advantage for businesses right and that's why we do have different business models you know because in the end of the day you're not doing this only for fun you you really need to run money too for the company to grow and and build more things for your users and so that's absolutely legit uh approach not everything needs to be open source you chose it that way but it's great that you have free tier and we can also link it in the show notes sure um what are you looking at you know do you need some you said you have already so many clients in different nations different verticals what else would you benefit from by sharing rock set into a wider community you know through these podcasts all right so there's a lot of ways to answer this question but but this is the vector group right so selfishly I kind of already hinted at this is I'm trying to get a clearer sense by where the value is going to come from in for vectors in the in the short and medium term for people like there's a lot of people out there and we saw this there's a million people trying to oh my god vectors are happening how do I plug this into my business like is there it's can I use this and we've seen a bunch of interesting super novel use cases like things you would not expect and you know there's an insurance company that want to that wants to like scan internal documents you know do they want to do search they want to do like internal search semantic search um and so for me my my most selfish interest here is to really get a clear picture of like which of these like little subdomains is actually really providing like real value like what is really what is really like taking off it's hard it's sometimes it's hard to tell like who's just messing around because everyone's messing around literally everyone is messing around and who's like actually latch on to something that's got some real legs and every time we find a customer that's got like real legs we dig in we're like all in we're like all right how can we help you like let me let's you know again like the the I'm waiting for one of these people to come back and be like can we retrain our embedding so like all right yeah let's go build it right so that's kind of my yeah I I want people to keep messing around with this stuff I I want to figure like all of us messing around it is going to find where it gets traction like where we can get our hooks in and where things start to start to really make progress and then I just want to hear from those people like I want to know what what you need every time we talk to someone it's something new and surprising right um and that's kind of though yeah when the real world intersects with all this like you know uh in my head it's all an indexes and graph theory or whatever but but uh when the real word intersects is always something like simple that you need that would make your life a lot easier and that's the kind of stuff that I'm eager to hear yeah I think uh I could share with you without saying what would be okay uh one uh member of my team said hey we're we're we're using one one um search engine today which also has you know beyond the um sparse indexals that vector search support and so he was saying okay they're using hnsw algorithm but I cannot tweak the amp parameter and I forgot what was the second parameter and look because I cannot do that recall is really below what it needs to be it just doesn't work and then he went online it's an open source database he typed you know the issue on github and they realized oh we missed really important thing so they quickly uh expose the parameters and so he now can tune them right so so yeah the tuning of the index is another this is a good one right so a lot of these systems have like a tier there's like a coarse grain and a fine grain so you have hnsw over IVF or hnsw over or IVF or IVF and then each of these has parameters and so you get these like massive config strings that set that say how these are built um and we we expose this so you can do all this stuff but in real life if you're building like what what number do you even pick like how do you know I don't know that person must have gone through a lot to decide they needed to change that ever because it's not obvious it's not like oh yeah you it's like you look at the data like 16s wrong like the infrastructure to like optimize this system is not trivial and then even if you do optimize it you have to rerun everything you have to rebuild that index right once you kind of trained it so to speak so yeah I think that's a that's a huge area where our our infrastructure is not helpful at the moment yeah but I'm sure you will learn in general excited like Luis look you have so much information that I think we should record another episode as well down the road as you guys progressing on the database and you add all this interesting you know tweaks that and not to the database as well but I'm also super excited about the direction because basically you offer like if you take pure vector databases you know they do not implement SQL support right right they like the purpose of what what the existence is something else right they've been designed to have vectors as the first class citizens and so they they make it super easy to plug in a model or actually have the model you know almost pulled from hugging face or some other model storage model model hub but then when you want to do some facets or whatever you want to call them aggregations right that's not as easy depends on database probably as well but I've seen some I don't want to name them but in any case they know it's it's a weak point and it's probably because they do not want to serve that segment of the market maybe they do it's partially right but it's so hard yeah exactly yeah I mean I think that the really good vector databases who succeed will slowly turn into databases and databases will turn into like these things are merging they're just coming at each other for different directions like like if you're at a vector database if you're building a vector database and you're looking at your metadata filtering support you're like I can't make this more powerful without just reinventing SQL like at some point I'm going to have to just build SQL and so one day they're going to bite the bullet and we'll I mean maybe not SQL but something you know SQL complete if you will right because you just need all that stuff and then pretty soon you get into the problem of like hey my metadata filter is the slow part of this of my thing so now what like oh now I'm doing query optimization like SQL query optimization like now I'm building query optimizers like metadata filter optimizers and you know so we have all that like we brought all that to the party right like I have a I have a cost based optimizer for my SQL query so if your metadata filter does crazy stuff I can like do you know all kinds of SQL magic to like to optimize this query but on the flip side like yeah like so everybody's everybody I think the good systems need all this stuff it so it's just we took a hard problem we took two hard problems and we say congratulations this now one hard problem and it's like okay well okay it's a big hard problem yeah I love how you you model it that this database is and non-data bases sort of will converge eventually even though everyone I think at this point calls themselves a database yeah probably minor exceptions but still you are spot on on whether or not first of all what is a database right and then whether or not you have all these features that that need to be supported and and also like really importantly the world is used to having SQL databases right so like if you sort of I don't have a better analogy but basically if you develop something and you say it can run but cannot walk and you're like okay but sometimes you need to walk right that's amazing before we close I really like to ask this question with some people find it a little awkward to answer but I do feel it's important it's a little bit philosophical and I ask what drives you it used to be why you do this but basically when you wake up you know you are driven to continue but what's inside that spinning you've been through it right you've been doing this for so many years also Facebook at scale but you want to continue to do that so I am the way I think about this is there's there's like a shiny problem at the heart of all this that I love and if you if you let me I will sit there and like I will be happy if like I just come into work every day and like look through the corridors and and fix bugs anything that's crashing then look through the profiles and like optimize code I can just do this this just makes me happy and so like building like reliable scalable systems make me happy so there's like this shiny problem in the middle of all this and it's like the common thread through everything that I could just do and be happy and it it's rewarded and rewarding right and so that like the basis of like it's really easy to like this stuff so then obviously you have to extend upon that like the way that you get driven beyond the shiny thing because you know I could go do that for like Minecraft mods I don't have to do that for databases is like in some larger mission that like you feel connected to so for me the the mission here was a little bit too old the people was actually kind of the original driving force like this is the people I don't even care what we're I don't care what we're doing like let's go do it like us as a group that's gonna be fun but then the whole AI thing I mean look I we can get philosophical you want to get philosophical do it real quick there's like two or three nominations for technologies that will change the 21st century like and I you got to work pretty hard to not put AI at the top of that list maybe there's some other ones you could argue like maybe nuclear fusion is a 21st century revolution maybe gene editing like I don't know you could come up with something but like chances are that AI is gonna be like a defining 21st century technology so you're gonna let me play with my shiny toys in that yeah that's okay I'm out of bed now right I'll get out of bed I'll come I'll come get out of bed and I will let's go let's go build something so that's I think that's my answer to your question amazing and I think you got it on from here to really and and they saw passion knowledge so you did see the movements so I'm really excited to see what you guys got a built thank you so much for joining me today to discuss yes we didn't go to the NM tuning this algo and this is how the algorithm goes but hey I really enjoyed the product level this is what this is on the money some during my company say yeah fantastic thank you so much Luis you know enjoy your day and let's talk soon awesome thank you for having me and yeah happy to chat again all right cheers bye bye