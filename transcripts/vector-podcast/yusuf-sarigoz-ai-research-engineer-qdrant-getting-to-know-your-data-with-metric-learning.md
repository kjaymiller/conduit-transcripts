---
description: '<p>Topics:</p><p>00:00 Intro</p><p>01:03 Yusuf’s background</p><p>03:00
  Multimodal search in tech and humans</p><p>08:53 CLIP: discovering hidden semantics</p><p>13:02
  Where to start to apply metric learning in practice. AutoEncoder architecture included!</p><p>19:00
  Unpacking it further: what is metric learning and the difference with deep metric
  learning?</p><p>28:50 How Deep Learning allowed us to transition from pixels to
  meaning in the images</p><p>32:05 Increasing efficiency: vector compression and
  quantization aspects</p><p>34:25 Yusuf gives a practical use-case with Conversational
  AI of where metric learning can prove to be useful. And tools!</p><p>40:59 A few
  words on how the podcast is made :) Yusuf’s explanation of how Gmail smart reply
  feature works internally</p><p>51:19 Metric learning helps us learn the best vector
  representation for the given task</p><p>52:16 Metric learning shines in data scarce
  regimes. Positive impact on the planet</p><p>58:30 Yusuf’s motivation to work in
  the space of vector search, Qdrant, deep learning and metric learning — the question
  of Why</p><p>1:05:02 Announcements from Yusuf</p><p>- Join discussions at Discord:
  <a href="https://discord.qdrant.tech">https://discord.qdrant.tech</a> </p><p>- Yusuf''s
  Medium: <a href="https://medium.com/@yusufsarigoz">https://medium.com/@yusufsarigoz</a>
  and LinkedIn: <a href="https://www.linkedin.com/in/yusufsarigoz/">https://www.linkedin.com/in/yusufsarigoz/</a>
  </p><p>- GSOC 2022: TensorFlow Similarity - project led by Yusuf: <a href="https://docs.google.com/document/d/1fLDLwIhnwDUz3uUV8RyUZiOlmTN9Uzy5ZuvI8iDDFf8/edit#heading=h.zftd93u5hfnp">https://docs.google.com/document/d/1fLDLwIhnwDUz3uUV8RyUZiOlmTN9Uzy5ZuvI8iDDFf8/edit#heading=h.zftd93u5hfnp</a>
  </p><p>- Dmitry''s Twitter: <a href="https://twitter.com/DmitryKan">https://twitter.com/DmitryKan</a></p><p>Full
  Show Notes: <a href="https://www.youtube.com/watch?v=AU0O_6-EY6s">https://www.youtube.com/watch?v=AU0O_6-EY6s</a></p>'
image_url: https://media.rss.com/vector-podcast/20220507_080542_57009c58f961b6d0713e057b9a5a4832.jpg
pub_date: Sat, 07 May 2022 20:37:42 GMT
title: Yusuf Sarıgöz - AI Research Engineer, Qdrant - Getting to know your data with
  metric learning
url: https://rss.com/podcasts/vector-podcast/479453
---

Hello, today we have a new episode of the Vector Podcast and today I'm super happy to have you, Suf Sangos, with me. He holds the role of AI Research Engineer at Quadrant.
It's a Vector Search Database Company and you might remember we had an episode with Tom Lackner, who is the user of Quadrant today. We have an episode and discussion with you, Suf, who works for Quadrant.
And one of the core topics today we're going to be discussing metric learning, but before that, hey, you Suf, how are you doing? I'm very excited to join you in this episode to discuss metric learning and thank you for having me. Yeah, thanks for coming up.
Really, I think this topic is something that has been crossing my area of focus and also some of the questions that users are asking, you know, okay, if I have this data set, how can I be sure that it will work with neural search, right? And I think metric learning seems to be one of the answers.
But before we start discussing this in deep, in depth, I was thinking, could you please introduce yourself to our audience? Yes, sure. Armist has told Suf's software developer and AI researcher with a background in linguistics at the university.
Actually, I've been developing software since my high school years. During my master's study, I combined my experience and my education to study machine translation.
After several years of experience in different roles and at different startups, I ended up with the multi model retrieval because I had a long experience in both computer vision and measured language processing. So for some time, my main focus is metric learning.
I was already a user of co-advent, even before joining co-advent and I thought it would be very cool to work for an open source project that I find valuable myself. Yeah, sounds awesome. Sounds cool. You just mentioned multi model.
So you mean like multi model search, right? And I think this field is still kind of in many ways shaping up and many people are still learning and kind of scratching their heads like what is multi model? Like maybe if you could give an example or a little bit explain what is multi model. Yes, sure.
Actually, as you just said, multi model is quite a new topic actually. Actually, it's resurrecting with developments in deep metric learning. One of the most famous applications is a clip by OpenAI, short for contrastive language image, the pre-training.
In the most basic term, they train a model to construct a unified vector space for both images and tests. Basically, they have two encoders, one for images and one for tests, support that you have a pair of images and its textual description.
When you see this image and that textual description to these encoders, you are supposed to get very similar vectors, vector output from these encoders. So you can search images with a textual query or Y-14.
So you sort of crossed the, so in a way with one modalities text or image is another modality, but in this case, we kind of like cross go across modalities. I think we can cross the border of modalities with this.
Yeah, which I think to many users will sound like a magic because you essentially, if you view an image like a set of pixels and if you query textual queries a set of words, now you sort of somehow magically search your words in pixels, but actually that's not exactly what's happening.
Of course, we do the embedding and so on, but in a nutshell, it kind of sounds like this magical cross model search there.
 Yes, I expected for newcomers is a little bit like magic, but from quite a long time, we have already been using vector search in the context of image search, but in that case, we search for images with a query which is image if that, but in this case, we make a connection between two modalities actually.
This is also how our human brain is functioning.
For the most of the time, we don't consume the information from a single modality actually when we try to understand our environment, we both take it as a visual input and also an audio input and we also talk to people around them for it gives us a better understanding of the environment.
So if we want to make our AI smarter, we also need to help them gain this ability as well. So beyond searching for images with a textual query, this also helps us to combine information from different sources.
So in this case, maybe we can also have AI better understand its environment by combining, for example, a stream from the camera and also maybe an output from a speech recognition and encoding them into a vector we can combine these two vectors to fit into that encoder.
So this also opens such new opportunities. Yeah, that's a great intro there also like how you gave analogy with how human brain functions, so like how we take so many signals into our decision making.
And specifically, like what you mentioned about clip, I like the fact that in practical settings, let's say if you have images, let's say of some goods and you want to make a search in those goods and you also have some metadata, let's say titles or descriptions, right?
It may be that some human decided what to put in that text, but they didn't put everything that there is on the image, right? And so I think clip helps us to find sort of semantics that's hidden inside the image itself, right? So I think that's kind of like has practical impact on what we built.
Yeah, exactly.
 Actually, in the traditional source, for example, let's get the product source as example, when you want to develop a product source for, for example, an e-commerce website, you need to enter different terms that can define that product to have a user's find that product with different wording, but this is not so practical because people use very different terms to refer to things.
And you in the current capacity of e-commerce websites, we have hundreds of thousands of products and they also need to be updated once you add new products and remove new products.
And also like myths acted at typos to this complexity, is actually explored to millions, maybe a tens of millions of possibilities. This is beyond the power of humans actually.
But once you make connections, make a connection between text and images, you don't need to enter such descriptive text, you only encode images into vectors and index time into a vector database.
Then in the inference time, all you need is just encode the textual input as well and create that pre-indexed database to get similar results.
Actually, this also buildings new opportunities, for example, people usually enter some pre-defined textual descriptors in this search engines, but some new products may have brand new features that people are not accustomed to.
So even in this case, our vector search based solution that combines images and text can be in that image as well. Yeah, that sounds cool. So it kind of opens up a lot of opportunities that didn't exist before when we modeled our object purely through textual representation.
Maybe somebody did attempt to also encode images of some other binary format, but I think maybe it wasn't as efficient or definitely not multi-model. So that sounds so cool.
And so how do you connect? Where do you start? Usually, let's say if you have a data set, right? And you want to implement neural search experience.
At one point of time, do you start thinking about what the metric is the best for my data set? And also, how do you approach it from which angle do you usually approach this? And this is something that really helps you to hear your theoretical as well as practical thoughts of this.
Yes, you're actually there are lots of very different techniques and methods and approaches to metric learning that can work for some specific types of problems.
But in my practical experience, I usually begin with with with an auto encoder, because it's already very easy to implement and easy to train. It can be applied to almost any data track. Basically, in auto encoders, we have two models and encoder and the encoders.
The encoders part encodes samples into an dimensional vector. This and should be much lower than the dimensionality of the input sample. And the decoder is supposed to reconstruct the input sample when this encoded vector is given to it. So this is a the self-provised method.
So it can be applied to any type of data set. You don't need labels. It usually gives a very good resource. After training such a model, you can visualize embedding. We call the output of the encoders, vectors embedding. So you can visualize such embedding with a tool.
This tool can be, for example, TensorFlow projectors and another tool by Yubach. I just couldn't show my word in there. Sorry. No worries. We can find those links later, I guess. Yeah, we can put a link in the description.
And this visualization tools have us see if our encoders really involve similar samples need to each closer to each other than the similar ones. If it is, we can use this encoders part.
We can just dispose the decoder part and we can simply keep the encoder part and use it to encode our samples and index them in the vector. And we can already start searching semantics. But we usually do buzzers than this one with only small set of labeled data.
And you actually need only a few with that one. Actually, we are preparing some publications to demonstrate this one. After you train and encoders with a considerable number of unlabeled data, all you need to do is just to find to in it with a small set of labeled data.
On the supervised site, there are really quite a number of very different approaches to matrix learning from more traditional margin-based approaches to newer categorization-based approaches. And actually, they deserve a long discussion of data. For sure. Yeah, that's awesome.
But just to unpack it a little bit, so in a natural metric learning process allows me to learn the optimal distance metric for my data. So it's kind of like a function of my dataset properties, inner properties. Yeah, actually, let's clarify this metric thing.
What does it mean in this context? In this context, a metric is a non-negative function with two inputs. Let's say X and Y. And it is used to measure what is called the distance between X and Y. When we feed such two inputs, it gives us a scaler's positive value.
If this value is closer to zero, then we can assume that those two inputs are more similar to each other with two inputs with a higher distance value. So our whole objective in metric learning is to train functions that can give this distance value.
On the practical site, we usually train a model that outputs a vector and a dimensional vector. And then we can apply different distance functions such as Euclidean and cosine distance to get a measurement of the distance value. There is also a term deep metric learning.
Actually, the traditional metric learning uses some linear transformations to project samples into an dimensional feature space to apply a metric function.
But this linear aspect of such transformations limits the use of traditional metric learning using time with more richers, data types, for example, images and texts.
So deep metric learning benefits from the methods of deep learning to learn non-linear transformations to project samples into a new and dimensional vector space.
But in this context, I usually use metric learning as an umbrella term to refer to both traditional metric learning and deep metric learning. Just like we do with machine learning to refer to both classical machine learning and deep learning. Yeah, that makes sense. Thank you.
And so essentially, in the lay main terms, deep learning allows us to vectorize data objects that previously we couldn't vectorize in a celly, so images or I don't know. And do it efficiently, because in images, you might have way too many pixels.
So if you just take the vector of all the pixels, it's way too big of an object to deal with. And so you vectorize, as you said, in the beginning, and you basically sort of project it in a lower dimensional space. So now you can actually efficiently operate on it. Exactly.
Let's get images as an example. Let's assume that we have images with a size of 200 times 200. And we also have a channel value of three. So we end up with 200 times 200 times three values for a single image. And also, let's actually, too many values also mean a great variance value.
So it's not so practical to make a measurement between two images, because those pixel values can include very surface, quite shallow surface features that do not make any sense in our semantics.
But once we encode those high dimensional inputs into a low dimensional vector space, for example, we usually have 500 to 12, 10 to the 12, 12, 12, 14 dimensional vectors. And this value is really low when compared to the original dimension of that sample.
So in this case, that model should learn, should learn a representation of high dimensional samples. Actually, we just throw the unnecessary part of those samples, and we only keep the part that matters for us. Yeah, yeah.
So kind of in some sense, you could say it's like signal compression, right?
So in some sense, like using the signal law, like the distribution, you could actually compress things, like I don't know if theoretically speaking in an image, you have like one object, and the rest is just the background of one color.
You really don't need to pass all these pixels independently, like you could just say, okay, it's a background I've learned that it's that color kind of semantically, I guess, and then what matters is the object somewhere there that we focus on when we look at this picture, right? Yeah, exactly.
Actually, in the original distribution case, for example, of images, we don't have any connection between the value of a pixel and the semantic counterpart of that pixel one. But once we transform it into a vector space, at least theoretically we can make conclusions.
For example, we have a 1024 dimensional vector as a representation of that image. In this case, if we examine this vector space, we can make conclusions of this value in the index zero, in cause the features of this feature of image.
For example, it can, in cause the size of a specific object or the colors value of a specific object or maybe some more abstract features of objects. This enables us to search it more efficiently instead of otherwise our values are actually distributed to a very wide range.
And we don't have such interpretations in that distribution space. Yeah, that makes sense. It's a very unique high variant and also in some senses, like waste of space because we are not communicating that much more information by sort of encoding all these pixels.
But we could actually extract some features and patterns in the image.
I think some early work on this was done using, if I remember, it was called a Godworth filter or some other ways of kind of smoothing your image and trying to learn what features you have, for instance, if you try to differentiate between spruce and widely trees.
So like for the purposes of keeping one tree and then maybe removing the others. But I think it wasn't as efficient perhaps as compared to deep learning because deep learning, as far as understanding, basically like learns without features in many ways.
It learns from the data and then you should have some target function that you're optimizing for so it can recreate the weights inside it. Exactly.
Actually, what is most differentiating feature of deep learning is deep learning is actually used to learn the parameters of complex functions instead of manually tuning them. Before deep learning, we already had most of the filters we currently have.
But the parameters of such filters were supposed to be manually tuned by experts in that domain. But in deep learning, we learn those parameters directly from data. And as you said, actually, the beginning of metric learning is also in dimensionality reduction.
We have most popular contrastive loss, for example.
 And the first introduction of contrastive loss is in 2005 and the original purpose of that function actually to reduce dimensionality of high dimensional inputs rather than vector source or anything F for actually another end just tried to reduce the dimensionality of high dimensional input to use lower dimensional input F features to other models.
Yeah, that sounds exciting. Actually, before you brought this up, I didn't think that way because I was experimenting in my team also with things like product quantization. So you do have all already the vectors computed by the neural network, but you could actually quantize them even further.
So you save space and maybe of course you introduce some overlaps that might decrease your precision, but slightly, but you're gonna save a ton of space and make your search more efficient.
So it's almost like you could think of dimensionality reduction in so many different levels and ways as you have the reason about your data, right? Yeah, exactly.
Actually, metric learning is itself a type of dimensionality reduction, but even after you apply metric learning and vector encoding to your data, you still have a high dimensional vector. You have, for example, 10, 10, 10, 10, 4, dimensional data times 32 bits for a single flaw.
So it's already a huge data when you have, for example, millions of samples. So you can still actually apply some quantization methods to get even smaller representations from that one.
And this can be also hierarchical, meaning that you can get several representations of the same sample at different levels of information encoded in that feature space. Yeah, that's fantastic.
 So I was also thinking like, if you could give like some practical example or setting where I could start thinking about deploying metric learning and also like, could you sort of point us in the direction of what tools are available so that I don't think we need to reinvent everything from scratch, but maybe there are some practices, also best practices available, you know, to structure this process.
Can you give some advice on that? Yeah, sure. For a starter example, actually, metric learning is best known for is used in face recognition, but personally, I don't support use of machine learning to process biometric information.
So I give an example from our everyday life, actually, we almost everyday use it, smart deploy. The feature found in, for example, GMA, LinkedIn, and other messaging apps. Actually, it is trained from a large collection of conversation histories in these platforms.
Basically, they just like the example we put in the beginning image and textual unified vector space, they construct a unified vector space for conversation histories and single sentences.
For any moment of conversation, you encode the history of that conversation to retrieve most relevant replies to that history. And you can show them as suggestions to the usage, and users can pitch one of them.
And what is exciting with this setup, you can also log the chosen reply, and you can continue improving your model from direct feedback from your actual users. So it's a really practical use case of metric learning.
And for practitioners who want to start experimenting with metric learning, actually, there are lots of tools to solve very few problems in metric learning.
So in the context of deep learning model development itself, we have several libraries, such as high-torch metric learning and transfer flow similarity.
There are other libraries as well, but I think these are the most mature libraries and most cultural, how should I say, virtual libraries to tackle with different data tasks.
On the other hand, for visualization, we have this transfer flow projector, is a browser-based tool for you can examine your embedding easily with that one.
There are also vector search databases, there are increasing in numbers, but of course, I am a fan of Quaddon because it's really doing a great job with an extensive filtering support for a variety of data tasks. And it's doing this very efficiently, very elegant in only 40 megawise.
So it opens up very important is to put your metric learning model into production and to combine vector search with super search as well. So you can just filter your data based on their payload information at the same time as vector search.
I think these are other than that, beyond beside my research and engineering practices, I'm also maintaining a repository called Automatic Learning and I'm regularly sharing new developments in the domain of metric learning with personal annotations.
So I think it might be also quite helpful for those who want to find their ways in this domain. That's awesome. Thank you.
I will certainly make sure to add all of these links in the description notes, in the notes to this podcast and usually all of these podcasts that I do, they have a lot of links that actually you almost can use as an educational material. And thanks so much for adding so much information here.
And I actually wanted to drill a little bit again into that example that brilliant example you gave about predicting sort of what snacks when I type.
Actually, I used this feature quite a lot and especially like when you're on the go and today I think I've used it somewhere with a Gmail, I was on the go and I had only one finger, right?
So just holding my phone as I go and there was a question and the answer was something, yes, it happened or yes, it did.
And maybe it wasn't the best sort of semantical choice or maybe not the most elegant choice linguistically, like maybe I would add more color, but because I was on the go, it was fine to save that, you know, few minutes and don't be distracted by the phone.
So I just pressed that button and off it goes. And so that's a fantastic feature. So I wanted to sort of open up the process a little bit of metric learning in this case. Basically, I imagine and please correct me if I'm wrong.
As an input, I would have, let's say, a pair of sentences that what was the input and what was the prediction and that prediction could be either curated by experts or we could have minded from the logs, whatever.
So let's say we have a corpus like this, right? So we can employ sequence to sequence model or some other model to actually train like our first first predictor.
So at which point would you start thinking and how exactly would you start thinking about metric learning? Like how can I change the behavior of my model? Like will I replace like last layer of my neural network with like different layer that I have learned from metric learning?
Can you a bit open up this kitchen for me? Thanks.
Actually, this smart supply has its own paper by Google as well and they are really doing a great job to describe the whole logic to whole design decisions behind this feature.
 As you already said, the suggested duplicates are not the best, the most specific replies that you can imagine, but this is actually are spied design because they do not generate those replies, but they have a large collection of such replies and they should be as flexible as possible to fit into different circumstances.
So they shouldn't have any specific references to a specific sentence in the conversation. So that should be a generic enough to apply almost any conversation.
For the training slide, yeah actually, they filter a large collection from the different platforms they are running Gmail and other platforms and they filter short replies and thematically more broad samples such as as you gave as an example. Yes, I did or no, I didn't does it have such examples.
And the actual training algorithm works like this. They actually come up with a very creative, very clever, lost function for just a terrain with this model. They have only a pair of two samples and there is no other label or information.
We only have one input and one ground truth, we have no other scoring, no other label or anything else. So we only get a batch of, for example, and samples and we encode those two and samples because we have two samples first page and we end up with two and samples.
And once we encode them with our encoder, we can compute a distance matrix between these all posts of the encoder. A distance matrix is a two-dimensional matrix to define every distance value between all possible pairs in a collection.
So we have a matrix of five and times and and we already have these samples as pairs. We already know that there is a company target samples for the sample, for the first sample at index zero, the company sample should also be at index zero for sample at index one.
The company sample sample should be at index one. So we can generate these target labels just based on this information. So it's like a categorical classification now.
So for the first sample in the pair at index zero, the categorical label should be zero and others all index values should be wrong.
So we can just encode this information as a one-heart encoding and we can simply use a Crohn's entropy loss once we encode this information as a one-heart encoding and we can train this model with this loss.
So it is called multiple negative ranking loss because in in some way we rank all possible replies in a batch with multiple negatives and only one positive sample. Yeah.
And so you would train this network with this with this loss function and so the output will be what? Like will it be like the optimal metric or optimal? Yeah.
In one, we train this model, we end up with a model that can encode a sentence in such a way that that vector can retrieve the most relevant vectors from a collection of possible replies. So after we train this model, we encode all possible replies and index them in a vector database.
And at the inference time, we encode the usage input again with this model and make a query, a vector source query to that pre-index database of possible replies and we can get, for example, a car, a chain, a nearest neighbor to that vector to suggest to use it. Yeah.
I mean, after you explain this, like to me, like the mental image that evokes is that we sort of like learn rather than learning the metric, we're actually learning the vectors themselves.
We're learning the best vector representation for our object to satisfy some goal, right? Let's say that for this sentence, the closest reply should be this in some sense. Yeah, exactly. Actually, the model learns a representation that satisfies the satisfies our purpose.
So in some way, we can fully pick any distance metric based on this intuition. Yeah. So the second part of your question, when we can think about metric learning.
Actually, metric learning can be applied to almost any domain of problems, but there are some particular cases where metric learning really shines over other alternatives.
These are actually data scarce regimes, especially for labeled, if you are short for labeled data, you can still do a pretty good job with, for example, auto encoder, as we already discussed previously. And also, if you have rapid-changing distributions, it's again, very helpful.
And if you have, for example, a very, very high number of classes, again, metric learning can do a good job. Finally, metric learning is one of the best way to be able to actually increase the performance of machine learning models, even after training.
In normal deep learning training, there is no way to increase the performance of a model after training is complete. But in metric learning, this is quite possible.
For example, instead of just a training classification model to make a probability distribution over set of classes, we can train a metric learning model and encode samples with that model to store somewhere.
And during the inference, we can query that store to get more similar chain nearest neighbors and decide on the predicted category based on the majority of those chain nearest neighbors. This is called chain uncostication, in fact.
And in the practical side, on the practical side, you can continue to add new samples to that store without any need to retrain the model. And once you add new samples to that store your model performance will also increase.
And also, there is another use case, for example, a more recent approach by DeepMind. Up until now, the only way to make AI smarter is usually train a bigger and bigger language model. But in the most recent study by DeepMind, they augment language models with retrieval capability.
This means actually they encode and store a large collection of corpus in a Rector's database. And during the inference, they query this database to get most relevant sentences, most relevant text to the user input. And they combine them to feed to the model.
And with this technique, they can achieve the same performance as GPT3 with 25x less parameters. So it's a very efficient way of AI. So I'm also quite happy to see the direction of AI towards a more efficient one with metric learning as well. Yeah, yeah, it's fantastic.
And I think it's like a good impact on the planning, because I don't think we want to spend too much electricity on all power and training neural networks. Yeah, exactly.
And it also enables democratization of Deep Learning, because not everyone has the same resources as this large companies as Google, Facebook, and OpenAI. So I think it's also important for that reason as well. Yeah, that's fantastic. I mean, you gave quite a lot of detail on metric learning.
Of course, there is a ton to learn. And I even, I've seen like a book cited on one of the metric learning pages that I found through your awesome metric learning resource. And now that we touched a bit on where the AI is also going and then how to make it more efficient.
I also like to ask a question of why sort of this magical question which drills into your motivation as to why at all you are in this space, let's say deep learning and quadrant vector search and also specifically metric learning.
Can you a bit elaborate on the philosophy that drives you here? Yes, sure. Actually, what motivates me to work with metric learning is it's potential to approach many different problems very efficiently.
Before metric learning actually, you need to train very different models to solve very different problems. But with metric learning, you can train a single model and you can use the very same model to solve very different problems.
And this is also another fight that makes metric learning efficient. Actually, metric learning has a great potential, but you also need a great tool to put it into production. For example, upon to now there was no way to combine vector search with paid-out information.
Even if you make a connection, it was not for practical because you lose some information because you do not, you could not filter the tool systems of information at the same time. Quadrant is doing a great job by combining vector search with filterable paid-out information.
So it opens up quite a few new opportunities. For that one, you can filter your information based on if geographic, geographic place, for example, or another sparse category, numeric value or anything else while at the same time doing a vector search. So I think it's really exciting.
One of the most common problems in AI, you actually do the research, but you don't have the required tooling to make it practical in the real world.
So I think it's quite important to have such tools as Quadrant to achieve very different, very difficult and challenging problems very alien than efficiently. Yeah, absolutely. That's quite deep. Thank you so much for sharing this.
It also resonates with me because in many ways, you know, deep learning on one hand, maybe some people feel like it's kind of overhyped and there is so much material on the web.
On the other hand, when you start doing it yourself, you might end up, you know, going into down the rabbit hole and you don't know all the tools as you said. You don't know all the best practices.
And also, like, before we had vector databases, you couldn't actually, well, apply this, like, okay, you could of course build some nice demo and, you know, throw a web page and just ask somebody, okay, type something here and my neural network will do something.
But now, like, you could kind of scale this further and index your embeddings and see the end result of what you're doing through the retrieval process. So I think that opens up a lot of opportunities. So that's super cool. Yeah, exactly.
Actually, once we have such tooling, the domain is also improving more rapidly and also the improvements in the domain also foster development of such tools.
So I think it's like too far and it will be a metric learning will be in a better place in the future with this rapid developments in the domain. Yeah, absolutely.
And I was thinking, like, there's like a ton of material, I'm sure we'll have to digest, at least I will have to digest a lot of it and see how I can apply this. And thankfully, you have, you know, you have this awesome metric learning resource on GitHub that we can check out.
We'll make sure to leave it in the notes. And if if some of us want to kind of work with you or interact with you, can you make like a little announcement where we can join forces and kind of learn more about metric learning and maybe contribute to this field together with you? Yes, you're right.
I have several announcements maybe. First, beyond my resource and engineering site, I'm also a community guide guide and we have a difficult server at Quadrant where we hold paper reading class. We had the first one about contrastive laws and we will also have another fashion about triplet laws.
And I also wrote a wrote an intuitional triplet law post. Our approach will be like, after I will write such intuitional post about papers and then we will hold Q&A sessions in our discourse servers.
So everyone who is curious about metric learning can join the discourse server to enjoy this discussion. Apart from that one, beside my professional life, I'm recognized as a Google developer expert on machine learning, on the volunteering site, community site.
And this year at Google's thunder off call, I will serve as a transfer flow mentor for the transfer flow, the library take Python package, if a package for metric learning in the transfer flow ecosystem.
So university students and fresh graduates can apply to Google's thunder off call if they want to work with me in this effort and contribute to the field. That's fantastic.
 I think Google's thunder off code is an exciting place to be and there are so many projects but it's great to learn that you are leading the metric learning exploration there and I'm sure there will be interest towards it and I will make sure to also leave the relevant link in the show notes on this.
Yeah, thanks so much. Use of this this was a pleasure to discuss with you. I feel like I dipped some of my fingers in the water of metric learning. I think there is still a ton to learn and thanks so much for introducing it from so multiple angles. We've enjoyed this conversation.
Thank you Dimitriv again for this great opportunity. I hope the audience also enjoyed it as well and I hope it will be helpful for those who are interested in metric learning. Yeah, for sure. Thank you so much.
I learned a ton and I hope I'll also see you maybe doing some presentations or reading your blogs to learn more about it. Thanks so much. Thank you so much. Yeah, bye bye.