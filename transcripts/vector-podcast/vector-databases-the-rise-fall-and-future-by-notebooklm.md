---
description: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.vectorpodcast.com/">https://www.vectorpodcast.com/</a></p><p>I
  had fun interacting with NotebookLM - mostly for self-educational purposes. I think
  this tool can help by bringing an additional perspective over a textual content.
  It ties to what RAG (Retrieval Augmented Generation) can do to content generation
  in another modality. In this case, text is used to augment the generation of a podcast
  episode. </p><p>This episode is based on my blog post: <a target="_blank" rel="noopener
  noreferrer nofollow" href="https://dmitry-kan.medium.com/the-rise-fall-and-future-of-vector-databases-how-to-pick-the-one-that-lasts-6b9fbb43bbbe">https://dmitry-kan.medium.com/the-rise-fall-and-future-of-vector-databases-how-to-pick-the-one-that-lasts-6b9fbb43bbbe</a></p><p></p><p>Time
  codes:</p><p>00:00 Intro to the topic</p><p>1:11 Dmitry''s knowledge in the space</p><p>1:54
  Unpacking the Rise &amp; Fall idea</p><p>3:14 How attention got back to Vector DBs
  for a bit</p><p>4:18 Getting practical: Dmitry''s guide for choosing the right Vector
  Database</p><p>4:39 FAISS</p><p>5:34 What if you need fine-grained keyword search?
  Look at Apache Lucene-based engines</p><p>6:41 Exception to the rule: Late-interaction
  models</p><p>8:30 Latency and QPS: GSI APU, Vespa, Hyperspace</p><p>9:28 Strategic
  approach</p><p>9:55 Cloud solutions: CosmosDB, Vertex AI, Pinecone, Weaviate Cloud</p><p>10:14
  Community voice: pgvector</p><p>10:48 Picture of the fascinating future of the field</p><p>12:23
  Question to the audience</p><p>12:44 Taking a step back: key points</p><p>13:45
  Don''t get caught up in trendy shiny new tech</p>'
image_url: https://media.rss.com/vector-podcast/ep_cover_20250302_080303_04f8b5f2665529faa9d13569b97a18c9.png
pub_date: Sun, 02 Mar 2025 08:27:58 GMT
title: 'Vector Databases: The Rise, Fall and Future - by NotebookLM'
url: https://rss.com/podcasts/vector-podcast/1922013
---

Welcome back everybody. Today, we're gonna be diving into the world of vector databases. Ooh, fun. They're rise, they're potential fall, and with the future holds. Okay. You know, you sent us this fascinating medium article to kind of guide our exploration. Ooh.
Called The Rise, Fall, and Future of Vector Databases. How to pick the one that lasts by Dmitry Kan. Yeah, I saw that one. Published January 6th, 2025. Mm-hmm. So guess the term vector database might actually be on its way out.
Really? And your choice of database could hinge on needing things like faceted search. Oh, wow. Or even those super cool late interaction models. Huh, interesting. And treat. I know I am. Let's break it all down. Okay, let's do it. So it's gonna be good.
What I thought was so interesting about this article is how it really blends like the technical side with the broader AI landscape. Yeah, you're right. It's not just about the nuts and bolts. It's about how perceptions and adoption of vector databases are shifting within the AI world. Absolutely.
Like this is not just a technical deep dive. Right. This is about how people are thinking about these things. Yeah. And using them. Totally. And Dmitry brings this really unique perspective He does. to this whole conversation.
Because he was like deeply involved in this emerging market just a few years back. Oh, really? He was even advising VCs on which vector database companies to back. Wow. So he's like an insider. Yeah, he's got the inside scoop. So he really saw this whole thing unfold firsthand.
He was there from the beginning. Wow, that's amazing. And it's interesting because just a few years ago, vector databases were like the hot topic. They were everywhere, right? Everybody was talking about it. Like they were the key to unlocking all these powerful AI applications.
Like this was gonna change everything. Everyone was so excited. Yeah. Okay, so let's unpack this whole rise and fall idea. Okay. So Dmitry noticed something interesting. What's up? Fewer people were reading his early articles about vector databases. Oh, really? Huh? I wonder why.
What do you make of that? Well, you know, it kind of hints at a potential shift in the industry. Okay. Instead of being seen as these like standalone solutions, it seems like vector search technology is kind of merging with other AI advancements, becoming part of a bigger picture.
Like what? Think LLM, small time modal search. They're all getting more integrated. Okay, so it's not that vector databases are like vanishing. Right. They're evolving. Exactly. I'm blending into more comprehensive solutions. That's it. Okay, I got it. The technology itself is still crucial.
But how we think about it and use it is evolving. Okay. Like, you know, you have your traditional databases, right? Like your SQL and no SQL types. Well, a lot of them have integrated vector search capabilities now. Oh, wow.
So the data type itself is becoming normalized within these existing systems. Okay. I see. So it's becoming more commonplace. Yeah. Exactly. It's not this like niche thing anymore. Right. It's just part of the toolkit. It's becoming part of the fabric of how we work with data.
I like that fabric of how we work with data. It's a good way to put it right. But here's where things get really interesting. Okay. Tell me. Dmitry saw this resurgence in views for those older articles. Oh, so people are coming back to them.
They're coming back and guess what? What? We've been right when major funding announcements hit for some vector database startups back in April 2023. Oh, interesting. Like, big money was flowing back into this space. Yeah. Like, pine cones, $100 million series B. Yeah. Pinecone was huge.
Weve 8 securing $50 million. Huh. And QDran getting $7.5 million in seed funding. Yeah. Those were big headlines. They were. It really highlights how much media coverage and industry buzz can influence how we perceive technology trends. Codally. It's like a self-fulfilling prophecy almost. Yeah.
And it makes you think like how much of what we perceive is like the next big thing is actually driven by, you know, the hype, the hype, the funding, the media attention. Yeah. It's fascinating. So clearly, there's still a ton of innovation and investment happening in the vector database space.
Be sure. But let's get practical for our listener out there. Let's give him some actionable advice. The real gem in this article is Demetri's guide for choosing the right vector database. Right. Because there's no one size fits all solution. Exactly. It really depends on your specific needs.
It's like having a roadmap for navigating this complex landscape. Totally a roadmap. So where does he suggest starting? Okay. I'm ready. His secret weapon is, FAISS. Okay. No, it's not technically a full-fledged database. Right. It's more of a powerful library. Okay.
So the kicker, it can handle massive data sets. Okay. We're talking over a billion vectors. Wow. That's a lot. So it can scale. We can handle the big stuff. And the beauty of FAISS is its simplicity and scalability. So it's perfect for, it's perfect for initial exploration and prototyping.
You can just get in there and start playing around. Exactly. Yeah. But of course, uh oh, there's always a butt. There's a trade-off. Okay. What is it? Built-in filtering capabilities. Uh, so you can't really do that fine-grained search. Right. Like with keywords and stuff.
Which might mean getting creative with workarounds? Okay. So you've got to be a little clever. A little bit. If you want to use FAISS, I.S. for certain things. Yeah. So if you need that fine-grained controlled keyword search. Yeah.
Along with your vector search, what does Demetri recommend? I'm all ears. He suggests looking at databases built on top of Lucene. Lucene. Options like open search, elastic search, and a patchy solar. Got it. So these are all built on this like solid foundation of Lucene technology. Yeah.
Lucene's been around for a while, right? It's a mature technology with a proven track record. Yeah. So it's reliable. Reliable. Yeah. And it provides that robust keyword search. Okay. You mentioned plus multilingual support. That's important these days. Super important.
And it performs incredibly well. So it's fast and efficient. Nice. This makes it particularly well suited for e-commerce. Oh, interesting why e-commerce? Where features like faceting, which allows users to refine their search by specific attributes. Oh, I see. So like filtering by brands. Yeah.
Like filtering by brand. Price range. Price range size. All those things are essential. Makes sense for e-commerce. He did mention one exception though, right? Though there's always an exception. What is it? Cudrant, even though it's not built on Lucene. Oh, okay. Includes fascinating capabilities.
Interesting. So it's kind of a hybrid approach. Making it a contender in those scenarios too. So Cudrant's kind of a wild card. A little bit. Yeah. It's got its own unique set of features. And it shows the importance of going beyond general categories. Yeah.
And really digging into the specific features each database offers. Absolutely. You can't just like assume that because it's in one category. Right. It's got all the features you need. You got to do your research. You got to look under the hood. Exactly.
Now what if you need something more advanced? Okay. Like what? Like support for those late interaction models. Late interaction models, huh? Yeah. If you heard of these. I've heard the term, but I'm not really sure what they were. Okay. So imagine you're searching for the perfect pair of red shoes.
Okay. I like shoes. But only after you've seen a picture of the outfit you want them to match. Oh, I see. So like the context of the search changes. Exactly. And then you see something you see later on. That's where late interaction models come in. Okay.
Allowing you to refine your search based on context that's only available later in the process. So it's like a more dynamic way of searching. It is a more dynamic way of searching. Interesting. And it requires a different level of database support. I bet.
And Dmitry points to QDrent or Vespa as potential solutions. Okay. So they can handle those late interactions. Because they offer that support natively. So you don't have to hack it together yourself. Exactly. That's good to know.
So choosing a database that can handle those complexities is critical for performance and efficiency. You don't want your search to be slow and clunky. Especially if you're dealing with a lot of data. Right. Or if you need those results in real time. But it doesn't stop there. There's more.
The next step into Dmitry's roadmap is super important. Okay. Hit me. Considering latency. Latency, okay. And those query per second abans? Oh, yes. QPS. Can make or break your application? You're telling me. If your database is slow. Yeah. Or it can't handle the volume of queries.
It's going to be a bad experience for the user. It's going to be a disaster. So you've got to think about those things up front. Absolutely. And choose a database that can handle the load. If high performance is the name of the game. Yeah.
You'll want to explore solutions like GSI, APU, Vespa, or hyperspace. Got it. In fact, Dmitry even shared an anecdote about a CTO. Oh, I love a good anecdote. You'll confess that no open source vector database could handle their extreme workload. Wow. So they had to go with a commercial solution.
They'd find something else. That's interesting. Choosing wisely is essential. You can't just pick the first one you see. No. You got to your homework. And think about your long term needs. So the takeaway here is you need to think strategically. Yep.
Do you invest the engineering time to set up and maintain an open source database? Right. Or do you go with the convenience and potentially higher costs of a cloud solution? Right. It's a classic trade off. There's no right or wrong answer. It depends on your situation.
It's all about finding the balance that works best for your specific situation. Absolutely. And there are a lot of great cloud and API based options out there. Like what? Like Cosmos DB, Vertex AI, Pinecone Cloud, Weaviate Cloud, and other. But there's no shortage of options.
There's a lot to choose from. It's a good problem to have, right? It is a good problem to have. Better than having no options at all. And we love hearing from our community. Oh yes, our listeners are the best. One reader, Matt Collins, suggested exploring extensions like PG Vector.
Did you vector? Okay. Which adds vector search to Postgresql. Oh, so you can just add it onto your existing Postgres database. Exactly. That's pretty cool. It's a really clever solution. You have to rip and replace your whole infrastructure.
And it speaks to the constantly evolving nature of the vector database landscape. It's a fast moving field. There's always something new happening. You've been in new solutions emerging. Speaking of evolution. Oh, this is where it gets really interesting.
Dmitry paints a fascinating picture of the future. I can't wait to hear this. He believes the future lies in what he calls neural search frameworks. Oh, wow. These frameworks could revolutionize how we build AI-powered applications. Okay.
And then we have a system that streamlines the entire process from data modeling and embedding selection to evaluation and scaling.
So instead of wrestling with the complexities of choosing and integrating all the different components, it would be like having an intelligent assistant guiding you through building a search application no matter what database technology you're using. Exactly.
And this vision ties in nicely with the concept of compound AI systems. Oh, interesting. So where LLMs vector databases and other AI components work together like a well coordinated orchestra. So instead of focusing on the individual instruments, you're conducting the entire symphony. Precisely.
I love that analogy. Users can then focus on the task they're trying to solve, rather than the technical nuts and bolts. So it's about abstracting away the complexity and empowering users to focus on the bigger picture. It's about making AI more accessible and user friendly.
It's fascinating how this all connects to those funding announcements we talked about earlier. Right. It seems like the industry might be moving towards a more unified approach to AI solutions. That's a keen observation. While individual components like vector databases are still important.
For sure. The future might be about how these pieces fit into a larger ecosystem. Yeah, it's all about the big picture. This brings us to an interesting question for you, the listener. Oh, yes. Let's get our listeners involved.
Do you see neural search frameworks as a complete paradigm shift? Or will specialized vector databases continue to have a distinct role to play? It's tough question. It's something to think about. Let us know your thoughts in the comments. We'd love to hear from you.
But before we get too caught up in the future, let's take a step back and revisit one of Dmitry's key points about the impact of media coverage on perceptions of technology trends. Right. That was a really important point.
It's a crucial reminder to be discerning consumers of information, especially in a field as dynamic as AI, where innovation is constant. What might seem like a decline could actually be a natural evolution. Interesting. As a technology matures and finds its place within a larger ecosystem. Right.
Like a caterpillar transforming into a butterfly. That's a wonderful analogy. It's still the same creature, just in a more advanced and beautiful form. It underscores the importance of staying curious, continuing to explore, and never assuming that any technology is truly dead.
Because it might just be evolving into something even better. Who knows what exciting developments await us in the world of vector databases? I'm definitely eager to see what the future holds. E2. This deep dive has given me a whole new perspective. I'm sure it has for our listeners as well.
You know, as we're discussing this, it strikes me that Dmitry's journey with vector databases mirrors a broader trend in the tech world. Oh, how so? We often get caught up in the hype cycle. Oh, yeah, for sure.
But true innovation often emerges when technologies evolve and integrate in unexpected ways. It's like that saying the whole is greater than the sum of its parts. And that brings us to another crucial point from the article. Okay. One that I think holds immense value for our listeners today.
I'm all ears. Remember how Dmitry emphasized that it's not just about the vectors themselves. It's about understanding the nuances of data pre-processing model selection and bedding techniques. And even knowing when to switch back to traditional keyword search for certain tasks.
Yeah, sometimes the old ways are still the best. He's advocating for a more holistic approach where vector databases are seen as one tool among many in the AI toolbox. So it's not a silver bullet. It's not a magic solution. It's one piece of the puzzle. Exactly.
There is a deeper understanding of the underlying principles, not just blindly applying the latest trendy technology. Right. It's about making informed choices based on a thorough analysis of your specific needs and constraints. So don't just jump on the bandwagon.
Do your research and figure out what's right for you. So for those of you out there exploring AI solutions, don't get fixated on buzzwords. Take the time to really grasp the fundamentals. Understand the basics. Experiment with different approaches. Stay around with different tools.
And don't be afraid to challenge assumptions. Question everything. And remember, the AI landscape is constantly evolving. What works best today might be superseded by something even more powerful and efficient tomorrow. So stay curious. They engage. And keep learning.
Couldn't have said it better myself. Well folks, that brings us to the end of our deep dive into the world of vector databases. It's been a wild ride. We've explored their rise, their potential fall, and the exciting possibilities of neural search frameworks. We've covered a lot of ground.
We've also learned some valuable lessons about navigating the hype cycle and making informed decisions in a rapidly changing technological landscape. It's been a fascinating journey. Absolutely. And we hope you've enjoyed it as much as we have. Until next time. Keep exploring. Keep questioning.
And keep that thirst for knowledge alive. It's funny actually while we're focused on all this cutting edge tech, Dmitry actually kind of throws it back to basics in the article a little bit. Oh yeah, I remember that part.
He recounts this conversation he had with the chief data scientist at a major bank. That was a good one, which I thought was so interesting because it really emphasizes how even with all these advancements, sometimes the simplest solution is the best one. You don't always need the fanciest tools.
Right. Sometimes it's about using the right tool for the job. Exactly. This bank had poured resources into building this complex vector search system. Okay. But guess what? What? They ended up getting better results with good old fashioned keyword search. Really? For some very specific tasks. Huh.
So even the big bangs are going back to basics sometimes. Sometimes it makes more sense. Yeah. It's a powerful reminder that we shouldn't dismiss those tried and true methods. Like don't throw out the baby with the bathwater. Right. Exactly.
The tools when used strategically can outperform the flashiest new tech. It's all about choosing the right tool for the job. It's like trying to use a chainsaw to cut a piece of paper. Oof. Yeah, that wouldn't end well. Sometimes a simple pair of scissors does the job better. Much better.
And that brings us back to Dmitry's vision of neural search frameworks. Okay. If they become a reality. Yeah. Could they simplify these choices for us? Interesting question.
Would they be able to determine the best approach? Like whether it's vector search, keyword search or a hybrid based on the task at hand. That's the dream. How be amazed? It would be like having this AI assistant that just knows the best way to search for anything. That's a fantastic question.
It really gets to the heart of what these frameworks could potentially offer. Like a more intelligent and adaptable approach to search. So instead of us having to figure it all out. Yeah. The system would just do it for us.
A vision of system that not only combines different AI components, but also understands which tool is best suited for each specific task. That would be a game changer. It would free us from getting bogged down in the technical details and allow us to focus on solving real world problems.
It's all about making AI work for us. Not the other way around. Exactly. And it highlights the importance of staying flexible and open to new possibilities. As the AI landscape continues to evolve, we need to be willing to adapt and embrace new approaches.
Even if the challenger existing assumptions. Challenge the status quo. Right. Well said, well, this deep dive has been a whirlwind of information. It has. But I think the biggest takeaway for me is that the world of vector databases and AI in general is anything but static.
It's constantly changing. It's a constantly evolving landscape full of exciting possibilities and unexpected twists in turn. You never know what's going to come next. And that's what makes it so exciting. I completely agree. And it's a landscape that requires us to stay curious. Keep learning.
And never stop asking questions. And on that note, we'd love to hear from you, our listeners. Yes, please share your thoughts. What are your thoughts on the future of vector databases? Hmm.
Do you think neural search frameworks will revolutionize the way we build AI applications? That's the big question. Share your insights, your predictions, and your questions. We're all ears. We're always eager to continue the conversation.
Until next time, keep exploring, keep innovating, and keep diving deep into the fascinating world of AI. That's a wrap on this deep dive, folks. We hope you've enjoyed the journey as much as we have.