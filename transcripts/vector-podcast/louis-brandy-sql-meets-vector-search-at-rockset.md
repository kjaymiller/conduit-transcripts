---
description: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=0s">00:00</a>
  Intro</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=42s">00:42</a>
  Louis''s background</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=339s">05:39</a> From Facebook
  to Rockset</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=461s">07:41</a>
  Embeddings prior to deep learning / LLM era</p><p><a target="_blank" rel="noopener
  noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=755s">12:35</a>
  What''s Rockset as a product</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=927s">15:27</a> Use cases</p><p><a
  target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1084s">18:04</a>
  RocksDB as part of Rockset</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1233s">20:33</a> AI capabilities:
  ANN index, hybrid search</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1511s">25:11</a> Types of
  hybrid search</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1685s">28:05</a>
  Can one learn the alpha?</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=1803s">30:03</a> Louis''s
  prediction of the future of vector search</p><p><a target="_blank" rel="noopener
  noreferrer nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2035s">33:55</a>
  RAG and other AI capabilities</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2506s">41:46</a>
  Call out to the Vector Search community</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2776s">46:16</a>
  Vector Databases vs Databases</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=TiwqVlDpsl8&amp;t=2956s">49:16</a>
  Question of WHY</p>'
image_url: https://media.rss.com/vector-podcast/ep_cover_20240501_010549_d5b842295c8b59f78ff9fa1e488d2af8.png
pub_date: Wed, 01 May 2024 13:54:39 GMT
title: Louis Brandy - SQL meets Vector Search at Rockset
url: https://rss.com/podcasts/vector-podcast/1460893
---

Hello there, vector podcast. Season three and this promised I'm trying to shoot for 30 minute episodes. Let's see how I'm going to do on this one. I'm super excited to have Luis Brandy, vice president of engineering at Rockset. I know you guys are building database.
Hey Luis, how are you doing? I'm doing great. So far so good. Thank you for having me today. Oh yeah, excited. Excited to learn about Rockset as well. But before that, it's a tradition.
Could you please introduce yourself a little bit about your background and how you got to your stage in your professional life? Sure. So I've been at Rockset for two years and change over two years. VP of engineering. Before that, I was at Facebook for 11 years.
So I did roughly three things at Facebook and it's funny because even the ones that feel least relevant have become more relevant recently. I did spam fighting infrastructure for my first much of time at Facebook and that involved like two large systems.
One was like a super real time system, which turns into the real time database we're going to talk about today. And the other was we did a lot of vector clustering. Like back I was doing vectors but way before they were cool. This time was like 2011, 2015 or so.
And we used vectors a lot in in spam fighting and image classification. And this is like even before like the deep learning took over the world like this is right before deep learning changed everything in this in this space. But we were using vectors a lot.
We built some pretty powerful systems actually built like large scale vector clustering. I don't know before it was cool. Now everyone's building large scale vector applications. And then I worked on a lot of other stuff at my time at Facebook.
So there was a lot of core C++ core libraries, a lot of infrastructure stuff. I worked on an open source stuff called folly and thrift. So these are basically like core libraries that Facebook has released over the years. And the theme of all this is like highly scalable infra.
And then I did some real time and some vector stuff back in the spam fighting days. It's not totally applicable necessarily to the modern world. But it's still pretty interesting background. It a very interesting confluence of things that have brought me to Roxette.
So yeah, that's my life story roughly and in nutshell, there's more. But I think that will do for the for the intro. Yeah, for sure. Very exciting, really exciting. I heard about thrift.
And I also remember like early on many years ago, when some of you guys were on stage, you know, from the engineering at Facebook, you would constantly, you know, hint to the point that yeah, we ran out of the capabilities of this database. So we needed to scale up.
We needed to build a new one sometimes. And that was really really interesting that it's constantly like, you know, you're always battle against too many images, too many videos and so on and so forth. Yeah, one thing that I've always said was that like everything is broken at scale.
 Like like, there's this idea that sometimes you reach for the right tool for the job, but the reality is like when when you push the even the right tool to the limit, it will fall over and you'll find yourself doing things that other people, you know, rebuilding something that other people take for granted.
Like my favorite example of this is at Facebook, we had a team on on my core C++ group that was working on Malak. Like who who works on Malak? It turns out there are people that work at Malak.
They're most of them work at like a place like Facebook or Google or places like that, but but that's like the kind of thing where you can save a lot of money by making tiny improvements to Malak. So it's worth doing. It's amazing. I remember I did a bit of a C++ as well.
I guess like you could say two and a half years.
And at some point in the 90 virus company here in Finland, I had to choose which Malak will it be, right? And I had to sort of discuss with my team and I was like, struck really, is that really the thing we need to discuss?
And they said, yeah, actually you won't believe because we are running on a mobile phone back then it was this Microsoft's Windows mobile, I guess it was called, right? So you have to be really careful to the round.
Yeah, I mean, there's only here for Malak's in the world. So you might have chosen ours. Who knows? Amazing. All these say is that you've been really, really deep and low level. And so I think you you doubled in coding obviously, right? Yeah. So I was a fairly technical.
I've been a manager for relatively long time. I don't know, 12 years or so, but I've always been a fairly technical manager in my path. And so for example, for years I worked in the course, SQL's plus libraries at Facebook, even while I was a manager, even a director.
I was on the SQL standards committee for a while and doing things like that. Sorry, I got paged. Everything's fine. So yeah, I've definitely worked in the code. I've tried to stay as hands on as possible. In most recent years, it's become increasingly difficult.
I just I don't know, it's sort of the dark side of management. You slowly slide into more managerial things. But I still try to stay about as hands on as I possibly can. Oh, tell me about, tell me about me about that.
I mean, I'm also on the product management side today and previously a manager of people as well. And I'm like, am I sliding backwards? Do I need to? Sometimes I do, but it's not on the same level as it used to be for sure. But it makes sense to stay on these topics.
And and then after all these years, you decided to move to Roxette. I've read a blog post that I think you've written for the company where you give the reasons why you did so and you explain about the team strengths and so on support. Some of them are from Facebook as well.
Today matter, right? Can you sort of repeat that story a little bit like why you moved from a big company you could say, right? To a startup. So the answer is in short is the people. The core group at Roxette is a bunch of, I shouldn't say the core group now.
The core group now has grown a lot, but the original founding or was a bunch of extremely strong Facebook people that I knew from Facebook and from. And so you know, you mentioned rebuilding databases.
For example, like two of the main people were probably three of the main people responsible for rebuilding databases at Facebook are at Roxette. So Drupal, who's who's our CTO was built RoxDB at Facebook.
And that was part of replacing the storage plan of my sequel and a highly scalable way at Facebook. And then of course, the graph database that powers literally all of Facebook like Facebook is a graph and it is primarily powered by a graph database called Tau.
Nathan and Vencat are two people who worked who worked on that at at extensively at like tech leads and founders in some sense of that project Facebook. So this is like extremely pedigree group.
So to me, I don't care so much about it, they're also like genuinely amazing people to work with and work around.
 And so this is kind of this idea of like, hey, you want to join us startup with a bunch of the smartest people you've ever worked with and like try to do something and worst case scenario, you know, it all goes, you know, kaput or whatever, but you have like you worked with like some of the best people on a really interesting problem for a couple years.
And I was like, yeah, I'm in for that. There's a longer version of that story, but that's that is really the central reason of why I ended up I ended up switching. Yeah, I mean, it sounds like a brilliant reason too.
But I'm also interested you said you've been using embeddings before like Facebook and on vectors and you said that prior to deep learning era.
So can you explain a bit like how these vectors were sort of created if it's possible? So there is some sensitivity here, but it's not maybe for the reason you think it's not a trade sensitivity. The sensitivity with abuse abuse use cases. What we were doing was image classification.
 And and most of this is I'm not going to go into too much detail for maybe obvious reasons, but there are there are images that you are not allowed to to to use or put up and they and and obviously what they don't want to do is hand all these companies like the images and say if you see this illegal image, tell us.
So oftentimes they give you hashes. And but these aren't actual hashes. They are not a hash of the illegal image. They are a locality sensitive hash and they're a vector. What they are is literally a vector.
And Euclidean distance is the measurement of so you basically have a a classic vector search problem. You're given a pile of vectors. If there's a technology known as photo DNA that you can look up. It's it's not as far as I know it's not like an open standard.
So you don't actually it's not actually in the public domain. What it actually is, but it's effectively a mechanism for turning images into vectors that's used as this hashing mechanism.
And and so Facebook built a bunch of infrastructure to flag hashes that came through for reasons that are not fun to talk about. Let's put it that way. Like they're there. There's like again, I don't want to get into it.
It's kind of it's awful, right? But at the end of the day, like you have you have vectors flowing into the system. And what you're doing every single upload is is doing essentially a vector search.
You're saying, Hey, given this corpus of vectors is this vector that fly that's coming in match any use. That was the basic core of the system. But once you have this like these vectors, you can start to do other abuse things. So for example, you can start clustering vectors.
You can build vector clusters. And that way you can find like neighborhoods of images, like similar images. Now here similar is here similar means something quite different. Because these were not like semantic similarity.
So this is not like what you would get from an embedding today from like say, you know, any of the modern. Yeah, I heard clip. Yeah, whatever. Yeah. These were these were these were much more like text textual. I mean, texture. People familiar with like image processing techniques.
This is these are vectors based on things like local pixel gradients or wavelet transforms things like that.
So when we say images were similar, we mean to things like, you know, like rebalancing the white scale or or changing the hue and saturation like like those kinds of image manipulation or re encoding it right from a different JPEG, different JPEG encoding.
Like it was tolerant to that kind of manipulation, not like it wasn't like finding images of elephants, like that's that's not what it was doing. Yeah, yeah, I remember I took a course. Actually, I studied master degree in Finland here dedicated to data security.
And one of the courses was about, you know, how you can temper with images that had watermarks, right? So like, yeah, and then how do you make that watermark resilient to any tempering that might happen on the image level, right? On any of the bands and stuff. And as you explained, he was in stuff.
So that's basically they digital image processing is the word to Google if someone wants to. And then it's like a big, big topic. But what struck me and what you explained is that every image upload had to go through that process, which means it had to be super scalable.
And also your database of vectors would be ever growing all the time as the image passes through or doesn't, you would need to add it somewhere to your vector space. So in this case, no, this is the one advantage we had, because we only care about matches to a specific relatively small set.
Oh, I see, I see. So it's like a set that shouldn't grow ideally, right? Yeah, or very, very nominal. I see. Yeah. And so this is, so it's funny because that that's a big difference that that makes it easy in that era.
Today, you'd have to bust out all the A and N stuff and maybe stuff we'll get into to really be able to do a really much more scalable vector search. So this was really more about evaluating a relatively fixed set of vectors.
So you can hyper optimize how that was organized in like a, and, but evaluating it at an insane scale. So the update problem wasn't very hard, but the evaluation problem was like it needed to be extremely high scale. Yeah, a bunch of questions in my mind, but let's move move on to Roxette.
Tell me more about the what part, you know, what it is as the product. And then slowly, let's go deeper into the technology side. Yeah. So my standard statement of what Roxette is is Roxette is a search and analytics database built for the cloud.
And that's a bunch of, I forgot one, it's a real time search and analytics database for the cloud.
Now that's a bunch of little buzz worries that, you know, it's very easy to get lost in the kind of marketing feel of that, but each of those words does like non trivial amounts of work and what it is I'm really trying to build here. So first of all, it's a search and analytics database.
So here, what we mean is like a like an OLAP style analytics database is like it's it's like that's where we're starting. We want to run an analytics type queries and this I won't get into all of this, but this is like separate from your OLTP style databases.
So this is not my sequel, not a large transactional thing. It is a but is it OLAP style database.
And search and analytics is a very interesting pairing in this world because systems like elastic search or very search oriented system systems like rocks that have analytics styles, but these are actually not that different architecturally. They're very the way you use them may feel different.
The primitives you're using feel different, but all that sits fairly shallowly in the technology. The underlying architecture of these systems ends up looking quite similar. So search and analytics actually go together quite nicely from like a I can do both.
Maybe I don't do both well, but that will mostly exist at the top, not not in the not in the infrastructure. It's in the cloud. So the whole system is built to be elastic from the beginning. So if you send me twice as much data, I can scale you out in a way that you know, like it just works.
You don't have to worry. You're not reprovisioning more machines to double your cluster size or anything like that. And then real time.
So our focus has always been real time, which is to say specifically most people when they think of real time they want their queries to be fast, but the real heart of real time is ingest latency.
So if you send me new data, how quickly does that data get manifested in the queries? If it's tomorrow, if it shows up in tomorrow's queries, you're not that's not a real time system.
And there's a lot of systems like this, these very big batch style, like mega exabyte type of like doob clusters that you you can query yesterday's data, right? And get and get like genuinely enormous amounts of data. That is not rock set like as that's not rock sets problem.
But for us, it's like, hey, if you want like last minutes data and it's ideally several zero smaller of a working set, then that's where rock set is meant is meant to work really well. And so this is like the heart of this is what we've set out to build at a high level.
And I don't know if you want to do want me to keep going. I don't know. I feel like I've already said too much. I want I want no, it's amazing. It's a good start. I wanted to stay a little bit on the product side. If you go now and flip over to the use cases for the moment.
So what are the typical use cases and sort of can you zoom out as much as possible, maybe even giving, you know, even if hypothetical, it's fine. For example, so products that use your product. Yeah. So we we have a bunch of customers in a bunch of different domains and it's we can even go.
So so one way to think about this is just like who's using it and why like what domains are they using it in? And so for example, we have a bunch of gaming customers. So this is like there's real time events occurring in games.
Imagine an online an online game of some sort and they're collating that information constantly and having it be real uptime say leader boards or things like that are happening. There's a lot there's several actually like logistics and supply chain type people using it.
 So like where is my package right now or where is the boat in the ocean like these kinds of queries are like very commonly done, you know, like where is the where they're basically tracking their entire supply chain trying to find shortages and what's going to create problems down the line in like a logistic type settings.
There's a lot of FinTech. There's a lot of financial financial firms use it a lot of fraud detection. So again fraud and spam these are very real time problems. You can't like detect yesterday spam or fraud. That's like really harmful. You got to you need to know now right.
And then a lot of like recommendation and like product experience. So anytime that like you want to power a user facing experience, you almost always need that to be real time. So you know example I like to use is there's a there's a there's a place called what not if you go to what not.
com if you've never heard of it. What not is basically a streaming site for buying and selling. So it's sort of eBay meets Twitch kind of a easiest way I could describe it. But what's really cool about that is you have a recommendation problem like I want to buy something or people selling it.
So I it's really in the sites. And my interest were you to show me like you might want to check these things out. That's like a recommendation problem. But it's like really real time right. It has to match me to online sellers at any given moment.
And so it's a recommendation system that has to get built needs decent amount of needs high scale. And it also needs to be real time. It needs to use a lot of real time data. So these are all use cases for Rockset. These are every one of these is real customers using Rockset to do something.
Yeah, for sure. Now I want to go back to jump back to tech side. So Rockset and inside it are you using RocksDB or something else? So okay. So okay. Are we using RocksDB? So first of all do we know what RocksDB is? Just everyone's on the same page.
RocksDB is an engine that was built by Drew Bat Facebook. And I shouldn't say by Drew, but by a team that Drew was a part of. Like he was one of the original founders of that team. There's certainly a lot of people involved in RocksDB. It's a key value store right.
It's built sort of to scale very well and sort of do log structure merge over time. Rockset absolutely uses RocksDB as its storage plane. And so there's a lot of Rockset built on top of RocksDB. So Rockset is not RocksDB as a service. That is not what Rockset is.
We do use it as the storage plane of Rockset. And we do take heavy advantage of, again, to get into the technical weeds a little bit like log structured merges to keep our indexes sort of up to date continuously. And that is a big part of like the real timeness of Rockset.
Like being able to update the index continuously and having this like heavy weight infrastructure to merge these indexes and then the kind of the appendonly log structured way that you do. And the LSM world is part of the secret sauce.
It's not that secret, but it's part of the secret sauce of Rockset. Yeah, for sure. But then also all these things like vector search, you know, storing the embeddings. Is that also happening outside of RocksDB? Basically, in the layer you explained.
So hold on, you asked about vector, what were the things? Oh, embeddings. And embeddings and vector search itself and the sort of a and n indexes presumably. Yeah.
So the a and n index, so we've added, we've extended RocksDB a little bit to kind of have this notion of a blob of memory that you attach to a particular thing. It's what's going to be the a and n index. And then you can build custom operators to merge them, for example.
And so that we do, we do essentially shove the a and n index into this. And so it gets into RocksDB. RocksDB doesn't know about a and n indexes. It just knows there's a blob of memory that it has to log structure merge down the road. As far as embeddings, for us, that's just arrays.
So for us, an embedding is just a vector. And for us, a vector is just an array. There's no real difference in the way these things are stored. And those are stored in RocksDB. Yeah, got it.
And so, and basically, what other AI capabilities does RocksDB offer, you know, basically everything? What's the secret source of that thing? So they're facing, right? But still. So I have two, there's a few things to talk about here. We talk about secret sauce.
So one thing we skipped over about one thing that's worth touching on in terms of RocksDB or architecture is RocksDB has two things that you hope every database has, but not every database has one is we have disaggregated storage, like fully disaggregated storage.
So if you double your storage, you can, you can, basically, you can double your storage, you can double your compute, you can do either. You don't have to do both, right? You can, they are stable.
They, there's compute optimized machines and storage optimized machines, and you can add to either group independently. We also have compute and compute isolation. So you can set aside a set of machines, for example, just to do ingest and a different set of machines, just to do queries.
And they both operate on the same backend, for example. You can go farther than that.
You can have different groups of machines for different sets of queries or by 10 in or whatever you can go wild with this idea, isolating compute from it's from each other, right? Once you have disaggregated storage, this is an idea you can do.
This is already really powerful for AI use cases, like in a way you don't necessarily appreciate, because what it means is I have a way to do my index rebuilds, which are expensive in a vector world, away from the machines handling queries.
Like I'm not, like what's not going to happen is the machine, the database is going to bog itself down doing an index updates of some sort while queries are trying to be served and you're going to get time out. So being able to actually separate out compute is very powerful in these AI settings.
Again, another example, no one's done this like in total anger yet, but it's going to come, which is like the hey, I have a god awful amount of vectors. I want to update them to the next generation of my the new open AI model has come out. I want to rerun the entire data set.
We can do that in this kind of like off on the side fashion in a way that just reduz it all in place without affecting the running application as an example.
So that's one like kind of very architectural found is a very database type of a feature that you you will miss it if you don't have it when the day comes.
Moving up to kind of more AI level things, the other thing that we have is like we have a huge pile of infrastructure of like doing SQL and relational queries, right? In this system that's separate from the vector stuff.
So when the vector stuff gets mixed with that stuff, the things get very powerful and very magical.
And so this gets you into so there's it's funny because database people talk a certain way and AI people talk a certain way and a lot of times they're actually saying the same thing, but they use none of the same words.
And so they don't know they're talking about the same thing, but as an example, like so in an AI context, things like metadata filtering or hybrid search, these are all things Rockset does out of the box.
Like metadata filtering in an AI context or a vector context, that's just like the wear clause of a SQL query. Like that's all that is like where X is created and this time is created and that. Like so for us, it's that's all done. Like metadata filtering is easy. That's not a hard problem at all.
All you have to do is you know, I have a super powerful query language. I'm query optimizer. All you have to do is kind of merge that with the a and n kind of vector search and I get like metadata filtering is like a not that's not a hard problem for us to solve.
Like it would be for others to solve. And so I do think we really shine in situations where a you care about real time ingest, be you care about any kind of hybrid or metadata filtering.
Rockset's really good as well for for kind of raw vector power, but I wouldn't say we're like the best database in the world for like, I don't know, I view it more like we kind of going where our customers are taking us.
Like if the customers came to me as like, Hey, if you if you if I can have 10 times more vectors and like 4% more precision and recall, if you implemented this slightly better algorithm with these parameters, we would do it.
But almost always it's like they want we want that like hybrid search seems to be the king. Like it's it's it's merging these things. And that's where like a lot of our effort has gone is into making the hybrid search story like making these two worlds work together like fairly seamlessly.
Like be able to say like show me the closest 10 vectors that were updated in the last 10 minutes. Like that that kind of query is really powerful. And that's kind of what we've been focused on in terms of in terms of. But I guess the timestamp example you gave it's also like metadata check right.
It's kind of like way close where you say between a and b timestamps. Yes. Yes. But like hybrid search at least the way I'm hearing people do this is that let's say take the search domains example.
You might have a keyword search right which is your sparse index and then you have your then syntax vector search. And you want to combine the two in some way. For example, you could say I still trust keyword search. So let's give it 75% of weight and then 25% goes to vector.
And then you combine them into leave them in some merging strategy. And then you return back to the user. Is this how you see hybrid search or do you see? So I have a whole ran here. You might you might have yes you've unlocked my ran here.
So let's go so hybrid search is one of these very overloaded terms exactly as you have kind of this is kind of sometimes what people mean. Sometimes people do they they smuggle metadata filtering as a hybrid search.
Strictly speaking under my definition, metadata filtering is a kind of hybrid search. It just sort of has extreme weights right like it's weight one if it matches and zero if it doesn't. And so it's kind of like a weighted hybrid search.
You can also do this kind of linear combination hybrid search right like I have a BM 25 keyword type a ranker which by the way, rockset can do like rockset has this rockset you can build you can do this order by keyword ranking limit 10 like you could write that.
And then you can also then do the vector limit 10 like show me the 10 closest vectors. There's nothing stopping you from saying or you know order by 0.25 of that plus 0.75 of that for example, in your in your example.
So that kind of linear combination hybrid search is is doable like that that's how that's how you could do rockset. Sorry, that's how you can do that kind of hybrid search on rockset today.
 Now you people do do slightly more advanced things than this by the way there are like you can go beyond that in hybrid search and get into things like by encoding and crossing coding where you really do try to take the the expanded vector space and treat it non-linearly so it's no longer a linear combination of the two halves.
And we've this is this is something we are actively looking at.
 I don't so it's I don't think it's hard to add like it's easy extension onto onto onto the current system but it's more of like a science question like it's more of like if you tell me what to add I'll add it sure that's easy but it's like what do we add like what's the right crossing code I don't know that's a much harder problem that's like much more of a scientific question in terms of like do I need to train an encoder for your particular use case is there such a thing as a good off the shelf one right so that's that's kind of where we're at with this but but in terms of adding that functionality that is like an active you've you've this is the this is the frontier right now for us that's for those people that they're trying to go beyond the kind of bilinear yeah wait yeah another thing yeah bilinear is it's it's amazing maybe you can share some resources as well for for me and the audience to read but also I thought you know when hybrid search sort of topic emerged right in in the vector database world you know bb8 Pinecone milbus what you're like and so on I think one thing that was overlooked and I really wanted to tap into that at some point is to learn the alpha rise because it's not given like how should you come if you go with linear combination you know what should be the alpha for your data yeah it's fun yeah this is what's certain like the search community has been doing things like this for a long time like search people are quite familiar with this idea of I have a semantic search system I have a keyword ranking system I have an alpha and I've learned I learned that alpha and I inject it into my system and then they've even gone farther like search has this whole like wand idea people I don't know if people are familiar so again we have to have all these community like weekend weekend exactly right joe bersham listening to this podcast will probably say yeah I know what you're talking about yeah yeah yeah so it's funny because like the vector community is sort of like I mean it's not it's not rehashing it's not relearning because it's got this new thing this a and n things what's got to like drag a and through the search history of like things these other kinds of things so yes so so learning the ant parameter um this is not a particularly hard thing to do using rock set but it's not a thing we we don't we don't help you like I don't have a button you push to to automatically learn your your alpha like you can send me whatever query you want it can have whatever alpha in it you want you can build whatever system you can query us arbitrarily to generate an alpha however you'd like and and then send me the queries with the alpha you you you you you dreaded and ready but that's that's roughly how that's going to look today for us yeah do you think at all maybe picking a little bit into the future and sort of inspiration do you think at all that the industry you iin one day will end up suggesting these values to their users you know learning from the data and sort of maybe even like you know looking at how things behave you know introduction what do people click although yeah there is a risk of going too much into the application logic which you probably do not want to do but I know I my view is kind of like so once upon a time I had a similar feeling this reminds me of a similar discussion that didn't happen that long ago which was like around feature stores like database people looked at feature stores and we're like what do you need a feature store for like you just use a database store for features and the reality is most feature stores that's what they are they are databases that on top of them put a lot of things to help manage as a first class citizen the lifetime of a feature like orchestration platforms like like techton and he's like orc orc orcust and that orchestration systems that's that's what you're I think it no matter what there'll always be a database in there and something like rockset will be in there and the question of whether or not rockset the company is like a larger piece of software that has rockset the database and some orchestration layers above it to help you do these kinds of things that's a harder question I think that if you ask me to make a prediction about where things are going my guess is that for the foreseeable future hybrid searches king of some kind so very few problems will be purely vector search I that's my guess almost all will be will we greatly benefited by some form of hybridization even if it's just metadata filtering um and then that means that the more advanced search techniques that will slowly migrate over which means things like alpha learning and weak and and all these other kinds of higher level two-stage retrieval type ideas that that come from the search world I do think will come over and more and more influence the vector search world because the vector search ultimately is a form of search so it shouldn't be surprising that most of these same ideas are still still apply yeah for sure I mean there is this extreme example from Mark Cuban the episode on Lex Friedman podcast that they just finished listening to he says that probably in the future all of us will have their own LLAMs trained for whatever reason you know for example you want to do stock trading and so you start you know draining your model maybe on specific subset of stocks or whatever and then it will help you it will augment augment you as they say yeah as an entity yeah I would love I would love for a chat GPT that could like put in making an email sketch me a skeleton email in my voice like the chat GPT voice if I say hey write me an email to say this to somebody it's not my voice right it's a I don't know it's a little too corporate my voice is a little bit more yeah so it'd be cool to have it like learn my voice and be able to you know write me a skeleton that of something that was like sounded like me that would be that would be awesome I'll be I'm there for that yeah what I would like that some model or whatever it is would remind me that I forgot to drink water you know something like that so it learns my habits and it knows that it's bad for my health you know remember to do these remember to stand out remember to walk things like this you know I drank some water that's good everyone drinks water yes yeah please do because it's very healthy you need to drink I guess two liters a day whatever some people do forget this and then they say have you know I have to take pink here or so whatever no you don't just drink water but so what else do you want to share about Rockset you know as an offering as a AI enabler you know maybe do you guys plan to support rag or do you think rag is sort of like client side you know thing as well that people can do you know using your tap things like that no no we we um we actually have a bunch of rag type style use cases on Rockset today and I do I do think Rockset naturally supports rag but it's interesting so like I guess one of the my kind of open questions is pure rag and I'm making up a term here but but but it is actually one of the very few like almost perfect vector use cases in its pure vector search but I'm actually not convinced because even most of the people that we're we know that are doing like rag style things want are also doing some amount of boosting and or metadata filtering to like further augment like hybrid augmented the retrieval that augments the generation um uh and so so for example like hey if the user asks about a certain thing when you search for blurbs to augment the generation boost the more recent ones kind of a kind of a thing like there's this kind of thing that gets injected into these systems um yeah so I'm I'm we you can build this with Rockset today and I'm quite keen on on these kinds of use cases I would say that like like looking forward I'm I am quite interested in this kind of emerging dynamic of like where the real value is from here they're sort of like at least three dimensions things could go one is like better and better an an algorithms that squeeze more performance and more scale and more whatever recall out of out of everything out of every bite of RAM and so forth and so on another direction is incrementability so a lot of these there's a lot of a lot of these like really advanced really strong systems sorry a n n indexes are not updateable easily so the sort of updateability destroys a lot of what you just worked really hard to build or you spend way too much CPU to do it so which is better like which which in on in real life which are the what I rather update twice as fast or twice as painlessly or what I rather get three and a half percent more you know on my precision recall and then the third dimension is how do these things integrate with other indexes right so certain a and n indexes are much better at doing meditative filter at scale than other ones are and so you know if there's more value in that than the 3% I got over here then I so it's not all together clear we are pretty heavily betting on the I shouldn't say we're betting on it like right now we we got the hybrid stuff relatively easily so that's the thing that we're building heavily because all the all the hybridization has been and the the incrementability because that's core like so for us the incrementability is like not you have to have that I can't use an an index that requires like overnight training like that's not a thing that that rock that doesn't work with rocks x we were trying to be real time and then I guess there's like one fourth dimension that could blow all this up which is that somehow the vectors get so good that none of the rest of this matters like maybe there is maybe there is no rag maybe there is no like maybe the vectors just good enough maybe the machine is smart enough that we don't need any of the rest of this we don't need any hybrids I think that's unlikely in the short and medium term but who knows in the in the long that's probably require some kind of singularity yes it is jump right because that means that you do not need foundational models from metal whoever right you could train it from scratch and if you can do it within a couple minutes then why would you bother taking those models right that's very interesting it's my that that's that's why I said there's three and then I threw the fourth one in because I it's it's not impossible but I think it's not likely not anytime exactly I mean it's probably if this is about to happen then probably we would already see the room like you know the signals of that but today still we can see how these giants keep training the models and they keep open sourcing sometimes encodes sometimes for real but yeah it's it's another topic to cover I have a very practical question as well so for example if I do have a model and that model could be from Higging Face for example so it's not mine how do I bring the embeddings to Rockset can I leverage the Rockset's infrastructure to compute the embeddings themselves so this the answer in short is no today and it is on my list super high on my list so there is a customer who came to me tomorrow and was like hey I want to run this model using your infrastructure over my data I'd probably find a way to make that work for that like an existing customer like I would like because that's a feature I want to build I'm like waiting for the excuse to build that the problem for me is it's just really hard to build generally like if it was like call this API or support these exact kind of models it's not so hard but to do it in general without having like a specific customer demand it's a little bit trickier so we can kind of wait until that take a little bit more shape but we have the pieces in place like it's not hard for me to spin up a bunch of machines that run on your data and write to your database I just it's the actual like last mile of wire of like what code do I run how do I secure that code you know like that kind of stuff that's like what's missing from us so today and today you have to give me the embedding you're gonna have to run them and put them in a rock set but this is at the top of my list of sort of features I want to build yeah I mean it just sounds and by the way you know if you take database today probably you could divide them into two groups you know using these dimensions specifically whether or not you can compute embeddings inside and sometimes you do not want that because you want to like fine tune the model and obviously the database wouldn't have access to it unless there is a very easy way to plug it in which I haven't seen by the way probably I'm missing something but I haven't seen it and everyone today has some sort of vector support you know both the traditional databases as well as this new breed of vector databases but yeah that's interesting that's interesting that you guys are looking in that direction what else you know like if if someone wants in the audience wants to try rock set today you know do they need to pay it right away well can they have some free tier to play around oh there's free there's free tiers yeah so you can play around you can play around for free in rock set and uh if anybody is like super interested and they have something interesting and they they they can always email us too um we we will try to find a way to make make make that stuff work as much as possible but yes there is a free tier you can go back around with it yeah um and um it is managed so that the one thing you have to understand about rock set is the managed service right so you're not going to download it and run it or whatever it's not that's not the way it works no and and by the way that's exactly the advantage for businesses right and that's why we do have different business models you know because in the end of the day you're not doing this only for fun you you really need to run money too for the company to grow and and build more things for your users and so that's absolutely legit uh approach not everything needs to be open source you chose it that way but it's great that you have free tier and we can also link it in the show notes sure um what are you looking at you know do you need some you said you have already so many clients in different nations different verticals what else would you benefit from by sharing rock set into a wider community you know through these podcasts all right so there's a lot of ways to answer this question but but this is the vector group right so selfishly I kind of already hinted at this is I'm trying to get a clearer sense by where the value is going to come from in for vectors in the in the short and medium term for people like there's a lot of people out there and we saw this there's a million people trying to oh my god vectors are happening how do I plug this into my business like is there it's can I use this and we've seen a bunch of interesting super novel use cases like things you would not expect and you know there's an insurance company that want to that wants to like scan internal documents you know do they want to do search they want to do like internal search semantic search um and so for me my my most selfish interest here is to really get a clear picture of like which of these like little subdomains is actually really providing like real value like what is really what is really like taking off it's hard it's sometimes it's hard to tell like who's just messing around because everyone's messing around literally everyone is messing around and who's like actually latch on to something that's got some real legs and every time we find a customer that's got like real legs we dig in we're like all in we're like all right how can we help you like let me let's you know again like the the I'm waiting for one of these people to come back and be like can we retrain our embedding so like all right yeah let's go build it right so that's kind of my yeah I I want people to keep messing around with this stuff I I want to figure like all of us messing around it is going to find where it gets traction like where we can get our hooks in and where things start to start to really make progress and then I just want to hear from those people like I want to know what what you need every time we talk to someone it's something new and surprising right um and that's kind of though yeah when the real world intersects with all this like you know uh in my head it's all an indexes and graph theory or whatever but but uh when the real word intersects is always something like simple that you need that would make your life a lot easier and that's the kind of stuff that I'm eager to hear yeah I think uh I could share with you without saying what would be okay uh one uh member of my team said hey we're we're we're using one one um search engine today which also has you know beyond the um sparse indexals that vector search support and so he was saying okay they're using hnsw algorithm but I cannot tweak the amp parameter and I forgot what was the second parameter and look because I cannot do that recall is really below what it needs to be it just doesn't work and then he went online it's an open source database he typed you know the issue on github and they realized oh we missed really important thing so they quickly uh expose the parameters and so he now can tune them right so so yeah the tuning of the index is another this is a good one right so a lot of these systems have like a tier there's like a coarse grain and a fine grain so you have hnsw over IVF or hnsw over or IVF or IVF and then each of these has parameters and so you get these like massive config strings that set that say how these are built um and we we expose this so you can do all this stuff but in real life if you're building like what what number do you even pick like how do you know I don't know that person must have gone through a lot to decide they needed to change that ever because it's not obvious it's not like oh yeah you it's like you look at the data like 16s wrong like the infrastructure to like optimize this system is not trivial and then even if you do optimize it you have to rerun everything you have to rebuild that index right once you kind of trained it so to speak so yeah I think that's a that's a huge area where our our infrastructure is not helpful at the moment yeah but I'm sure you will learn in general excited like Luis look you have so much information that I think we should record another episode as well down the road as you guys progressing on the database and you add all this interesting you know tweaks that and not to the database as well but I'm also super excited about the direction because basically you offer like if you take pure vector databases you know they do not implement SQL support right right they like the purpose of what what the existence is something else right they've been designed to have vectors as the first class citizens and so they they make it super easy to plug in a model or actually have the model you know almost pulled from hugging face or some other model storage model model hub but then when you want to do some facets or whatever you want to call them aggregations right that's not as easy depends on database probably as well but I've seen some I don't want to name them but in any case they know it's it's a weak point and it's probably because they do not want to serve that segment of the market maybe they do it's partially right but it's so hard yeah exactly yeah I mean I think that the really good vector databases who succeed will slowly turn into databases and databases will turn into like these things are merging they're just coming at each other for different directions like like if you're at a vector database if you're building a vector database and you're looking at your metadata filtering support you're like I can't make this more powerful without just reinventing SQL like at some point I'm going to have to just build SQL and so one day they're going to bite the bullet and we'll I mean maybe not SQL but something you know SQL complete if you will right because you just need all that stuff and then pretty soon you get into the problem of like hey my metadata filter is the slow part of this of my thing so now what like oh now I'm doing query optimization like SQL query optimization like now I'm building query optimizers like metadata filter optimizers and you know so we have all that like we brought all that to the party right like I have a I have a cost based optimizer for my SQL query so if your metadata filter does crazy stuff I can like do you know all kinds of SQL magic to like to optimize this query but on the flip side like yeah like so everybody's everybody I think the good systems need all this stuff it so it's just we took a hard problem we took two hard problems and we say congratulations this now one hard problem and it's like okay well okay it's a big hard problem yeah I love how you you model it that this database is and non-data bases sort of will converge eventually even though everyone I think at this point calls themselves a database yeah probably minor exceptions but still you are spot on on whether or not first of all what is a database right and then whether or not you have all these features that that need to be supported and and also like really importantly the world is used to having SQL databases right so like if you sort of I don't have a better analogy but basically if you develop something and you say it can run but cannot walk and you're like okay but sometimes you need to walk right that's amazing before we close I really like to ask this question with some people find it a little awkward to answer but I do feel it's important it's a little bit philosophical and I ask what drives you it used to be why you do this but basically when you wake up you know you are driven to continue but what's inside that spinning you've been through it right you've been doing this for so many years also Facebook at scale but you want to continue to do that so I am the way I think about this is there's there's like a shiny problem at the heart of all this that I love and if you if you let me I will sit there and like I will be happy if like I just come into work every day and like look through the corridors and and fix bugs anything that's crashing then look through the profiles and like optimize code I can just do this this just makes me happy and so like building like reliable scalable systems make me happy so there's like this shiny problem in the middle of all this and it's like the common thread through everything that I could just do and be happy and it it's rewarded and rewarding right and so that like the basis of like it's really easy to like this stuff so then obviously you have to extend upon that like the way that you get driven beyond the shiny thing because you know I could go do that for like Minecraft mods I don't have to do that for databases is like in some larger mission that like you feel connected to so for me the the mission here was a little bit too old the people was actually kind of the original driving force like this is the people I don't even care what we're I don't care what we're doing like let's go do it like us as a group that's gonna be fun but then the whole AI thing I mean look I we can get philosophical you want to get philosophical do it real quick there's like two or three nominations for technologies that will change the 21st century like and I you got to work pretty hard to not put AI at the top of that list maybe there's some other ones you could argue like maybe nuclear fusion is a 21st century revolution maybe gene editing like I don't know you could come up with something but like chances are that AI is gonna be like a defining 21st century technology so you're gonna let me play with my shiny toys in that yeah that's okay I'm out of bed now right I'll get out of bed I'll come I'll come get out of bed and I will let's go let's go build something so that's I think that's my answer to your question amazing and I think you got it on from here to really and and they saw passion knowledge so you did see the movements so I'm really excited to see what you guys got a built thank you so much for joining me today to discuss yes we didn't go to the NM tuning this algo and this is how the algorithm goes but hey I really enjoyed the product level this is what this is on the money some during my company say yeah fantastic thank you so much Luis you know enjoy your day and let's talk soon awesome thank you for having me and yeah happy to chat again all right cheers bye bye