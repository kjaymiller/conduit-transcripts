---
description: '<p><strong>Show notes</strong>:</p><p>1. Pinecone 2.0: <a href="https://www.pinecone.io/learn/pinecon..."
  rel="noopener noreferrer nofollow">https://www.pinecone.io/learn/pinecon...</a>
  It is GA and free: <a href="https://www.pinecone.io/learn/v2-pric..." rel="noopener
  noreferrer nofollow">https://www.pinecone.io/learn/v2-pric...</a></p><p>2. Get your
  “Love Thy Nearest Neighbour” t-shirt :) shoot an email to greg@pinecone.io</p><p>3.
  Billion-Scale Approximate Nearest Neighbour Search Challenge: <a href="https://big-ann-benchmarks.com/index...."
  rel="noopener noreferrer nofollow">https://big-ann-benchmarks.com/index....</a>
  </p><p>4. ANNOY: <a href="https://github.com/spotify/annoy" rel="noopener noreferrer
  nofollow">https://github.com/spotify/annoy</a></p><p>5. FAISS: <a href="https://github.com/facebookresearch/f..."
  rel="noopener noreferrer nofollow">https://github.com/facebookresearch/f...</a>
  </p><p>6. HNSW: <a href="https://github.com/nmslib/hnswlib" rel="noopener noreferrer
  nofollow">https://github.com/nmslib/hnswlib</a> </p><p>7. “How Zero Results Are
  Killing Ecommerce Conversions” <a href="https://lucidworks.com/post/how-zero-..."
  rel="noopener noreferrer nofollow">https://lucidworks.com/post/how-zero-...</a>
  </p><p>8. Try out Pinecone vector DB: <a href="https://app.pinecone.io/" rel="noopener
  noreferrer nofollow">https://app.pinecone.io/</a> </p><p>9. Twitter: <a href="https://twitter.com/Pinecone_io"
  rel="noopener noreferrer nofollow">https://twitter.com/Pinecone_io</a> </p><p>10.
  LinkedIn: <a href="https://www.linkedin.com/company/pine..." rel="noopener noreferrer
  nofollow">https://www.linkedin.com/company/pine...</a> </p><p>11. Greg’s Twitter:
  <a href="https://twitter.com/grigoriy_kogan" rel="noopener noreferrer nofollow">https://twitter.com/grigoriy_kogan</a>
  </p><p>12. Dmitry''s Twitter: <a href="https://twitter.com/DmitryKan" rel="noopener
  noreferrer nofollow">https://twitter.com/DmitryKan</a></p><p>Watch on YouTube: <a
  href="https://www.youtube.com/watch?v=jT3i7NLwJ8w" rel="noopener noreferrer nofollow">https://www.youtube.com/watch?v=jT3i7NLwJ8w</a></p>'
image_url: https://media.rss.com/vector-podcast/20211206_061204_ed150262b3f862f73666d3cce317fc98.jpg
pub_date: Mon, 06 Dec 2021 18:00:04 GMT
title: Greg Kogan - Pinecone - Vector Podcast with Dmitry Kan
url: https://rss.com/podcasts/vector-podcast/334671
---

Hello everyone, so, Dr. Podcast here. Today I have Greg Coggen with the charter of marketing. He works for Pinecon. So today we will dive into Pinecon and maybe Greg will give us some highlights as well. Hi Greg. It's me, Tree. Thanks for having me. Yeah, awesome. Thanks for joining.
So I was thinking maybe you can introduce yourself to our audience because actually I personally was quite impressed that you're so technical and even though you're in charge of marketing, you're like your lingo is so technical.
So technical, so can you do have some technical background? Yeah, I actually have a degree in naval architecture. It's an engineering degree and that was my career for three years. And I did systems engineering and mechanical engineering electrical and so on.
While I was doing that, I also was moonlighting as a web developer and taught myself PHP and things like that and reading about startups and eventually became clear that I should make my day jobs related to startups.
And so I left my engineering career and went to work with startups with marketing and I fell in love with it. That was about nine years ago. And I've been working with for the past eight years. I was consulting and advising technical startups on marketing.
And I loved it because I was able to use my engineering thinking and get along well with technical founders and the like the coding foundation I had allowed me to get a grasp for what it is the products do.
 And last year I joined pineconous the VP of marketing and the engineering background certainly helps we have a technical product technical users and really everyone at the company has a very technical background, even our director of product has a PhD in electrical engineering just to give you a sense.
And I was like, wow, that's impressive. Yeah, that's like you mentioned to the H.P. actually this was one of the first languages I called learned to code and decide Pearl, but yeah, this days.
I'm almost I slowed down before before I told people I learned PHP because I know there's a bit of stigma with it. It was like messy and it's like, you know, not as pristine or.
Yeah, as fancy as something else, but they got the job job done like with with that foundation, a lot of other things made a lot more sense. Yeah, absolutely. Yeah, I mean, I also enjoyed actually like it was one of the first jobs I got was in PHP.
So I built like a forum and every class in the code was starting with oops and I was asking the new engineer doesn't mean all OP like object oriented programming. And he said, no, it just means oops, I'm not technical. So he wasn't technical enough to know what is all P.
But anyway, that was kind of funny. Yeah, that's cool. So basically like you have the technical background. You also know how to explain things.
I think it's very important in our profession at large and sounds like you've been you've been advancing into this topic more and more to the level of becoming, you know, symbol or like BPO marketing actually to be precise, right. Yeah, that's awesome.
So tell me more a bit more about fine code like what what are you guys building and yeah, I know that you've recently had a major upgrade of fine code. Maybe if you wish you could highlight some of the improvements you guys made. Sure.
So we're building a vector database that makes it very easy to deploy to build and deploy the vector search into production applications. This is especially useful for semantic search and recommendation systems.
There are, we saw, I should say the founders saw that there's several ways of doing this to try and emulate the big companies like Facebook, Google, Microsoft and Spotify.
 They all involved a lot of engineering work and a lot of infrastructure work and maintenance to actually make it run in production, whether you're a small startup and have better things to focus on or a big tech company and also have better things to focus on, especially when supporting your search and recommender systems would involve like a big team of engineers.
So we recently announced Pinecone 2.0 and that's that's a major release that gets us closer to helping companies deploy this in production.
So one of the biggest things we've heard from users is that to get this in production, they need to emulate some of their traditional search features they had before, but they're trying to replace. And that was specifically filtering.
They wanted to have some control over the nearest neighbor search results that they were getting through Pinecone.
Another thing was cost since typically vector search nearest neighbor searches are done in memory companies with millions and billions of items, which are the types of companies that benefit most from Pinecone.
We're finding it prohibitively expensive to do vector search not just on Pinecone, but anywhere. And so for them, the barrier to getting into production wasn't lack of engineering teams. It was like just astronomical cost projections.
And so for that, we are releasing hybrid storage, which stores part of the, which basically stores some data on disk and a smaller amount of data in memory, which reduces costs up to 10x, reduces infrastructure costs. And we're passing that along to users.
So it's going to reduce it or manage the infrastructure, but their costs are going to go down as well. And there's some other things like sock to compliance. They're totally new rest API and Python client. And console. And a bunch of other things as well.
So, yeah, and there's even more I can't announce just yet, but we're our engineering team is growing in our development velocities picking up as well. So we're going to have lots of new things to share very soon. Yeah, that's fantastic. Can't wait. And then compress on the on the 2.0 release.
But I just noticed your t-shirt says love the nearest neighbor. Wow. This is so relevant to this discussion. We have lots more of these. Anyone can send me an email. I got Pinecone that I know and I'll get your form to fill out to get one. Oh, thanks. Thanks, Greg. I'll gladly wear it.
So yeah, I mean that that covers the value prop behind your product. So I mean the key element for me is also that as you said, you're reducing cost and you know, like you provide fully managed, you know, solution to better search.
So teams don't have to kind of like run around, figure out some low level things and just get to business. That's great. So the next thing I wanted to ask you like more like on the lines of how you know there are different ways of implementing vector search right and there are different algorithms.
There is an end bench marks that will be big and then benchmarks soon as well. That competition is going for listeners outshare the link as well. But what ways did you kind of consider to implement your tech. I know some parts of it are proprietary.
So maybe you cannot share too much detail, but maybe you can share some things give us a clue how you do things on kind of like algorithmic side and also like kind of like speak to the product that large like, you know, you mentioned, so see two compliance.
So it was very important for your customers, right. So that also is kind of included in the how part.
Yeah, I'll be a little lighter on the technical side because I would rather, I'd rather point you to our docs and point people to our docs and some of the articles and examples we have, then say something that's imprecise from a technical standpoint.
Generally that there are sort of three layers, we see three layers in the inside of vector search solution or vector database. The lowest layer is the near neighbor search algorithm like annoy or hnsw. Then there's an index library, which contains those algorithms and that's like face.
And then there's a shell around that, which we're calling vector database that provides things like live index updates and crowd operations on vectors and filtering and metadata storage and things like that. So for the index, we, Pankoan does use face for exact search.
You can choose if what sort of engine you're running and a proprietary index for approximate search, which is obviously the bulk of use cases for us.
And we thought a lot about performance comparisons, maybe even open sourcing that proprietary index so we can, so we can be included in an end benchmark.
While we were thinking about that, we learned from users that actually like eaking out slightly more slightly lower latencies or slightly higher recall from the index was not really what they were after. That's not where they were stuck.
They were stuck on downstream things like horizontal scaling and adding features to an index. Setting up the infrastructure and managing it. And so since learning that and valid data that we focus much more on those things. And stayed with a proprietary index for the for approximate search.
And sure enough, we find that even people who ask a lot about this after they sign up and start using it, they really, you know, the solve their use case and they don't ask us about it again after that from some other search or recommendation system to vector search.
And you're just looking for an easy way to run it in production. So that's the use case just implement vector search and production.
 Or a lot of people come to us from from like an application side, which is they don't even know they want to use vector search, but they know they want to replace their semantic their keyword search with semantic search or they want to implement image similarity search that will work on fuzzy matches or they want to do anomaly detection.
So and or classification and things like that. It really is it has as many applications as search information retrieval general. A lot of people come to us for vectors, excuse me for semantic search. So they have their embedding models like bird or something like that.
And they got it working in the lab, the data science team got semantic search working using embeddings. Now they're like, okay, engineering team or ML engineering team.
How do we get this in our product? How do we make this? How do we keep latency below 200 milliseconds? How do we add filtering to this to give users control. And the ML engineering team is then goes out and finds like, oh, we can do this with something like bank home.
So those are those are the typical use cases, I would say semantic search, the most common or somebody just coming because they're looking for vector search and regardless of what it's for. Yeah, yeah, from from our from our perspective for Pinecone.
We don't care what your data is like if it's in an embedding format, you can index it and then you search through it. Any it works with any model, any any, you know, initial data and because we have a rest API, you can call it from anywhere.
So you can use it in a notebook, you can use it in the backend application. Yeah, we're seeing a lot of interesting use cases. Yeah, sounds great. Sounds like a lot actually of use case that you mentioned.
I mean, obviously it's search, but then the answer to could also be like data science that they want to run.
If you take five, for instance, you know, metadata science teams, they run like large scale experiments using the library, but like obviously when that's the data science part, that's the exploration part.
But the moment you want to put this out to prod, you'll face a bunch of kind of like low level engineering concerns, like, oh, how do I do this? How do you do that? Reinventing the wheel isn't ever fun.
Well, sometimes it's fun if it's kind of like they'd work, but if you don't have time, you kind of like when I'm both faster than obviously you will want to use an existing solution for that. Yeah, we find that, you know, for the data science team, they don't, it's not their issue.
They need to develop the model and and prove that the method works. It becomes an engineering teams issue or the ML engineering teams issue. And yeah, they're often not exactly lacking things to do.
So, some organizations are all about like focusing on the core product and trying to use managed services wherever possible. Others like to develop things in house and prefer to take open source as much as possible.
So I think it depends on your, you know, how you prioritize your focus and what kind of, you know, what's your engineering culture at the company? Yeah, absolutely.
And sounds like you also address the elements of like, so see to and I believe you also will have GPR covered at some point already covered.
So we say we're GDPR friendly, which means there's no, there's no official certification you can get for being GDPR, you can just be following the regulations and able to make the proper disclosures and able to act on requests for deletion and things like that.
These are the types of things like the security aspects. It's another thing that a data science team might not force to when they're developing like a factor search solutions to some application. But when it goes engineering when you start talking about getting it into production.
And depending on the company, you're, yeah, you start, you know, all these things come up.
Does it meet our security, does it pass our security review? Does it pass our reliability requirements? Who's going to be on call if this thing goes down like all these things come up and we worry about those things so that the users don't have to.
Yeah, that's a big benefit like to the users again to focus on what matters to them. And by the way, I don't want to just so this doesn't come off as like promotional.
Anyone listening to this can treat this as just heads up about what you should think about if you want to get vector search in your production, even if you're using some other solution, like these are things you should plan for. And start thinking about it and making. Leaving time to do.
Yeah, absolutely. You don't want to be caught by surprise in those, those items for sure. Yeah, that's awesome. By the way, I remember that you guys also made a bunch of blog posts on like FICE and LSH. I mean, I really like the way you did it.
You know, it's almost look what looks like a comic book, you know, you know, get, get, get deep with, with these things. And I think you also shared the source code, like some notebooks. Is that right? Is that. Yeah, we, we, we publish. And articles on vector search on face on.
Semantic search different techniques and things like that. A lot of them are done by the very talented. James breaks, I should give him a shout out. We have a new one today about the index composite indexes and index factory in face.
We share code snippets and we have example notebooks for all of them. And yeah, we're very happy to see people like them. Even people who are not familiar with vector search will see it and it peaks their interest because engineers like to see how things work and learn new things.
And that's our goal. It's some of them have almost nothing to do with Pinecone. And we have more people to learn about. Vector search to. Realize that they can use vector search to replace their to improve the current applications and.
If we succeed in that, I think it'll certainly help us, but really everyone in the. In this space. Yeah, I mean, absolutely. Those looks like our jam, you know, people are reading, citing and kind of discussing on Slack and things like that.
And yeah, it sounds like you guys are also kind of willing to share your knowledge with the community, even like beyond kind of share, you know, customer interaction and so on. Right. So that's that's awesome. Yeah. I think we are moving slowly to the third section of our podcast, which is why.
And I think I know it's a little bit more philosophical kind of stance and what you do. And kind of like how you do it. I don't know if you've been reflecting on your journey. I know you said you joined last year. Join bank on last year.
But I guess I'll start off by just asking you what motivates you to be part of vector search development and this community as much. Me personally, I've worked with 40, 40 startups when I was consulting over 40 startups. And when I met, you know, the founder of Pinecone.
And learned about the product and about the space. I saw a familiar pattern, which caught my attention. And the familiar pattern was from 2015. Six years ago now, almost seven when I started working with the time, very small company called Domino Data Lab, which.
It's an ML ops platform at the time, we call that a data science platform. It's used by over 20% or the fortune 500 companies. And the time was a small team and it was a product for data scientists, but like nobody knew exactly what is a data scientist.
Few people called themselves that even if they were doing data science work. A lot of work data science work was done on just people's laptops. And there's no. It was a very young. Area, let's say. Not not quite mature. There's not a tooling for it and so on.
And over time, over a few years, it became, of course, data science became. A core function in many companies, like just like engineering and marketing and customer support. And as that happened, like having the right tooling for that function.
And kind of maturing the capabilities and making sure it's everything data sciences run can run in production securely and reliably and things like that. And so it became more important. Of course, the companies that were. Solving those things were growing with that demand.
And so I wanted to be a part of that journey, that kind of journey again. And again, I saw in Pinecon, I saw product that is pretty early in the space. And I saw a lot of data based concept and. We had to spend a lot of time explaining to people what that means they weren't getting it.
On the user side, you see many, many engineers doing ML engineering work. We don't yet call themselves ML engineers. They're still titled the software engineers. Or they might get data scientists, but they're now working on like production applications.
And also we see that companies are struggling as they as they want to take vector search out of the lab and into production production applications. They're running up against the same challenges like the technology they have. They had available wasn't quite. Built for that.
For huge scale and for like secure and reliable. And so that's the environment. And. Yeah, that's exciting to be. To be in an emerging category like that. And solve a real need and see watch the need. Grow. Yeah. That's my personal, you know, that's what motivates me. And that's why.
So I'm excited to be here. If you want to go even even on a more philosophical level, like. It's really rewarding to me to. Help grow. The kinds of technologies that are powering. Our like software infrastructure, which, which, which, which everything in this world runs on today.
And, you know, you know, the things that are in the back that it's kind of behind the scenes and under the hood that you know most consumers and most people don't know that. Their Facebook feed is powered by similarity search or that their Google search is powered by similar research. But it.
Even without them knowing it affects them tremendously. And. And, you know, I think that's really cool. Yeah, yeah. Some, some so deep.
I mean, your connection to it and in general, like it sounds like you are excited to be at the bleeding edge of stack, right? So kind of like building the next thing. And it's always exciting. Of course, it's also in many ways. Kind of what I don't want to use the word dangerous.
I want to use the word kind of like intense and, you know, like, smoothness, nice and bold type of thing, right? Yeah, yeah, it's. For sure, we don't know how the future will play out. We have our hopes and we're making our bets. And it's exciting to try it. And it that's it motivates us.
Yeah, we're not looking for a safe. For safety here. Yeah, yeah, absolutely. But on that front, like on the future, a little bit touching on the future of this market, even though it's emerging. You know, and it's still unfolding in many ways. And there are so many players already.
But I'm just thinking like, what do you think, kind of what strategic items and missing on the market right now? You know, when you think about not the data science part, I think that data science is developed quite well. We have a lot of competing, you know, algorithms and frameworks.
But like more like on the business side, right? And maybe that's in line with like how users understand the systems. Maybe they don't understand enough. Like, or like what items and missing and maybe you're working on that.
Maybe you're willing to share maybe not, but maybe something along those lines that we can discuss. Yeah, I think you actually. You made the right point, which is. For a certain, for a certain audience.
There's not, I mean, there's still more to be done for a very technical audience that's familiar with the vector search. But they have a lot of tools in front of them and. Right now, whatever extra features they needed, they've, they've hopefully figured out.
It's everyone else who doesn't yet understand this and doesn't quite see. How it applies to their applications. And for whom it's not clear what, you know, how to choose an algorithm, how to tune it. That's, I think the future isn't educating.
Those people and those companies and then bringing this capability to them. And that means just helping them understand what it is. But it also means making the. Products more accessible to them. Like. Taking care of some of the technical details. So that they can just focus on.
Yeah, they're business side of things in their application. And they're really many companies out there that can use. Vector search, but just haven't heard of it. Don't realize it. And. I think the future is in reaching those people. I think even looking. Beyond vector search and just.
Vector embeddings in general, I think it's more, as more and more companies adopt. And I think that's. And I think that's. And I think that's. And I think that's what I think it's about. And L.P. And continue hiring for data scientists.
And now machine learning engineers, which, by the way, are growing at a faster pace than. Data scientists. The number of people with machine learning engineer titles. And they're working on. And they're working on. And they're working on. Check this. Whereas data scientists grew by.
I don't remember exactly, but single digits. So, and obviously not all those mental engineers are working on vector search. But. They will have more and more. Vector embedding data. But they're trying to wrangle. If they want to maintain and. And so, and so, and so, and so. And so, and so. And so.
And the past five years, we, we saw. Introduction of data warehouses and data lakes and really like companies. Realizing that they need to centralize their other data. For their data science teams and analysts and so on. And so, we, we believe the same will.
Companies will need the same thing for vector embeddings. So that they have a. One database for. All their vectorized data that can feed models, that can feed applications, feed. Training and analysis and so on. So. Yeah, that might be a few years out. And we'll see if that. So. And that's.
Those are the kinds of things we're thinking about often, yeah, beyond vector search. How do we get? How do we help people get more use out of there? Yeah, I mean, so I guess it goes along the lines also producing docs and, you know, kind of the computation.
I can't explaining and source code explaining things, right? How can I, you know, keep the road running and kind of doing things. With my, because I don't want to focus on like, you know, actually what I really want is to achieve my goal.
Let's say create a music search service or something like that. Yeah, exactly. Yeah, that's a trap. A lot of people and companies fall into. They love the technology. They love their very proud of building something unique.
As you should be, but you have to remember that people you're serving are just trying to solve some business problem.
Some of them, the early adopters, they'll, they might be very curious about how it works under the hood and they might want to have the ability to pull some levers and turn some knobs.
But the vast majority of people just want to implement machine learning into the applications to create a smarter search function to increase user engagement, things like that. Yeah, yeah. I think that was also one recent article.
I will also link it in the notes explaining that you can apply back to search to solve the zero-heat problem in e-commerce. And that's how you can save, well, actually earn money, right? So save the user experience in that sense. Yeah, so it sounds like more and more use cases are coming up.
And you guys at the forefront of actually hearing what are the use cases, right? And kind of hopefully you'll be sharing some of those with the audience at large and something we'll learn from you guys. Yeah, we're still constantly surprised by what people want to do with the fact of search.
And yeah, we want to make the product available to as many people as possible to see what they come up with. I will say though, we also surprised in a way by how many people want to just do vector search on text data, which seems like such a simple thing to us, maybe.
But it gets back to this point that not everyone is as far along as people in the vector search community. So we've got to bring more people with us and help them see that once they're done with a semantic search use case, there's actually a lot more they can do with it. Yeah. Later on with it.
Yeah, I think it's something that probably needs a bit of kind of discovery for everyone, but also sort of like blogging more about that and sharing more about that.
No, it's not only text, it's actually everything that is inculdable as a vector, right? And it could be dense, it could be sparse, it could be whatever you have there as long as it's a vector.
Then you can send it in index and search and then you need tools to choose the metric function, right? We didn't talk about it, but I know you guys support like three major distances like Euclidean and the product and design.
So I mean, this is like more or less this standard across many data science applications, but I'm sure there is somebody somewhere sitting in the garage and venting in new metric and probably you will want to kind of provide plug-in architecture for that case as well, right?
Yeah, well, we have our own people in this figurative garages working on stuff as well.
So, but also to go back to the previous thing, the vector database that surrounds the engine as well, which might just look like more traditional database features rather than, and simply apply to vector search rather than some breakthrough algorithms or things like that.
Although, yeah, you know, the filtering that we introduced with point cone 2.0 is doing single stage filtering on a vector index was, let's say, let's not say that it took a lot of late nights in the garage. Yeah, yeah, sounds exciting.
It sounds like what your customers will benefit from, right? Almost immediately. Yeah, that's fantastic.
Yeah, I was thinking, like, do you want to add anything more on fine-going or like, for instance, if somebody wants to try it out today, what's the process looks like or should they just shoot you at the email? Yeah, well, if they want to shoot me an email, they're welcome to do that.
If they want to a t-shirt, send me an email, graygadpinecon.io. But actually, we want to make it very easy for people to start and experiment with. And so, you can go to pintcoin.io slash start and create a free account. And for small workloads, it's actually free to use.
You get one pod, which is enough for, definitely enough for experimenting. And if you have a small workload, it's enough for your production use case. That's the easiest and fastest way to sign up. You don't have to talk to anyone.
If you need custom deployment configurations, like certain availability zones or anything else, you can send me an email or you can use a contact form on our site and we'll get you set up. And it's almost as quick. We just have to set up some configurations.
But we want to help you get to production and that means not standing in your way. So that's the best way to go to pintcoin.io slash start. Awesome. And we'll make sure to link that in the notes as well. And you said, what do you mean Kubernetes, right? Kubernetes pod? Yes. Oh, yeah.
I mean, we didn't touch on this episode, but obviously you guys are scaling with Kubernetes. So you're also modern on that side as well. Oh, yeah.
We, you know, I should have mentioned this when you asked about the inner workings, but yeah, we're using Kubernetes to make the whole service horizontally scalable. And of course, the total managed on our side.
So you don't have to know anything about containers or Kubernetes or worry about any of it. But I mean, it's Kafka for streaming to support streaming index updates or batch updates. There are load balancers that are API gateways that are just a bunch of different.
There's a key value store under the hood. If you want to see the architecture, you can cut our docs and learn a bit more about it. But again, you don't have to know anything about it. And that's the point. We made it.
You just make your API calls and get your results and do something with those results. Yeah. Exactly. Fantastic.
And by the way, are you planning to kind of at some point, maybe open source, or actually implement some things for the public to send the data in? Well, do you think it's not a problem at all? Some kind of connector called some kind of gluing code to the Pinecone on the side of integration.
So I guess obviously clients will still look at how do they plug in Pinecone in the right part of their architecture. Yeah, we're thinking a lot about that. We're looking at what are the most common data sources.
What does typically usage look like? And what's the trickiest part for people? And we are thinking about how to make the trickiest part, parts easiest, as many people as possible. So can't say much more than that, but certainly we'll have some common use cases covered soon. Yeah, sure.
I mean, that's so important. I mean, a lot of things like in machine learning, you know, that like 80% goes to data collection and cleaning.
And then in the end, you plug in some model and, ooh, I sold the task, right? And the same kind of goes to the trying databases or, you know, software like, okay, how do I plug this in? And days go by and you are still figuring things out. So I think that's the, that's something to address.
And I guess you guys are doing that, right? Yeah. Yeah, yeah, we definitely. And also a lot of people, you know, we expect people to keep their data warehouse and their document store, you know, because we are, we are your vector database, we're not your blob storage or document storage.
So, a lot of people use PICO and alongside the data warehouse. Or some other database and the easier and more seamless connections are between the two, the easier it is to get factor search into production. So that's what we're thinking about. Yeah, sounds great. Thanks.
And yeah, I think we can wrap up like I really enjoyed talking to you, Greg. I mean, your, your short is the best. I once I get it, I will wear it as well. And I'll be compatible with that through search. So thanks so much for your thoughts. I mean, this was super deep.
And I mean, also you shared some of your personal kind of, you know, attitude and aspirations in this area. It's still emerging, but I mean, it's great to see you guys at the forefront of it. And I hope to hear more.
And just last question, where our listeners can follow you or maybe like Twitter or LinkedIn, where are you kind of publicly available? So for Panko, you on, we publish a lot of things on our website. So you can go to pinecone.io and at the bottom, you can subscribe for email updates.
And you get, you know, all these face articles and things that you heard about, you'll get them in your inbox on Twitter. We're at Panko and underscore IO. On LinkedIn, we also have a big following there. Me personally, I'm at Gregory underscore Kogan. Gregory is gri g o r i y underscore K o g a n.
But a lot of things I post there are Panko and related because that's what I think about a lot these days. And I'll also add that big credit to you for also leading the way with, with doing a podcast like this.
Yeah, it's exciting to see more people learn about this about vector search and start thinking about it and implementing it. And a lot of it is thanks to a evangelist like you who put in the work to do that. Thanks. Glad to hear that. Thanks so much.
And actually, I must say that I'm educating myself equally on this journey. So hopefully as part of this journey, you know, the listeners and the readers can can educate as well. So in the end, you know, value increases by doing these things. So that's that's what drives me here.
So thanks so much for joining the show. Yeah, I hope we can record another one at some time down the road. Yeah, that would be awesome. Awesome. Thanks, Greg. Bye bye.