---
description: '<p>00:00 Intro</p><p>00:30 Greets for Doug</p><p>01:46 Apache Solr and
  stuff</p><p>03:08 Hello LTR project</p><p>04:42 Secret sauce of Doug''s continuous
  blogging</p><p>08:50 SearchArray</p><p>13:22 Running complex ML experiments</p><p>17:29
  Efficient search orgs</p><p>22:58 Writing a book on search and AI</p><p></p><p>Show
  notes:</p><p>- Doug''s talk on Learning To Rank at Reddit delivered at the Berlin
  Buzzwords 2024 conference: <a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=gUtF1gyHsSM">https://www.youtube.com/watch?v=gUtF1gyHsSM</a></p><p>-
  Hello LTR: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/o19s/hello-ltr">https://github.com/o19s/hello-ltr</a></p><p>-
  Lexical search for pandas with SearchArray: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://github.com/softwaredoug/searcharray">https://github.com/softwaredoug/searcharray</a></p><p>-
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://softwaredoug.com/">https://softwaredoug.com/</a></p><p>-
  What AI Engineers Should Know about Search: <a target="_blank" rel="noopener noreferrer
  nofollow" href="https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search">https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search</a></p><p>-
  AI Powered Search: <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.manning.com/books/ai-powered-search">https://www.manning.com/books/ai-powered-search</a></p><p>-
  Quepid: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/o19s/quepid">https://github.com/o19s/quepid</a></p><p>-
  Branching out in your ML / search experiments: <a target="_blank" rel="noopener
  noreferrer nofollow" href="https://dvc.org/doc/use-cases">https://dvc.org/doc/use-cases</a></p><p>-
  Doug on Twitter: <a target="_blank" rel="noopener noreferrer nofollow" href="https://x.com/softwaredoug">https://x.com/softwaredoug</a></p><p>-
  Doug on LinkedIn: <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.linkedin.com/in/softwaredoug/">https://www.linkedin.com/in/softwaredoug/</a></p>'
image_url: https://media.rss.com/vector-podcast/ep_cover_20240718_110721_6a250f534a47b913cfe9ab7513e63b01.png
pub_date: Thu, 18 Jul 2024 11:10:42 GMT
title: Berlin Buzzwords 2024 - Doug Turnbull - Learning in Public
url: https://rss.com/podcasts/vector-podcast/1572886
---

few years. Cool. Yeah. Hello, how are you? Hi, Doug. It's great meeting you at Berlin Boswords. Yeah, I can see you. Yeah, great to see you. It's your second time on the podcast and, yeah, excited to be back. Yeah. Awesome.
I think it's like two years or only one that I can take so, but how have you been? I've been great. I've just been doing traditional learning to rank over at Reddit. And it's been a lot of fun. A lot of it's just meet and say to stuff. Yeah.
The stuff that I think is really important, like your training data with search and you're getting your features right and that sort of thing. Not actually too much vector search lately. So kind of paving a path in the ranking model space.
And I still think that's really important for if you're building a rag app or if you're building a lot of these things, a lot of people are sort of discovering this through the vector route. They're like realizing there's a small other side of information retrieval. Yeah, that's important.
And that's that's really exciting to me because I think a lot of new ideas that suffer coming into this space. Yeah, amazing talk as well. I'm sure we'll link it. What was it's published? The one you just gave.
And you also reminded me of time as I told you of the time when I was working on solar starting at version 1.5. Yeah. It was eaching to ask you which version are you running? But then I was like, what will it matter to me? Well, it's still well, it's we were running solar 7 until recently.
And one of the things you didn't talk about in the talk was having performance problems with solar 7. Yeah. And moving to solar 9 fixed it. So it helped with a lot of stability and performance problems.
And that's just one of those things that a lot of these projects, machine like not just like learning to rank is like a lot of machine learning projects.
You what I find especially with learning to rank, you're often like building out and scaling up infrastructure for a certain problem at the same time you're doing machine learning. Yeah. So it's you're finding these problems. Yeah.
And you will spend weeks or months like, why is it slow? It's unexpectedly slow. Yeah. What's behind it is and then you realize, oh, solar 9 doesn't have this problem and we'll resolve it. Yeah. And we were already upgrading.
So like, okay, we can put this we don't have to stress out about this performance problem. But that's why it takes a year, two years sometimes for these projects. Yeah. Yeah. Start to show. Hey, oh. Yeah.
I also would like to say thank you for your project that I think you started back at OSC open source connections. Yeah. Hello LTR. Yeah. Which I think it's still out there and it's out. That's very project. Yeah.
It really allowed me to quickly, you know, jump on the on the train and start moving because I was actually alone on the team. I did do search before, but it wasn't related to ML at all, right? It was like feature engineering, but on a different side of things. And yeah. So thanks for that, really.
Yeah. I like, I think it's really important. And one thing I think it's the career advice that's helped me is to learn in public. So a lot of hello LTR came up when I was learning how to do LTR. And I had to get some examples and like try different things out.
And then as I made mistakes, those mistakes became lessons for the LTR training that came out of fellow LTR, also called fellow LTR that open source connection it does. So it's I really encourage people like the best way, the best teachers are often people actively learning. Yeah.
Because you will encounter the mistakes that the experts forgot about. Yeah. I couldn't tell you about how to learn how a loop worked from Python because I've done that too wrong.
But the person who would have the empathy to teach that really well to someone learning that's grad should would be probably my son if he was learning Python for style.
So I really encourage like be out there speaking, blogging, acting because you'll have insight to how to teach your project that expert won't. Yeah. Yeah.
That's that's another side of your professional life that amazes me is that how do you find time to block so it's like and that those are really deep things sometimes you go into detail with its code or where you offer some thought model like do you sleep at home.
I think I just have a high tolerance for making mistakes in public. Oh, and also I think a lot of it has to do with having a history degree. Oh, really? I didn't know that. Yeah. I think so history and computer science.
So when you get when you do history, it's a lot of writing, writing, writing, reading, writing. And then a lot of it's also when you get to this your senior level history, it's like not just writing an essay, but can you write your argument in a single page? Yeah.
And so that's which is funny because you think when you're a student, you think I'm going to make the margins big and I'm going to make the text big so I can take up more space. Yeah. Well, when you start writing a lot, you tend to write, you tend to get really verbose. Yeah.
Then you have to learn to just make your arguments like exactly. Yes. Yes. And then you're shorter. And yeah. So yeah, it also now when I'm doing the product management role, I have I do not have a history degree like you, but I have to write some things in a concise way.
Sometimes they say you have to remove half of the page because you're not fitting the page limit. I make that mistake all the time. How many one pages are exactly? Like 10 pages.
And another thing is like never talk about hypothetical future because you don't even know yourself what it will happen or not. Right? Yeah.
When they talk either talk about things that you're absolutely certain have happened or you're certain that they have planned already, right? That's how we do the product management. Yeah. So it teaches that that side of things.
But I guess what I do is out and I then go to blogging and and and I use you as a great example there. You go and unleash yourself and blogging and you write what you want, right? But you still need to what you want said that you became more successful blogger at the moment.
You actually started modeling that specific person you're writing to not an abstract audience and not yourself because you're not writing.
So is this how you still perceive it? Well, I definitely write to myself six months from now, but I also write the audience I imagine is like a close group of friends. So I almost think about blogging as sometimes and this is easy.
It's easy for people often to imagine sitting down and writing a long email or Slack message. And what if you just turn that into a blog post? Yeah.
And to me, that's that's an inspiration for this so many times you get excited about something and you want to send a message to your friends and share it. We'll turn that enthusiasm and that message into a blog post. And then that those are the best blog posts.
And I also think it's really important to remember it's blogging. It's like it's a step above writing us a media post. It's very informal. Don't take it too seriously. You will make a mistake. Exactly. You will it's and it's a do it for fun. Yeah.
But yeah, I do it a lot because I want I think I I there's a meme of like someone starting out on something. Yeah. Someone being very senior and then or someone being like mid-career and then someone super senior in their career.
And often the like starting out this meme starting out super senior are the same. Yeah. And it's like my version of that is doing when you start out you code and do stuff to impress your friends like in high school or whatever.
And then you get like all worried about like having some big impact and like impressing the whole world. And then when you get super senior again, you're just like I just want to like do full stuff to impress my friends. Yeah.
And which actually turns out also to be stuff that the whole world cares about because usually your friends are are like doing cool stuff themselves like you know vector searcher or doing cool AI stuff. Yeah. So it turns out that the rest of the world finds that interest in too.
But I think that's a really important thing to have an authentic voice. Yeah. So it's also part of the building up your profile. Yeah. Yeah. So I think like like Steve Jobs I think I think said like computer is a bicycle for the mind, right? And so blogging is also in a way bicycle for the mind.
You have to rework your self-help, right? It's also the programming that you do on the site like searcher rate. So tell me more about what was the motivation. Why did you start working? So I think I like to go against the grain a little bit.
So I actually had worked on different versions of vector search for a long time before this for craze. And different hacks and things to make vector search work in a in a different in the solar elastic search world. So everyone's in vector search.
And I decided that in part because I wanted to get do a little bit more native programming, get facts. I used to do that. I used to be a C programmer. Yeah. I found that vector search is very welcoming to machine learning engineer data science community.
But the traditional lexical search engines like solar and elastic search, they're very weird. Yeah. They're very like you have to know this weird query DSL. You have to understand these things. Organization.
So I wanted to take that and take that lexical world and bring it into a data science or data high data sort of environment that is very comfortable to machine learning people on data science. Yeah. So I built search array.
And what search array the reason I built that or what that does is it's basically a lexical extension to pandas. So if I have text, I can make a pandas column that's just like tokenized text. And then I can ask it to score against a keyword and get a BM25 score.
And the main reason I built this was so in a co-lad notebook or something. I can quickly further set ideas while having to stand up solar elastic search or think about Docker container and all this stuff. And I said I could see like, okay, I want to tokenize things a certain way.
I want to score change the BM25 scoring to be a certain way. Yeah. And which is you think about like 90% of what you do in a lexical search engine is tweaking the tokenization Yes. Finging the scoring, trying to index something new and search against that like, oh, I have any recognition field now.
No. Well, it's and the other thing is what the other thing you do a lot in lexical search engines is I want to boost by recency and I want to do these other things. And a lot of these things can just be done with a really fast like I take this column numerical date column in pandas. Yeah.
I take a numpy array that's a BM25 score. I multiply them together. Yeah. I have a score that's a recency weighted yeah. What does that look like in terms of my offline metrics? Yeah. Interesting. Without having to go off to like, you have to figure out a last search and like that, a satiric stuff.
So basically it allows you to try out some ideas really quickly, right? But then there will be some kind of offset compared with the reality because tokenizers and solar probably work differently. Yeah. But that would be different.
Probably will be closing up, right? So it's also if you nailed the signal that like you explained today in your presentation, you know, what about the number of comments or what about, you know, the recent C&C and so on. Yeah. Although this be on the go and I'll like try that really quickly. Yeah.
Yeah. And a lot of times it's it's a big effort to index some new data into the search engine. Yeah. Right. Yeah. Like you have to go is the upstream system fast enough to handle those load and to stay up to date.
And really to justify a project, you might start with a prototype and say, okay, I just pull for a small small chest set of data. I pulled in some data. It seems like there's some signal here. Yeah. Let's plan a project around it. Yeah.
And so this is to me and actually I'll my sees the conference after we'll invest for it. So I'll talk about planning. Yeah.
But to me, a lot of this like how do we build better prototypes to build plans and have ideas and have conversations between engineers, data scientists and product managers is really one of the inspirations for search array.
Uh, good times to do this before I'd be like, okay, I have to stand up some examples. Yeah. Just some yeah. Yeah. Yeah. Yeah. Spend time on that. Yeah. How am I going to index to allocate a cluster and whatnot? Yeah. Exactly. Yeah. Oh, that's amazing.
I actually this reminded me when I was working on the learning to run. And this was the last project I did in my 10 year tenure at AlphaSense. I said, Hey, can I have this really expensive laptop? So it would be like 30 gig around one terabyte drive. I thought I need so much.
Do you have a base for some reason? And it was SSD. And and and I got it approved. It was like, oh my god. So many. And I spent like a year working on it and was kind of like bloated version of search array because I could do everything on the laptop.
This connected right? The only problem I remember was wrecking my experiment tree because I would like, let's do right, would verfricate or like kind of branch out. That's right.
And then like, okay, should they go back now? Because retreat because looks looks like I went down the the rabbit hole and it doesn't give at any value. So I need to go back to that state when it was that bigger, you know, and deciduous or whatever, right? So and start off from there.
That sounds a lot of like what some of the functionality included. The sort of like search relevance tuning tool to you, you PID. Because I remember when I was building that many years ago, it was very much like every time you submit like you tweak the query and it saves that as a try.
Yeah, another time. You can't fork off stuff, but you can go back and be like, oh, this thing didn't work out.
I'm going to go back and yeah, it's it is funny how yeah, I have the same feeling and even in a notebook environment, I don't have that because notebooks you tweak a little bit, you forget what happened, you like, why did I thought my MDCG was good and I got bad.
What did I do wrong? You wish that you were like somehow the notebook was like versioning itself as you were going. Yeah, exactly. But somehow the whole environment was version, but yeah, that doesn't exist. I wish that kind of thing existed. Yeah, it was.
There was a tool we were using, but then it was acquired by some company. It was called spell.run. So it basically was like an integrated Python notebook environment that runs a cluster and they were heading in the direction. I was giving a lot of feedback to them.
Like, hey, can you actually build an infrastructure which will allow me to also maintain my branched out, you know, experiment space? And I think they got acquired probably stored before they could do this and probably they continue doing this.
I don't know, but there is another project called DVC, I think, which allows you to basically maintain your experiments as deep hashes, right? So you basically, you can, you can, you can get hash your code along with your data and then you upload your data.
Let's say to some cloud, I don't know, drive some drive abstract one. And then you have your code associated with that. So you can basically restore you or someone else that can restore the experiment.
I think if that, if that was frictionless, right? Or even the matter of it existing, right? Because I had to literally write something down on a piece of paper to remember what I need to do. You know, sometimes I would go crazy.
At Shopify, so we had a, we had a, our testing, search testing infrastructure, the notebooks. So everything was in a monorepo. So you could stand up, elastic search, and you could have, we had a, this is a Rails environment.
There's a, all the relevance logic was in a Ruby library that we, Rails monolith would load and so call in the network, call, elastic search and do whatever, pre and post processing.
But when we stood up the test environment, we would say, we wanted to load this, we wanted to load the right configs, but we would basically put the, come to the, commit task of the repo that we, that it was supposed to be, and it would load the config and it would be amazing.
But yeah, it's, it's getting reproducible environments. Yeah, and experiments is a challenge.
This is where, I mean, at some point, basically, like your experiment rate will be, you know, trumped by how quickly you can deploy this or how quickly you can like, shuffle things, right? So yeah, I think so.
This is where infrastructure comes as a big topic and in your talk, I think you spent a good, yeah. Yeah, yeah.
I think it's like partnership, right? So we had a, there has to be like a big team in my career too, as partnerships, like partnerships with PM, partnerships with data, yeah, partnerships with infrastructure.
You really have to have one cohesive team and one of the anti-patterns is when they're so separate, yes, that it creates, I agree. You have to throw a requirement over the fence, yeah, and then a month later, maybe you get something back, but it's not quite what you want.
You really have to act like one team, yeah, and search is so multi-functional.
Yeah, yeah, and I've seen it at Shopify, the challenge was like infrastructure was a different or, and so we would throw things back and forth over the fence and be not quite right, we want to, and we'd have to figure out the right way to partner at Reddit.
It's a bit more, we have a bit more of a challenge that data is a different group.
 So we're sort of throwing things over the fence, getting things back, yeah, and so we have to like actively work to make sure those partnerships are like, are healthy, yeah, but it's a big challenge and I think like organizationally, there are reasons that companies separate things out that are beyond search.
 So it's not like there's an easy solution, but it's definitely when you get to search with these data products, like not just search for recommendations and feed and things, these become having cross-functional partnerships and not only cross-functional partnerships, but individuals who can work beyond their domain and get them for like very multiple hats, yeah, is really important.
 Yeah, I think you're absolutely spot on, you know, and back in the previous company, declined of silo AI and now I don't know, I feel sort of like the same, but one thing I found after like breaking some arrows in the beginning, I found that if you can, try to find the permutual benefits that they will be driven as well as you, you don't know what's the outcome going to be because experiments are always like that, right?
Yeah, but the fact that we are having an experiment cross-department, this is amazing, then you go to all these meetings with executives and you say you praise them and they probably some way praise you like your team and and that's how you get the the right thing, right?
But things happen, things happen, you just need to be persistent I guess.
Yeah, things happen all the time and like, you know, organizational changes are like the weather.
 You never know, you know, there's going to be a reward for yeah, someone comes in with a new perspective or whatever and that's another career lesson is not to get too caught up like emotionally, you know, or something happens, you know, it's not a lot of times it's just that so many things are already in control that are just like out in the politics or whatever organization changes are going to be.
I like this sort of mental model called circles of interest. Yeah, in the inner one it's like your direct control, it's probably you, your time and whatever, where you work, specific tasks.
Yeah, another one is like inference, so you cannot control but you can influence people or things or whatever it is and then the last one is that even if it bothers you but you cannot do anything, so it's a more control area.
Yeah, so you have to accept it or move on or do something but don't get stuck on that, so it's have it's have and things of course keep moving between the it's just like dynamic system but still good to be aware of.
Yeah, I'm sure with your way of blogging and book writing and yeah, all these projects you actually have that way of kind of, okay, if this is stuck, I'm going to, you know, uh, read stress by blogging, even though writing is, oh, you're right.
I do think like the other career advice is like you get hyper focused on one thing, you lose the forest for the trees. Yes, and take a step back. Maybe there's a project that you really like that got canceled or something. Yes.
 We'll take a step back and and uh, first of all, a year you don't remember, but there are so many interesting things to work on and I think people forget that that there's there's so many interesting things to work on and I, you know, I had a brief break between Shopify and Reddit and I, I realized what life would be like when I was retired because I would get up and it's not like I just laid around and nothing.
I was just like, oh, what could I play with? What could I do? Oh, there's a problem. There's that interest in probably. Yeah, yeah. And uh, that really opens your eyes to that. Uh, there's always, there's sort of like more fish in the sea, so to speak of like problems to work on or cool stuff.
So yeah, there was even a study that when people retire because they get money or like a lottery or some other way, they go enjoy life, but they also age much quicker. Yeah. And sometimes they, unfortunately, die quicker because they have nothing to sort of strive for. Yeah. Yeah.
So that's, that's really really cool advice. And if this was not enough, all this cute bit, search array, blogging, of course, work and other things, podcasting now. Uh, you also write a book. Tell me a bit more about that before we close. Oh, yeah. Yeah.
It's, it's, it's, you just joked on the stage that the idea came to 2018. Yeah. So, Trey, Trey initiated the book. So, Trey's the primary author. And Trey came to me and I think 2018 said, hey, I want to let you know I'm writing a search book. I think I'll be done.
And I want to really, you know, for work and my wife and everything and family, I want to be done in six months. So I'm going to stress everyone out. And here we are. It's, you know, there was a pandemic. There was a lot of stuff that happened. But, uh, it's 2024.
And, uh, and it's funny because the nature, what you might refer to as AI in 2018, of course, is now is LLM's and these things. But, uh, it's, it's really exciting. I think like a lot of the things in the book are timeless. Yeah. Techniques. Awesome.
Um, we initially focused the book on solar, but we're taking, we took a step back when we said, let's make this applicable to many search engines. Yeah. And there are examples being worked on for many platforms. It's the ecosystem is so huge now.
There's all kinds of vector databases that are, uh, even adding electrical serve. And then there's, of course, solar, elastic search, there's open search, there's a bespa. Yeah. Um, in this more and more traditional space. And, um, so like I worked primarily on the learning terrain content.
And so, um, a lot of the things about how you get training data, train a model or, uh, how you evaluate these things, how you expose users to search results that are maybe a bit novel. Like you do a little bit of exploration to build out your training data.
All of these things are, um, regardless of where search goes or where rag goes for whatever. And it's, it's, they're still very relevant.
And it feels like in a way, a lot of how users are interacting with, with the world and with products is through, um, some kind of search or some kind of retrieval system. Yeah.
Even if it's a recommendation system or a fee system, that's becoming feeling more like search, where it's like real time. And I'm getting the stuff updated in real time. And of course, rag is searched. So I think search is still there, right? Getting over the world and all of which. Yeah, exactly.
Yeah. I've realized some crowd is now gathering, uh, to have lunch and we will, we will have lunch soon as well. Uh, it's always a pleasure to talk to you. And finally, in person, I think we've never met, but I think if you've been to, uh, you see the revolution in 2003, seeing around in islands.
Oh, I've been there as well. Is that the one in San Diego or no, no, in Dublin, in Dublin, yeah. Have you been there? Yes. I wasn't. Yeah. Yeah. Uh, then I, I didn't dare to, uh, you know, to go high. But, you know, that's when I, we introduced Kupit, actually. I think. Yeah. Oh, it's amazing.
The workter. Yeah. That's a still relevant project. That's, you know, it's running 2013 JavaScript. Say to the art. Yeah. And I've been consistently deploying it to an every company. I agree. So in TomTom, we just released a new algorithm to production. Thanks to Kupit in two weeks. A lot of weeks.
It was, it was on the bookshelf, of course, quite some time because the team couldn't figure out how to test the quality. And I said, okay, let's just do labeling, right? And let's use Q. Yeah. Just simple labels and, and we're, we're, uh, more than 10% increase in precision with new algorithm.
And they said, as a product manager, I approved the release. Let's go. That's also, that's great. Thanks for creating the tool. Great. Sure. Happy to. I love making tools. Yeah. Thanks for your time, Doug. Enjoy the conference. Thank you. Stay in Berlin. Yes. Thank you. Awesome. Thanks.