---
description: <p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=0s">00:00</a>
  Intro</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=114s">01:54</a>
  Reflection on the past year in AI</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=488s">08:08</a>
  Reader LLM (and RAG)</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=756s">12:36</a> Does it
  need fine-tuning to a domain?</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=860s">14:20</a>
  How LLMs can lie</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=1052s">17:32</a>
  What if data isn't perfect</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=1281s">21:21</a> SWIRL's
  secret sauce with Reader LLM</p><p><a target="_blank" rel="noopener noreferrer nofollow"
  href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=1435s">23:55</a> Feedback
  loop</p><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=1574s">26:14</a>
  Some surprising client perspective</p><p><a target="_blank" rel="noopener noreferrer
  nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=1877s">31:17</a>
  How Gen AI can change communication interfaces</p><p><a target="_blank" rel="noopener
  noreferrer nofollow" href="https://www.youtube.com/watch?v=5fafSkzKpfw&amp;t=2051s">34:11</a>
  Call-out to the Community</p>
image_url: https://media.rss.com/vector-podcast/ep_cover_20240515_120505_ab56f7a7d7ebadfb6bbd3486a4d2e7ad.png
pub_date: Wed, 15 May 2024 12:57:55 GMT
title: Sid Probstein, part II - Bring AI to company data with SWIRL
url: https://rss.com/podcasts/vector-podcast/1480271
---

Hello there, this is Vector Podcast Season 3 and I'm super excited to be talking to companies with thousands and thousands of users and thousands and thousands of systems that it's been a time of inspiration and a little bit of continued nervousness about what it all means.
Last March on the 15th actually was the 14th was Pi Day and that was the one year anniversary of GPT-4. What I've learned is that those large enterprises were again looked at GPT-4 and said this is going to change our business.
This can really help everybody be an efficient expert and just slice through the current problems of silo data and inconsistent systems.
But at the same time there were a lot of fear about well are we exposing invaluable internal data to AI's that are then going to be trained on it? Is this going to be exposed? Lost? There have been many many lawsuits.
 So ultimately the large enterprises did what they always do which is engage with it on their own terms and many of them purchased download installed AI, generative AI's and LLMs in their private clouds and we're working with one large company that did that and trained it with a bunch of what they called safe data.
 So annual reports and you employ a handbook and it's very interesting to talk to but it can't really help a business person or somebody trying to answer a question in the supply chain group or in the R&D group or in HR because this doesn't have access to those systems and in those places you've ever worked there.
You know when you onboard the first thing they do is your manager does right is they open a bunch of tickets so that you could have access to systems. That's hard enough.
So the reason that there's been so in a way so little progress right lots of installs of AI but not that much real I'd love to hear from you some of the use cases out there.
 People are still trying to say we're still trying to get the data to the AI so that it can provide the benefit and what ultimately what what happened is this they've got the AI's installed the first generation of AI architecture solution architectures is what I will refer to as a vendor driven put the data in architecture literally every product out there I don't want to name them but they all say the first step is put the data in again like for some people for many applications from POVs for testing it out that's great and I've who hasn't done it with a few PDFs right and got some interesting results but you can't just take a copy of a departmental database and hand it over to a centralized corporate database for training like that their rules in place to prevent that even more difficult is the idea that you would send it outside your perimeter into someone else's cloud right at another big manufacturing firm they have a 24 month waiting list to onboard a new SaaS product right they'd like we have to put our security team on it so I believe it's a very interesting time and ultimately what happened is Swirl thought differently about the problem as you said we thought about it from the search technology perspective why would we move all of the data instead move the essentially take only the data that you didn't give it to the AI at that moment and what Swirl does first to do that is we create a single pane of glass well the next thing I'll mention is Swirl is software we are a software company and our software is typically deployed in the customers private cloud there's we are happy to do hosting for POVs and for various applications but for larger enterprise we don't expect that to be the case once you deploy Swirl it integrates with your single sign on systems such as Microsoft or Octa or ping federate others you can have cast whatever in there once it's configured you send a question prompt or query search query to Swirl it brokers that query to all the sources that it's authorized to do so and it does so on behalf of that user so it's not only is it safe compliance search using existing infrastructure but it's personal the data the user or caller gets back is based on what that user can see so I use it all the time and it's my email my outlook my calendar my LinkedIn whatever right it's my view we actually love the idea that we should present the data to the user so you get that single pane of glass and actually you can decide what to do with it you can say I don't want this source or whatever you can make adjustments but ultimately we then execute rag we have our own excellent high quality rag better than many in particular it seeks highly relevant passages from all of the documents we can fetch the documents and authenticate on the fly as to do that um bind those to a prompt we have our own prompt engineering you can uh override it and then do the rag against a huge list of AI providers actually we support more than 20 today including most of the ones we see out there open AI open AI and azure bedrock and prop at google mistral uh co here etc and in all cases no code should be required you configure an existing connector more than likely you're putting in just endpoint information and authentication tokens and then swirl again does that broker and creates that pane of glass and execute rag you can also use swirl just for the R if you have your own rag right you can get the result list and do your fetching or you can hook after you've got the swirl has the fetched results and you can operate that on just the full documents the key to this i love that you asked is the reader lllm we have been really heads down working on the reader llm um i've actually been asking people if they have heard the term before and many haven't uh i don't know what what your take is on on reader llm these days oh yeah i'm still catching up really i mean the way i see it and i'm still kind of plowing through rag itself right so you you said what is my take on on how easy it is to on board to the say i models and so on i i have a sense that people are aware of this because it's so easy to access through chat chat gpt and similar tools but then when it comes to deploying these things i don't think that it's as easy right so because you you have to go through a list of models you need to figure out which one to pick and and and and hence you need to be a data scientist right at that point or ml practitioner or whatever um and it's not and it's like the web is exploding with so many cheap advice you know use these use that but then as you go through that process you realize that none of those models work and so you need to do something okay the risk rag but setting up rag means that you need to bring in an effective database that you haven't seen before and things like this right so it's yeah so i love that so just speaking of misinformation right i think you're absolutely right there's so much um confusing stuff out there you do not need a vector database to rag you never did it's it's a it's a vendor thing that i totally understand they're charging per gigabyte or whatever so they say you have to have it to rag uh there's an excellent study by zet hub and actually simpson garf ankles and advisor to swore all you may have heard that name incredible tech writer um he recently wrote a study a survey or a summary i should say of the zet hub study the zet hub study shows that you do not need to vectorize your data to get high quality results instead you just increase the number of results you get from a so-called naive nonvector search engine or database and re-rank using vectors that's exactly what swore all this we vectorize the result set snippets we vectorize the full text of the documents we vectorize the query the prompt whatever it is right and our reader llem is responsible for a complex similarity re-ranking you can actually plug the a your choice of embeddings into our reader llem embeddings are actually just a feature one one of the many things that llem's do so you can change that but the reader llem here's really the core of it it's the middle layers of the generative AI llem without the you know um text generation and text interpretation part that's not there at all instead you use it to determine the similarity right cosine or they're many different algorithms but ultimately you're taking some algorithm like that and you're using embeddings plus the reader llem's own knowledge to say how similar is the query or prompt or part of it to the response that i got or find the most relevant passage in a document because you're absolutely right there are tools like langshane out there as in one example which give you lots of interesting tooling right but it's still on you the developer i actually had chat tpt generate me a pipeline just as a demo and the biggest problem is it generated a function that i have to fill in which is called select documents that's really hard and ultimately like you're basically just providing the pipeline to move the data once again but it's the reader llem in swirl is all about re-ranking and finding the best passages so that you are not sending a hundred pdf of which one paragraph is relevant you are sending the paragraph that way you can put a lot more data and you can also not blow out your token limits right assuming you have such a thing if you're on prem but that's what that's the reader lm i'll say this their reader lm are the unsung heroes of especially search but also a rag when you're looking at i would say bing or or chat gpt and you ask it a question and it goes and fetches documents from the web it's almost certainly using a reader llm to determine which pages are best and to be fair being in google have incredible knowledge of that already so it's not like it's that hard but then they're almost certainly reading the most relevant passages right they're not just passing the whole web page in so reader lm's are a thing they're definitely becoming more and more prevalent and they provide a critical non hallucinating step to help find the best results so the user doesn't have to and that's very interesting and and how let's say if you plug into a companies network right so and they focus on something i don't know healthcare banking what have you would you need to fine tune reader lm in any way no i actually don't recommend it i think there's a lot of evidence that fine tuning because of its fundamentally lossy process right is somewhat responsible for hallucinations there's been quite a bit written about this and i think that ultimately the the winning combination today is that you use a very well trained capable model that is generalist and you provide it with the data that you need to provide it with at the moment you need to for example swirls prompt engineering does a few things one we force it to only consider the rag data and not add its own model thoughts right you can interpret but don't say don't create facts that aren't presented to you second force it to disambiguate this is one of the worst errors in prompt engineering is not is just letting it go right up on past equating right two entities with the same name as if they're the same thing so our default engineering says listen if you see and into two entities with the same name don't you know essentially call that out and don't just gloss over it the last one is especially when you're talking about multiple sources of data and enterprise data the user must be able to verify or nobody wants to make a career limiting move because they took chat gpt's and answer and said here it is here it is right put it up on the on the investor site not a good idea but swirl also forces the AI to quote the sources that you use to cite them and of course you also have access to the underlying search results right so you can verify that yes you have a million dollars in insurance coverage and it covers x y and z that's key yeah that's amazing I was just you reminded me of when you said about hallucinations I was just listening to one interview is not related to AI world attack world it's political sciences and so she was asked the scientists she was asked you know are you using chat gpt at work and she said yes sometimes I do sometimes I use it as a co-writer so you know I I draft some things quickly and and I still see that chat gpt is very crude you know in the way it approaches you know I can do it better but sometimes I'm just you know lazy or tired okay let it do it but then the thing that struck her was that it actually hallucinates she was asking give me you know top five books in political science you know in specific country and chat gpt was very confident and and said they said the five books and the authors and when she googled them they don't exist and and then she said they don't exist and then chat gpt responded okay here is only one book that you should read and that didn't exist either so she was genuinely like baffled and she said okay you might say something with less confidence but why lie why do you lie she doesn't know what is hallucinations but she's she looks at it as a user and it's very disconcerting so believe it or not when I first started using gpt 4 I got a hallucination that I thought was so real I wrote to the publisher and said why is this article no longer online and the publisher wrote back and said there is no such article but it could have been it was authored by someone they said gpt 4 said it was authored by another author who had posted on that site the url looked correct and the content looked I mean the snippet it gave me looked absolutely real but again when they build these models a few you know 10 20 gigabyte model right of gpt 4 or 35 or whatever it is petabytes and petabytes of data went into that so by definition it's lossy but the way the lllm the generative part works is it must provide a response so you know how that is when you can't quite remember the name of something and it's essentially doing the same thing so it knows it I saw an artifact that looked like that but I don't have the artifact anymore so it generates something that is the consensus version of what it would have been had it existed and that's why I don't believe in fine tuning so much think if you have a high capable model with some reasoning and the ability to interpret text and follow instructions you provide it with your internal data and that is the beauty of reg because here's the thing the reason it's so good at things why does why does chat gpt 4 sound like a smart person on you know reddit or or some or Facebook or something like that right and that's because that's where it was trained from you're internal and of course on something like reddit or whatever they have a new the same conversation 10 million times right I mean how many discussions of whatever twin peaks or battle star galactica you know are there there are a lot of them and so it learns the core of these things right and can answer those questions but if you feed at your internal data like it's probably not so repetitive it's probably much more conflicting than not and so you that's why you produce more problems it's much better give it the one thing that's really relevant and let it reason yeah that sounds go and slight live right it's something that can be updated throughout the lifecycle of your company or department whatever but there is one challenge they want to offer to you and came to me just today as I was thinking and preparing for this episode data is not gold you know sometimes it is gold because everyone talks about it la la la but like it also is very complex machinery and it can have the stakes of it of its own you know misattribution misclassification and human error what have you how how would you say reader lllm or swirl gonna tackle this issue or is it just gonna transparently sort of like garbage in garbage out type of response it's a great question speaking of hallucinations in AI right we all have probably worked with somebody at one time another who made a mistake right or whatever didn't understand the problem enough and that stuff gets into teams and slack and you know documents are wrong like it's incredible you're right it's incredibly messy in the enterprise happy as anybody not worked at a firm where they had you know 500 versions of the same PowerPoint that is just evolved right so absolutely well these are things that ultimately are gonna have to be continued to be work on but here's one point number one if you leave the system in the system data in the system of record you're much less likely to introduce new problems especially like security problems and you leave it in the system of record than any domain modeling lexicon's ontologies text items you get the benefit of those if someone cared about that source they might very well have done some of that right so if you pull it all out and put it in a vector database like what happened to all of that knowledge so I would argue that the systems of record that are valuable have things in place to deal with that number two the reader lm does a couple things that to help this one it's aware of certain commonly problematic formats email is the worst reply forward and signature content very very problematic we have a solution for public data too so that you can get article content without getting as an example at navigation advertisements cloked data stuff like that right so because very often public data is relevant right to to large enterprise like they want to see policy changes regulatory changes online catalog changes right that that's all relevant stuff then there's the similarity problem right so one of the another thing the reader lm does it can do semantic analysis to determine which is the latest version of the same document that's a one of the great lm's are amazing at that much better at old school like multi windows setups where you're trying to take out like a signature of the document and say well this could it's very similar but lm does it much better right and you can quickly say now this is the latest version of that spreadsheet or you can let the user decide it's another thing who doesn't love shopping I love being able to look at my shopping cart full of swirl results and say you know this one I know isn't really relevant these are the five I've risen or maybe this is the source or these are the sources that I want my data from today that's another way of allowing the user to bring their expertise and experience and knowledge and say no no no colibre not thoughts but snowflake not oracle whatever and I'm not picking on anybody we all can say they're all present they all have value the question is which one has the answer for me today well until the until they can write the query with the context that answers that you know I think the key is to keep the user in the loop make sure that there are citations and ultimately that in a year the systems will be smarter and many of these problems will be solved after all almost all the naive search engines right that were BM25 or whatever pretty much all have vector upgrades now only questions can you wait long enough to vectorize at high-dimensional space a few million documents exactly yeah sometimes when I use chat GPT I don't use it that often by the way for some reason maybe it says something about me maybe I should you learn to do it but sometimes as you said you know it just generates something it seems a little average you know it's a code snippet or something like that you try it it doesn't work at that point when I when I get frustrated a little bit I'm like can you show me the source maybe a link to stack over flow so I can go and drill in for myself you know I don't have to sort of keep pounding and you and I'm asking you know okay that didn't work this didn't work because I can do the same thing just staring at the stack over flow page right and maybe they have been already some updates and someone said no that doesn't work in all some times they see you see the selected answer but then there is another one which everyone says that works not the selected one so that's just funny yeah that's amazing so reader lulm like just to sort of bring it back to the ground especially for those who are sort of no vice like myself I still consider myself no vice you know have you sort of taken a reader lulm off the shelf you sort of implemented someone's paper or took it or did you did you have to train it how did you go about it we built it largely from it's it's been an evolving thing but they're they're definitely our other reader lulm's out there the key is to preserve the structure right and the pieces the structure that allows you to do similarity we implemented our own similarity and other algos we also do things like named entity recognition and sentiment analysis well those are great at that stuff it can do scoring for machine learning purposes right so we have a nice intention detection system now that will essentially based on the responses that you get to tell you which sources are most relevant right up front right based on the responses and also optionally ratings right if you want to bring bring that into the system passage detection is totally in response our reader lulm's passage detection is totally in response to the problem you described right which is the data is messy and we don't necessarily want to ship a you know 500 100 page PDFs that have essentially the same data so there we it finds the most relevant passage super quickly and truncates the document down to a window around it um those those are the things and it we've really implemented it ourselves it's our it's our own it's our own creation oh that's fantastic so that's your secret source as well I mean that's that's something to be proud of and also I want to sort of close up that the sort of you know description that he gave or maybe looking at the future does world have some way of feedback do you plan to if not do you plan to implement do you think it's reasonable to have a feedback loop you know like in chat jpd you can say thumbs up thumbs down you cannot say much you know you can say this was the answer I don't know if that's gonna go into the loop but whatever because it gives me the the joy of sort of completing it um yeah oh yes so when swirl AI connect is deployed in the enterprise where starters you get to connect the data and get rag and your choice of AI's and by the way it's again configuration for the AI you put your keys in right check pick the model and you can rag against it you can also choose the role you want to use different generative AI in rights you can use it for query writing you can use it for direct answer you can use it for rag if it has embeddings you can use that to power the the reader L so just just to be clear there it's uh it's a bit more flexible yeah i was asking about feedback right so like do you plan do you have it and if not do you plan to think it's reasonable to have it right absolutely so after you deploy AI connect as mentioned you get those abilities then we have an analytics package which will give you insight as to which sources are providing the most relevant responses and rating and putting all of that into dashboards understanding who are the number one users who write the best prompts who get which sources produce the best results which prompts you absolutely is all part of the the offering and ultimately it's part of what we tailor right for the for the deployment and again that can be on premises but AI connect is the key because it's collecting that data on again always in the customers private cloud like we don't see it we're not sass but that data is absolutely turnable into gold a variety of different gold things and so you can hopefully figure out which AI works best for which groups you can figure out which sources right are providing the best input for rag etc yeah that's fantastic i love that you do have feedback uh i think it's definitely gold it could could also be super messy and noisy and stuff but it's better than absence of it um yeah that's amazing maybe like in the past year so you've been deploying this with clients obviously you don't have to mention the names but was there something that surprised you how clients you know sort of perceived uh swirl yeah i i would say that um people have not really been looking for search if i'm the AI the explosion of AI and the excitement around AI kind of crowded everything out round everything out so that's why i think so many of these copy in architectures were got so much momentum but and i by the way i think people are doing incredible stuff with that so it's not like those aren't perfectly legitimate i mean every database ever starts that way right you put the data in and you get inside of it's just that there's a bit more to the story right there's a whole other world of well there's a lot of these and i just moved them to cloud and i can't necessarily do it but people weren't thinking search i'm not sure what they believed the answer would be but uh there were some excellent posts there was one on linkedin by um vector ventures i think or um i should probably get the name right but in any event they published an excellent piece about how search is probably the answer to making AI work in a lot of these cases and uh you know they also point out there's not that many people who have come at it from the search perspective so that was a bit surprising to me because the large enterprise has always loved search always uh because that that's how knowledge workers and people get stuff done right it's yes you have business intelligence and dashboards and reporting and we like those things but so much of the qualitative why did things happen explain it to me how do i solve this that's been something that search did a good job of um ultimately it's a technology right and the marriage of search with llm that seems to be the unlocker if you will in the enterprise and that's that was surprising to me right i i thought that there would be much more of a search first approach and i think everybody had to get through the understanding of what it means to adopt AI and how the first generation works and now i think people are recognizing real time real time architecture using systems of record with re-ranking and and then just stay keeping up right with the incredible innovation in it in let's call it generative AI right that's that's the interesting thing but again i come back to what i said at the beginning there's going to be a many many incredible generative AI's they're going to do different things that we haven't even seen i don't think the most extraordinary ones they'll be from the big science publishers they're going to build incredible life sciences gai i'm sure people like bloomberg ft you're going to build incredible um financial ones and that's great but all of those still need your data to operate on your environment and give you answers that are meaningful and that problem that problem is the problem that's world solves so just to understand what were they expecting was it like chat interface or you said they didn't expect search no they thought they would ask the question oh yeah so they thought like a chat right yeah that everybody wants kind of a conversational interface you know another thing i learned actually you're really reminded me people are not so interested in the idea that there is an AI place that you go i think another very logical step is business folks knowledge workers they would like to use the channels they use today so rather than i have to have a new place to go why can't i talk to it on teens or in slack or on my whatsapp why can't i text it um if i need to get a visual i could always go to a screen right and then i could have it show me the underlying data show me the graph show me the chart but for the the the future is not applications that are destinations the future is an ongoing that i log with the AI that understands your business your world has access to your data and becomes your uh trusted advisor and agent i don't want to use the word co-pilot because i think that's a little it's much more your confidant it's much more your agent it's going to tell you stuff like hey that question you asked last month there's a very different answer this month that's a pretty interesting thing or it's going to let you explore so you know tell me about our customer service ratings well which region right disambiguation which was previously something you know that you would do like through facets in search right that's kind of thing that should become more dialogue oriented but those things that's going to take some time because in order to know how to disambiguate you still have to know what data is relevant right so so that's been surprising but i think we're going to see a wave of search driven innovation and i'm excited about it i think the more people shift away from innovating in a repository to innovating across repositories we'll see you know another another layer of innovation and and even more productivity left right for for the people to use it oh yeah that's fantastic the way i put it and i'm glad to hear this because there's the search professional you know now a product manager i love the fact that the powerhouse of you know the future of AI still continues to be searched right at the core and i think search it also says that search isn't solved and maybe this is another iteration that we will approach it but it's like because search is also perception right it's also how you express yourself how you perceive what you see maybe the interfaces will change right so sometimes i do want to you know that that product that google had google glass sometimes i want to have glass on me to take a picture or you know not to be as distracted by going and fetching my phone or something right because today i still have to do that it's not as immersive experience and also i've noticed working with engineers now when i flipped on this side of you know the process i'm a product manager so i keep thinking about things and they keep coding and sometimes i've noticed that they don't even go back on slack from like a couple hours when i when i ask something because they don't want to be uh you know distracted from their ideas so maybe there could be a way for me or agent or whoever to sort of sneak into their idea ask a question talk to them right that would be fantastic maybe it sounds also a little crazy like you you still want to have privacy and sort of you know uh flow but at the same time there is reality of your job right you you do need to go back to your email to your slack or whatever you're using teams and get distracted and then you forget what is it that you've been onto when you come back to your your motive execution absolutely you know in a way applications are distracting i think there was a really good study recently that showed the danger of interrupting engineers right because of the context switch um it's definitely the same for business people they're just like everybody else right context matters and it can be hard to switch um i think that's the real promise of a i look at chat gpt you go to chat gpt they're gonna have search soon web search you can ask it questions you don't have to go to google and being in five other places right to get it and that is the real possibility that you would choose the way you want to interact with it and that thing in theory that single point that single pane of glass or single conversational agent right that could potentially be in front of many many sources of data and that i think that's what what people realize it's hard to say how does what does it really look like in five years if a i really continues along the path of sun the answer is it's the end of applications yeah yeah exactly and going back to being immersive and sort of feeling that i'm myself and i am in control and not like vice versa when today i don't feel like i'm in control applications update by themselves i phone restarts i have no idea what's in that update i will not be able to ever understand what they do but they do it so sometimes i feel like whatever i have bought belongs to someone else but probably this will change and i think this should change as we wrap up i was thinking is there something you want to sort of call out to the community and say you know by now swirl obviously has progressed you guys open source i love it you you have a bunch of contributors probably that you trust and you work with but is there anything that you would you know benefit from calling out the the larger community i think i'm very happy to see the the folks shift and focus towards search i think the thing i'd call out is to say you know there are many different user communities that want to consume AI they will benefit from it and i think the key is not to go too far on the hype cycle right and because honestly another thing i learned is not everybody is into the details of how AI works right and like fine tuning is an example it's a very deep discussion at some level i'm no expert right i can tell a lot about it but i think there's people who have done much more on it than i will ever do but the end of the day the user that's way way way far from the user's head right what they're what they're trying to understand and the people are making decisions about bringing these things in are is it safe how can i trust it how do i get it to provide a benefit so i think the honest thing is rather than focusing on like we've got a few more tokens than somebody else talk about use cases focus on the user i think that's where that's what's world did from the beginning because if you're in search like there is nothing but the user right the user's intent is everything right and from like we can go back to lots of lots of great writing about that from biaires e8s to tinkle and and all points in between but the user's intent's important and that's the thing to focus on what are they trying to accomplish and build great use cases that ultimately you know allow people to focus on the things they'd rather focus on instead of you know the minutia and the time of collecting all these different data points yeah that's i think that's i think what you do as a as a tech industry responding to the user demand for AI my two cents oh that's amazing i don't don't try to outsmart the users and uh make things that you produce explainable and so they probably will adopt them weaker uh that's amazing i also see uh super uh maybe provocative really nice one from your side where you say that you outshine google i will link it in the show notes and maybe we'll discuss it at some point as well something about ranking looks it i really enjoyed chatting to you today i'm sure there will be someone you know in the community reaching out and maybe trying out swirl to be honest it's itching for me to try it out right when i when i said it when i mentioned in my company and someone said i would love to have that single keyword box so that i can search slack and conference and email and everything um that's amazing that's fantastic and also amazing that you guys do it uh in the open so everyone can try it um all the best to you good luck in in whatever you're building in your uh next big things thanks to me tree thank you so much it was great to talk to you and uh when you want to ready to try a swirl you got the open source version enjoy our slack and we'll be happy to help absolutely thank you very much enjoy your day youtube